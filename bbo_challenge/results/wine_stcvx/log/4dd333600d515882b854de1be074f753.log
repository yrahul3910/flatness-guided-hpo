running: {'--uuid': '4dd333600d515882b854de1be074f753', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231015_053414', '--opt': 'strongcvx', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d wine -o strongcvx -u 4dd333600d515882b854de1be074f753 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231015_053414
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam wine acc 45 1
with data root: None
suggestion time taken 15.532106 iter 0 next_points [{'alpha': 4.891662013933443e-05, 'batch_size': 138, 'beta_1': 0.9036810333399725, 'beta_2': 0.9997812237126854, 'epsilon': 4.737181392042039e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.05931772244725085, 'tol': 0.00042429509346534683, 'validation_fraction': 0.23986589472563458}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.130258 value -0.527586 suggestion {'alpha': 4.891662013933443e-05, 'batch_size': 138, 'beta_1': 0.9036810333399725, 'beta_2': 0.9997812237126854, 'epsilon': 4.737181392042039e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.05931772244725085, 'tol': 0.00042429509346534683, 'validation_fraction': 0.23986589472563458}
observation time 0.000003, current best -0.527586 at iter 0
suggestion time taken 15.353226 iter 1 next_points [{'alpha': 0.008763419685226065, 'batch_size': 141, 'beta_1': 0.9823826703247138, 'beta_2': 0.9996709465004034, 'epsilon': 2.4008388324022296e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.004753762298065126, 'tol': 0.00014463716795040446, 'validation_fraction': 0.388387766980181}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.147112 value -0.541379 suggestion {'alpha': 0.008763419685226065, 'batch_size': 141, 'beta_1': 0.9823826703247138, 'beta_2': 0.9996709465004034, 'epsilon': 2.4008388324022296e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.004753762298065126, 'tol': 0.00014463716795040446, 'validation_fraction': 0.388387766980181}
observation time 0.000003, current best -0.541379 at iter 1
suggestion time taken 15.349586 iter 2 next_points [{'alpha': 1.6247540333578727, 'batch_size': 28, 'beta_1': 0.9132029714782298, 'beta_2': 0.9991503292923928, 'epsilon': 2.59381983417018e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.02890773665842058, 'tol': 0.00023846867569204323, 'validation_fraction': 0.7789229882854777}]
function_evaluation time 0.204449 value -0.675369 suggestion {'alpha': 1.6247540333578727, 'batch_size': 28, 'beta_1': 0.9132029714782298, 'beta_2': 0.9991503292923928, 'epsilon': 2.59381983417018e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.02890773665842058, 'tol': 0.00023846867569204323, 'validation_fraction': 0.7789229882854777}
observation time 0.000004, current best -0.675369 at iter 2
suggestion time taken 16.515557 iter 3 next_points [{'alpha': 0.010480470313540312, 'batch_size': 33, 'beta_1': 0.9898575578808047, 'beta_2': 0.986057254947415, 'epsilon': 1.7754677244093483e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 7.55210550925007e-05, 'tol': 0.0006068027865203496, 'validation_fraction': 0.4908704167713355}]
function_evaluation time 0.116963 value -0.395567 suggestion {'alpha': 0.010480470313540312, 'batch_size': 33, 'beta_1': 0.9898575578808047, 'beta_2': 0.986057254947415, 'epsilon': 1.7754677244093483e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 7.55210550925007e-05, 'tol': 0.0006068027865203496, 'validation_fraction': 0.4908704167713355}
observation time 0.000003, current best -0.675369 at iter 3
suggestion time taken 15.792568 iter 4 next_points [{'alpha': 0.5564625017831627, 'batch_size': 20, 'beta_1': 0.9791673431066578, 'beta_2': 0.9072359469596307, 'epsilon': 9.519948708676918e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 8.367163593996127e-05, 'tol': 2.970860195424407e-05, 'validation_fraction': 0.6890783369240632}]
function_evaluation time 0.144956 value -0.337685 suggestion {'alpha': 0.5564625017831627, 'batch_size': 20, 'beta_1': 0.9791673431066578, 'beta_2': 0.9072359469596307, 'epsilon': 9.519948708676918e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 8.367163593996127e-05, 'tol': 2.970860195424407e-05, 'validation_fraction': 0.6890783369240632}
observation time 0.000003, current best -0.675369 at iter 4
suggestion time taken 15.444164 iter 5 next_points [{'alpha': 0.014829832437075918, 'batch_size': 129, 'beta_1': 0.8775143937365292, 'beta_2': 0.9489601718229744, 'epsilon': 7.102455510896282e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0061360853529910135, 'tol': 6.771352290649574e-05, 'validation_fraction': 0.25265086298823713}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.187743 value -0.698522 suggestion {'alpha': 0.014829832437075918, 'batch_size': 129, 'beta_1': 0.8775143937365292, 'beta_2': 0.9489601718229744, 'epsilon': 7.102455510896282e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0061360853529910135, 'tol': 6.771352290649574e-05, 'validation_fraction': 0.25265086298823713}
observation time 0.000004, current best -0.698522 at iter 5
suggestion time taken 16.016367 iter 6 next_points [{'alpha': 0.6094662636007778, 'batch_size': 69, 'beta_1': 0.6567774531251327, 'beta_2': 0.9999963534569549, 'epsilon': 2.74491666992633e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0002447118553579217, 'tol': 0.00046890972008343715, 'validation_fraction': 0.801906904385681}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.075727 value -0.331281 suggestion {'alpha': 0.6094662636007778, 'batch_size': 69, 'beta_1': 0.6567774531251327, 'beta_2': 0.9999963534569549, 'epsilon': 2.74491666992633e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0002447118553579217, 'tol': 0.00046890972008343715, 'validation_fraction': 0.801906904385681}
observation time 0.000003, current best -0.698522 at iter 6
suggestion time taken 15.565114 iter 7 next_points [{'alpha': 2.3056963311034877e-05, 'batch_size': 34, 'beta_1': 0.8351721465660858, 'beta_2': 0.9999911587808764, 'epsilon': 7.947349397913851e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0017095183777776446, 'tol': 0.01884903597873026, 'validation_fraction': 0.10671258279462045}]
function_evaluation time 0.269637 value -0.705911 suggestion {'alpha': 2.3056963311034877e-05, 'batch_size': 34, 'beta_1': 0.8351721465660858, 'beta_2': 0.9999911587808764, 'epsilon': 7.947349397913851e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0017095183777776446, 'tol': 0.01884903597873026, 'validation_fraction': 0.10671258279462045}
observation time 0.000004, current best -0.705911 at iter 7
suggestion time taken 16.050866 iter 8 next_points [{'alpha': 2.3501495651245688e-05, 'batch_size': 140, 'beta_1': 0.8670521179859776, 'beta_2': 0.9998917824592255, 'epsilon': 9.048623728164475e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0001332652339860195, 'tol': 2.8720721926246508e-05, 'validation_fraction': 0.11283437897918375}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.090947 value -0.331281 suggestion {'alpha': 2.3501495651245688e-05, 'batch_size': 140, 'beta_1': 0.8670521179859776, 'beta_2': 0.9998917824592255, 'epsilon': 9.048623728164475e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0001332652339860195, 'tol': 2.8720721926246508e-05, 'validation_fraction': 0.11283437897918375}
observation time 0.000003, current best -0.705911 at iter 8
suggestion time taken 15.923247 iter 9 next_points [{'alpha': 2.5747816231288128e-05, 'batch_size': 14, 'beta_1': 0.8548642281603771, 'beta_2': 0.9984821884635363, 'epsilon': 4.645208245180668e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 2.5903899155903375e-05, 'tol': 0.00013355420343174232, 'validation_fraction': 0.7905832534018662}]
function_evaluation time 0.101044 value -0.266502 suggestion {'alpha': 2.5747816231288128e-05, 'batch_size': 14, 'beta_1': 0.8548642281603771, 'beta_2': 0.9984821884635363, 'epsilon': 4.645208245180668e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 2.5903899155903375e-05, 'tol': 0.00013355420343174232, 'validation_fraction': 0.7905832534018662}
observation time 0.000003, current best -0.705911 at iter 9
suggestion time taken 15.629949 iter 10 next_points [{'alpha': 0.09839520904981437, 'batch_size': 27, 'beta_1': 0.9178142666085511, 'beta_2': 0.9999923535730779, 'epsilon': 2.9077340014174314e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 5.764837004586558e-05, 'tol': 0.0807769768237171, 'validation_fraction': 0.48963841297760236}]
function_evaluation time 0.129520 value -0.416010 suggestion {'alpha': 0.09839520904981437, 'batch_size': 27, 'beta_1': 0.9178142666085511, 'beta_2': 0.9999923535730779, 'epsilon': 2.9077340014174314e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 5.764837004586558e-05, 'tol': 0.0807769768237171, 'validation_fraction': 0.48963841297760236}
observation time 0.000003, current best -0.705911 at iter 10
suggestion time taken 16.185345 iter 11 next_points [{'alpha': 2.168658601068427e-05, 'batch_size': 139, 'beta_1': 0.9553929004678883, 'beta_2': 0.998643170898365, 'epsilon': 3.6939530195825614e-08, 'hidden_layer_sizes': 121, 'learning_rate_init': 2.1686707492349155e-05, 'tol': 0.019149220125213515, 'validation_fraction': 0.34686224712841124}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.085271 value -0.316995 suggestion {'alpha': 2.168658601068427e-05, 'batch_size': 139, 'beta_1': 0.9553929004678883, 'beta_2': 0.998643170898365, 'epsilon': 3.6939530195825614e-08, 'hidden_layer_sizes': 121, 'learning_rate_init': 2.1686707492349155e-05, 'tol': 0.019149220125213515, 'validation_fraction': 0.34686224712841124}
observation time 0.000003, current best -0.705911 at iter 11
suggestion time taken 15.595718 iter 12 next_points [{'alpha': 0.3108379312870751, 'batch_size': 69, 'beta_1': 0.9674063495173998, 'beta_2': 0.9948603269846433, 'epsilon': 1.1065320868618711e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 3.121190548191993e-05, 'tol': 0.07962297596102388, 'validation_fraction': 0.16725080517525348}]
function_evaluation time 0.117636 value -0.345074 suggestion {'alpha': 0.3108379312870751, 'batch_size': 69, 'beta_1': 0.9674063495173998, 'beta_2': 0.9948603269846433, 'epsilon': 1.1065320868618711e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 3.121190548191993e-05, 'tol': 0.07962297596102388, 'validation_fraction': 0.16725080517525348}
observation time 0.000003, current best -0.705911 at iter 12
suggestion time taken 16.064993 iter 13 next_points [{'alpha': 0.0016306316494634702, 'batch_size': 47, 'beta_1': 0.7683122617134812, 'beta_2': 0.9991178334153642, 'epsilon': 1.1417474059480582e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 2.88753919913189e-05, 'tol': 0.036722922286664454, 'validation_fraction': 0.376229396422633}]
function_evaluation time 0.118426 value -0.359360 suggestion {'alpha': 0.0016306316494634702, 'batch_size': 47, 'beta_1': 0.7683122617134812, 'beta_2': 0.9991178334153642, 'epsilon': 1.1417474059480582e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 2.88753919913189e-05, 'tol': 0.036722922286664454, 'validation_fraction': 0.376229396422633}
observation time 0.000003, current best -0.705911 at iter 13
suggestion time taken 15.410386 iter 14 next_points [{'alpha': 0.00017520527479060214, 'batch_size': 47, 'beta_1': 0.9671193361064141, 'beta_2': 0.9357030267526091, 'epsilon': 4.974101641347379e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0805268444573984, 'tol': 0.032901633774301844, 'validation_fraction': 0.25804399726558136}]
function_evaluation time 0.163855 value -0.620443 suggestion {'alpha': 0.00017520527479060214, 'batch_size': 47, 'beta_1': 0.9671193361064141, 'beta_2': 0.9357030267526091, 'epsilon': 4.974101641347379e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0805268444573984, 'tol': 0.032901633774301844, 'validation_fraction': 0.25804399726558136}
observation time 0.000003, current best -0.705911 at iter 14
suggestion time taken 16.173120 iter 15 next_points [{'alpha': 0.10552518037516768, 'batch_size': 46, 'beta_1': 0.8580520229671785, 'beta_2': 0.9999973596000487, 'epsilon': 5.339924023830955e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 6.517146842992231e-05, 'tol': 0.00010133380254111355, 'validation_fraction': 0.5451920204898555}]
function_evaluation time 0.166724 value -0.359852 suggestion {'alpha': 0.10552518037516768, 'batch_size': 46, 'beta_1': 0.8580520229671785, 'beta_2': 0.9999973596000487, 'epsilon': 5.339924023830955e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 6.517146842992231e-05, 'tol': 0.00010133380254111355, 'validation_fraction': 0.5451920204898555}
observation time 0.000003, current best -0.705911 at iter 15
suggestion time taken 15.543170 iter 16 next_points [{'alpha': 0.012596758875637498, 'batch_size': 140, 'beta_1': 0.9370758086811523, 'beta_2': 0.9991275432219519, 'epsilon': 1.6112932933889804e-09, 'hidden_layer_sizes': 113, 'learning_rate_init': 1.0305412232268676e-05, 'tol': 0.018639583051141044, 'validation_fraction': 0.5738565753786834}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.076056 value -0.330788 suggestion {'alpha': 0.012596758875637498, 'batch_size': 140, 'beta_1': 0.9370758086811523, 'beta_2': 0.9991275432219519, 'epsilon': 1.6112932933889804e-09, 'hidden_layer_sizes': 113, 'learning_rate_init': 1.0305412232268676e-05, 'tol': 0.018639583051141044, 'validation_fraction': 0.5738565753786834}
observation time 0.000003, current best -0.705911 at iter 16
suggestion time taken 16.181074 iter 17 next_points [{'alpha': 0.4897927020045618, 'batch_size': 10, 'beta_1': 0.7468854415308589, 'beta_2': 0.9918769697105116, 'epsilon': 7.053051656861191e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 1.6399380595452347e-05, 'tol': 0.0003000957470632072, 'validation_fraction': 0.21232683887291845}]
function_evaluation time 0.311752 value -0.323892 suggestion {'alpha': 0.4897927020045618, 'batch_size': 10, 'beta_1': 0.7468854415308589, 'beta_2': 0.9918769697105116, 'epsilon': 7.053051656861191e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 1.6399380595452347e-05, 'tol': 0.0003000957470632072, 'validation_fraction': 0.21232683887291845}
observation time 0.000003, current best -0.705911 at iter 17
suggestion time taken 16.572251 iter 18 next_points [{'alpha': 0.1399712486919243, 'batch_size': 65, 'beta_1': 0.6509616819881091, 'beta_2': 0.9994046451557224, 'epsilon': 5.059715247452432e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.02811768492350831, 'tol': 0.04413750549209209, 'validation_fraction': 0.6059328400925871}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.151578 value -0.620443 suggestion {'alpha': 0.1399712486919243, 'batch_size': 65, 'beta_1': 0.6509616819881091, 'beta_2': 0.9994046451557224, 'epsilon': 5.059715247452432e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.02811768492350831, 'tol': 0.04413750549209209, 'validation_fraction': 0.6059328400925871}
observation time 0.000004, current best -0.705911 at iter 18
suggestion time taken 16.110842 iter 19 next_points [{'alpha': 0.0006072368897178552, 'batch_size': 46, 'beta_1': 0.9639261884124011, 'beta_2': 0.9999970831918238, 'epsilon': 2.6211999481495742e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00594713135230303, 'tol': 0.0042624955285633795, 'validation_fraction': 0.8972325287026326}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.088574 value -0.485961 suggestion {'alpha': 0.0006072368897178552, 'batch_size': 46, 'beta_1': 0.9639261884124011, 'beta_2': 0.9999970831918238, 'epsilon': 2.6211999481495742e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00594713135230303, 'tol': 0.0042624955285633795, 'validation_fraction': 0.8972325287026326}
observation time 0.000004, current best -0.705911 at iter 19
suggestion time taken 16.049155 iter 20 next_points [{'alpha': 0.00014124343506970597, 'batch_size': 10, 'beta_1': 0.8334047625240446, 'beta_2': 0.9999885565720498, 'epsilon': 1.6762689405485127e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.010088974680128095, 'tol': 0.09736386679603695, 'validation_fraction': 0.7650242209948227}]
function_evaluation time 0.175158 value -0.802217 suggestion {'alpha': 0.00014124343506970597, 'batch_size': 10, 'beta_1': 0.8334047625240446, 'beta_2': 0.9999885565720498, 'epsilon': 1.6762689405485127e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.010088974680128095, 'tol': 0.09736386679603695, 'validation_fraction': 0.7650242209948227}
observation time 0.000003, current best -0.802217 at iter 20
suggestion time taken 15.764846 iter 21 next_points [{'alpha': 0.002315645972962067, 'batch_size': 20, 'beta_1': 0.9869210277324624, 'beta_2': 0.916248090264582, 'epsilon': 4.514463476317773e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.06652439958180047, 'tol': 0.03768875430290456, 'validation_fraction': 0.8444681794781693}]
function_evaluation time 0.135299 value -0.592118 suggestion {'alpha': 0.002315645972962067, 'batch_size': 20, 'beta_1': 0.9869210277324624, 'beta_2': 0.916248090264582, 'epsilon': 4.514463476317773e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.06652439958180047, 'tol': 0.03768875430290456, 'validation_fraction': 0.8444681794781693}
observation time 0.000003, current best -0.802217 at iter 21
suggestion time taken 16.312771 iter 22 next_points [{'alpha': 7.485739919111737e-05, 'batch_size': 47, 'beta_1': 0.5328820804143525, 'beta_2': 0.9999968288806115, 'epsilon': 1.745215795052195e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 2.883945276302739e-05, 'tol': 0.00047102518151351973, 'validation_fraction': 0.5807050998647453}]
function_evaluation time 0.086857 value -0.338424 suggestion {'alpha': 7.485739919111737e-05, 'batch_size': 47, 'beta_1': 0.5328820804143525, 'beta_2': 0.9999968288806115, 'epsilon': 1.745215795052195e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 2.883945276302739e-05, 'tol': 0.00047102518151351973, 'validation_fraction': 0.5807050998647453}
observation time 0.000003, current best -0.802217 at iter 22
suggestion time taken 15.694722 iter 23 next_points [{'alpha': 0.31590270095982254, 'batch_size': 136, 'beta_1': 0.8499719595777949, 'beta_2': 0.99703575537007, 'epsilon': 9.328231180997608e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0018707150361837819, 'tol': 2.644809442146857e-05, 'validation_fraction': 0.8711263767587075}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.120922 value -0.478079 suggestion {'alpha': 0.31590270095982254, 'batch_size': 136, 'beta_1': 0.8499719595777949, 'beta_2': 0.99703575537007, 'epsilon': 9.328231180997608e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0018707150361837819, 'tol': 2.644809442146857e-05, 'validation_fraction': 0.8711263767587075}
observation time 0.000003, current best -0.802217 at iter 23
suggestion time taken 16.269672 iter 24 next_points [{'alpha': 0.21206609729488574, 'batch_size': 139, 'beta_1': 0.9887482086892693, 'beta_2': 0.9940844750765131, 'epsilon': 6.385731287375915e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 1.0239801272395456e-05, 'tol': 0.008175296921981578, 'validation_fraction': 0.42008082899945415}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.082619 value -0.330788 suggestion {'alpha': 0.21206609729488574, 'batch_size': 139, 'beta_1': 0.9887482086892693, 'beta_2': 0.9940844750765131, 'epsilon': 6.385731287375915e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 1.0239801272395456e-05, 'tol': 0.008175296921981578, 'validation_fraction': 0.42008082899945415}
observation time 0.000003, current best -0.802217 at iter 24
suggestion time taken 15.745642 iter 25 next_points [{'alpha': 0.0664504304268088, 'batch_size': 47, 'beta_1': 0.8564404648427669, 'beta_2': 0.9988545059884736, 'epsilon': 3.988861912265843e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 7.125586277122726e-05, 'tol': 0.06613244747691302, 'validation_fraction': 0.8997788219680178}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.070553 value -0.345074 suggestion {'alpha': 0.0664504304268088, 'batch_size': 47, 'beta_1': 0.8564404648427669, 'beta_2': 0.9988545059884736, 'epsilon': 3.988861912265843e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 7.125586277122726e-05, 'tol': 0.06613244747691302, 'validation_fraction': 0.8997788219680178}
observation time 0.000003, current best -0.802217 at iter 25
suggestion time taken 16.575487 iter 26 next_points [{'alpha': 2.354412445552724, 'batch_size': 27, 'beta_1': 0.9151570952641827, 'beta_2': 0.9999900646809944, 'epsilon': 4.818665783424242e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 8.182119520440754e-05, 'tol': 0.003704983440613892, 'validation_fraction': 0.7714147553060504}]
function_evaluation time 0.133395 value -0.380049 suggestion {'alpha': 2.354412445552724, 'batch_size': 27, 'beta_1': 0.9151570952641827, 'beta_2': 0.9999900646809944, 'epsilon': 4.818665783424242e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 8.182119520440754e-05, 'tol': 0.003704983440613892, 'validation_fraction': 0.7714147553060504}
observation time 0.000006, current best -0.802217 at iter 26
suggestion time taken 15.934329 iter 27 next_points [{'alpha': 3.466318851399241e-05, 'batch_size': 28, 'beta_1': 0.8620345903121727, 'beta_2': 0.9864328594382105, 'epsilon': 4.861595356657352e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0005548288590473392, 'tol': 0.00018538403030809807, 'validation_fraction': 0.660083080558686}]
function_evaluation time 0.125863 value -0.414286 suggestion {'alpha': 3.466318851399241e-05, 'batch_size': 28, 'beta_1': 0.8620345903121727, 'beta_2': 0.9864328594382105, 'epsilon': 4.861595356657352e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0005548288590473392, 'tol': 0.00018538403030809807, 'validation_fraction': 0.660083080558686}
observation time 0.000003, current best -0.802217 at iter 27
suggestion time taken 16.247989 iter 28 next_points [{'alpha': 1.197806592768167e-05, 'batch_size': 70, 'beta_1': 0.9107470070585973, 'beta_2': 0.9999323794367286, 'epsilon': 4.704969418550904e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.004228785892521544, 'tol': 0.0047178947784644355, 'validation_fraction': 0.14685946721729468}]
function_evaluation time 0.279698 value -0.652956 suggestion {'alpha': 1.197806592768167e-05, 'batch_size': 70, 'beta_1': 0.9107470070585973, 'beta_2': 0.9999323794367286, 'epsilon': 4.704969418550904e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.004228785892521544, 'tol': 0.0047178947784644355, 'validation_fraction': 0.14685946721729468}
observation time 0.000003, current best -0.802217 at iter 28
suggestion time taken 16.066311 iter 29 next_points [{'alpha': 1.7928659463099127e-05, 'batch_size': 141, 'beta_1': 0.9414376302216942, 'beta_2': 0.9994516824182668, 'epsilon': 2.112564304435191e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0003515406616678619, 'tol': 0.0017546371841767009, 'validation_fraction': 0.8838485180192527}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.093570 value -0.373153 suggestion {'alpha': 1.7928659463099127e-05, 'batch_size': 141, 'beta_1': 0.9414376302216942, 'beta_2': 0.9994516824182668, 'epsilon': 2.112564304435191e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0003515406616678619, 'tol': 0.0017546371841767009, 'validation_fraction': 0.8838485180192527}
observation time 0.000003, current best -0.802217 at iter 29
suggestion time taken 15.810731 iter 30 next_points [{'alpha': 3.291208946162195, 'batch_size': 69, 'beta_1': 0.9825462458590678, 'beta_2': 0.9968443543155961, 'epsilon': 1.1322679439237422e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.00020842577447955556, 'tol': 0.00010705626226792283, 'validation_fraction': 0.3719112159589937}]
function_evaluation time 0.101937 value -0.380049 suggestion {'alpha': 3.291208946162195, 'batch_size': 69, 'beta_1': 0.9825462458590678, 'beta_2': 0.9968443543155961, 'epsilon': 1.1322679439237422e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.00020842577447955556, 'tol': 0.00010705626226792283, 'validation_fraction': 0.3719112159589937}
observation time 0.000003, current best -0.802217 at iter 30
suggestion time taken 16.772238 iter 31 next_points [{'alpha': 3.7599339453262215e-05, 'batch_size': 35, 'beta_1': 0.5186766644302644, 'beta_2': 0.9983980455811494, 'epsilon': 2.8777996361683882e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 3.795225721822885e-05, 'tol': 0.0005191860319509092, 'validation_fraction': 0.2076330902390508}]
function_evaluation time 0.140644 value -0.302709 suggestion {'alpha': 3.7599339453262215e-05, 'batch_size': 35, 'beta_1': 0.5186766644302644, 'beta_2': 0.9983980455811494, 'epsilon': 2.8777996361683882e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 3.795225721822885e-05, 'tol': 0.0005191860319509092, 'validation_fraction': 0.2076330902390508}
observation time 0.000004, current best -0.802217 at iter 31
suggestion time taken 15.861509 iter 32 next_points [{'alpha': 6.499079647198431e-05, 'batch_size': 20, 'beta_1': 0.8888798893433942, 'beta_2': 0.9943884937997622, 'epsilon': 1.9005652425437448e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0950841117811594, 'tol': 0.010706697809982506, 'validation_fraction': 0.7209187919516619}]
function_evaluation time 0.174603 value -0.493842 suggestion {'alpha': 6.499079647198431e-05, 'batch_size': 20, 'beta_1': 0.8888798893433942, 'beta_2': 0.9943884937997622, 'epsilon': 1.9005652425437448e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0950841117811594, 'tol': 0.010706697809982506, 'validation_fraction': 0.7209187919516619}
observation time 0.000004, current best -0.802217 at iter 32
suggestion time taken 16.835964 iter 33 next_points [{'alpha': 0.012102826626728042, 'batch_size': 34, 'beta_1': 0.7506273644238312, 'beta_2': 0.9982473356085284, 'epsilon': 4.196514710975161e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.05826139788673602, 'tol': 0.003380860489413626, 'validation_fraction': 0.678867470514184}]
function_evaluation time 0.342545 value -0.668473 suggestion {'alpha': 0.012102826626728042, 'batch_size': 34, 'beta_1': 0.7506273644238312, 'beta_2': 0.9982473356085284, 'epsilon': 4.196514710975161e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.05826139788673602, 'tol': 0.003380860489413626, 'validation_fraction': 0.678867470514184}
observation time 0.000003, current best -0.802217 at iter 33
suggestion time taken 16.426618 iter 34 next_points [{'alpha': 8.739064426589705, 'batch_size': 13, 'beta_1': 0.9892332477591298, 'beta_2': 0.999951962531434, 'epsilon': 9.23835991012813e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.020301844904286086, 'tol': 1.0290225714310637e-05, 'validation_fraction': 0.5186057232696952}]
function_evaluation time 0.318289 value -0.718473 suggestion {'alpha': 8.739064426589705, 'batch_size': 13, 'beta_1': 0.9892332477591298, 'beta_2': 0.999951962531434, 'epsilon': 9.23835991012813e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.020301844904286086, 'tol': 1.0290225714310637e-05, 'validation_fraction': 0.5186057232696952}
observation time 0.000003, current best -0.802217 at iter 34
suggestion time taken 16.762807 iter 35 next_points [{'alpha': 5.570400046387232, 'batch_size': 17, 'beta_1': 0.9809239633630464, 'beta_2': 0.9998387721698939, 'epsilon': 9.260349963657734e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 3.865234579286721e-05, 'tol': 0.09651069964286464, 'validation_fraction': 0.11883585611108655}]
function_evaluation time 0.235735 value -0.344089 suggestion {'alpha': 5.570400046387232, 'batch_size': 17, 'beta_1': 0.9809239633630464, 'beta_2': 0.9998387721698939, 'epsilon': 9.260349963657734e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 3.865234579286721e-05, 'tol': 0.09651069964286464, 'validation_fraction': 0.11883585611108655}
observation time 0.000004, current best -0.802217 at iter 35
suggestion time taken 15.742954 iter 36 next_points [{'alpha': 0.0013974892940471011, 'batch_size': 46, 'beta_1': 0.9352779982515884, 'beta_2': 0.9999873404369742, 'epsilon': 6.601608029327033e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.0010492149920708494, 'tol': 0.018074396422560875, 'validation_fraction': 0.8410203929759967}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.109372 value -0.522167 suggestion {'alpha': 0.0013974892940471011, 'batch_size': 46, 'beta_1': 0.9352779982515884, 'beta_2': 0.9999873404369742, 'epsilon': 6.601608029327033e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.0010492149920708494, 'tol': 0.018074396422560875, 'validation_fraction': 0.8410203929759967}
observation time 0.000003, current best -0.802217 at iter 36
suggestion time taken 16.359133 iter 37 next_points [{'alpha': 6.534860387592129e-05, 'batch_size': 28, 'beta_1': 0.7709322583106217, 'beta_2': 0.9999872859821943, 'epsilon': 1.5725115547509458e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.0003730909182547668, 'tol': 0.00024903823674487553, 'validation_fraction': 0.20556842531985156}]
function_evaluation time 0.289047 value -0.556158 suggestion {'alpha': 6.534860387592129e-05, 'batch_size': 28, 'beta_1': 0.7709322583106217, 'beta_2': 0.9999872859821943, 'epsilon': 1.5725115547509458e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.0003730909182547668, 'tol': 0.00024903823674487553, 'validation_fraction': 0.20556842531985156}
observation time 0.000003, current best -0.802217 at iter 37
suggestion time taken 15.780820 iter 38 next_points [{'alpha': 0.056880028184809625, 'batch_size': 139, 'beta_1': 0.9489575588730641, 'beta_2': 0.9999982496822798, 'epsilon': 2.1477956220225304e-07, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.00010826715898606251, 'tol': 0.00996385168661376, 'validation_fraction': 0.1333403154350053}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.096168 value -0.295074 suggestion {'alpha': 0.056880028184809625, 'batch_size': 139, 'beta_1': 0.9489575588730641, 'beta_2': 0.9999982496822798, 'epsilon': 2.1477956220225304e-07, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.00010826715898606251, 'tol': 0.00996385168661376, 'validation_fraction': 0.1333403154350053}
observation time 0.000003, current best -0.802217 at iter 38
suggestion time taken 15.738005 iter 39 next_points [{'alpha': 2.366726261616504, 'batch_size': 14, 'beta_1': 0.9614295938386174, 'beta_2': 0.9999745021729246, 'epsilon': 3.328225860190469e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.00509765975014148, 'tol': 0.0031871507971340065, 'validation_fraction': 0.40482050790514273}]
function_evaluation time 0.476578 value -0.858867 suggestion {'alpha': 2.366726261616504, 'batch_size': 14, 'beta_1': 0.9614295938386174, 'beta_2': 0.9999745021729246, 'epsilon': 3.328225860190469e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.00509765975014148, 'tol': 0.0031871507971340065, 'validation_fraction': 0.40482050790514273}
observation time 0.000004, current best -0.858867 at iter 39
suggestion time taken 16.677050 iter 40 next_points [{'alpha': 2.0871773706993436e-05, 'batch_size': 11, 'beta_1': 0.9670937021835133, 'beta_2': 0.9937989067163624, 'epsilon': 8.181837767589803e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.00023930962614811713, 'tol': 0.0007737950629148013, 'validation_fraction': 0.3888998435872919}]
function_evaluation time 0.466347 value -0.380296 suggestion {'alpha': 2.0871773706993436e-05, 'batch_size': 11, 'beta_1': 0.9670937021835133, 'beta_2': 0.9937989067163624, 'epsilon': 8.181837767589803e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.00023930962614811713, 'tol': 0.0007737950629148013, 'validation_fraction': 0.3888998435872919}
observation time 0.000004, current best -0.858867 at iter 40
suggestion time taken 15.786638 iter 41 next_points [{'alpha': 0.5300026385156678, 'batch_size': 47, 'beta_1': 0.9351485464643136, 'beta_2': 0.9510203247534864, 'epsilon': 2.157755884180261e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.005853994405378227, 'tol': 7.198614368071552e-05, 'validation_fraction': 0.1971522321015681}]
function_evaluation time 0.288137 value -0.774384 suggestion {'alpha': 0.5300026385156678, 'batch_size': 47, 'beta_1': 0.9351485464643136, 'beta_2': 0.9510203247534864, 'epsilon': 2.157755884180261e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.005853994405378227, 'tol': 7.198614368071552e-05, 'validation_fraction': 0.1971522321015681}
observation time 0.000004, current best -0.858867 at iter 41
suggestion time taken 16.919815 iter 42 next_points [{'alpha': 0.4975756666055836, 'batch_size': 12, 'beta_1': 0.8195480666484204, 'beta_2': 0.9999944315236551, 'epsilon': 8.226779804447452e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 7.082674719180447e-05, 'tol': 0.006474156498802512, 'validation_fraction': 0.5941833280586392}]
function_evaluation time 0.260421 value -0.479064 suggestion {'alpha': 0.4975756666055836, 'batch_size': 12, 'beta_1': 0.8195480666484204, 'beta_2': 0.9999944315236551, 'epsilon': 8.226779804447452e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 7.082674719180447e-05, 'tol': 0.006474156498802512, 'validation_fraction': 0.5941833280586392}
observation time 0.000003, current best -0.858867 at iter 42
suggestion time taken 16.076623 iter 43 next_points [{'alpha': 5.8240273149531305e-05, 'batch_size': 140, 'beta_1': 0.8987427610661308, 'beta_2': 0.999997312250954, 'epsilon': 4.669014356773854e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0006702739690762137, 'tol': 0.0114688221548907, 'validation_fraction': 0.8691562620402499}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.105578 value -0.416010 suggestion {'alpha': 5.8240273149531305e-05, 'batch_size': 140, 'beta_1': 0.8987427610661308, 'beta_2': 0.999997312250954, 'epsilon': 4.669014356773854e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0006702739690762137, 'tol': 0.0114688221548907, 'validation_fraction': 0.8691562620402499}
observation time 0.000004, current best -0.858867 at iter 43
suggestion time taken 15.692057 iter 44 next_points [{'alpha': 1.906469722792654e-05, 'batch_size': 140, 'beta_1': 0.9891567564723669, 'beta_2': 0.9701659635087131, 'epsilon': 6.306780132417493e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0001761912397014022, 'tol': 0.00028961015339349006, 'validation_fraction': 0.48782105822926525}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.086325 value -0.288424 suggestion {'alpha': 1.906469722792654e-05, 'batch_size': 140, 'beta_1': 0.9891567564723669, 'beta_2': 0.9701659635087131, 'epsilon': 6.306780132417493e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.0001761912397014022, 'tol': 0.00028961015339349006, 'validation_fraction': 0.48782105822926525}
observation time 0.000003, current best -0.858867 at iter 44
saving meta data: {'args': {'--uuid': '4dd333600d515882b854de1be074f753', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231015_053414', '--opt': 'strongcvx', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])}
saving results
saving timing
saving suggest log
done
