running: {'--uuid': '4474c96d6ea15bb0bcfa2e9f231790cc', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d breast -o strongcvx -u 4474c96d6ea15bb0bcfa2e9f231790cc -m nll -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam breast nll 45 1
with data root: None
suggestion time taken 19.326078 iter 0 next_points [{'alpha': 1.0730572297793805e-05, 'batch_size': 113, 'beta_1': 0.964332906332259, 'beta_2': 0.925908474955253, 'epsilon': 3.946925530306317e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.002573732663396572, 'tol': 0.07872584467332326, 'validation_fraction': 0.618234192009242}]
function_evaluation time 0.509187 value 1.941604 suggestion {'alpha': 1.0730572297793805e-05, 'batch_size': 113, 'beta_1': 0.964332906332259, 'beta_2': 0.925908474955253, 'epsilon': 3.946925530306317e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.002573732663396572, 'tol': 0.07872584467332326, 'validation_fraction': 0.618234192009242}
observation time 0.000005, current best 1.941604 at iter 0
suggestion time taken 19.363917 iter 1 next_points [{'alpha': 7.045877257776458, 'batch_size': 11, 'beta_1': 0.9694492758885644, 'beta_2': 0.998662701813849, 'epsilon': 2.7108263476360938e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0024358761950722774, 'tol': 5.554134745454261e-05, 'validation_fraction': 0.6906343760985842}]
function_evaluation time 2.104583 value 0.751334 suggestion {'alpha': 7.045877257776458, 'batch_size': 11, 'beta_1': 0.9694492758885644, 'beta_2': 0.998662701813849, 'epsilon': 2.7108263476360938e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0024358761950722774, 'tol': 5.554134745454261e-05, 'validation_fraction': 0.6906343760985842}
observation time 0.000005, current best 0.751334 at iter 1
suggestion time taken 18.757432 iter 2 next_points [{'alpha': 0.17015079920650994, 'batch_size': 227, 'beta_1': 0.9864825208909318, 'beta_2': 0.9998906457798318, 'epsilon': 1.3047172762879117e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0006418541319476612, 'tol': 0.006796693305028277, 'validation_fraction': 0.694253219693368}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.536739 value 2.696423 suggestion {'alpha': 0.17015079920650994, 'batch_size': 227, 'beta_1': 0.9864825208909318, 'beta_2': 0.9998906457798318, 'epsilon': 1.3047172762879117e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0006418541319476612, 'tol': 0.006796693305028277, 'validation_fraction': 0.694253219693368}
observation time 0.000013, current best 0.751334 at iter 2
suggestion time taken 19.926045 iter 3 next_points [{'alpha': 0.0002579512744779576, 'batch_size': 64, 'beta_1': 0.825974395467236, 'beta_2': 0.9844544618091117, 'epsilon': 9.51480921262145e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.008420539623502612, 'tol': 3.443400984565307e-05, 'validation_fraction': 0.8848378159960371}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.674374 value 0.916220 suggestion {'alpha': 0.0002579512744779576, 'batch_size': 64, 'beta_1': 0.825974395467236, 'beta_2': 0.9844544618091117, 'epsilon': 9.51480921262145e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.008420539623502612, 'tol': 3.443400984565307e-05, 'validation_fraction': 0.8848378159960371}
observation time 0.000008, current best 0.751334 at iter 3
suggestion time taken 19.057556 iter 4 next_points [{'alpha': 0.13083603989641482, 'batch_size': 151, 'beta_1': 0.9598111795198685, 'beta_2': 0.9998244828414025, 'epsilon': 8.4047751544492e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.038177242053460604, 'tol': 0.00011942495316429085, 'validation_fraction': 0.6054687228279337}]
function_evaluation time 0.689865 value 1.090677 suggestion {'alpha': 0.13083603989641482, 'batch_size': 151, 'beta_1': 0.9598111795198685, 'beta_2': 0.9998244828414025, 'epsilon': 8.4047751544492e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.038177242053460604, 'tol': 0.00011942495316429085, 'validation_fraction': 0.6054687228279337}
observation time 0.000005, current best 0.751334 at iter 4
suggestion time taken 20.562651 iter 5 next_points [{'alpha': 0.022447886902294465, 'batch_size': 11, 'beta_1': 0.6049674545489515, 'beta_2': 0.9998358285615442, 'epsilon': 8.508144344461346e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.023411054456869276, 'tol': 0.0014477604756361298, 'validation_fraction': 0.38966515494220727}]
function_evaluation time 2.473299 value 0.847846 suggestion {'alpha': 0.022447886902294465, 'batch_size': 11, 'beta_1': 0.6049674545489515, 'beta_2': 0.9998358285615442, 'epsilon': 8.508144344461346e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.023411054456869276, 'tol': 0.0014477604756361298, 'validation_fraction': 0.38966515494220727}
observation time 0.000006, current best 0.751334 at iter 5
suggestion time taken 20.118895 iter 6 next_points [{'alpha': 0.045296782071109216, 'batch_size': 151, 'beta_1': 0.9605805482397174, 'beta_2': 0.9997365887497898, 'epsilon': 6.390040833065548e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 2.795731853384409e-05, 'tol': 0.011995750246396783, 'validation_fraction': 0.7305091380238316}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.227072 value 13.850243 suggestion {'alpha': 0.045296782071109216, 'batch_size': 151, 'beta_1': 0.9605805482397174, 'beta_2': 0.9997365887497898, 'epsilon': 6.390040833065548e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 2.795731853384409e-05, 'tol': 0.011995750246396783, 'validation_fraction': 0.7305091380238316}
observation time 0.000005, current best 0.751334 at iter 6
suggestion time taken 19.541501 iter 7 next_points [{'alpha': 1.0523290573331314, 'batch_size': 113, 'beta_1': 0.9406314158555515, 'beta_2': 0.9999497552042301, 'epsilon': 2.2124991170534233e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0005040732342881315, 'tol': 0.001540144275020377, 'validation_fraction': 0.11224514678809257}]
function_evaluation time 0.934741 value 2.841175 suggestion {'alpha': 1.0523290573331314, 'batch_size': 113, 'beta_1': 0.9406314158555515, 'beta_2': 0.9999497552042301, 'epsilon': 2.2124991170534233e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0005040732342881315, 'tol': 0.001540144275020377, 'validation_fraction': 0.11224514678809257}
observation time 0.000005, current best 0.751334 at iter 7
suggestion time taken 20.223042 iter 8 next_points [{'alpha': 0.02815669395597238, 'batch_size': 226, 'beta_1': 0.835395907304748, 'beta_2': 0.9999818265322225, 'epsilon': 9.19392318075643e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 5.5250568723292847e-05, 'tol': 4.90974193151999e-05, 'validation_fraction': 0.5261234447303222}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 1.020513 value 11.771728 suggestion {'alpha': 0.02815669395597238, 'batch_size': 226, 'beta_1': 0.835395907304748, 'beta_2': 0.9999818265322225, 'epsilon': 9.19392318075643e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 5.5250568723292847e-05, 'tol': 4.90974193151999e-05, 'validation_fraction': 0.5261234447303222}
observation time 0.000007, current best 0.751334 at iter 8
suggestion time taken 19.459048 iter 9 next_points [{'alpha': 0.3141467153494073, 'batch_size': 56, 'beta_1': 0.9659143554647601, 'beta_2': 0.9649934877973222, 'epsilon': 1.6885132879372486e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0036391498660912226, 'tol': 0.0052020526281161585, 'validation_fraction': 0.7881047378438502}]
function_evaluation time 0.657434 value 0.613311 suggestion {'alpha': 0.3141467153494073, 'batch_size': 56, 'beta_1': 0.9659143554647601, 'beta_2': 0.9649934877973222, 'epsilon': 1.6885132879372486e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0036391498660912226, 'tol': 0.0052020526281161585, 'validation_fraction': 0.7881047378438502}
observation time 0.000005, current best 0.613311 at iter 9
suggestion time taken 20.390862 iter 10 next_points [{'alpha': 0.0029237771864379924, 'batch_size': 64, 'beta_1': 0.9847917101265173, 'beta_2': 0.9303020772993574, 'epsilon': 3.493577292416069e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0008682272349680109, 'tol': 0.005965165663583385, 'validation_fraction': 0.2610256374977325}]
function_evaluation time 1.764637 value 0.684738 suggestion {'alpha': 0.0029237771864379924, 'batch_size': 64, 'beta_1': 0.9847917101265173, 'beta_2': 0.9303020772993574, 'epsilon': 3.493577292416069e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0008682272349680109, 'tol': 0.005965165663583385, 'validation_fraction': 0.2610256374977325}
observation time 0.000018, current best 0.613311 at iter 10
suggestion time taken 19.373447 iter 11 next_points [{'alpha': 8.996266831745749e-05, 'batch_size': 15, 'beta_1': 0.6204716935411962, 'beta_2': 0.9999950897985123, 'epsilon': 4.884188381110696e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0016931991315056196, 'tol': 0.05150498514496728, 'validation_fraction': 0.6748727256573752}]
function_evaluation time 0.813068 value 0.432522 suggestion {'alpha': 8.996266831745749e-05, 'batch_size': 15, 'beta_1': 0.6204716935411962, 'beta_2': 0.9999950897985123, 'epsilon': 4.884188381110696e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0016931991315056196, 'tol': 0.05150498514496728, 'validation_fraction': 0.6748727256573752}
observation time 0.000005, current best 0.432522 at iter 11
suggestion time taken 20.633205 iter 12 next_points [{'alpha': 0.40423047522808875, 'batch_size': 227, 'beta_1': 0.982039854733851, 'beta_2': 0.9070537258765081, 'epsilon': 1.0586913485435833e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 4.946192237374416e-05, 'tol': 6.051155832055104e-05, 'validation_fraction': 0.6696936153676389}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.254562 value 13.241380 suggestion {'alpha': 0.40423047522808875, 'batch_size': 227, 'beta_1': 0.982039854733851, 'beta_2': 0.9070537258765081, 'epsilon': 1.0586913485435833e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 4.946192237374416e-05, 'tol': 6.051155832055104e-05, 'validation_fraction': 0.6696936153676389}
observation time 0.000005, current best 0.432522 at iter 12
suggestion time taken 20.218215 iter 13 next_points [{'alpha': 0.016011147224902274, 'batch_size': 75, 'beta_1': 0.9483726728320917, 'beta_2': 0.9991751046961902, 'epsilon': 1.0181473532038879e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.00010363267079054244, 'tol': 0.0002550817316094516, 'validation_fraction': 0.16316813213899803}]
function_evaluation time 1.674873 value 7.263728 suggestion {'alpha': 0.016011147224902274, 'batch_size': 75, 'beta_1': 0.9483726728320917, 'beta_2': 0.9991751046961902, 'epsilon': 1.0181473532038879e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.00010363267079054244, 'tol': 0.0002550817316094516, 'validation_fraction': 0.16316813213899803}
observation time 0.000005, current best 0.432522 at iter 13
suggestion time taken 19.751887 iter 14 next_points [{'alpha': 0.004109041934762609, 'batch_size': 34, 'beta_1': 0.9242773850403387, 'beta_2': 0.9999988990725038, 'epsilon': 3.170994528632267e-08, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.00040928683979166516, 'tol': 0.0006877023411734467, 'validation_fraction': 0.14682255569749048}]
function_evaluation time 2.308816 value 0.334609 suggestion {'alpha': 0.004109041934762609, 'batch_size': 34, 'beta_1': 0.9242773850403387, 'beta_2': 0.9999988990725038, 'epsilon': 3.170994528632267e-08, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.00040928683979166516, 'tol': 0.0006877023411734467, 'validation_fraction': 0.14682255569749048}
observation time 0.000015, current best 0.334609 at iter 14
suggestion time taken 20.894552 iter 15 next_points [{'alpha': 0.44003991539688014, 'batch_size': 226, 'beta_1': 0.9617216009333333, 'beta_2': 0.9977620311774756, 'epsilon': 6.691062125370946e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.04419066549633512, 'tol': 0.00018997747775373062, 'validation_fraction': 0.5108223459993556}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.631266 value 2.990860 suggestion {'alpha': 0.44003991539688014, 'batch_size': 226, 'beta_1': 0.9617216009333333, 'beta_2': 0.9977620311774756, 'epsilon': 6.691062125370946e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.04419066549633512, 'tol': 0.00018997747775373062, 'validation_fraction': 0.5108223459993556}
observation time 0.000007, current best 0.334609 at iter 15
suggestion time taken 19.846427 iter 16 next_points [{'alpha': 0.0006648404126756917, 'batch_size': 41, 'beta_1': 0.9882881199763809, 'beta_2': 0.924085006243385, 'epsilon': 1.5215156297765172e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.00010317468090707154, 'tol': 2.876915210965267e-05, 'validation_fraction': 0.18477381645819776}]
function_evaluation time 1.777867 value 2.869234 suggestion {'alpha': 0.0006648404126756917, 'batch_size': 41, 'beta_1': 0.9882881199763809, 'beta_2': 0.924085006243385, 'epsilon': 1.5215156297765172e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.00010317468090707154, 'tol': 2.876915210965267e-05, 'validation_fraction': 0.18477381645819776}
observation time 0.000007, current best 0.334609 at iter 16
suggestion time taken 21.114468 iter 17 next_points [{'alpha': 0.00048069915099140207, 'batch_size': 30, 'beta_1': 0.9881929826388274, 'beta_2': 0.9999795177557772, 'epsilon': 1.3441290440284377e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.005440696355809249, 'tol': 0.01833246733729477, 'validation_fraction': 0.19462714003287093}]
function_evaluation time 1.681725 value 1.639182 suggestion {'alpha': 0.00048069915099140207, 'batch_size': 30, 'beta_1': 0.9881929826388274, 'beta_2': 0.9999795177557772, 'epsilon': 1.3441290440284377e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.005440696355809249, 'tol': 0.01833246733729477, 'validation_fraction': 0.19462714003287093}
observation time 0.000005, current best 0.334609 at iter 17
suggestion time taken 20.025735 iter 18 next_points [{'alpha': 0.0010199875778271114, 'batch_size': 227, 'beta_1': 0.9204152443432119, 'beta_2': 0.9999981754483919, 'epsilon': 1.3803376057112577e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0009028617573817271, 'tol': 0.0018261563897872452, 'validation_fraction': 0.2177392861448882}]
function_evaluation time 0.719960 value 5.328711 suggestion {'alpha': 0.0010199875778271114, 'batch_size': 227, 'beta_1': 0.9204152443432119, 'beta_2': 0.9999981754483919, 'epsilon': 1.3803376057112577e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0009028617573817271, 'tol': 0.0018261563897872452, 'validation_fraction': 0.2177392861448882}
observation time 0.000007, current best 0.334609 at iter 18
suggestion time taken 20.978608 iter 19 next_points [{'alpha': 0.00011580519265171907, 'batch_size': 227, 'beta_1': 0.7246385641926628, 'beta_2': 0.9988926527073163, 'epsilon': 2.2301184891011676e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0011179305082647869, 'tol': 0.008941329661937052, 'validation_fraction': 0.39168591113893414}]
function_evaluation time 0.683818 value 4.749724 suggestion {'alpha': 0.00011580519265171907, 'batch_size': 227, 'beta_1': 0.7246385641926628, 'beta_2': 0.9988926527073163, 'epsilon': 2.2301184891011676e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0011179305082647869, 'tol': 0.008941329661937052, 'validation_fraction': 0.39168591113893414}
observation time 0.000006, current best 0.334609 at iter 19
suggestion time taken 19.809617 iter 20 next_points [{'alpha': 0.004934814663820543, 'batch_size': 45, 'beta_1': 0.6360744443080156, 'beta_2': 0.9999977550655317, 'epsilon': 2.7314596998464235e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.0004417537695116712, 'tol': 0.003806482545892361, 'validation_fraction': 0.17172929632884584}]
function_evaluation time 0.795117 value 0.331290 suggestion {'alpha': 0.004934814663820543, 'batch_size': 45, 'beta_1': 0.6360744443080156, 'beta_2': 0.9999977550655317, 'epsilon': 2.7314596998464235e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.0004417537695116712, 'tol': 0.003806482545892361, 'validation_fraction': 0.17172929632884584}
observation time 0.000005, current best 0.331290 at iter 20
suggestion time taken 20.684636 iter 21 next_points [{'alpha': 0.0004942931377085536, 'batch_size': 149, 'beta_1': 0.5049288290316095, 'beta_2': 0.9998932700314332, 'epsilon': 8.618052661989463e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 5.388749684584109e-05, 'tol': 0.001222652194403197, 'validation_fraction': 0.7299997684172294}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.324354 value 15.524796 suggestion {'alpha': 0.0004942931377085536, 'batch_size': 149, 'beta_1': 0.5049288290316095, 'beta_2': 0.9998932700314332, 'epsilon': 8.618052661989463e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 5.388749684584109e-05, 'tol': 0.001222652194403197, 'validation_fraction': 0.7299997684172294}
observation time 0.000014, current best 0.331290 at iter 21
suggestion time taken 19.462554 iter 22 next_points [{'alpha': 0.225868803731192, 'batch_size': 25, 'beta_1': 0.9899873997696541, 'beta_2': 0.9995835709514943, 'epsilon': 1.4369044926807983e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 1.4168071789094913e-05, 'tol': 0.0009987542842356393, 'validation_fraction': 0.128421216746309}]
function_evaluation time 0.827985 value 12.286470 suggestion {'alpha': 0.225868803731192, 'batch_size': 25, 'beta_1': 0.9899873997696541, 'beta_2': 0.9995835709514943, 'epsilon': 1.4369044926807983e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 1.4168071789094913e-05, 'tol': 0.0009987542842356393, 'validation_fraction': 0.128421216746309}
observation time 0.000008, current best 0.331290 at iter 22
suggestion time taken 21.357598 iter 23 next_points [{'alpha': 0.7307203015788872, 'batch_size': 90, 'beta_1': 0.7617158302309728, 'beta_2': 0.9999947494053265, 'epsilon': 2.302324920198176e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.013486194016107794, 'tol': 0.0008162093923917195, 'validation_fraction': 0.743222522264994}]
function_evaluation time 0.748461 value 0.847917 suggestion {'alpha': 0.7307203015788872, 'batch_size': 90, 'beta_1': 0.7617158302309728, 'beta_2': 0.9999947494053265, 'epsilon': 2.302324920198176e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.013486194016107794, 'tol': 0.0008162093923917195, 'validation_fraction': 0.743222522264994}
observation time 0.000005, current best 0.331290 at iter 23
suggestion time taken 19.764903 iter 24 next_points [{'alpha': 0.07414022257261783, 'batch_size': 151, 'beta_1': 0.9477762491388927, 'beta_2': 0.9999665172708414, 'epsilon': 6.923353904392001e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 2.579622387929857e-05, 'tol': 0.011963466142616775, 'validation_fraction': 0.6203280581806052}]
function_evaluation time 0.461742 value 8.445899 suggestion {'alpha': 0.07414022257261783, 'batch_size': 151, 'beta_1': 0.9477762491388927, 'beta_2': 0.9999665172708414, 'epsilon': 6.923353904392001e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 2.579622387929857e-05, 'tol': 0.011963466142616775, 'validation_fraction': 0.6203280581806052}
observation time 0.000008, current best 0.331290 at iter 24
suggestion time taken 20.796477 iter 25 next_points [{'alpha': 0.3606627684597942, 'batch_size': 111, 'beta_1': 0.9303800040205619, 'beta_2': 0.9999833893322712, 'epsilon': 3.1451947427559028e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.00012592418043975542, 'tol': 0.0058367790116946915, 'validation_fraction': 0.11002749674081312}]
function_evaluation time 0.786844 value 11.788053 suggestion {'alpha': 0.3606627684597942, 'batch_size': 111, 'beta_1': 0.9303800040205619, 'beta_2': 0.9999833893322712, 'epsilon': 3.1451947427559028e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.00012592418043975542, 'tol': 0.0058367790116946915, 'validation_fraction': 0.11002749674081312}
observation time 0.000008, current best 0.331290 at iter 25
suggestion time taken 20.214940 iter 26 next_points [{'alpha': 1.055200827377744, 'batch_size': 227, 'beta_1': 0.7400908602756565, 'beta_2': 0.9999895221431441, 'epsilon': 2.614096993155729e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0016401889581485669, 'tol': 1.4851072709358681e-05, 'validation_fraction': 0.31478231524534916}]
function_evaluation time 0.822988 value 0.319429 suggestion {'alpha': 1.055200827377744, 'batch_size': 227, 'beta_1': 0.7400908602756565, 'beta_2': 0.9999895221431441, 'epsilon': 2.614096993155729e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0016401889581485669, 'tol': 1.4851072709358681e-05, 'validation_fraction': 0.31478231524534916}
observation time 0.000006, current best 0.319429 at iter 26
suggestion time taken 17.746325 iter 27 next_points [{'alpha': 5.69446068591261e-05, 'batch_size': 18, 'beta_1': 0.7861412106131124, 'beta_2': 0.9999983298676776, 'epsilon': 1.1226225689519534e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.038748394011942404, 'tol': 0.02276333013406429, 'validation_fraction': 0.15886702307497627}]
function_evaluation time 1.593314 value 0.317354 suggestion {'alpha': 5.69446068591261e-05, 'batch_size': 18, 'beta_1': 0.7861412106131124, 'beta_2': 0.9999983298676776, 'epsilon': 1.1226225689519534e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.038748394011942404, 'tol': 0.02276333013406429, 'validation_fraction': 0.15886702307497627}
observation time 0.000005, current best 0.317354 at iter 27
suggestion time taken 14.670375 iter 28 next_points [{'alpha': 9.116244252655791e-05, 'batch_size': 226, 'beta_1': 0.9140204519419526, 'beta_2': 0.9999951920308529, 'epsilon': 5.9473936405829016e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0003753840554387185, 'tol': 0.008038160164976504, 'validation_fraction': 0.23434572984227772}]
function_evaluation time 0.428340 value 9.149326 suggestion {'alpha': 9.116244252655791e-05, 'batch_size': 226, 'beta_1': 0.9140204519419526, 'beta_2': 0.9999951920308529, 'epsilon': 5.9473936405829016e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0003753840554387185, 'tol': 0.008038160164976504, 'validation_fraction': 0.23434572984227772}
observation time 0.000005, current best 0.317354 at iter 28
suggestion time taken 15.480235 iter 29 next_points [{'alpha': 0.7173469654154231, 'batch_size': 111, 'beta_1': 0.8834724689186954, 'beta_2': 0.902864606114435, 'epsilon': 8.561028750023594e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 6.96880959847374e-05, 'tol': 0.0001663607776017457, 'validation_fraction': 0.6947324524508977}]
function_evaluation time 0.300012 value 11.874156 suggestion {'alpha': 0.7173469654154231, 'batch_size': 111, 'beta_1': 0.8834724689186954, 'beta_2': 0.902864606114435, 'epsilon': 8.561028750023594e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 6.96880959847374e-05, 'tol': 0.0001663607776017457, 'validation_fraction': 0.6947324524508977}
observation time 0.000005, current best 0.317354 at iter 29
suggestion time taken 14.950913 iter 30 next_points [{'alpha': 0.00020423346929670854, 'batch_size': 227, 'beta_1': 0.5301646165375217, 'beta_2': 0.9998543793994616, 'epsilon': 6.642737559496709e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00804944113874842, 'tol': 0.00021826419698815224, 'validation_fraction': 0.6956512451743173}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.371921 value 0.751393 suggestion {'alpha': 0.00020423346929670854, 'batch_size': 227, 'beta_1': 0.5301646165375217, 'beta_2': 0.9998543793994616, 'epsilon': 6.642737559496709e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00804944113874842, 'tol': 0.00021826419698815224, 'validation_fraction': 0.6956512451743173}
observation time 0.000005, current best 0.317354 at iter 30
suggestion time taken 15.293462 iter 31 next_points [{'alpha': 0.0014862245408529648, 'batch_size': 113, 'beta_1': 0.9020072496278219, 'beta_2': 0.9999564378891066, 'epsilon': 4.259291212844126e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00018105548672003237, 'tol': 9.081231550585725e-05, 'validation_fraction': 0.30956435077623384}]
function_evaluation time 0.178527 value 13.956407 suggestion {'alpha': 0.0014862245408529648, 'batch_size': 113, 'beta_1': 0.9020072496278219, 'beta_2': 0.9999564378891066, 'epsilon': 4.259291212844126e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00018105548672003237, 'tol': 9.081231550585725e-05, 'validation_fraction': 0.30956435077623384}
observation time 0.000003, current best 0.317354 at iter 31
suggestion time taken 15.384422 iter 32 next_points [{'alpha': 0.000240218785643712, 'batch_size': 41, 'beta_1': 0.8282613761762002, 'beta_2': 0.9998911522555936, 'epsilon': 5.475655676216887e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.02913352297079537, 'tol': 0.00030159498384877055, 'validation_fraction': 0.5570002272109139}]
function_evaluation time 0.625017 value 1.064436 suggestion {'alpha': 0.000240218785643712, 'batch_size': 41, 'beta_1': 0.8282613761762002, 'beta_2': 0.9998911522555936, 'epsilon': 5.475655676216887e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.02913352297079537, 'tol': 0.00030159498384877055, 'validation_fraction': 0.5570002272109139}
observation time 0.000004, current best 0.317354 at iter 32
suggestion time taken 20.895377 iter 33 next_points [{'alpha': 2.2316468910174247e-05, 'batch_size': 151, 'beta_1': 0.6238086165673442, 'beta_2': 0.9997379588343536, 'epsilon': 5.4360669673781685e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.00166077858231897, 'tol': 0.018002212680535586, 'validation_fraction': 0.13906854632026877}]
function_evaluation time 0.832670 value 0.314720 suggestion {'alpha': 2.2316468910174247e-05, 'batch_size': 151, 'beta_1': 0.6238086165673442, 'beta_2': 0.9997379588343536, 'epsilon': 5.4360669673781685e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.00166077858231897, 'tol': 0.018002212680535586, 'validation_fraction': 0.13906854632026877}
observation time 0.000015, current best 0.314720 at iter 33
suggestion time taken 20.379997 iter 34 next_points [{'alpha': 5.187433165407557e-05, 'batch_size': 227, 'beta_1': 0.735059196160788, 'beta_2': 0.9988395067389647, 'epsilon': 1.1624568112570389e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.005254766102080243, 'tol': 0.0010259230114326712, 'validation_fraction': 0.11373010768119933}]
function_evaluation time 0.698335 value 0.449680 suggestion {'alpha': 5.187433165407557e-05, 'batch_size': 227, 'beta_1': 0.735059196160788, 'beta_2': 0.9988395067389647, 'epsilon': 1.1624568112570389e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.005254766102080243, 'tol': 0.0010259230114326712, 'validation_fraction': 0.11373010768119933}
observation time 0.000006, current best 0.314720 at iter 34
suggestion time taken 19.943058 iter 35 next_points [{'alpha': 5.2367273085157035e-05, 'batch_size': 227, 'beta_1': 0.6105055264352536, 'beta_2': 0.9786367075696013, 'epsilon': 7.268045380707381e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.005268837185284277, 'tol': 0.09552038212437844, 'validation_fraction': 0.4905012421911254}]
function_evaluation time 0.427508 value 0.483657 suggestion {'alpha': 5.2367273085157035e-05, 'batch_size': 227, 'beta_1': 0.6105055264352536, 'beta_2': 0.9786367075696013, 'epsilon': 7.268045380707381e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.005268837185284277, 'tol': 0.09552038212437844, 'validation_fraction': 0.4905012421911254}
observation time 0.000005, current best 0.314720 at iter 35
suggestion time taken 21.632281 iter 36 next_points [{'alpha': 1.4248023966490786e-05, 'batch_size': 226, 'beta_1': 0.5697085279884372, 'beta_2': 0.9999985345757912, 'epsilon': 2.3177186996750123e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0008859620927526371, 'tol': 0.08555104964105587, 'validation_fraction': 0.3436225897515433}]
function_evaluation time 0.559769 value 7.176554 suggestion {'alpha': 1.4248023966490786e-05, 'batch_size': 226, 'beta_1': 0.5697085279884372, 'beta_2': 0.9999985345757912, 'epsilon': 2.3177186996750123e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0008859620927526371, 'tol': 0.08555104964105587, 'validation_fraction': 0.3436225897515433}
observation time 0.000009, current best 0.314720 at iter 36
suggestion time taken 19.883020 iter 37 next_points [{'alpha': 1.5149090800966245, 'batch_size': 225, 'beta_1': 0.9842815305753652, 'beta_2': 0.9999139318463101, 'epsilon': 2.5430698035858618e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0029519025788969614, 'tol': 0.000574384068572383, 'validation_fraction': 0.7358684054392189}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.578834 value 0.597034 suggestion {'alpha': 1.5149090800966245, 'batch_size': 225, 'beta_1': 0.9842815305753652, 'beta_2': 0.9999139318463101, 'epsilon': 2.5430698035858618e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0029519025788969614, 'tol': 0.000574384068572383, 'validation_fraction': 0.7358684054392189}
observation time 0.000005, current best 0.314720 at iter 37
suggestion time taken 21.589899 iter 38 next_points [{'alpha': 0.6778345922915278, 'batch_size': 90, 'beta_1': 0.7573874841622777, 'beta_2': 0.9999928999277127, 'epsilon': 1.1942716781069032e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0654165651179304, 'tol': 0.05108439517585508, 'validation_fraction': 0.13841735451028717}]
function_evaluation time 0.254889 value 0.405509 suggestion {'alpha': 0.6778345922915278, 'batch_size': 90, 'beta_1': 0.7573874841622777, 'beta_2': 0.9999928999277127, 'epsilon': 1.1942716781069032e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0654165651179304, 'tol': 0.05108439517585508, 'validation_fraction': 0.13841735451028717}
observation time 0.000005, current best 0.314720 at iter 38
suggestion time taken 20.537438 iter 39 next_points [{'alpha': 0.17134947805083586, 'batch_size': 30, 'beta_1': 0.9677750650205704, 'beta_2': 0.9999970841974438, 'epsilon': 2.2735611343823214e-09, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.0012035329450489202, 'tol': 0.02988575902110374, 'validation_fraction': 0.39445183210617724}]
function_evaluation time 1.210651 value 0.616190 suggestion {'alpha': 0.17134947805083586, 'batch_size': 30, 'beta_1': 0.9677750650205704, 'beta_2': 0.9999970841974438, 'epsilon': 2.2735611343823214e-09, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.0012035329450489202, 'tol': 0.02988575902110374, 'validation_fraction': 0.39445183210617724}
observation time 0.000005, current best 0.314720 at iter 39
suggestion time taken 20.168052 iter 40 next_points [{'alpha': 2.5639309560297634, 'batch_size': 45, 'beta_1': 0.9424660293341374, 'beta_2': 0.993535575346474, 'epsilon': 1.6226850390223345e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.02255109291682458, 'tol': 0.016999747403991128, 'validation_fraction': 0.5228374109660612}]
function_evaluation time 0.625768 value 1.042318 suggestion {'alpha': 2.5639309560297634, 'batch_size': 45, 'beta_1': 0.9424660293341374, 'beta_2': 0.993535575346474, 'epsilon': 1.6226850390223345e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.02255109291682458, 'tol': 0.016999747403991128, 'validation_fraction': 0.5228374109660612}
observation time 0.000018, current best 0.314720 at iter 40
suggestion time taken 21.820954 iter 41 next_points [{'alpha': 0.00023282595338659556, 'batch_size': 41, 'beta_1': 0.967675026228022, 'beta_2': 0.9999622607575346, 'epsilon': 4.55467064184113e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0012213441639853915, 'tol': 0.0002347682354428942, 'validation_fraction': 0.8708247051198632}]
function_evaluation time 0.579616 value 9.345802 suggestion {'alpha': 0.00023282595338659556, 'batch_size': 41, 'beta_1': 0.967675026228022, 'beta_2': 0.9999622607575346, 'epsilon': 4.55467064184113e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0012213441639853915, 'tol': 0.0002347682354428942, 'validation_fraction': 0.8708247051198632}
observation time 0.000012, current best 0.314720 at iter 41
suggestion time taken 20.189194 iter 42 next_points [{'alpha': 0.001496903909336885, 'batch_size': 225, 'beta_1': 0.9578950511239381, 'beta_2': 0.9999982391088021, 'epsilon': 8.338006498222965e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 4.520755938027358e-05, 'tol': 0.05818388700289447, 'validation_fraction': 0.8657808606361617}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.244318 value 15.888431 suggestion {'alpha': 0.001496903909336885, 'batch_size': 225, 'beta_1': 0.9578950511239381, 'beta_2': 0.9999982391088021, 'epsilon': 8.338006498222965e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 4.520755938027358e-05, 'tol': 0.05818388700289447, 'validation_fraction': 0.8657808606361617}
observation time 0.000005, current best 0.314720 at iter 42
suggestion time taken 21.641656 iter 43 next_points [{'alpha': 2.091948262445503e-05, 'batch_size': 227, 'beta_1': 0.9483333933717777, 'beta_2': 0.9600913260450388, 'epsilon': 2.1147369157948406e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 1.5594373424637177e-05, 'tol': 0.000147504984960945, 'validation_fraction': 0.6031040289171713}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.263126 value 21.262468 suggestion {'alpha': 2.091948262445503e-05, 'batch_size': 227, 'beta_1': 0.9483333933717777, 'beta_2': 0.9600913260450388, 'epsilon': 2.1147369157948406e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 1.5594373424637177e-05, 'tol': 0.000147504984960945, 'validation_fraction': 0.6031040289171713}
observation time 0.000006, current best 0.314720 at iter 43
suggestion time taken 20.423489 iter 44 next_points [{'alpha': 0.04173536591741592, 'batch_size': 25, 'beta_1': 0.9702854660040826, 'beta_2': 0.9999979625255608, 'epsilon': 3.845490770215111e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0043929706745686106, 'tol': 1.4779517493186556e-05, 'validation_fraction': 0.1417920007282503}]
function_evaluation time 0.914552 value 1.055535 suggestion {'alpha': 0.04173536591741592, 'batch_size': 25, 'beta_1': 0.9702854660040826, 'beta_2': 0.9999979625255608, 'epsilon': 3.845490770215111e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0043929706745686106, 'tol': 1.4779517493186556e-05, 'validation_fraction': 0.1417920007282503}
observation time 0.000007, current best 0.314720 at iter 44
saving meta data: {'args': {'--uuid': '4474c96d6ea15bb0bcfa2e9f231790cc', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])}
saving results
saving timing
saving suggest log
done
