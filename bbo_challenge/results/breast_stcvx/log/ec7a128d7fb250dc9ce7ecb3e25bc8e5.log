running: {'--uuid': 'ec7a128d7fb250dc9ce7ecb3e25bc8e5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d breast -o strongcvx -u ec7a128d7fb250dc9ce7ecb3e25bc8e5 -m nll -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam breast nll 45 1
with data root: None
suggestion time taken 18.879813 iter 0 next_points [{'alpha': 6.73639993224049e-05, 'batch_size': 227, 'beta_1': 0.9595441737598005, 'beta_2': 0.9890962774589414, 'epsilon': 3.4944474004442473e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.03459386212538402, 'tol': 5.143400099778803e-05, 'validation_fraction': 0.17708669255083487}]
function_evaluation time 0.726958 value 0.360092 suggestion {'alpha': 6.73639993224049e-05, 'batch_size': 227, 'beta_1': 0.9595441737598005, 'beta_2': 0.9890962774589414, 'epsilon': 3.4944474004442473e-07, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.03459386212538402, 'tol': 5.143400099778803e-05, 'validation_fraction': 0.17708669255083487}
observation time 0.000009, current best 0.360092 at iter 0
suggestion time taken 18.964778 iter 1 next_points [{'alpha': 0.00010181873586673576, 'batch_size': 50, 'beta_1': 0.5078094489991498, 'beta_2': 0.9998808304046628, 'epsilon': 4.189821616753806e-07, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.09099595086566645, 'tol': 0.01580773637465721, 'validation_fraction': 0.24852591820601996}]
function_evaluation time 0.970579 value 0.265529 suggestion {'alpha': 0.00010181873586673576, 'batch_size': 50, 'beta_1': 0.5078094489991498, 'beta_2': 0.9998808304046628, 'epsilon': 4.189821616753806e-07, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.09099595086566645, 'tol': 0.01580773637465721, 'validation_fraction': 0.24852591820601996}
observation time 0.000007, current best 0.265529 at iter 1
suggestion time taken 18.547098 iter 2 next_points [{'alpha': 0.001784032175761302, 'batch_size': 227, 'beta_1': 0.6207184424183501, 'beta_2': 0.9999785599512688, 'epsilon': 1.9016116343740194e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.00020415783723215308, 'tol': 0.0028968426632656765, 'validation_fraction': 0.36866662510891796}]
function_evaluation time 0.708500 value 0.671653 suggestion {'alpha': 0.001784032175761302, 'batch_size': 227, 'beta_1': 0.6207184424183501, 'beta_2': 0.9999785599512688, 'epsilon': 1.9016116343740194e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.00020415783723215308, 'tol': 0.0028968426632656765, 'validation_fraction': 0.36866662510891796}
observation time 0.000008, current best 0.265529 at iter 2
suggestion time taken 19.603252 iter 3 next_points [{'alpha': 0.00040373936138790784, 'batch_size': 15, 'beta_1': 0.9509390146779104, 'beta_2': 0.9999806586720495, 'epsilon': 6.376590469508139e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.00025573085020418474, 'tol': 0.05719232334284936, 'validation_fraction': 0.13126757495438307}]
function_evaluation time 1.220240 value 0.316078 suggestion {'alpha': 0.00040373936138790784, 'batch_size': 15, 'beta_1': 0.9509390146779104, 'beta_2': 0.9999806586720495, 'epsilon': 6.376590469508139e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.00025573085020418474, 'tol': 0.05719232334284936, 'validation_fraction': 0.13126757495438307}
observation time 0.000007, current best 0.265529 at iter 3
suggestion time taken 18.537892 iter 4 next_points [{'alpha': 0.22671590356119078, 'batch_size': 151, 'beta_1': 0.9771940970862568, 'beta_2': 0.9975780441899166, 'epsilon': 6.941713851338408e-09, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.0067298609877976465, 'tol': 0.00010226936309540936, 'validation_fraction': 0.32774022258613045}]
function_evaluation time 0.776911 value 1.399081 suggestion {'alpha': 0.22671590356119078, 'batch_size': 151, 'beta_1': 0.9771940970862568, 'beta_2': 0.9975780441899166, 'epsilon': 6.941713851338408e-09, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.0067298609877976465, 'tol': 0.00010226936309540936, 'validation_fraction': 0.32774022258613045}
observation time 0.000007, current best 0.265529 at iter 4
suggestion time taken 21.215452 iter 5 next_points [{'alpha': 7.068963036668036, 'batch_size': 151, 'beta_1': 0.5139282772357632, 'beta_2': 0.9999942249736111, 'epsilon': 8.184235531751545e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0017633456990501955, 'tol': 0.0019236905019440569, 'validation_fraction': 0.31707008019081534}]
function_evaluation time 1.026559 value 0.358689 suggestion {'alpha': 7.068963036668036, 'batch_size': 151, 'beta_1': 0.5139282772357632, 'beta_2': 0.9999942249736111, 'epsilon': 8.184235531751545e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0017633456990501955, 'tol': 0.0019236905019440569, 'validation_fraction': 0.31707008019081534}
observation time 0.000008, current best 0.265529 at iter 5
suggestion time taken 18.331097 iter 6 next_points [{'alpha': 0.0029473034630409876, 'batch_size': 45, 'beta_1': 0.9885851356977886, 'beta_2': 0.999773627654196, 'epsilon': 4.8839451386444495e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 1.7423219290366277e-05, 'tol': 0.000193192534187414, 'validation_fraction': 0.7920382210418452}]
function_evaluation time 0.395452 value 11.588314 suggestion {'alpha': 0.0029473034630409876, 'batch_size': 45, 'beta_1': 0.9885851356977886, 'beta_2': 0.999773627654196, 'epsilon': 4.8839451386444495e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 1.7423219290366277e-05, 'tol': 0.000193192534187414, 'validation_fraction': 0.7920382210418452}
observation time 0.000008, current best 0.265529 at iter 6
suggestion time taken 16.567802 iter 7 next_points [{'alpha': 0.001113300129847999, 'batch_size': 151, 'beta_1': 0.726165623826659, 'beta_2': 0.9880043614243708, 'epsilon': 2.0197748502408384e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 3.4746786540607936e-05, 'tol': 0.0033838280462322656, 'validation_fraction': 0.12169571425974882}]
function_evaluation time 0.474437 value 14.094016 suggestion {'alpha': 0.001113300129847999, 'batch_size': 151, 'beta_1': 0.726165623826659, 'beta_2': 0.9880043614243708, 'epsilon': 2.0197748502408384e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 3.4746786540607936e-05, 'tol': 0.0033838280462322656, 'validation_fraction': 0.12169571425974882}
observation time 0.000007, current best 0.265529 at iter 7
suggestion time taken 17.547179 iter 8 next_points [{'alpha': 1.4930416969414237e-05, 'batch_size': 11, 'beta_1': 0.8489941295630338, 'beta_2': 0.9529170571609268, 'epsilon': 3.643928020950868e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0900773942199285, 'tol': 0.0002614518537650705, 'validation_fraction': 0.2645450204480664}]
function_evaluation time 2.083846 value 0.436099 suggestion {'alpha': 1.4930416969414237e-05, 'batch_size': 11, 'beta_1': 0.8489941295630338, 'beta_2': 0.9529170571609268, 'epsilon': 3.643928020950868e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0900773942199285, 'tol': 0.0002614518537650705, 'validation_fraction': 0.2645450204480664}
observation time 0.000007, current best 0.265529 at iter 8
suggestion time taken 16.726738 iter 9 next_points [{'alpha': 1.7878900504342363, 'batch_size': 75, 'beta_1': 0.969698250312581, 'beta_2': 0.999990016250139, 'epsilon': 8.061601141124944e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0004442086393652187, 'tol': 0.003445682913522869, 'validation_fraction': 0.6127793052211694}]
function_evaluation time 0.662971 value 4.538128 suggestion {'alpha': 1.7878900504342363, 'batch_size': 75, 'beta_1': 0.969698250312581, 'beta_2': 0.999990016250139, 'epsilon': 8.061601141124944e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0004442086393652187, 'tol': 0.003445682913522869, 'validation_fraction': 0.6127793052211694}
observation time 0.000008, current best 0.265529 at iter 9
suggestion time taken 17.828544 iter 10 next_points [{'alpha': 0.00010555198022874523, 'batch_size': 112, 'beta_1': 0.6307203315111221, 'beta_2': 0.9999875836848421, 'epsilon': 2.184979329116743e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.004476972550192824, 'tol': 0.01164118308710931, 'validation_fraction': 0.4398136226013426}]
function_evaluation time 0.662391 value 0.386052 suggestion {'alpha': 0.00010555198022874523, 'batch_size': 112, 'beta_1': 0.6307203315111221, 'beta_2': 0.9999875836848421, 'epsilon': 2.184979329116743e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.004476972550192824, 'tol': 0.01164118308710931, 'validation_fraction': 0.4398136226013426}
observation time 0.000007, current best 0.265529 at iter 10
suggestion time taken 16.655517 iter 11 next_points [{'alpha': 5.156286246502935, 'batch_size': 225, 'beta_1': 0.974629638764708, 'beta_2': 0.9448503379562649, 'epsilon': 1.6657405835102857e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0022040417536357665, 'tol': 0.007396077448769557, 'validation_fraction': 0.8118801489937105}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.458277 value 1.085352 suggestion {'alpha': 5.156286246502935, 'batch_size': 225, 'beta_1': 0.974629638764708, 'beta_2': 0.9448503379562649, 'epsilon': 1.6657405835102857e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0022040417536357665, 'tol': 0.007396077448769557, 'validation_fraction': 0.8118801489937105}
observation time 0.000008, current best 0.265529 at iter 11
suggestion time taken 21.254033 iter 12 next_points [{'alpha': 0.001051790723630947, 'batch_size': 17, 'beta_1': 0.9442701614777188, 'beta_2': 0.9999944668020422, 'epsilon': 8.995246030630133e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 9.51071581333798e-05, 'tol': 0.045767233223516945, 'validation_fraction': 0.5904480768318522}]
function_evaluation time 0.987067 value 5.126881 suggestion {'alpha': 0.001051790723630947, 'batch_size': 17, 'beta_1': 0.9442701614777188, 'beta_2': 0.9999944668020422, 'epsilon': 8.995246030630133e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 9.51071581333798e-05, 'tol': 0.045767233223516945, 'validation_fraction': 0.5904480768318522}
observation time 0.000007, current best 0.265529 at iter 12
suggestion time taken 19.507535 iter 13 next_points [{'alpha': 3.642298607499643e-05, 'batch_size': 28, 'beta_1': 0.9464585363441579, 'beta_2': 0.9999499590738471, 'epsilon': 1.9259389328251174e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.005678561819892237, 'tol': 0.00014886506276614393, 'validation_fraction': 0.8972622824803653}]
function_evaluation time 0.756767 value 0.887062 suggestion {'alpha': 3.642298607499643e-05, 'batch_size': 28, 'beta_1': 0.9464585363441579, 'beta_2': 0.9999499590738471, 'epsilon': 1.9259389328251174e-07, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.005678561819892237, 'tol': 0.00014886506276614393, 'validation_fraction': 0.8972622824803653}
observation time 0.000010, current best 0.265529 at iter 13
suggestion time taken 19.024101 iter 14 next_points [{'alpha': 0.6107248833154281, 'batch_size': 50, 'beta_1': 0.5549662596739598, 'beta_2': 0.9999920017535843, 'epsilon': 2.9691371613286077e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0005268862053375657, 'tol': 0.002542839734748548, 'validation_fraction': 0.2741588250427887}]
function_evaluation time 0.623549 value 0.490382 suggestion {'alpha': 0.6107248833154281, 'batch_size': 50, 'beta_1': 0.5549662596739598, 'beta_2': 0.9999920017535843, 'epsilon': 2.9691371613286077e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0005268862053375657, 'tol': 0.002542839734748548, 'validation_fraction': 0.2741588250427887}
observation time 0.000010, current best 0.265529 at iter 14
suggestion time taken 19.869458 iter 15 next_points [{'alpha': 0.22446588202093365, 'batch_size': 225, 'beta_1': 0.9239744544339509, 'beta_2': 0.9557301416364531, 'epsilon': 5.779034463534757e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 4.4484058881257464e-05, 'tol': 0.0018146851178586912, 'validation_fraction': 0.5837481335221137}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.392251 value 13.933762 suggestion {'alpha': 0.22446588202093365, 'batch_size': 225, 'beta_1': 0.9239744544339509, 'beta_2': 0.9557301416364531, 'epsilon': 5.779034463534757e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 4.4484058881257464e-05, 'tol': 0.0018146851178586912, 'validation_fraction': 0.5837481335221137}
observation time 0.000008, current best 0.265529 at iter 15
suggestion time taken 18.811371 iter 16 next_points [{'alpha': 7.996275035095491, 'batch_size': 28, 'beta_1': 0.6570483181587253, 'beta_2': 0.9597250076238637, 'epsilon': 1.7091084833294822e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.08651595410885408, 'tol': 3.2047955858021274e-05, 'validation_fraction': 0.12178072772290878}]
function_evaluation time 0.933490 value 0.466325 suggestion {'alpha': 7.996275035095491, 'batch_size': 28, 'beta_1': 0.6570483181587253, 'beta_2': 0.9597250076238637, 'epsilon': 1.7091084833294822e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.08651595410885408, 'tol': 3.2047955858021274e-05, 'validation_fraction': 0.12178072772290878}
observation time 0.000016, current best 0.265529 at iter 16
suggestion time taken 20.547594 iter 17 next_points [{'alpha': 0.00019124079508503375, 'batch_size': 18, 'beta_1': 0.9634794500342865, 'beta_2': 0.999955077446493, 'epsilon': 1.984780331581259e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0013564847935421652, 'tol': 0.003155659986775993, 'validation_fraction': 0.4090169141299402}]
function_evaluation time 1.266626 value 0.623746 suggestion {'alpha': 0.00019124079508503375, 'batch_size': 18, 'beta_1': 0.9634794500342865, 'beta_2': 0.999955077446493, 'epsilon': 1.984780331581259e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0013564847935421652, 'tol': 0.003155659986775993, 'validation_fraction': 0.4090169141299402}
observation time 0.000021, current best 0.265529 at iter 17
suggestion time taken 20.944661 iter 18 next_points [{'alpha': 0.00010344005732236192, 'batch_size': 50, 'beta_1': 0.8454713397494013, 'beta_2': 0.9999950900605337, 'epsilon': 5.121758260760402e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.015001396646151409, 'tol': 0.00026388962549307173, 'validation_fraction': 0.6526080557521061}]
function_evaluation time 0.827744 value 0.991359 suggestion {'alpha': 0.00010344005732236192, 'batch_size': 50, 'beta_1': 0.8454713397494013, 'beta_2': 0.9999950900605337, 'epsilon': 5.121758260760402e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.015001396646151409, 'tol': 0.00026388962549307173, 'validation_fraction': 0.6526080557521061}
observation time 0.000008, current best 0.265529 at iter 18
suggestion time taken 19.956620 iter 19 next_points [{'alpha': 1.584939816583116e-05, 'batch_size': 220, 'beta_1': 0.9770370493865537, 'beta_2': 0.9994102926238339, 'epsilon': 1.5647777344658444e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 2.096231495580795e-05, 'tol': 0.017806095180525307, 'validation_fraction': 0.43183107906919554}]
function_evaluation time 0.260407 value 18.180454 suggestion {'alpha': 1.584939816583116e-05, 'batch_size': 220, 'beta_1': 0.9770370493865537, 'beta_2': 0.9994102926238339, 'epsilon': 1.5647777344658444e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 2.096231495580795e-05, 'tol': 0.017806095180525307, 'validation_fraction': 0.43183107906919554}
observation time 0.000007, current best 0.265529 at iter 19
suggestion time taken 18.926925 iter 20 next_points [{'alpha': 1.279259531445074e-05, 'batch_size': 10, 'beta_1': 0.9708843607163863, 'beta_2': 0.9890074943324255, 'epsilon': 1.2846609817311223e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 7.175002127321089e-05, 'tol': 0.0003065966441527802, 'validation_fraction': 0.22417422983361382}]
function_evaluation time 1.564666 value 4.890298 suggestion {'alpha': 1.279259531445074e-05, 'batch_size': 10, 'beta_1': 0.9708843607163863, 'beta_2': 0.9890074943324255, 'epsilon': 1.2846609817311223e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 7.175002127321089e-05, 'tol': 0.0003065966441527802, 'validation_fraction': 0.22417422983361382}
observation time 0.000005, current best 0.265529 at iter 20
suggestion time taken 20.528075 iter 21 next_points [{'alpha': 3.207700138671244e-05, 'batch_size': 227, 'beta_1': 0.8081212682099201, 'beta_2': 0.9999933627855883, 'epsilon': 5.364937963433488e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.002671737329212475, 'tol': 1.4667571485582507e-05, 'validation_fraction': 0.6702744528548041}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.694215 value 0.778915 suggestion {'alpha': 3.207700138671244e-05, 'batch_size': 227, 'beta_1': 0.8081212682099201, 'beta_2': 0.9999933627855883, 'epsilon': 5.364937963433488e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.002671737329212475, 'tol': 1.4667571485582507e-05, 'validation_fraction': 0.6702744528548041}
observation time 0.000009, current best 0.265529 at iter 21
suggestion time taken 19.851323 iter 22 next_points [{'alpha': 0.04507590877281458, 'batch_size': 90, 'beta_1': 0.8634260356080302, 'beta_2': 0.9989235187380548, 'epsilon': 8.722041137570363e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 9.025197062131218e-05, 'tol': 0.000729235272786212, 'validation_fraction': 0.8955828957914465}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.391074 value 13.366513 suggestion {'alpha': 0.04507590877281458, 'batch_size': 90, 'beta_1': 0.8634260356080302, 'beta_2': 0.9989235187380548, 'epsilon': 8.722041137570363e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 9.025197062131218e-05, 'tol': 0.000729235272786212, 'validation_fraction': 0.8955828957914465}
observation time 0.000009, current best 0.265529 at iter 22
suggestion time taken 19.893642 iter 23 next_points [{'alpha': 0.061399112195706776, 'batch_size': 12, 'beta_1': 0.6597276690488837, 'beta_2': 0.9862167616923151, 'epsilon': 4.2369947512739195e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 2.0257196275254343e-05, 'tol': 1.3373593442002113e-05, 'validation_fraction': 0.7970109411462865}]
function_evaluation time 0.985205 value 5.494572 suggestion {'alpha': 0.061399112195706776, 'batch_size': 12, 'beta_1': 0.6597276690488837, 'beta_2': 0.9862167616923151, 'epsilon': 4.2369947512739195e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 2.0257196275254343e-05, 'tol': 1.3373593442002113e-05, 'validation_fraction': 0.7970109411462865}
observation time 0.000015, current best 0.265529 at iter 23
suggestion time taken 21.178972 iter 24 next_points [{'alpha': 1.3230638433462396e-05, 'batch_size': 11, 'beta_1': 0.871949556108357, 'beta_2': 0.9590030764096319, 'epsilon': 4.135868917770602e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 1.351487172394417e-05, 'tol': 0.002910284939443173, 'validation_fraction': 0.2416857214207931}]
function_evaluation time 3.268640 value 7.120460 suggestion {'alpha': 1.3230638433462396e-05, 'batch_size': 11, 'beta_1': 0.871949556108357, 'beta_2': 0.9590030764096319, 'epsilon': 4.135868917770602e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 1.351487172394417e-05, 'tol': 0.002910284939443173, 'validation_fraction': 0.2416857214207931}
observation time 0.000008, current best 0.265529 at iter 24
suggestion time taken 20.317384 iter 25 next_points [{'alpha': 3.5127076232478034, 'batch_size': 225, 'beta_1': 0.9687461718032031, 'beta_2': 0.9999617925302816, 'epsilon': 8.295221343274686e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0011522834937269097, 'tol': 0.0070139010418932835, 'validation_fraction': 0.5403029909698216}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.684384 value 2.573660 suggestion {'alpha': 3.5127076232478034, 'batch_size': 225, 'beta_1': 0.9687461718032031, 'beta_2': 0.9999617925302816, 'epsilon': 8.295221343274686e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0011522834937269097, 'tol': 0.0070139010418932835, 'validation_fraction': 0.5403029909698216}
observation time 0.000007, current best 0.265529 at iter 25
suggestion time taken 19.231367 iter 26 next_points [{'alpha': 0.00022277957323825015, 'batch_size': 227, 'beta_1': 0.8867086785968377, 'beta_2': 0.999399765428919, 'epsilon': 1.6842224735046762e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.05645678026509384, 'tol': 0.002445430289950428, 'validation_fraction': 0.33514617628739585}]
function_evaluation time 0.722025 value 3.037519 suggestion {'alpha': 0.00022277957323825015, 'batch_size': 227, 'beta_1': 0.8867086785968377, 'beta_2': 0.999399765428919, 'epsilon': 1.6842224735046762e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.05645678026509384, 'tol': 0.002445430289950428, 'validation_fraction': 0.33514617628739585}
observation time 0.000007, current best 0.265529 at iter 26
suggestion time taken 20.593482 iter 27 next_points [{'alpha': 2.7943510078505835, 'batch_size': 224, 'beta_1': 0.9867932898051222, 'beta_2': 0.9999597130723681, 'epsilon': 9.263588729399024e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.00010084590400660964, 'tol': 0.07366405725657087, 'validation_fraction': 0.5537160766038356}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.359226 value 10.087975 suggestion {'alpha': 2.7943510078505835, 'batch_size': 224, 'beta_1': 0.9867932898051222, 'beta_2': 0.9999597130723681, 'epsilon': 9.263588729399024e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.00010084590400660964, 'tol': 0.07366405725657087, 'validation_fraction': 0.5537160766038356}
observation time 0.000010, current best 0.265529 at iter 27
suggestion time taken 19.187433 iter 28 next_points [{'alpha': 4.062701651811079, 'batch_size': 227, 'beta_1': 0.9585846115524322, 'beta_2': 0.9986413057560121, 'epsilon': 3.001616593691841e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0006260940669287632, 'tol': 0.0009658404632490364, 'validation_fraction': 0.7017788732084914}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.795676 value 6.778872 suggestion {'alpha': 4.062701651811079, 'batch_size': 227, 'beta_1': 0.9585846115524322, 'beta_2': 0.9986413057560121, 'epsilon': 3.001616593691841e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0006260940669287632, 'tol': 0.0009658404632490364, 'validation_fraction': 0.7017788732084914}
observation time 0.000010, current best 0.265529 at iter 28
suggestion time taken 21.431562 iter 29 next_points [{'alpha': 0.35138862737523774, 'batch_size': 151, 'beta_1': 0.9830093722053426, 'beta_2': 0.9949227579478699, 'epsilon': 1.0396882967012449e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.0001694064947860417, 'tol': 0.06457153047526608, 'validation_fraction': 0.7803468712482227}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.292578 value 12.484521 suggestion {'alpha': 0.35138862737523774, 'batch_size': 151, 'beta_1': 0.9830093722053426, 'beta_2': 0.9949227579478699, 'epsilon': 1.0396882967012449e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.0001694064947860417, 'tol': 0.06457153047526608, 'validation_fraction': 0.7803468712482227}
observation time 0.000005, current best 0.265529 at iter 29
suggestion time taken 20.217704 iter 30 next_points [{'alpha': 8.495369324470436, 'batch_size': 111, 'beta_1': 0.8705953919466854, 'beta_2': 0.9999928507223591, 'epsilon': 3.441393327652817e-09, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.03361573125326625, 'tol': 1.380787949957181e-05, 'validation_fraction': 0.6731128814367958}]
function_evaluation time 0.930733 value 0.443119 suggestion {'alpha': 8.495369324470436, 'batch_size': 111, 'beta_1': 0.8705953919466854, 'beta_2': 0.9999928507223591, 'epsilon': 3.441393327652817e-09, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.03361573125326625, 'tol': 1.380787949957181e-05, 'validation_fraction': 0.6731128814367958}
observation time 0.000007, current best 0.265529 at iter 30
suggestion time taken 21.435037 iter 31 next_points [{'alpha': 7.606711369277635e-05, 'batch_size': 226, 'beta_1': 0.6189798075313954, 'beta_2': 0.9999096829880114, 'epsilon': 5.010959971577246e-09, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.029895295385527938, 'tol': 0.014265590140418477, 'validation_fraction': 0.8818507809044739}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.639401 value 0.897029 suggestion {'alpha': 7.606711369277635e-05, 'batch_size': 226, 'beta_1': 0.6189798075313954, 'beta_2': 0.9999096829880114, 'epsilon': 5.010959971577246e-09, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.029895295385527938, 'tol': 0.014265590140418477, 'validation_fraction': 0.8818507809044739}
observation time 0.000006, current best 0.265529 at iter 31
suggestion time taken 19.786917 iter 32 next_points [{'alpha': 0.012724451248562557, 'batch_size': 18, 'beta_1': 0.6626414283913428, 'beta_2': 0.9994197051159212, 'epsilon': 9.158440876007922e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.0007598928563891378, 'tol': 0.005953887262569803, 'validation_fraction': 0.1540102329603236}]
function_evaluation time 1.607479 value 0.419546 suggestion {'alpha': 0.012724451248562557, 'batch_size': 18, 'beta_1': 0.6626414283913428, 'beta_2': 0.9994197051159212, 'epsilon': 9.158440876007922e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.0007598928563891378, 'tol': 0.005953887262569803, 'validation_fraction': 0.1540102329603236}
observation time 0.000010, current best 0.265529 at iter 32
suggestion time taken 21.276053 iter 33 next_points [{'alpha': 1.4330812359275568e-05, 'batch_size': 226, 'beta_1': 0.9771806854300745, 'beta_2': 0.9548609433870574, 'epsilon': 1.327078746045673e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0842322601294856, 'tol': 0.04677096160410021, 'validation_fraction': 0.2979289677414797}]
function_evaluation time 0.638350 value 0.346560 suggestion {'alpha': 1.4330812359275568e-05, 'batch_size': 226, 'beta_1': 0.9771806854300745, 'beta_2': 0.9548609433870574, 'epsilon': 1.327078746045673e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0842322601294856, 'tol': 0.04677096160410021, 'validation_fraction': 0.2979289677414797}
observation time 0.000014, current best 0.265529 at iter 33
suggestion time taken 19.958045 iter 34 next_points [{'alpha': 0.4567119733827804, 'batch_size': 11, 'beta_1': 0.7880060777728349, 'beta_2': 0.9950950296151617, 'epsilon': 6.753100707633553e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0005511605619721312, 'tol': 0.003992124121626579, 'validation_fraction': 0.8358731009593211}]
function_evaluation time 1.381048 value 0.580000 suggestion {'alpha': 0.4567119733827804, 'batch_size': 11, 'beta_1': 0.7880060777728349, 'beta_2': 0.9950950296151617, 'epsilon': 6.753100707633553e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0005511605619721312, 'tol': 0.003992124121626579, 'validation_fraction': 0.8358731009593211}
observation time 0.000017, current best 0.265529 at iter 34
suggestion time taken 21.389459 iter 35 next_points [{'alpha': 0.013358165184113834, 'batch_size': 226, 'beta_1': 0.9840260282865979, 'beta_2': 0.9997320754296669, 'epsilon': 1.6950158874024867e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0028369300965699223, 'tol': 0.00028729484298796145, 'validation_fraction': 0.511076967981375}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.522771 value 1.611298 suggestion {'alpha': 0.013358165184113834, 'batch_size': 226, 'beta_1': 0.9840260282865979, 'beta_2': 0.9997320754296669, 'epsilon': 1.6950158874024867e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0028369300965699223, 'tol': 0.00028729484298796145, 'validation_fraction': 0.511076967981375}
observation time 0.000005, current best 0.265529 at iter 35
suggestion time taken 20.613899 iter 36 next_points [{'alpha': 0.25641782241456273, 'batch_size': 15, 'beta_1': 0.9577317796387004, 'beta_2': 0.9988628135192299, 'epsilon': 2.3224832499370716e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.056739033110840026, 'tol': 0.00019038951144266462, 'validation_fraction': 0.336155510106409}]
function_evaluation time 2.162899 value 0.888946 suggestion {'alpha': 0.25641782241456273, 'batch_size': 15, 'beta_1': 0.9577317796387004, 'beta_2': 0.9988628135192299, 'epsilon': 2.3224832499370716e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.056739033110840026, 'tol': 0.00019038951144266462, 'validation_fraction': 0.336155510106409}
observation time 0.000006, current best 0.265529 at iter 36
suggestion time taken 21.462356 iter 37 next_points [{'alpha': 3.1987513793577547, 'batch_size': 151, 'beta_1': 0.9653386857779964, 'beta_2': 0.9997831567160138, 'epsilon': 7.119693375304275e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 1.0875306556797232e-05, 'tol': 0.00891083698941621, 'validation_fraction': 0.11498145000117273}]
function_evaluation time 0.511759 value 12.959285 suggestion {'alpha': 3.1987513793577547, 'batch_size': 151, 'beta_1': 0.9653386857779964, 'beta_2': 0.9997831567160138, 'epsilon': 7.119693375304275e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 1.0875306556797232e-05, 'tol': 0.00891083698941621, 'validation_fraction': 0.11498145000117273}
observation time 0.000007, current best 0.265529 at iter 37
suggestion time taken 20.409105 iter 38 next_points [{'alpha': 0.01764204050631688, 'batch_size': 151, 'beta_1': 0.9882011637550769, 'beta_2': 0.9993724769888972, 'epsilon': 1.981659347854233e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.01045119726579996, 'tol': 0.00039708621086328, 'validation_fraction': 0.1753196432408323}]
function_evaluation time 0.959509 value 1.491731 suggestion {'alpha': 0.01764204050631688, 'batch_size': 151, 'beta_1': 0.9882011637550769, 'beta_2': 0.9993724769888972, 'epsilon': 1.981659347854233e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.01045119726579996, 'tol': 0.00039708621086328, 'validation_fraction': 0.1753196432408323}
observation time 0.000005, current best 0.265529 at iter 38
suggestion time taken 19.611326 iter 39 next_points [{'alpha': 2.962354648770216, 'batch_size': 226, 'beta_1': 0.9512110200085365, 'beta_2': 0.9999716409361861, 'epsilon': 8.100567019836823e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.016470229232453677, 'tol': 0.0016278084649651058, 'validation_fraction': 0.7860826780796691}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.746752 value 0.973617 suggestion {'alpha': 2.962354648770216, 'batch_size': 226, 'beta_1': 0.9512110200085365, 'beta_2': 0.9999716409361861, 'epsilon': 8.100567019836823e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.016470229232453677, 'tol': 0.0016278084649651058, 'validation_fraction': 0.7860826780796691}
observation time 0.000005, current best 0.265529 at iter 39
suggestion time taken 21.494717 iter 40 next_points [{'alpha': 6.964749703793938, 'batch_size': 151, 'beta_1': 0.7926186548571628, 'beta_2': 0.9998266834117872, 'epsilon': 2.840847451917332e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 2.7041655988464894e-05, 'tol': 0.0002716255018112889, 'validation_fraction': 0.2594540419170906}]
function_evaluation time 0.437625 value 12.350131 suggestion {'alpha': 6.964749703793938, 'batch_size': 151, 'beta_1': 0.7926186548571628, 'beta_2': 0.9998266834117872, 'epsilon': 2.840847451917332e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 2.7041655988464894e-05, 'tol': 0.0002716255018112889, 'validation_fraction': 0.2594540419170906}
observation time 0.000013, current best 0.265529 at iter 40
suggestion time taken 19.763864 iter 41 next_points [{'alpha': 0.0031297420273322355, 'batch_size': 227, 'beta_1': 0.613284385560184, 'beta_2': 0.9999980781107043, 'epsilon': 2.092102927769781e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 7.425634492485501e-05, 'tol': 0.035314342793958536, 'validation_fraction': 0.797750287423726}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.289919 value 9.621925 suggestion {'alpha': 0.0031297420273322355, 'batch_size': 227, 'beta_1': 0.613284385560184, 'beta_2': 0.9999980781107043, 'epsilon': 2.092102927769781e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 7.425634492485501e-05, 'tol': 0.035314342793958536, 'validation_fraction': 0.797750287423726}
observation time 0.000008, current best 0.265529 at iter 41
suggestion time taken 21.444953 iter 42 next_points [{'alpha': 0.00368662295488697, 'batch_size': 50, 'beta_1': 0.9409237026913876, 'beta_2': 0.996779442528636, 'epsilon': 3.76456275325762e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.005765493832644446, 'tol': 0.03399922564785142, 'validation_fraction': 0.8809555803397545}]
function_evaluation time 0.464910 value 1.389004 suggestion {'alpha': 0.00368662295488697, 'batch_size': 50, 'beta_1': 0.9409237026913876, 'beta_2': 0.996779442528636, 'epsilon': 3.76456275325762e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.005765493832644446, 'tol': 0.03399922564785142, 'validation_fraction': 0.8809555803397545}
observation time 0.000012, current best 0.265529 at iter 42
suggestion time taken 20.552740 iter 43 next_points [{'alpha': 0.01138674284715241, 'batch_size': 12, 'beta_1': 0.6957857134335265, 'beta_2': 0.9998802114688015, 'epsilon': 3.910495211010558e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.0068799933898142825, 'tol': 5.250819739868684e-05, 'validation_fraction': 0.5012201045361595}]
function_evaluation time 2.869645 value 1.092346 suggestion {'alpha': 0.01138674284715241, 'batch_size': 12, 'beta_1': 0.6957857134335265, 'beta_2': 0.9998802114688015, 'epsilon': 3.910495211010558e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.0068799933898142825, 'tol': 5.250819739868684e-05, 'validation_fraction': 0.5012201045361595}
observation time 0.000005, current best 0.265529 at iter 43
suggestion time taken 20.059426 iter 44 next_points [{'alpha': 0.05034828022591259, 'batch_size': 16, 'beta_1': 0.9130759094507673, 'beta_2': 0.9972221461276699, 'epsilon': 6.730093490035102e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 3.505806022269385e-05, 'tol': 3.220023335191872e-05, 'validation_fraction': 0.17068485783334944}]
function_evaluation time 0.972132 value 6.697983 suggestion {'alpha': 0.05034828022591259, 'batch_size': 16, 'beta_1': 0.9130759094507673, 'beta_2': 0.9972221461276699, 'epsilon': 6.730093490035102e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 3.505806022269385e-05, 'tol': 3.220023335191872e-05, 'validation_fraction': 0.17068485783334944}
observation time 0.000013, current best 0.265529 at iter 44
saving meta data: {'args': {'--uuid': 'ec7a128d7fb250dc9ce7ecb3e25bc8e5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])}
saving results
saving timing
saving suggest log
done
