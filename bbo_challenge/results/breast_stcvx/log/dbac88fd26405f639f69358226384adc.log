running: {'--uuid': 'dbac88fd26405f639f69358226384adc', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d breast -o strongcvx -u dbac88fd26405f639f69358226384adc -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam breast acc 45 1
with data root: None
suggestion time taken 21.344799 iter 0 next_points [{'alpha': 0.00035716749371319595, 'batch_size': 18, 'beta_1': 0.6583068078614306, 'beta_2': 0.9999236742678101, 'epsilon': 4.166556128420841e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.05501747110687056, 'tol': 0.018247707385439006, 'validation_fraction': 0.8387637213137731}]
function_evaluation time 0.624714 value -0.905495 suggestion {'alpha': 0.00035716749371319595, 'batch_size': 18, 'beta_1': 0.6583068078614306, 'beta_2': 0.9999236742678101, 'epsilon': 4.166556128420841e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.05501747110687056, 'tol': 0.018247707385439006, 'validation_fraction': 0.8387637213137731}
observation time 0.000009, current best -0.905495 at iter 0
suggestion time taken 22.627810 iter 1 next_points [{'alpha': 0.2030163439979175, 'batch_size': 225, 'beta_1': 0.906823055217766, 'beta_2': 0.9486663680109534, 'epsilon': 5.905288414846157e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 3.812664632448172e-05, 'tol': 0.011693021042993095, 'validation_fraction': 0.18132983987495124}]
function_evaluation time 0.698595 value -0.545055 suggestion {'alpha': 0.2030163439979175, 'batch_size': 225, 'beta_1': 0.906823055217766, 'beta_2': 0.9486663680109534, 'epsilon': 5.905288414846157e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 3.812664632448172e-05, 'tol': 0.011693021042993095, 'validation_fraction': 0.18132983987495124}
observation time 0.000006, current best -0.905495 at iter 1
suggestion time taken 21.678903 iter 2 next_points [{'alpha': 0.022654013758680046, 'batch_size': 113, 'beta_1': 0.577823207368639, 'beta_2': 0.9992094586081713, 'epsilon': 3.020266567865864e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.02306928783085432, 'tol': 0.0011100162042239413, 'validation_fraction': 0.5038825597596167}]
function_evaluation time 0.767521 value -0.901099 suggestion {'alpha': 0.022654013758680046, 'batch_size': 113, 'beta_1': 0.577823207368639, 'beta_2': 0.9992094586081713, 'epsilon': 3.020266567865864e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.02306928783085432, 'tol': 0.0011100162042239413, 'validation_fraction': 0.5038825597596167}
observation time 0.000006, current best -0.905495 at iter 2
suggestion time taken 23.130164 iter 3 next_points [{'alpha': 0.19632057855334875, 'batch_size': 25, 'beta_1': 0.6506137578681036, 'beta_2': 0.9957540923082723, 'epsilon': 1.5773609481368552e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.005795338333418308, 'tol': 5.313927807204324e-05, 'validation_fraction': 0.18468793744603898}]
function_evaluation time 2.023752 value -0.912088 suggestion {'alpha': 0.19632057855334875, 'batch_size': 25, 'beta_1': 0.6506137578681036, 'beta_2': 0.9957540923082723, 'epsilon': 1.5773609481368552e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.005795338333418308, 'tol': 5.313927807204324e-05, 'validation_fraction': 0.18468793744603898}
observation time 0.000007, current best -0.912088 at iter 3
suggestion time taken 26.030226 iter 4 next_points [{'alpha': 1.2273277585911224, 'batch_size': 74, 'beta_1': 0.9820196182726142, 'beta_2': 0.9917592366569786, 'epsilon': 9.67153681419026e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 2.5049616837739724e-05, 'tol': 1.1057618594516232e-05, 'validation_fraction': 0.6654418141948616}]
function_evaluation time 1.075362 value -0.472527 suggestion {'alpha': 1.2273277585911224, 'batch_size': 74, 'beta_1': 0.9820196182726142, 'beta_2': 0.9917592366569786, 'epsilon': 9.67153681419026e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 2.5049616837739724e-05, 'tol': 1.1057618594516232e-05, 'validation_fraction': 0.6654418141948616}
observation time 0.000010, current best -0.912088 at iter 4
suggestion time taken 22.622792 iter 5 next_points [{'alpha': 0.0023369816614002485, 'batch_size': 41, 'beta_1': 0.9799408548688135, 'beta_2': 0.996545824835354, 'epsilon': 1.0858672410153589e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.009933196360587366, 'tol': 2.0622276992026717e-05, 'validation_fraction': 0.5904654144821962}]
function_evaluation time 1.073118 value -0.914286 suggestion {'alpha': 0.0023369816614002485, 'batch_size': 41, 'beta_1': 0.9799408548688135, 'beta_2': 0.996545824835354, 'epsilon': 1.0858672410153589e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.009933196360587366, 'tol': 2.0622276992026717e-05, 'validation_fraction': 0.5904654144821962}
observation time 0.000011, current best -0.914286 at iter 5
suggestion time taken 22.482573 iter 6 next_points [{'alpha': 0.7260263121655604, 'batch_size': 16, 'beta_1': 0.5727377505981514, 'beta_2': 0.9833977734795475, 'epsilon': 1.4806103371377074e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.03807971728530565, 'tol': 0.0001349520677378205, 'validation_fraction': 0.3174547641365367}]
function_evaluation time 2.095451 value -0.896703 suggestion {'alpha': 0.7260263121655604, 'batch_size': 16, 'beta_1': 0.5727377505981514, 'beta_2': 0.9833977734795475, 'epsilon': 1.4806103371377074e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.03807971728530565, 'tol': 0.0001349520677378205, 'validation_fraction': 0.3174547641365367}
observation time 0.000013, current best -0.914286 at iter 6
suggestion time taken 22.302163 iter 7 next_points [{'alpha': 0.8530692112209745, 'batch_size': 227, 'beta_1': 0.5759441434135125, 'beta_2': 0.9999988689180509, 'epsilon': 2.3617711198606264e-08, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.0003086248429763213, 'tol': 0.00012927800956107947, 'validation_fraction': 0.8064403943506678}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 1.008738 value -0.725275 suggestion {'alpha': 0.8530692112209745, 'batch_size': 227, 'beta_1': 0.5759441434135125, 'beta_2': 0.9999988689180509, 'epsilon': 2.3617711198606264e-08, 'hidden_layer_sizes': 200, 'learning_rate_init': 0.0003086248429763213, 'tol': 0.00012927800956107947, 'validation_fraction': 0.8064403943506678}
observation time 0.000010, current best -0.914286 at iter 7
suggestion time taken 23.184896 iter 8 next_points [{'alpha': 0.19960623286168822, 'batch_size': 15, 'beta_1': 0.9865933888309061, 'beta_2': 0.9999580349065895, 'epsilon': 1.2376401929756864e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.0006093939954304371, 'tol': 0.005600392908869783, 'validation_fraction': 0.1812825932725696}]
function_evaluation time 2.811634 value -0.903297 suggestion {'alpha': 0.19960623286168822, 'batch_size': 15, 'beta_1': 0.9865933888309061, 'beta_2': 0.9999580349065895, 'epsilon': 1.2376401929756864e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.0006093939954304371, 'tol': 0.005600392908869783, 'validation_fraction': 0.1812825932725696}
observation time 0.000012, current best -0.914286 at iter 8
suggestion time taken 22.038135 iter 9 next_points [{'alpha': 6.066854032533368e-05, 'batch_size': 227, 'beta_1': 0.94971934537519, 'beta_2': 0.9987351323052173, 'epsilon': 1.33472635309239e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0021147237263365462, 'tol': 0.08944185943541876, 'validation_fraction': 0.3497817250413256}]
function_evaluation time 0.593525 value -0.894505 suggestion {'alpha': 6.066854032533368e-05, 'batch_size': 227, 'beta_1': 0.94971934537519, 'beta_2': 0.9987351323052173, 'epsilon': 1.33472635309239e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0021147237263365462, 'tol': 0.08944185943541876, 'validation_fraction': 0.3497817250413256}
observation time 0.000007, current best -0.914286 at iter 9
suggestion time taken 25.066614 iter 10 next_points [{'alpha': 3.080598532402213, 'batch_size': 62, 'beta_1': 0.7508726343223613, 'beta_2': 0.9938020139163174, 'epsilon': 3.4549022486003413e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00038570359946524615, 'tol': 0.004229186739619406, 'validation_fraction': 0.2349932821853628}]
function_evaluation time 0.902128 value -0.887912 suggestion {'alpha': 3.080598532402213, 'batch_size': 62, 'beta_1': 0.7508726343223613, 'beta_2': 0.9938020139163174, 'epsilon': 3.4549022486003413e-07, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00038570359946524615, 'tol': 0.004229186739619406, 'validation_fraction': 0.2349932821853628}
observation time 0.000008, current best -0.914286 at iter 10
suggestion time taken 21.633104 iter 11 next_points [{'alpha': 2.24164436654024, 'batch_size': 30, 'beta_1': 0.9891482274395766, 'beta_2': 0.9999970360621842, 'epsilon': 1.2664027834517803e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.01733368361089702, 'tol': 0.03457062607471042, 'validation_fraction': 0.5998822816852604}]
function_evaluation time 1.016505 value -0.901099 suggestion {'alpha': 2.24164436654024, 'batch_size': 30, 'beta_1': 0.9891482274395766, 'beta_2': 0.9999970360621842, 'epsilon': 1.2664027834517803e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.01733368361089702, 'tol': 0.03457062607471042, 'validation_fraction': 0.5998822816852604}
observation time 0.000008, current best -0.914286 at iter 11
suggestion time taken 23.877603 iter 12 next_points [{'alpha': 0.4554595045773247, 'batch_size': 151, 'beta_1': 0.9885265173671007, 'beta_2': 0.9999981328523136, 'epsilon': 6.674665013477788e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.07197463188484884, 'tol': 8.724892776053484e-05, 'validation_fraction': 0.20209961017177805}]
function_evaluation time 0.751935 value -0.753846 suggestion {'alpha': 0.4554595045773247, 'batch_size': 151, 'beta_1': 0.9885265173671007, 'beta_2': 0.9999981328523136, 'epsilon': 6.674665013477788e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.07197463188484884, 'tol': 8.724892776053484e-05, 'validation_fraction': 0.20209961017177805}
observation time 0.000011, current best -0.914286 at iter 12
suggestion time taken 23.015487 iter 13 next_points [{'alpha': 5.384199834035022e-05, 'batch_size': 15, 'beta_1': 0.9313253434740764, 'beta_2': 0.9994952258519787, 'epsilon': 4.163197251562419e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.00013735177809757397, 'tol': 0.00021600089373772168, 'validation_fraction': 0.8327656734833758}]
function_evaluation time 1.273653 value -0.626374 suggestion {'alpha': 5.384199834035022e-05, 'batch_size': 15, 'beta_1': 0.9313253434740764, 'beta_2': 0.9994952258519787, 'epsilon': 4.163197251562419e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.00013735177809757397, 'tol': 0.00021600089373772168, 'validation_fraction': 0.8327656734833758}
observation time 0.000008, current best -0.914286 at iter 13
suggestion time taken 22.545247 iter 14 next_points [{'alpha': 0.04475287560962631, 'batch_size': 227, 'beta_1': 0.888384380884659, 'beta_2': 0.9999775068456073, 'epsilon': 1.473000079704591e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 3.806595328486732e-05, 'tol': 0.05246273678873457, 'validation_fraction': 0.8656203970674223}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.258548 value -0.573626 suggestion {'alpha': 0.04475287560962631, 'batch_size': 227, 'beta_1': 0.888384380884659, 'beta_2': 0.9999775068456073, 'epsilon': 1.473000079704591e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 3.806595328486732e-05, 'tol': 0.05246273678873457, 'validation_fraction': 0.8656203970674223}
observation time 0.000005, current best -0.914286 at iter 14
suggestion time taken 25.774756 iter 15 next_points [{'alpha': 0.00016639516077699196, 'batch_size': 30, 'beta_1': 0.5691937069683719, 'beta_2': 0.9329375244400936, 'epsilon': 9.25796313481471e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.011765345855221258, 'tol': 0.03261521999239873, 'validation_fraction': 0.38577937406220314}]
function_evaluation time 0.962506 value -0.896703 suggestion {'alpha': 0.00016639516077699196, 'batch_size': 30, 'beta_1': 0.5691937069683719, 'beta_2': 0.9329375244400936, 'epsilon': 9.25796313481471e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.011765345855221258, 'tol': 0.03261521999239873, 'validation_fraction': 0.38577937406220314}
observation time 0.000014, current best -0.914286 at iter 15
suggestion time taken 21.844541 iter 16 next_points [{'alpha': 0.06988826540003024, 'batch_size': 75, 'beta_1': 0.6962534004954878, 'beta_2': 0.995012708154032, 'epsilon': 1.974192973924979e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 3.078823002978263e-05, 'tol': 4.744303110987635e-05, 'validation_fraction': 0.24645203388368753}]
function_evaluation time 0.574011 value -0.549451 suggestion {'alpha': 0.06988826540003024, 'batch_size': 75, 'beta_1': 0.6962534004954878, 'beta_2': 0.995012708154032, 'epsilon': 1.974192973924979e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 3.078823002978263e-05, 'tol': 4.744303110987635e-05, 'validation_fraction': 0.24645203388368753}
observation time 0.000006, current best -0.914286 at iter 16
suggestion time taken 21.927749 iter 17 next_points [{'alpha': 2.0140713890222792, 'batch_size': 41, 'beta_1': 0.7824050358858876, 'beta_2': 0.9885431758002325, 'epsilon': 6.513049966433271e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 2.5528141820480442e-05, 'tol': 0.0006909145045023859, 'validation_fraction': 0.6637535988266496}]
function_evaluation time 0.515734 value -0.476923 suggestion {'alpha': 2.0140713890222792, 'batch_size': 41, 'beta_1': 0.7824050358858876, 'beta_2': 0.9885431758002325, 'epsilon': 6.513049966433271e-07, 'hidden_layer_sizes': 171, 'learning_rate_init': 2.5528141820480442e-05, 'tol': 0.0006909145045023859, 'validation_fraction': 0.6637535988266496}
observation time 0.000011, current best -0.914286 at iter 17
suggestion time taken 20.486603 iter 18 next_points [{'alpha': 0.22132891150033976, 'batch_size': 225, 'beta_1': 0.9413539109198686, 'beta_2': 0.9824085211634199, 'epsilon': 1.1844505419083625e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.08294888818849015, 'tol': 0.0005587172080667184, 'validation_fraction': 0.8654551310741154}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.349192 value -0.786813 suggestion {'alpha': 0.22132891150033976, 'batch_size': 225, 'beta_1': 0.9413539109198686, 'beta_2': 0.9824085211634199, 'epsilon': 1.1844505419083625e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.08294888818849015, 'tol': 0.0005587172080667184, 'validation_fraction': 0.8654551310741154}
observation time 0.000007, current best -0.914286 at iter 18
suggestion time taken 22.709320 iter 19 next_points [{'alpha': 0.8040609183159197, 'batch_size': 151, 'beta_1': 0.9730297974723771, 'beta_2': 0.9823501776429874, 'epsilon': 3.447275594744393e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0017510490740640493, 'tol': 7.249400321095978e-05, 'validation_fraction': 0.10090626017267541}]
function_evaluation time 0.979585 value -0.870330 suggestion {'alpha': 0.8040609183159197, 'batch_size': 151, 'beta_1': 0.9730297974723771, 'beta_2': 0.9823501776429874, 'epsilon': 3.447275594744393e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0017510490740640493, 'tol': 7.249400321095978e-05, 'validation_fraction': 0.10090626017267541}
observation time 0.000008, current best -0.914286 at iter 19
suggestion time taken 22.760657 iter 20 next_points [{'alpha': 3.108271440009273, 'batch_size': 223, 'beta_1': 0.9360022575141203, 'beta_2': 0.9999204855900371, 'epsilon': 1.0799239900733703e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 2.9810713648135603e-05, 'tol': 0.00017491038747109556, 'validation_fraction': 0.8108027632833036}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.596849 value -0.527473 suggestion {'alpha': 3.108271440009273, 'batch_size': 223, 'beta_1': 0.9360022575141203, 'beta_2': 0.9999204855900371, 'epsilon': 1.0799239900733703e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 2.9810713648135603e-05, 'tol': 0.00017491038747109556, 'validation_fraction': 0.8108027632833036}
observation time 0.000010, current best -0.914286 at iter 20
suggestion time taken 25.594378 iter 21 next_points [{'alpha': 0.5971625261816708, 'batch_size': 151, 'beta_1': 0.9697482839533618, 'beta_2': 0.9991912503091267, 'epsilon': 1.450270955649025e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 2.04802452761358e-05, 'tol': 0.008712021653299996, 'validation_fraction': 0.19439326959998476}]
function_evaluation time 0.464200 value -0.582418 suggestion {'alpha': 0.5971625261816708, 'batch_size': 151, 'beta_1': 0.9697482839533618, 'beta_2': 0.9991912503091267, 'epsilon': 1.450270955649025e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 2.04802452761358e-05, 'tol': 0.008712021653299996, 'validation_fraction': 0.19439326959998476}
observation time 0.000018, current best -0.914286 at iter 21
suggestion time taken 20.090739 iter 22 next_points [{'alpha': 0.0409727859347527, 'batch_size': 150, 'beta_1': 0.8118613097541119, 'beta_2': 0.9998077933728907, 'epsilon': 2.942521618278249e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.0003717443130784424, 'tol': 1.9071942724327998e-05, 'validation_fraction': 0.7705989040153973}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 1.000902 value -0.841758 suggestion {'alpha': 0.0409727859347527, 'batch_size': 150, 'beta_1': 0.8118613097541119, 'beta_2': 0.9998077933728907, 'epsilon': 2.942521618278249e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.0003717443130784424, 'tol': 1.9071942724327998e-05, 'validation_fraction': 0.7705989040153973}
observation time 0.000011, current best -0.914286 at iter 22
suggestion time taken 20.480248 iter 23 next_points [{'alpha': 0.017962278972984358, 'batch_size': 224, 'beta_1': 0.8207105629571242, 'beta_2': 0.999995267469562, 'epsilon': 5.6589089944925806e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0008457140506866479, 'tol': 0.01331187346723367, 'validation_fraction': 0.756977983393459}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.245314 value -0.593407 suggestion {'alpha': 0.017962278972984358, 'batch_size': 224, 'beta_1': 0.8207105629571242, 'beta_2': 0.999995267469562, 'epsilon': 5.6589089944925806e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0008457140506866479, 'tol': 0.01331187346723367, 'validation_fraction': 0.756977983393459}
observation time 0.000009, current best -0.914286 at iter 23
suggestion time taken 18.640210 iter 24 next_points [{'alpha': 0.0001881911141541145, 'batch_size': 148, 'beta_1': 0.9822925381603766, 'beta_2': 0.9999945264931359, 'epsilon': 4.723883593482424e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.007058693134361784, 'tol': 0.005692329157154047, 'validation_fraction': 0.8404271332698404}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.447674 value -0.892308 suggestion {'alpha': 0.0001881911141541145, 'batch_size': 148, 'beta_1': 0.9822925381603766, 'beta_2': 0.9999945264931359, 'epsilon': 4.723883593482424e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.007058693134361784, 'tol': 0.005692329157154047, 'validation_fraction': 0.8404271332698404}
observation time 0.000007, current best -0.914286 at iter 24
suggestion time taken 20.882274 iter 25 next_points [{'alpha': 0.003126615555843636, 'batch_size': 225, 'beta_1': 0.6108276888952968, 'beta_2': 0.9817607133602966, 'epsilon': 5.9792537772168676e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.003708293500860736, 'tol': 0.025867314194677107, 'validation_fraction': 0.7789929341457211}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.312297 value -0.841758 suggestion {'alpha': 0.003126615555843636, 'batch_size': 225, 'beta_1': 0.6108276888952968, 'beta_2': 0.9817607133602966, 'epsilon': 5.9792537772168676e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.003708293500860736, 'tol': 0.025867314194677107, 'validation_fraction': 0.7789929341457211}
observation time 0.000006, current best -0.914286 at iter 25
suggestion time taken 20.974693 iter 26 next_points [{'alpha': 0.004118546812098203, 'batch_size': 30, 'beta_1': 0.680371396307862, 'beta_2': 0.9468950666904355, 'epsilon': 5.9202551234703085e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0011296608664169865, 'tol': 1.5764384618267404e-05, 'validation_fraction': 0.8600518602106327}]
function_evaluation time 0.999337 value -0.843956 suggestion {'alpha': 0.004118546812098203, 'batch_size': 30, 'beta_1': 0.680371396307862, 'beta_2': 0.9468950666904355, 'epsilon': 5.9202551234703085e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0011296608664169865, 'tol': 1.5764384618267404e-05, 'validation_fraction': 0.8600518602106327}
observation time 0.000008, current best -0.914286 at iter 26
suggestion time taken 20.563645 iter 27 next_points [{'alpha': 0.0022139316006526276, 'batch_size': 25, 'beta_1': 0.7561221710598928, 'beta_2': 0.9999986819161589, 'epsilon': 5.972814550003431e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 8.75262328827117e-05, 'tol': 1.0012069763740088e-05, 'validation_fraction': 0.44850910856753795}]
function_evaluation time 2.062873 value -0.780220 suggestion {'alpha': 0.0022139316006526276, 'batch_size': 25, 'beta_1': 0.7561221710598928, 'beta_2': 0.9999986819161589, 'epsilon': 5.972814550003431e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 8.75262328827117e-05, 'tol': 1.0012069763740088e-05, 'validation_fraction': 0.44850910856753795}
observation time 0.000009, current best -0.914286 at iter 27
suggestion time taken 18.928626 iter 28 next_points [{'alpha': 0.3902537777900762, 'batch_size': 226, 'beta_1': 0.9324841252137217, 'beta_2': 0.9242954948375854, 'epsilon': 2.2355843915503953e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0027671779710287093, 'tol': 0.027361611137922768, 'validation_fraction': 0.6274731318840324}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.352200 value -0.771429 suggestion {'alpha': 0.3902537777900762, 'batch_size': 226, 'beta_1': 0.9324841252137217, 'beta_2': 0.9242954948375854, 'epsilon': 2.2355843915503953e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0027671779710287093, 'tol': 0.027361611137922768, 'validation_fraction': 0.6274731318840324}
observation time 0.000008, current best -0.914286 at iter 28
suggestion time taken 20.706839 iter 29 next_points [{'alpha': 0.020724819619644907, 'batch_size': 113, 'beta_1': 0.9857208758167443, 'beta_2': 0.9999811306521986, 'epsilon': 2.753881818199015e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.004926020808357648, 'tol': 0.0010793000572660559, 'validation_fraction': 0.25495799373484784}]
function_evaluation time 0.850508 value -0.898901 suggestion {'alpha': 0.020724819619644907, 'batch_size': 113, 'beta_1': 0.9857208758167443, 'beta_2': 0.9999811306521986, 'epsilon': 2.753881818199015e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.004926020808357648, 'tol': 0.0010793000572660559, 'validation_fraction': 0.25495799373484784}
observation time 0.000013, current best -0.914286 at iter 29
suggestion time taken 19.498016 iter 30 next_points [{'alpha': 2.4360144440231098e-05, 'batch_size': 226, 'beta_1': 0.8341997765257447, 'beta_2': 0.9978677641080019, 'epsilon': 2.7178242845879675e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.038606417317258536, 'tol': 3.071519201972185e-05, 'validation_fraction': 0.23427212097253736}]
function_evaluation time 0.838870 value -0.896703 suggestion {'alpha': 2.4360144440231098e-05, 'batch_size': 226, 'beta_1': 0.8341997765257447, 'beta_2': 0.9978677641080019, 'epsilon': 2.7178242845879675e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.038606417317258536, 'tol': 3.071519201972185e-05, 'validation_fraction': 0.23427212097253736}
observation time 0.000010, current best -0.914286 at iter 30
suggestion time taken 20.693197 iter 31 next_points [{'alpha': 0.026692918915996258, 'batch_size': 50, 'beta_1': 0.9240076146082994, 'beta_2': 0.9999537303017374, 'epsilon': 7.804072636601873e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0038103922260497958, 'tol': 0.0003694972491969269, 'validation_fraction': 0.7325309228451823}]
function_evaluation time 0.795140 value -0.903297 suggestion {'alpha': 0.026692918915996258, 'batch_size': 50, 'beta_1': 0.9240076146082994, 'beta_2': 0.9999537303017374, 'epsilon': 7.804072636601873e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0038103922260497958, 'tol': 0.0003694972491969269, 'validation_fraction': 0.7325309228451823}
observation time 0.000014, current best -0.914286 at iter 31
suggestion time taken 20.216739 iter 32 next_points [{'alpha': 0.027338832587603158, 'batch_size': 112, 'beta_1': 0.7476843094108978, 'beta_2': 0.9975179686541996, 'epsilon': 3.878610016704694e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0015381441446867142, 'tol': 0.0002489494715229073, 'validation_fraction': 0.8158194847845561}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 1.066394 value -0.896703 suggestion {'alpha': 0.027338832587603158, 'batch_size': 112, 'beta_1': 0.7476843094108978, 'beta_2': 0.9975179686541996, 'epsilon': 3.878610016704694e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0015381441446867142, 'tol': 0.0002489494715229073, 'validation_fraction': 0.8158194847845561}
observation time 0.000008, current best -0.914286 at iter 32
suggestion time taken 21.376355 iter 33 next_points [{'alpha': 0.00016038214464608104, 'batch_size': 11, 'beta_1': 0.8510716769007374, 'beta_2': 0.9989321808323898, 'epsilon': 2.5011014650295413e-08, 'hidden_layer_sizes': 103, 'learning_rate_init': 8.509170215042568e-05, 'tol': 0.00019202540614541387, 'validation_fraction': 0.3344324670778854}]
function_evaluation time 3.208823 value -0.854945 suggestion {'alpha': 0.00016038214464608104, 'batch_size': 11, 'beta_1': 0.8510716769007374, 'beta_2': 0.9989321808323898, 'epsilon': 2.5011014650295413e-08, 'hidden_layer_sizes': 103, 'learning_rate_init': 8.509170215042568e-05, 'tol': 0.00019202540614541387, 'validation_fraction': 0.3344324670778854}
observation time 0.000009, current best -0.914286 at iter 33
suggestion time taken 19.713669 iter 34 next_points [{'alpha': 0.04616184281544893, 'batch_size': 64, 'beta_1': 0.807114213220648, 'beta_2': 0.9999843429130494, 'epsilon': 1.4932936136304613e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.0018109344582722764, 'tol': 0.0006525081501784825, 'validation_fraction': 0.8705648645137365}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.748415 value -0.887912 suggestion {'alpha': 0.04616184281544893, 'batch_size': 64, 'beta_1': 0.807114213220648, 'beta_2': 0.9999843429130494, 'epsilon': 1.4932936136304613e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.0018109344582722764, 'tol': 0.0006525081501784825, 'validation_fraction': 0.8705648645137365}
observation time 0.000014, current best -0.914286 at iter 34
suggestion time taken 18.737653 iter 35 next_points [{'alpha': 0.001636952931235555, 'batch_size': 50, 'beta_1': 0.8225948107423253, 'beta_2': 0.9746716525671351, 'epsilon': 3.6726044414751015e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 4.317055886263702e-05, 'tol': 0.000427860284152147, 'validation_fraction': 0.8392649458067919}]
function_evaluation time 0.469845 value -0.549451 suggestion {'alpha': 0.001636952931235555, 'batch_size': 50, 'beta_1': 0.8225948107423253, 'beta_2': 0.9746716525671351, 'epsilon': 3.6726044414751015e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 4.317055886263702e-05, 'tol': 0.000427860284152147, 'validation_fraction': 0.8392649458067919}
observation time 0.000006, current best -0.914286 at iter 35
suggestion time taken 21.249120 iter 36 next_points [{'alpha': 0.7915152232665625, 'batch_size': 225, 'beta_1': 0.5759024855182922, 'beta_2': 0.9937933884830054, 'epsilon': 1.4674821242333816e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.006829715203463592, 'tol': 3.13381917584702e-05, 'validation_fraction': 0.3879526121774333}]
function_evaluation time 0.732216 value -0.907692 suggestion {'alpha': 0.7915152232665625, 'batch_size': 225, 'beta_1': 0.5759024855182922, 'beta_2': 0.9937933884830054, 'epsilon': 1.4674821242333816e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.006829715203463592, 'tol': 3.13381917584702e-05, 'validation_fraction': 0.3879526121774333}
observation time 0.000006, current best -0.914286 at iter 36
suggestion time taken 19.457856 iter 37 next_points [{'alpha': 1.247351755095592, 'batch_size': 150, 'beta_1': 0.9209857045754608, 'beta_2': 0.9999721448788169, 'epsilon': 1.3327054272894883e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.020881696104380745, 'tol': 0.0961231937622246, 'validation_fraction': 0.13948673305037404}]
function_evaluation time 0.578440 value -0.896703 suggestion {'alpha': 1.247351755095592, 'batch_size': 150, 'beta_1': 0.9209857045754608, 'beta_2': 0.9999721448788169, 'epsilon': 1.3327054272894883e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.020881696104380745, 'tol': 0.0961231937622246, 'validation_fraction': 0.13948673305037404}
observation time 0.000007, current best -0.914286 at iter 37
suggestion time taken 23.327150 iter 38 next_points [{'alpha': 0.02435697988789875, 'batch_size': 227, 'beta_1': 0.9888486913958935, 'beta_2': 0.9184713080668975, 'epsilon': 1.7032567635857048e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0004964785155137252, 'tol': 0.00012037754740424153, 'validation_fraction': 0.10820345030644403}]
function_evaluation time 0.566158 value -0.720879 suggestion {'alpha': 0.02435697988789875, 'batch_size': 227, 'beta_1': 0.9888486913958935, 'beta_2': 0.9184713080668975, 'epsilon': 1.7032567635857048e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0004964785155137252, 'tol': 0.00012037754740424153, 'validation_fraction': 0.10820345030644403}
observation time 0.000012, current best -0.914286 at iter 38
suggestion time taken 19.306032 iter 39 next_points [{'alpha': 1.0378476723522875e-05, 'batch_size': 64, 'beta_1': 0.9818112234739669, 'beta_2': 0.998449447812826, 'epsilon': 1.4529416076876657e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.007839450127765477, 'tol': 5.25966738800149e-05, 'validation_fraction': 0.49349594967671134}]
function_evaluation time 0.952226 value -0.901099 suggestion {'alpha': 1.0378476723522875e-05, 'batch_size': 64, 'beta_1': 0.9818112234739669, 'beta_2': 0.998449447812826, 'epsilon': 1.4529416076876657e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.007839450127765477, 'tol': 5.25966738800149e-05, 'validation_fraction': 0.49349594967671134}
observation time 0.000007, current best -0.914286 at iter 39
suggestion time taken 20.306222 iter 40 next_points [{'alpha': 0.0002669702638278731, 'batch_size': 14, 'beta_1': 0.9668916605047948, 'beta_2': 0.9691844410336252, 'epsilon': 1.4819038253667183e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.005320524247999918, 'tol': 0.01232825024558528, 'validation_fraction': 0.8354675382940796}]
function_evaluation time 0.823076 value -0.905495 suggestion {'alpha': 0.0002669702638278731, 'batch_size': 14, 'beta_1': 0.9668916605047948, 'beta_2': 0.9691844410336252, 'epsilon': 1.4819038253667183e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.005320524247999918, 'tol': 0.01232825024558528, 'validation_fraction': 0.8354675382940796}
observation time 0.000008, current best -0.914286 at iter 40
suggestion time taken 19.672761 iter 41 next_points [{'alpha': 0.0014064802363688094, 'batch_size': 227, 'beta_1': 0.5358253945396791, 'beta_2': 0.9999379819745566, 'epsilon': 2.6027415472918154e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0003330063855866099, 'tol': 0.00044354878474330836, 'validation_fraction': 0.7864463151710668}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.722183 value -0.775824 suggestion {'alpha': 0.0014064802363688094, 'batch_size': 227, 'beta_1': 0.5358253945396791, 'beta_2': 0.9999379819745566, 'epsilon': 2.6027415472918154e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0003330063855866099, 'tol': 0.00044354878474330836, 'validation_fraction': 0.7864463151710668}
observation time 0.000007, current best -0.914286 at iter 41
suggestion time taken 19.730883 iter 42 next_points [{'alpha': 0.7325899960286473, 'batch_size': 13, 'beta_1': 0.866035481831824, 'beta_2': 0.9998878289817538, 'epsilon': 2.3674111511593917e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.00017960782551526455, 'tol': 0.00031100616605565107, 'validation_fraction': 0.20973653142719606}]
function_evaluation time 3.487464 value -0.892308 suggestion {'alpha': 0.7325899960286473, 'batch_size': 13, 'beta_1': 0.866035481831824, 'beta_2': 0.9998878289817538, 'epsilon': 2.3674111511593917e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.00017960782551526455, 'tol': 0.00031100616605565107, 'validation_fraction': 0.20973653142719606}
observation time 0.000010, current best -0.914286 at iter 42
suggestion time taken 21.093674 iter 43 next_points [{'alpha': 0.00034053914877364965, 'batch_size': 227, 'beta_1': 0.9450603951802217, 'beta_2': 0.9991808544826918, 'epsilon': 2.0036221376306687e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00014665708554599955, 'tol': 4.608638339168731e-05, 'validation_fraction': 0.828763809580456}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.536859 value -0.821978 suggestion {'alpha': 0.00034053914877364965, 'batch_size': 227, 'beta_1': 0.9450603951802217, 'beta_2': 0.9991808544826918, 'epsilon': 2.0036221376306687e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00014665708554599955, 'tol': 4.608638339168731e-05, 'validation_fraction': 0.828763809580456}
observation time 0.000009, current best -0.914286 at iter 43
suggestion time taken 21.506129 iter 44 next_points [{'alpha': 0.0009937999617239204, 'batch_size': 151, 'beta_1': 0.9733051061502824, 'beta_2': 0.999997703834509, 'epsilon': 1.0656004701449872e-07, 'hidden_layer_sizes': 145, 'learning_rate_init': 2.0936793118326522e-05, 'tol': 0.030642947163278915, 'validation_fraction': 0.5479302998403814}]
function_evaluation time 0.372311 value -0.573626 suggestion {'alpha': 0.0009937999617239204, 'batch_size': 151, 'beta_1': 0.9733051061502824, 'beta_2': 0.999997703834509, 'epsilon': 1.0656004701449872e-07, 'hidden_layer_sizes': 145, 'learning_rate_init': 2.0936793118326522e-05, 'tol': 0.030642947163278915, 'validation_fraction': 0.5479302998403814}
observation time 0.000008, current best -0.914286 at iter 44
saving meta data: {'args': {'--uuid': 'dbac88fd26405f639f69358226384adc', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
