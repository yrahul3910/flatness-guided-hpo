running: {'--uuid': '45815bea5df559b8adda06509d524532', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d breast -o strongcvx -u 45815bea5df559b8adda06509d524532 -m nll -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam breast nll 45 1
with data root: None
suggestion time taken 16.320967 iter 0 next_points [{'alpha': 0.9364005492057618, 'batch_size': 227, 'beta_1': 0.615060813804674, 'beta_2': 0.9810192525149765, 'epsilon': 9.105672478920825e-09, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.015298426906553782, 'tol': 0.007955782018776149, 'validation_fraction': 0.16060422504612992}]
function_evaluation time 0.656264 value 1.167293 suggestion {'alpha': 0.9364005492057618, 'batch_size': 227, 'beta_1': 0.615060813804674, 'beta_2': 0.9810192525149765, 'epsilon': 9.105672478920825e-09, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.015298426906553782, 'tol': 0.007955782018776149, 'validation_fraction': 0.16060422504612992}
observation time 0.000004, current best 1.167293 at iter 0
suggestion time taken 15.716992 iter 1 next_points [{'alpha': 0.0002522218557381091, 'batch_size': 90, 'beta_1': 0.6803318131369827, 'beta_2': 0.9999593193316774, 'epsilon': 2.3537464939842662e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0030423826067748996, 'tol': 7.331280609135751e-05, 'validation_fraction': 0.33905011698587634}]
function_evaluation time 0.964870 value 0.272288 suggestion {'alpha': 0.0002522218557381091, 'batch_size': 90, 'beta_1': 0.6803318131369827, 'beta_2': 0.9999593193316774, 'epsilon': 2.3537464939842662e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0030423826067748996, 'tol': 7.331280609135751e-05, 'validation_fraction': 0.33905011698587634}
observation time 0.000005, current best 0.272288 at iter 1
suggestion time taken 15.545553 iter 2 next_points [{'alpha': 7.195184747290627, 'batch_size': 75, 'beta_1': 0.9542575046944561, 'beta_2': 0.9851897957015386, 'epsilon': 1.5909854394395858e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0005898377793463946, 'tol': 0.00011338511549365477, 'validation_fraction': 0.7691193447408157}]
function_evaluation time 0.615142 value 5.268359 suggestion {'alpha': 7.195184747290627, 'batch_size': 75, 'beta_1': 0.9542575046944561, 'beta_2': 0.9851897957015386, 'epsilon': 1.5909854394395858e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0005898377793463946, 'tol': 0.00011338511549365477, 'validation_fraction': 0.7691193447408157}
observation time 0.000005, current best 0.272288 at iter 2
suggestion time taken 15.956854 iter 3 next_points [{'alpha': 0.0606503652636631, 'batch_size': 75, 'beta_1': 0.9054210828416843, 'beta_2': 0.9999567686383398, 'epsilon': 1.1911120147228873e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.00028481815707391274, 'tol': 0.002243732295481881, 'validation_fraction': 0.265684497424002}]
function_evaluation time 1.393037 value 2.810120 suggestion {'alpha': 0.0606503652636631, 'batch_size': 75, 'beta_1': 0.9054210828416843, 'beta_2': 0.9999567686383398, 'epsilon': 1.1911120147228873e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.00028481815707391274, 'tol': 0.002243732295481881, 'validation_fraction': 0.265684497424002}
observation time 0.000005, current best 0.272288 at iter 3
suggestion time taken 15.576126 iter 4 next_points [{'alpha': 0.007644926284215678, 'batch_size': 13, 'beta_1': 0.9500966273752749, 'beta_2': 0.999993580656661, 'epsilon': 1.2355726037422672e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 4.320671155711137e-05, 'tol': 6.634704320402638e-05, 'validation_fraction': 0.6338092649235486}]
function_evaluation time 1.437334 value 5.731704 suggestion {'alpha': 0.007644926284215678, 'batch_size': 13, 'beta_1': 0.9500966273752749, 'beta_2': 0.999993580656661, 'epsilon': 1.2355726037422672e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 4.320671155711137e-05, 'tol': 6.634704320402638e-05, 'validation_fraction': 0.6338092649235486}
observation time 0.000005, current best 0.272288 at iter 4
suggestion time taken 16.204185 iter 5 next_points [{'alpha': 0.648754251992485, 'batch_size': 227, 'beta_1': 0.8540262934869698, 'beta_2': 0.9999985482288911, 'epsilon': 9.658463288218954e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.00156502498779021, 'tol': 0.0018098788012855362, 'validation_fraction': 0.819513157309183}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.421034 value 7.187123 suggestion {'alpha': 0.648754251992485, 'batch_size': 227, 'beta_1': 0.8540262934869698, 'beta_2': 0.9999985482288911, 'epsilon': 9.658463288218954e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.00156502498779021, 'tol': 0.0018098788012855362, 'validation_fraction': 0.819513157309183}
observation time 0.000016, current best 0.272288 at iter 5
suggestion time taken 16.180193 iter 6 next_points [{'alpha': 0.011592103206054626, 'batch_size': 11, 'beta_1': 0.9346030657568042, 'beta_2': 0.9996145480473123, 'epsilon': 7.480704696497646e-07, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.00017914368310596138, 'tol': 0.0010264061922188798, 'validation_fraction': 0.8467078931187144}]
function_evaluation time 1.493741 value 5.277024 suggestion {'alpha': 0.011592103206054626, 'batch_size': 11, 'beta_1': 0.9346030657568042, 'beta_2': 0.9996145480473123, 'epsilon': 7.480704696497646e-07, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.00017914368310596138, 'tol': 0.0010264061922188798, 'validation_fraction': 0.8467078931187144}
observation time 0.000005, current best 0.272288 at iter 6
suggestion time taken 15.524570 iter 7 next_points [{'alpha': 9.673634164380099, 'batch_size': 150, 'beta_1': 0.8008901781457146, 'beta_2': 0.9999305258704928, 'epsilon': 1.897353205342288e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.011176558983610098, 'tol': 2.044154733523914e-05, 'validation_fraction': 0.8943830336609322}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.557531 value 0.619410 suggestion {'alpha': 9.673634164380099, 'batch_size': 150, 'beta_1': 0.8008901781457146, 'beta_2': 0.9999305258704928, 'epsilon': 1.897353205342288e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.011176558983610098, 'tol': 2.044154733523914e-05, 'validation_fraction': 0.8943830336609322}
observation time 0.000005, current best 0.272288 at iter 7
suggestion time taken 16.099628 iter 8 next_points [{'alpha': 1.105609175452478, 'batch_size': 18, 'beta_1': 0.9553494361718201, 'beta_2': 0.9999899379271355, 'epsilon': 2.6214786656184495e-09, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.00019736430407328942, 'tol': 4.2116959967605104e-05, 'validation_fraction': 0.3285692484122119}]
function_evaluation time 2.566374 value 0.244420 suggestion {'alpha': 1.105609175452478, 'batch_size': 18, 'beta_1': 0.9553494361718201, 'beta_2': 0.9999899379271355, 'epsilon': 2.6214786656184495e-09, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.00019736430407328942, 'tol': 4.2116959967605104e-05, 'validation_fraction': 0.3285692484122119}
observation time 0.000006, current best 0.244420 at iter 8
suggestion time taken 15.816020 iter 9 next_points [{'alpha': 0.0004604196950022489, 'batch_size': 227, 'beta_1': 0.9465889609139667, 'beta_2': 0.999998786952701, 'epsilon': 3.3148399742935893e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 4.7605063342391664e-05, 'tol': 0.04570726620942673, 'validation_fraction': 0.2720254790035332}]
function_evaluation time 0.308876 value 12.573067 suggestion {'alpha': 0.0004604196950022489, 'batch_size': 227, 'beta_1': 0.9465889609139667, 'beta_2': 0.999998786952701, 'epsilon': 3.3148399742935893e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 4.7605063342391664e-05, 'tol': 0.04570726620942673, 'validation_fraction': 0.2720254790035332}
observation time 0.000005, current best 0.244420 at iter 9
suggestion time taken 16.347182 iter 10 next_points [{'alpha': 1.6061221460148822, 'batch_size': 56, 'beta_1': 0.9827085761502629, 'beta_2': 0.9991815523223134, 'epsilon': 3.970177776061027e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.028556715226279675, 'tol': 0.00023560211234978145, 'validation_fraction': 0.8326006608096101}]
function_evaluation time 0.587494 value 1.044603 suggestion {'alpha': 1.6061221460148822, 'batch_size': 56, 'beta_1': 0.9827085761502629, 'beta_2': 0.9991815523223134, 'epsilon': 3.970177776061027e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.028556715226279675, 'tol': 0.00023560211234978145, 'validation_fraction': 0.8326006608096101}
observation time 0.000005, current best 0.244420 at iter 10
suggestion time taken 15.829795 iter 11 next_points [{'alpha': 0.000643331562644616, 'batch_size': 41, 'beta_1': 0.9559354654278748, 'beta_2': 0.9669076230524803, 'epsilon': 3.2925812638238485e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.009153118233907796, 'tol': 1.436080896248866e-05, 'validation_fraction': 0.7010915777232365}]
function_evaluation time 1.031227 value 1.077919 suggestion {'alpha': 0.000643331562644616, 'batch_size': 41, 'beta_1': 0.9559354654278748, 'beta_2': 0.9669076230524803, 'epsilon': 3.2925812638238485e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.009153118233907796, 'tol': 1.436080896248866e-05, 'validation_fraction': 0.7010915777232365}
observation time 0.000005, current best 0.244420 at iter 11
suggestion time taken 14.833662 iter 12 next_points [{'alpha': 0.00010055434823640408, 'batch_size': 227, 'beta_1': 0.9782691275493827, 'beta_2': 0.998056363017322, 'epsilon': 3.358282217315562e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 5.679614150756607e-05, 'tol': 0.00023319762698833184, 'validation_fraction': 0.3472148623651065}]
function_evaluation time 0.568685 value 9.210535 suggestion {'alpha': 0.00010055434823640408, 'batch_size': 227, 'beta_1': 0.9782691275493827, 'beta_2': 0.998056363017322, 'epsilon': 3.358282217315562e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 5.679614150756607e-05, 'tol': 0.00023319762698833184, 'validation_fraction': 0.3472148623651065}
observation time 0.000005, current best 0.244420 at iter 12
suggestion time taken 15.480355 iter 13 next_points [{'alpha': 2.3779602569455287e-05, 'batch_size': 90, 'beta_1': 0.9564003474774699, 'beta_2': 0.9999585320210638, 'epsilon': 7.527511690327729e-09, 'hidden_layer_sizes': 149, 'learning_rate_init': 1.5512947405176056e-05, 'tol': 3.0851940338918216e-05, 'validation_fraction': 0.3111399681069687}]
function_evaluation time 0.413916 value 16.886718 suggestion {'alpha': 2.3779602569455287e-05, 'batch_size': 90, 'beta_1': 0.9564003474774699, 'beta_2': 0.9999585320210638, 'epsilon': 7.527511690327729e-09, 'hidden_layer_sizes': 149, 'learning_rate_init': 1.5512947405176056e-05, 'tol': 3.0851940338918216e-05, 'validation_fraction': 0.3111399681069687}
observation time 0.000005, current best 0.244420 at iter 13
suggestion time taken 15.201841 iter 14 next_points [{'alpha': 1.391328701851025e-05, 'batch_size': 12, 'beta_1': 0.7599938394884341, 'beta_2': 0.9999251743940748, 'epsilon': 5.549455742240776e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.002381337095375963, 'tol': 5.490125868338617e-05, 'validation_fraction': 0.22798614715244767}]
function_evaluation time 1.214967 value 0.458272 suggestion {'alpha': 1.391328701851025e-05, 'batch_size': 12, 'beta_1': 0.7599938394884341, 'beta_2': 0.9999251743940748, 'epsilon': 5.549455742240776e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.002381337095375963, 'tol': 5.490125868338617e-05, 'validation_fraction': 0.22798614715244767}
observation time 0.000005, current best 0.244420 at iter 14
suggestion time taken 16.078829 iter 15 next_points [{'alpha': 6.948283612957188, 'batch_size': 150, 'beta_1': 0.7442033292726822, 'beta_2': 0.999988942294181, 'epsilon': 1.3750175696170408e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.07187988404038204, 'tol': 0.00012127565926004709, 'validation_fraction': 0.8288727638628895}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.460556 value 3.088493 suggestion {'alpha': 6.948283612957188, 'batch_size': 150, 'beta_1': 0.7442033292726822, 'beta_2': 0.999988942294181, 'epsilon': 1.3750175696170408e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.07187988404038204, 'tol': 0.00012127565926004709, 'validation_fraction': 0.8288727638628895}
observation time 0.000005, current best 0.244420 at iter 15
suggestion time taken 16.059752 iter 16 next_points [{'alpha': 3.194286319880791e-05, 'batch_size': 10, 'beta_1': 0.8874888636533187, 'beta_2': 0.996204321881197, 'epsilon': 8.282537015977905e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.004329477454678705, 'tol': 0.00022106403851948603, 'validation_fraction': 0.8316170963137207}]
function_evaluation time 1.222636 value 0.595684 suggestion {'alpha': 3.194286319880791e-05, 'batch_size': 10, 'beta_1': 0.8874888636533187, 'beta_2': 0.996204321881197, 'epsilon': 8.282537015977905e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.004329477454678705, 'tol': 0.00022106403851948603, 'validation_fraction': 0.8316170963137207}
observation time 0.000005, current best 0.244420 at iter 16
suggestion time taken 16.731186 iter 17 next_points [{'alpha': 0.023436892272753394, 'batch_size': 18, 'beta_1': 0.9103064710416225, 'beta_2': 0.9977790406397709, 'epsilon': 3.749675202540969e-08, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.00015984067516234418, 'tol': 0.05419011101095367, 'validation_fraction': 0.18368630256398716}]
function_evaluation time 2.113532 value 0.474145 suggestion {'alpha': 0.023436892272753394, 'batch_size': 18, 'beta_1': 0.9103064710416225, 'beta_2': 0.9977790406397709, 'epsilon': 3.749675202540969e-08, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.00015984067516234418, 'tol': 0.05419011101095367, 'validation_fraction': 0.18368630256398716}
observation time 0.000005, current best 0.244420 at iter 17
suggestion time taken 16.054209 iter 18 next_points [{'alpha': 0.003333977322379611, 'batch_size': 18, 'beta_1': 0.976257565131332, 'beta_2': 0.9999786331071387, 'epsilon': 1.0679269128015999e-09, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.0010609003125893566, 'tol': 0.059675305419183554, 'validation_fraction': 0.7954643258801655}]
function_evaluation time 0.774113 value 0.446113 suggestion {'alpha': 0.003333977322379611, 'batch_size': 18, 'beta_1': 0.976257565131332, 'beta_2': 0.9999786331071387, 'epsilon': 1.0679269128015999e-09, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.0010609003125893566, 'tol': 0.059675305419183554, 'validation_fraction': 0.7954643258801655}
observation time 0.000005, current best 0.244420 at iter 18
suggestion time taken 16.835792 iter 19 next_points [{'alpha': 6.117395085096432e-05, 'batch_size': 225, 'beta_1': 0.8851697173521066, 'beta_2': 0.9997963191091759, 'epsilon': 5.240456403745292e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0012043946986536947, 'tol': 1.451152716504885e-05, 'validation_fraction': 0.2148898752487917}]
function_evaluation time 0.864372 value 0.603729 suggestion {'alpha': 6.117395085096432e-05, 'batch_size': 225, 'beta_1': 0.8851697173521066, 'beta_2': 0.9997963191091759, 'epsilon': 5.240456403745292e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0012043946986536947, 'tol': 1.451152716504885e-05, 'validation_fraction': 0.2148898752487917}
observation time 0.000005, current best 0.244420 at iter 19
suggestion time taken 15.914762 iter 20 next_points [{'alpha': 0.18543114205871655, 'batch_size': 13, 'beta_1': 0.9555800972932146, 'beta_2': 0.9965100941707858, 'epsilon': 1.360572527612474e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 4.77654337454913e-05, 'tol': 1.5106830260948413e-05, 'validation_fraction': 0.23435880492940575}]
function_evaluation time 1.171494 value 5.462968 suggestion {'alpha': 0.18543114205871655, 'batch_size': 13, 'beta_1': 0.9555800972932146, 'beta_2': 0.9965100941707858, 'epsilon': 1.360572527612474e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 4.77654337454913e-05, 'tol': 1.5106830260948413e-05, 'validation_fraction': 0.23435880492940575}
observation time 0.000005, current best 0.244420 at iter 20
suggestion time taken 16.726741 iter 21 next_points [{'alpha': 0.0006110055297979529, 'batch_size': 150, 'beta_1': 0.6396352782752485, 'beta_2': 0.9485462034954147, 'epsilon': 8.988573130907952e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.006426852170233963, 'tol': 1.871678039783936e-05, 'validation_fraction': 0.2523915463615762}]
function_evaluation time 0.631671 value 0.524571 suggestion {'alpha': 0.0006110055297979529, 'batch_size': 150, 'beta_1': 0.6396352782752485, 'beta_2': 0.9485462034954147, 'epsilon': 8.988573130907952e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.006426852170233963, 'tol': 1.871678039783936e-05, 'validation_fraction': 0.2523915463615762}
observation time 0.000005, current best 0.244420 at iter 21
suggestion time taken 16.167355 iter 22 next_points [{'alpha': 8.517087632939344, 'batch_size': 11, 'beta_1': 0.9837652344465552, 'beta_2': 0.9810072769900854, 'epsilon': 1.1199522635876514e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.014715609399930865, 'tol': 0.00478036798266918, 'validation_fraction': 0.45802700242566285}]
function_evaluation time 1.936316 value 0.745691 suggestion {'alpha': 8.517087632939344, 'batch_size': 11, 'beta_1': 0.9837652344465552, 'beta_2': 0.9810072769900854, 'epsilon': 1.1199522635876514e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.014715609399930865, 'tol': 0.00478036798266918, 'validation_fraction': 0.45802700242566285}
observation time 0.000005, current best 0.244420 at iter 22
suggestion time taken 16.862701 iter 23 next_points [{'alpha': 0.007153067025702999, 'batch_size': 226, 'beta_1': 0.8936650731166573, 'beta_2': 0.9982636485825418, 'epsilon': 3.901191595947657e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.082521122097488, 'tol': 0.0008136392267594643, 'validation_fraction': 0.6342441996108924}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.571246 value 1.233789 suggestion {'alpha': 0.007153067025702999, 'batch_size': 226, 'beta_1': 0.8936650731166573, 'beta_2': 0.9982636485825418, 'epsilon': 3.901191595947657e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.082521122097488, 'tol': 0.0008136392267594643, 'validation_fraction': 0.6342441996108924}
observation time 0.000005, current best 0.244420 at iter 23
suggestion time taken 16.136848 iter 24 next_points [{'alpha': 5.879452912868409e-05, 'batch_size': 113, 'beta_1': 0.9378199029959983, 'beta_2': 0.9640424962861699, 'epsilon': 6.851260391675925e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.016963984613821363, 'tol': 0.01190143062966004, 'validation_fraction': 0.6413658858550805}]
function_evaluation time 0.484697 value 1.008524 suggestion {'alpha': 5.879452912868409e-05, 'batch_size': 113, 'beta_1': 0.9378199029959983, 'beta_2': 0.9640424962861699, 'epsilon': 6.851260391675925e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.016963984613821363, 'tol': 0.01190143062966004, 'validation_fraction': 0.6413658858550805}
observation time 0.000004, current best 0.244420 at iter 24
suggestion time taken 16.689406 iter 25 next_points [{'alpha': 0.05867485948069328, 'batch_size': 151, 'beta_1': 0.6181736017884795, 'beta_2': 0.9504614690673645, 'epsilon': 1.3601018724095475e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.00010621640137920564, 'tol': 0.003404163956947146, 'validation_fraction': 0.7645849690104309}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.260556 value 15.583842 suggestion {'alpha': 0.05867485948069328, 'batch_size': 151, 'beta_1': 0.6181736017884795, 'beta_2': 0.9504614690673645, 'epsilon': 1.3601018724095475e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.00010621640137920564, 'tol': 0.003404163956947146, 'validation_fraction': 0.7645849690104309}
observation time 0.000005, current best 0.244420 at iter 25
suggestion time taken 15.766897 iter 26 next_points [{'alpha': 0.017296941422147556, 'batch_size': 227, 'beta_1': 0.826296706374607, 'beta_2': 0.9994843876934568, 'epsilon': 1.6862874298758862e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.053726876035227335, 'tol': 0.00011266175446575159, 'validation_fraction': 0.13325956874198577}]
function_evaluation time 0.619576 value 0.632586 suggestion {'alpha': 0.017296941422147556, 'batch_size': 227, 'beta_1': 0.826296706374607, 'beta_2': 0.9994843876934568, 'epsilon': 1.6862874298758862e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.053726876035227335, 'tol': 0.00011266175446575159, 'validation_fraction': 0.13325956874198577}
observation time 0.000005, current best 0.244420 at iter 26
suggestion time taken 16.643886 iter 27 next_points [{'alpha': 0.12325344057208205, 'batch_size': 14, 'beta_1': 0.9572563804530324, 'beta_2': 0.9998575710333552, 'epsilon': 2.0609835696280175e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.002803468678606123, 'tol': 0.0004429124903544668, 'validation_fraction': 0.3438571311071957}]
function_evaluation time 2.096451 value 0.721996 suggestion {'alpha': 0.12325344057208205, 'batch_size': 14, 'beta_1': 0.9572563804530324, 'beta_2': 0.9998575710333552, 'epsilon': 2.0609835696280175e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.002803468678606123, 'tol': 0.0004429124903544668, 'validation_fraction': 0.3438571311071957}
observation time 0.000005, current best 0.244420 at iter 27
suggestion time taken 15.940600 iter 28 next_points [{'alpha': 9.079063989192129, 'batch_size': 151, 'beta_1': 0.9481855942387568, 'beta_2': 0.9992961374182732, 'epsilon': 2.0985965267629923e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.004731134705497903, 'tol': 0.0002503106347470461, 'validation_fraction': 0.8837127650321889}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.640480 value 3.156209 suggestion {'alpha': 9.079063989192129, 'batch_size': 151, 'beta_1': 0.9481855942387568, 'beta_2': 0.9992961374182732, 'epsilon': 2.0985965267629923e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.004731134705497903, 'tol': 0.0002503106347470461, 'validation_fraction': 0.8837127650321889}
observation time 0.000005, current best 0.244420 at iter 28
suggestion time taken 16.604953 iter 29 next_points [{'alpha': 0.0033677929967924113, 'batch_size': 50, 'beta_1': 0.6320937109652162, 'beta_2': 0.9995409841485388, 'epsilon': 1.651684715390806e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.006306511074438674, 'tol': 0.005015436242716, 'validation_fraction': 0.4291814259387786}]
function_evaluation time 1.227936 value 0.609947 suggestion {'alpha': 0.0033677929967924113, 'batch_size': 50, 'beta_1': 0.6320937109652162, 'beta_2': 0.9995409841485388, 'epsilon': 1.651684715390806e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.006306511074438674, 'tol': 0.005015436242716, 'validation_fraction': 0.4291814259387786}
observation time 0.000005, current best 0.244420 at iter 29
suggestion time taken 15.922722 iter 30 next_points [{'alpha': 1.5965473238144585, 'batch_size': 75, 'beta_1': 0.9829600844535721, 'beta_2': 0.9999967088245659, 'epsilon': 3.702532698505381e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.02697997132598807, 'tol': 3.570916288973983e-05, 'validation_fraction': 0.766013557394147}]
function_evaluation time 0.520750 value 0.735984 suggestion {'alpha': 1.5965473238144585, 'batch_size': 75, 'beta_1': 0.9829600844535721, 'beta_2': 0.9999967088245659, 'epsilon': 3.702532698505381e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.02697997132598807, 'tol': 3.570916288973983e-05, 'validation_fraction': 0.766013557394147}
observation time 0.000005, current best 0.244420 at iter 30
suggestion time taken 17.212663 iter 31 next_points [{'alpha': 0.0024116178923490506, 'batch_size': 41, 'beta_1': 0.9423632912870415, 'beta_2': 0.9999949648299256, 'epsilon': 2.238631526066407e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.001199192723278426, 'tol': 0.0036733239514614466, 'validation_fraction': 0.23312052004005843}]
function_evaluation time 0.718680 value 0.589082 suggestion {'alpha': 0.0024116178923490506, 'batch_size': 41, 'beta_1': 0.9423632912870415, 'beta_2': 0.9999949648299256, 'epsilon': 2.238631526066407e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.001199192723278426, 'tol': 0.0036733239514614466, 'validation_fraction': 0.23312052004005843}
observation time 0.000003, current best 0.244420 at iter 31
suggestion time taken 16.461363 iter 32 next_points [{'alpha': 0.4586618574578269, 'batch_size': 12, 'beta_1': 0.6751080699359178, 'beta_2': 0.9999915574931584, 'epsilon': 4.1442364497913646e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.003772117050428065, 'tol': 0.00439714053020261, 'validation_fraction': 0.37796227113128317}]
function_evaluation time 2.337486 value 0.719596 suggestion {'alpha': 0.4586618574578269, 'batch_size': 12, 'beta_1': 0.6751080699359178, 'beta_2': 0.9999915574931584, 'epsilon': 4.1442364497913646e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.003772117050428065, 'tol': 0.00439714053020261, 'validation_fraction': 0.37796227113128317}
observation time 0.000004, current best 0.244420 at iter 32
suggestion time taken 16.948601 iter 33 next_points [{'alpha': 0.2916032187736913, 'batch_size': 13, 'beta_1': 0.8494290676976012, 'beta_2': 0.9999934137326613, 'epsilon': 3.284316954948809e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.01021450612474434, 'tol': 0.00016420129189259456, 'validation_fraction': 0.25995872597181574}]
function_evaluation time 1.003829 value 0.756293 suggestion {'alpha': 0.2916032187736913, 'batch_size': 13, 'beta_1': 0.8494290676976012, 'beta_2': 0.9999934137326613, 'epsilon': 3.284316954948809e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.01021450612474434, 'tol': 0.00016420129189259456, 'validation_fraction': 0.25995872597181574}
observation time 0.000004, current best 0.244420 at iter 33
suggestion time taken 16.032917 iter 34 next_points [{'alpha': 0.00022751488908564176, 'batch_size': 226, 'beta_1': 0.9823575594186917, 'beta_2': 0.999996944053592, 'epsilon': 1.8631132417647354e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.00011829564102354175, 'tol': 0.0005695273952596479, 'validation_fraction': 0.19606228203863474}]
function_evaluation time 0.529941 value 9.542446 suggestion {'alpha': 0.00022751488908564176, 'batch_size': 226, 'beta_1': 0.9823575594186917, 'beta_2': 0.999996944053592, 'epsilon': 1.8631132417647354e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.00011829564102354175, 'tol': 0.0005695273952596479, 'validation_fraction': 0.19606228203863474}
observation time 0.000005, current best 0.244420 at iter 34
suggestion time taken 16.789008 iter 35 next_points [{'alpha': 1.5450079351079445e-05, 'batch_size': 224, 'beta_1': 0.9203962505048761, 'beta_2': 0.9999954087005637, 'epsilon': 8.355532020397232e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.001795357784166429, 'tol': 0.0003971188209339292, 'validation_fraction': 0.43062408158117993}]
function_evaluation time 0.774777 value 3.090100 suggestion {'alpha': 1.5450079351079445e-05, 'batch_size': 224, 'beta_1': 0.9203962505048761, 'beta_2': 0.9999954087005637, 'epsilon': 8.355532020397232e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.001795357784166429, 'tol': 0.0003971188209339292, 'validation_fraction': 0.43062408158117993}
observation time 0.000005, current best 0.244420 at iter 35
suggestion time taken 16.399194 iter 36 next_points [{'alpha': 0.0071094856690955424, 'batch_size': 151, 'beta_1': 0.6801584808875124, 'beta_2': 0.9127989395448738, 'epsilon': 7.568861124433481e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.00288410705855163, 'tol': 0.0021730561245270315, 'validation_fraction': 0.7828713656848838}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.614152 value 0.327229 suggestion {'alpha': 0.0071094856690955424, 'batch_size': 151, 'beta_1': 0.6801584808875124, 'beta_2': 0.9127989395448738, 'epsilon': 7.568861124433481e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.00288410705855163, 'tol': 0.0021730561245270315, 'validation_fraction': 0.7828713656848838}
observation time 0.000005, current best 0.244420 at iter 36
suggestion time taken 15.829409 iter 37 next_points [{'alpha': 0.008262371070038374, 'batch_size': 225, 'beta_1': 0.5047957727841289, 'beta_2': 0.9976295862190703, 'epsilon': 2.7128739274499523e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 1.6344572972672094e-05, 'tol': 0.005633724917614502, 'validation_fraction': 0.7614903188326966}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.254743 value 16.318940 suggestion {'alpha': 0.008262371070038374, 'batch_size': 225, 'beta_1': 0.5047957727841289, 'beta_2': 0.9976295862190703, 'epsilon': 2.7128739274499523e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 1.6344572972672094e-05, 'tol': 0.005633724917614502, 'validation_fraction': 0.7614903188326966}
observation time 0.000005, current best 0.244420 at iter 37
suggestion time taken 16.878265 iter 38 next_points [{'alpha': 0.0001038744563747392, 'batch_size': 18, 'beta_1': 0.9872014921176143, 'beta_2': 0.9996306338785401, 'epsilon': 6.2059539097985595e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.05786219898513893, 'tol': 0.06570651221529403, 'validation_fraction': 0.8177816271580166}]
function_evaluation time 0.653847 value 0.699852 suggestion {'alpha': 0.0001038744563747392, 'batch_size': 18, 'beta_1': 0.9872014921176143, 'beta_2': 0.9996306338785401, 'epsilon': 6.2059539097985595e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.05786219898513893, 'tol': 0.06570651221529403, 'validation_fraction': 0.8177816271580166}
observation time 0.000005, current best 0.244420 at iter 38
suggestion time taken 16.018558 iter 39 next_points [{'alpha': 0.17953020465803315, 'batch_size': 41, 'beta_1': 0.9485802228178105, 'beta_2': 0.97082210215356, 'epsilon': 1.7831809117514618e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 2.340592648088659e-05, 'tol': 2.5864561122612633e-05, 'validation_fraction': 0.43315910940535785}]
function_evaluation time 0.762064 value 15.465239 suggestion {'alpha': 0.17953020465803315, 'batch_size': 41, 'beta_1': 0.9485802228178105, 'beta_2': 0.97082210215356, 'epsilon': 1.7831809117514618e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 2.340592648088659e-05, 'tol': 2.5864561122612633e-05, 'validation_fraction': 0.43315910940535785}
observation time 0.000005, current best 0.244420 at iter 39
suggestion time taken 16.715810 iter 40 next_points [{'alpha': 0.0007337320620481324, 'batch_size': 56, 'beta_1': 0.9706484012828245, 'beta_2': 0.9949429323719944, 'epsilon': 4.637588358759664e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0016560741724071636, 'tol': 0.008034116619490874, 'validation_fraction': 0.7684795290270188}]
function_evaluation time 0.592373 value 1.528509 suggestion {'alpha': 0.0007337320620481324, 'batch_size': 56, 'beta_1': 0.9706484012828245, 'beta_2': 0.9949429323719944, 'epsilon': 4.637588358759664e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0016560741724071636, 'tol': 0.008034116619490874, 'validation_fraction': 0.7684795290270188}
observation time 0.000005, current best 0.244420 at iter 40
suggestion time taken 16.062731 iter 41 next_points [{'alpha': 3.9872213040249953, 'batch_size': 227, 'beta_1': 0.7520863096885879, 'beta_2': 0.9988025145955683, 'epsilon': 1.4399272419984408e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 1.4840868016409621e-05, 'tol': 0.04878222823798479, 'validation_fraction': 0.3187715624433815}]
function_evaluation time 0.375642 value 15.127298 suggestion {'alpha': 3.9872213040249953, 'batch_size': 227, 'beta_1': 0.7520863096885879, 'beta_2': 0.9988025145955683, 'epsilon': 1.4399272419984408e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 1.4840868016409621e-05, 'tol': 0.04878222823798479, 'validation_fraction': 0.3187715624433815}
observation time 0.000005, current best 0.244420 at iter 41
suggestion time taken 16.693605 iter 42 next_points [{'alpha': 0.015186018004296309, 'batch_size': 220, 'beta_1': 0.8339795473123155, 'beta_2': 0.9999585882362345, 'epsilon': 1.7728523561551263e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0008973966064409063, 'tol': 0.03595199985629707, 'validation_fraction': 0.876950302345783}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.229280 value 12.221954 suggestion {'alpha': 0.015186018004296309, 'batch_size': 220, 'beta_1': 0.8339795473123155, 'beta_2': 0.9999585882362345, 'epsilon': 1.7728523561551263e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0008973966064409063, 'tol': 0.03595199985629707, 'validation_fraction': 0.876950302345783}
observation time 0.000004, current best 0.244420 at iter 42
suggestion time taken 16.268033 iter 43 next_points [{'alpha': 0.00033261651722406825, 'batch_size': 50, 'beta_1': 0.9788111613653481, 'beta_2': 0.9997546586774241, 'epsilon': 1.775328913499175e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0013977062290035324, 'tol': 1.3674325690258784e-05, 'validation_fraction': 0.14112699327046144}]
function_evaluation time 0.483774 value 3.108895 suggestion {'alpha': 0.00033261651722406825, 'batch_size': 50, 'beta_1': 0.9788111613653481, 'beta_2': 0.9997546586774241, 'epsilon': 1.775328913499175e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0013977062290035324, 'tol': 1.3674325690258784e-05, 'validation_fraction': 0.14112699327046144}
observation time 0.000003, current best 0.244420 at iter 43
suggestion time taken 16.022663 iter 44 next_points [{'alpha': 0.20742760053383602, 'batch_size': 15, 'beta_1': 0.971381106429087, 'beta_2': 0.9995735119682716, 'epsilon': 8.335788620711801e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0002367175688212334, 'tol': 0.006955289148309428, 'validation_fraction': 0.16890909876342813}]
function_evaluation time 3.166842 value 0.335529 suggestion {'alpha': 0.20742760053383602, 'batch_size': 15, 'beta_1': 0.971381106429087, 'beta_2': 0.9995735119682716, 'epsilon': 8.335788620711801e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0002367175688212334, 'tol': 0.006955289148309428, 'validation_fraction': 0.16890909876342813}
observation time 0.000004, current best 0.244420 at iter 44
saving meta data: {'args': {'--uuid': '45815bea5df559b8adda06509d524532', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])}
saving results
saving timing
saving suggest log
done
