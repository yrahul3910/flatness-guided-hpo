running: {'--uuid': '0ae382362e6b589c9831536c8a8d6646', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d breast -o strongcvx -u 0ae382362e6b589c9831536c8a8d6646 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam breast acc 45 1
with data root: None
suggestion time taken 19.500351 iter 0 next_points [{'alpha': 0.0009519339108976871, 'batch_size': 50, 'beta_1': 0.9288625876371003, 'beta_2': 0.9980475984375413, 'epsilon': 8.158392991336663e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 1.0462663116630434e-05, 'tol': 0.0019825806814963622, 'validation_fraction': 0.5532491283083466}]
function_evaluation time 0.402757 value -0.637363 suggestion {'alpha': 0.0009519339108976871, 'batch_size': 50, 'beta_1': 0.9288625876371003, 'beta_2': 0.9980475984375413, 'epsilon': 8.158392991336663e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 1.0462663116630434e-05, 'tol': 0.0019825806814963622, 'validation_fraction': 0.5532491283083466}
observation time 0.000008, current best -0.637363 at iter 0
suggestion time taken 19.608117 iter 1 next_points [{'alpha': 0.09911428514230976, 'batch_size': 11, 'beta_1': 0.5092319531275996, 'beta_2': 0.999974919115191, 'epsilon': 5.977958325841044e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 9.275590859317016e-05, 'tol': 0.0004310720647031065, 'validation_fraction': 0.8907631318405157}]
function_evaluation time 2.077904 value -0.775824 suggestion {'alpha': 0.09911428514230976, 'batch_size': 11, 'beta_1': 0.5092319531275996, 'beta_2': 0.999974919115191, 'epsilon': 5.977958325841044e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 9.275590859317016e-05, 'tol': 0.0004310720647031065, 'validation_fraction': 0.8907631318405157}
observation time 0.000026, current best -0.775824 at iter 1
suggestion time taken 18.961514 iter 2 next_points [{'alpha': 0.06996498388865839, 'batch_size': 151, 'beta_1': 0.9241962310138059, 'beta_2': 0.9999903011610926, 'epsilon': 6.4791595228716035e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.007887372647158613, 'tol': 0.033729701537533234, 'validation_fraction': 0.10976231721760946}]
function_evaluation time 0.830082 value -0.890110 suggestion {'alpha': 0.06996498388865839, 'batch_size': 151, 'beta_1': 0.9241962310138059, 'beta_2': 0.9999903011610926, 'epsilon': 6.4791595228716035e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.007887372647158613, 'tol': 0.033729701537533234, 'validation_fraction': 0.10976231721760946}
observation time 0.000006, current best -0.890110 at iter 2
suggestion time taken 19.699041 iter 3 next_points [{'alpha': 4.438818425220078, 'batch_size': 225, 'beta_1': 0.5180695072565041, 'beta_2': 0.9686062907995363, 'epsilon': 6.849616969292884e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.07247771048472391, 'tol': 0.003168689661840271, 'validation_fraction': 0.843428949732323}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.705633 value -0.852747 suggestion {'alpha': 4.438818425220078, 'batch_size': 225, 'beta_1': 0.5180695072565041, 'beta_2': 0.9686062907995363, 'epsilon': 6.849616969292884e-09, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.07247771048472391, 'tol': 0.003168689661840271, 'validation_fraction': 0.843428949732323}
observation time 0.000010, current best -0.890110 at iter 3
suggestion time taken 19.263224 iter 4 next_points [{'alpha': 0.2283811084110765, 'batch_size': 226, 'beta_1': 0.9771137931164966, 'beta_2': 0.9149443935630919, 'epsilon': 4.0971492927279416e-09, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.006567450154495609, 'tol': 0.0033926234220184033, 'validation_fraction': 0.23222028261080332}]
function_evaluation time 0.824786 value -0.852747 suggestion {'alpha': 0.2283811084110765, 'batch_size': 226, 'beta_1': 0.9771137931164966, 'beta_2': 0.9149443935630919, 'epsilon': 4.0971492927279416e-09, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.006567450154495609, 'tol': 0.0033926234220184033, 'validation_fraction': 0.23222028261080332}
observation time 0.000006, current best -0.890110 at iter 4
suggestion time taken 20.149073 iter 5 next_points [{'alpha': 6.963294009498985e-05, 'batch_size': 113, 'beta_1': 0.7546190157930069, 'beta_2': 0.993914182685428, 'epsilon': 3.761539184532225e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0005443575512251197, 'tol': 0.006688954788922008, 'validation_fraction': 0.19184905249422052}]
function_evaluation time 1.033282 value -0.835165 suggestion {'alpha': 6.963294009498985e-05, 'batch_size': 113, 'beta_1': 0.7546190157930069, 'beta_2': 0.993914182685428, 'epsilon': 3.761539184532225e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0005443575512251197, 'tol': 0.006688954788922008, 'validation_fraction': 0.19184905249422052}
observation time 0.000006, current best -0.890110 at iter 5
suggestion time taken 19.653753 iter 6 next_points [{'alpha': 1.0198117563508912e-05, 'batch_size': 64, 'beta_1': 0.9883040192855723, 'beta_2': 0.9999615196669045, 'epsilon': 8.76388800818399e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.005288970951454219, 'tol': 0.06360791196953376, 'validation_fraction': 0.4946358611352826}]
function_evaluation time 0.603181 value -0.841758 suggestion {'alpha': 1.0198117563508912e-05, 'batch_size': 64, 'beta_1': 0.9883040192855723, 'beta_2': 0.9999615196669045, 'epsilon': 8.76388800818399e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.005288970951454219, 'tol': 0.06360791196953376, 'validation_fraction': 0.4946358611352826}
observation time 0.000005, current best -0.890110 at iter 6
suggestion time taken 19.588153 iter 7 next_points [{'alpha': 0.00020361462484123547, 'batch_size': 112, 'beta_1': 0.8546869757544293, 'beta_2': 0.9999987089145062, 'epsilon': 1.837132349743857e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0004390196395880781, 'tol': 3.9587952845322276e-05, 'validation_fraction': 0.1475555258454186}]
function_evaluation time 0.681240 value -0.657143 suggestion {'alpha': 0.00020361462484123547, 'batch_size': 112, 'beta_1': 0.8546869757544293, 'beta_2': 0.9999987089145062, 'epsilon': 1.837132349743857e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0004390196395880781, 'tol': 3.9587952845322276e-05, 'validation_fraction': 0.1475555258454186}
observation time 0.000006, current best -0.890110 at iter 7
suggestion time taken 20.060040 iter 8 next_points [{'alpha': 0.0008987720706761098, 'batch_size': 113, 'beta_1': 0.8877033388497363, 'beta_2': 0.9872616491132454, 'epsilon': 1.385422417684588e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0059306716233010655, 'tol': 5.8612775718697475e-05, 'validation_fraction': 0.578017963827365}]
function_evaluation time 0.845131 value -0.916484 suggestion {'alpha': 0.0008987720706761098, 'batch_size': 113, 'beta_1': 0.8877033388497363, 'beta_2': 0.9872616491132454, 'epsilon': 1.385422417684588e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0059306716233010655, 'tol': 5.8612775718697475e-05, 'validation_fraction': 0.578017963827365}
observation time 0.000014, current best -0.916484 at iter 8
suggestion time taken 19.327860 iter 9 next_points [{'alpha': 0.5531225053831226, 'batch_size': 32, 'beta_1': 0.8807744746804944, 'beta_2': 0.9999938349650895, 'epsilon': 1.222957289247644e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.003656442673426039, 'tol': 0.00011085954675855132, 'validation_fraction': 0.1046347978866281}]
function_evaluation time 0.882565 value -0.892308 suggestion {'alpha': 0.5531225053831226, 'batch_size': 32, 'beta_1': 0.8807744746804944, 'beta_2': 0.9999938349650895, 'epsilon': 1.222957289247644e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.003656442673426039, 'tol': 0.00011085954675855132, 'validation_fraction': 0.1046347978866281}
observation time 0.000005, current best -0.916484 at iter 9
suggestion time taken 20.129640 iter 10 next_points [{'alpha': 0.00380883657197856, 'batch_size': 75, 'beta_1': 0.9466745184420665, 'beta_2': 0.9587743817449482, 'epsilon': 2.7147256142361627e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.00022071876891569133, 'tol': 0.05332525544603682, 'validation_fraction': 0.5458811755222107}]
function_evaluation time 0.554997 value -0.661538 suggestion {'alpha': 0.00380883657197856, 'batch_size': 75, 'beta_1': 0.9466745184420665, 'beta_2': 0.9587743817449482, 'epsilon': 2.7147256142361627e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.00022071876891569133, 'tol': 0.05332525544603682, 'validation_fraction': 0.5458811755222107}
observation time 0.000017, current best -0.916484 at iter 10
suggestion time taken 19.363603 iter 11 next_points [{'alpha': 1.705737047875583, 'batch_size': 226, 'beta_1': 0.9892078093457819, 'beta_2': 0.9999464745199278, 'epsilon': 3.8052186236917334e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.08236401798719568, 'tol': 0.005296585273842714, 'validation_fraction': 0.8019767120259108}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.577246 value -0.782418 suggestion {'alpha': 1.705737047875583, 'batch_size': 226, 'beta_1': 0.9892078093457819, 'beta_2': 0.9999464745199278, 'epsilon': 3.8052186236917334e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.08236401798719568, 'tol': 0.005296585273842714, 'validation_fraction': 0.8019767120259108}
observation time 0.000016, current best -0.916484 at iter 11
suggestion time taken 20.408106 iter 12 next_points [{'alpha': 0.0032356107403398527, 'batch_size': 227, 'beta_1': 0.9606600738986675, 'beta_2': 0.9999023585696084, 'epsilon': 4.540401117486811e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.06640601458734585, 'tol': 4.2973512393784944e-05, 'validation_fraction': 0.8986407686686891}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.466725 value -0.789011 suggestion {'alpha': 0.0032356107403398527, 'batch_size': 227, 'beta_1': 0.9606600738986675, 'beta_2': 0.9999023585696084, 'epsilon': 4.540401117486811e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.06640601458734585, 'tol': 4.2973512393784944e-05, 'validation_fraction': 0.8986407686686891}
observation time 0.000005, current best -0.916484 at iter 12
suggestion time taken 20.472464 iter 13 next_points [{'alpha': 0.23327572749877712, 'batch_size': 15, 'beta_1': 0.6431608825383262, 'beta_2': 0.9999705032603206, 'epsilon': 1.0514255892891456e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.0004400604638186499, 'tol': 1.940498861115285e-05, 'validation_fraction': 0.1823093596067488}]
function_evaluation time 2.965626 value -0.903297 suggestion {'alpha': 0.23327572749877712, 'batch_size': 15, 'beta_1': 0.6431608825383262, 'beta_2': 0.9999705032603206, 'epsilon': 1.0514255892891456e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.0004400604638186499, 'tol': 1.940498861115285e-05, 'validation_fraction': 0.1823093596067488}
observation time 0.000013, current best -0.916484 at iter 13
suggestion time taken 19.728801 iter 14 next_points [{'alpha': 0.0013215017460739545, 'batch_size': 227, 'beta_1': 0.9534585322341661, 'beta_2': 0.969580106142877, 'epsilon': 8.68047473147995e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0001490942641186203, 'tol': 0.00908982195440504, 'validation_fraction': 0.5371137614787139}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.391261 value -0.461538 suggestion {'alpha': 0.0013215017460739545, 'batch_size': 227, 'beta_1': 0.9534585322341661, 'beta_2': 0.969580106142877, 'epsilon': 8.68047473147995e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0001490942641186203, 'tol': 0.00908982195440504, 'validation_fraction': 0.5371137614787139}
observation time 0.000006, current best -0.916484 at iter 14
suggestion time taken 20.651299 iter 15 next_points [{'alpha': 0.012666152083420156, 'batch_size': 11, 'beta_1': 0.8089089094675821, 'beta_2': 0.9992550363465719, 'epsilon': 3.4844082284796447e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.003913949844420274, 'tol': 0.0017698872679534521, 'validation_fraction': 0.5181442687770488}]
function_evaluation time 2.600946 value -0.918681 suggestion {'alpha': 0.012666152083420156, 'batch_size': 11, 'beta_1': 0.8089089094675821, 'beta_2': 0.9992550363465719, 'epsilon': 3.4844082284796447e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.003913949844420274, 'tol': 0.0017698872679534521, 'validation_fraction': 0.5181442687770488}
observation time 0.000006, current best -0.918681 at iter 15
suggestion time taken 20.277080 iter 16 next_points [{'alpha': 9.67155018610289e-05, 'batch_size': 16, 'beta_1': 0.7808351755539199, 'beta_2': 0.9998592947097695, 'epsilon': 6.2991734960902925e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.002079163816738811, 'tol': 1.5849615540483662e-05, 'validation_fraction': 0.2161376941174712}]
function_evaluation time 0.877998 value -0.905495 suggestion {'alpha': 9.67155018610289e-05, 'batch_size': 16, 'beta_1': 0.7808351755539199, 'beta_2': 0.9998592947097695, 'epsilon': 6.2991734960902925e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.002079163816738811, 'tol': 1.5849615540483662e-05, 'validation_fraction': 0.2161376941174712}
observation time 0.000015, current best -0.918681 at iter 16
suggestion time taken 20.933819 iter 17 next_points [{'alpha': 0.0606173401651862, 'batch_size': 151, 'beta_1': 0.9842740513347968, 'beta_2': 0.9998395144759431, 'epsilon': 1.0615884578095166e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 2.229438884240719e-05, 'tol': 0.00033997230571217, 'validation_fraction': 0.6107566777945674}]
function_evaluation time 0.343081 value -0.582418 suggestion {'alpha': 0.0606173401651862, 'batch_size': 151, 'beta_1': 0.9842740513347968, 'beta_2': 0.9998395144759431, 'epsilon': 1.0615884578095166e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 2.229438884240719e-05, 'tol': 0.00033997230571217, 'validation_fraction': 0.6107566777945674}
observation time 0.000005, current best -0.918681 at iter 17
suggestion time taken 19.437557 iter 18 next_points [{'alpha': 0.0007682189975079498, 'batch_size': 227, 'beta_1': 0.7204194443773208, 'beta_2': 0.9999985223171075, 'epsilon': 2.883124449638472e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 9.073434638058535e-05, 'tol': 2.964122584918931e-05, 'validation_fraction': 0.6175005358043241}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.344567 value -0.417582 suggestion {'alpha': 0.0007682189975079498, 'batch_size': 227, 'beta_1': 0.7204194443773208, 'beta_2': 0.9999985223171075, 'epsilon': 2.883124449638472e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 9.073434638058535e-05, 'tol': 2.964122584918931e-05, 'validation_fraction': 0.6175005358043241}
observation time 0.000014, current best -0.918681 at iter 18
suggestion time taken 20.897701 iter 19 next_points [{'alpha': 0.08612904593018439, 'batch_size': 45, 'beta_1': 0.8947958306663468, 'beta_2': 0.997740210317058, 'epsilon': 5.105864485062796e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 1.9141004837928664e-05, 'tol': 0.0024190886391665576, 'validation_fraction': 0.5942386466593894}]
function_evaluation time 0.602448 value -0.569231 suggestion {'alpha': 0.08612904593018439, 'batch_size': 45, 'beta_1': 0.8947958306663468, 'beta_2': 0.997740210317058, 'epsilon': 5.105864485062796e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 1.9141004837928664e-05, 'tol': 0.0024190886391665576, 'validation_fraction': 0.5942386466593894}
observation time 0.000006, current best -0.918681 at iter 19
suggestion time taken 19.653748 iter 20 next_points [{'alpha': 0.0001197134664159522, 'batch_size': 90, 'beta_1': 0.9527309478726868, 'beta_2': 0.9996704864347962, 'epsilon': 1.5391693443635776e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0025660457697692252, 'tol': 0.01173743571037808, 'validation_fraction': 0.6506645753088625}]
function_evaluation time 0.770988 value -0.896703 suggestion {'alpha': 0.0001197134664159522, 'batch_size': 90, 'beta_1': 0.9527309478726868, 'beta_2': 0.9996704864347962, 'epsilon': 1.5391693443635776e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0025660457697692252, 'tol': 0.01173743571037808, 'validation_fraction': 0.6506645753088625}
observation time 0.000011, current best -0.918681 at iter 20
suggestion time taken 20.790979 iter 21 next_points [{'alpha': 0.00041428619189953477, 'batch_size': 30, 'beta_1': 0.9841954421735427, 'beta_2': 0.9999861331975699, 'epsilon': 1.747658781562094e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00056933355969296, 'tol': 0.07998904310361671, 'validation_fraction': 0.8236727725197994}]
function_evaluation time 0.494870 value -0.646154 suggestion {'alpha': 0.00041428619189953477, 'batch_size': 30, 'beta_1': 0.9841954421735427, 'beta_2': 0.9999861331975699, 'epsilon': 1.747658781562094e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00056933355969296, 'tol': 0.07998904310361671, 'validation_fraction': 0.8236727725197994}
observation time 0.000013, current best -0.918681 at iter 21
suggestion time taken 19.801138 iter 22 next_points [{'alpha': 0.36584005671106307, 'batch_size': 151, 'beta_1': 0.9896344922492815, 'beta_2': 0.9999126785113788, 'epsilon': 1.2391322458217473e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.022079949140798034, 'tol': 1.427075807829706e-05, 'validation_fraction': 0.35974239937619995}]
function_evaluation time 0.794776 value -0.901099 suggestion {'alpha': 0.36584005671106307, 'batch_size': 151, 'beta_1': 0.9896344922492815, 'beta_2': 0.9999126785113788, 'epsilon': 1.2391322458217473e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.022079949140798034, 'tol': 1.427075807829706e-05, 'validation_fraction': 0.35974239937619995}
observation time 0.000005, current best -0.918681 at iter 22
suggestion time taken 21.106864 iter 23 next_points [{'alpha': 1.4071854293006253e-05, 'batch_size': 225, 'beta_1': 0.6045614455510365, 'beta_2': 0.9878590930123755, 'epsilon': 2.4959269135852513e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.00015925237438277654, 'tol': 0.025915674122095295, 'validation_fraction': 0.24290927025852257}]
function_evaluation time 0.539753 value -0.553846 suggestion {'alpha': 1.4071854293006253e-05, 'batch_size': 225, 'beta_1': 0.6045614455510365, 'beta_2': 0.9878590930123755, 'epsilon': 2.4959269135852513e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.00015925237438277654, 'tol': 0.025915674122095295, 'validation_fraction': 0.24290927025852257}
observation time 0.000018, current best -0.918681 at iter 23
suggestion time taken 20.056825 iter 24 next_points [{'alpha': 0.012957655073453233, 'batch_size': 32, 'beta_1': 0.5613376789930189, 'beta_2': 0.9998996634590129, 'epsilon': 5.479919430671776e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.07213315699011444, 'tol': 0.004740105916978101, 'validation_fraction': 0.2449438403783344}]
function_evaluation time 1.616689 value -0.909890 suggestion {'alpha': 0.012957655073453233, 'batch_size': 32, 'beta_1': 0.5613376789930189, 'beta_2': 0.9998996634590129, 'epsilon': 5.479919430671776e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.07213315699011444, 'tol': 0.004740105916978101, 'validation_fraction': 0.2449438403783344}
observation time 0.000007, current best -0.918681 at iter 24
suggestion time taken 20.927235 iter 25 next_points [{'alpha': 2.74391365576778e-05, 'batch_size': 112, 'beta_1': 0.9812548090058165, 'beta_2': 0.9985875345761899, 'epsilon': 1.4299068677027972e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.05414670937724103, 'tol': 0.0073584782877650304, 'validation_fraction': 0.7765710008002014}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.419625 value -0.843956 suggestion {'alpha': 2.74391365576778e-05, 'batch_size': 112, 'beta_1': 0.9812548090058165, 'beta_2': 0.9985875345761899, 'epsilon': 1.4299068677027972e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.05414670937724103, 'tol': 0.0073584782877650304, 'validation_fraction': 0.7765710008002014}
observation time 0.000005, current best -0.918681 at iter 25
suggestion time taken 19.465946 iter 26 next_points [{'alpha': 0.0019108507838040741, 'batch_size': 43, 'beta_1': 0.8633585535121565, 'beta_2': 0.9999342774453077, 'epsilon': 4.807291594591797e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00013771663160762188, 'tol': 6.22149750047591e-05, 'validation_fraction': 0.6479124489140659}]
function_evaluation time 0.771659 value -0.628571 suggestion {'alpha': 0.0019108507838040741, 'batch_size': 43, 'beta_1': 0.8633585535121565, 'beta_2': 0.9999342774453077, 'epsilon': 4.807291594591797e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00013771663160762188, 'tol': 6.22149750047591e-05, 'validation_fraction': 0.6479124489140659}
observation time 0.000014, current best -0.918681 at iter 26
suggestion time taken 20.959020 iter 27 next_points [{'alpha': 0.0004085021657484363, 'batch_size': 41, 'beta_1': 0.9405277082647904, 'beta_2': 0.9999433092164013, 'epsilon': 4.89557107759638e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.015266303037887391, 'tol': 0.037940752868039884, 'validation_fraction': 0.42989828692049276}]
function_evaluation time 0.891115 value -0.905495 suggestion {'alpha': 0.0004085021657484363, 'batch_size': 41, 'beta_1': 0.9405277082647904, 'beta_2': 0.9999433092164013, 'epsilon': 4.89557107759638e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.015266303037887391, 'tol': 0.037940752868039884, 'validation_fraction': 0.42989828692049276}
observation time 0.000007, current best -0.918681 at iter 27
suggestion time taken 20.238445 iter 28 next_points [{'alpha': 1.3889858422349912, 'batch_size': 41, 'beta_1': 0.6396379764604436, 'beta_2': 0.941157183960262, 'epsilon': 1.0759916084068604e-08, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.019626222134801325, 'tol': 0.0027180367426554125, 'validation_fraction': 0.36332591239381273}]
function_evaluation time 0.501944 value -0.903297 suggestion {'alpha': 1.3889858422349912, 'batch_size': 41, 'beta_1': 0.6396379764604436, 'beta_2': 0.941157183960262, 'epsilon': 1.0759916084068604e-08, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.019626222134801325, 'tol': 0.0027180367426554125, 'validation_fraction': 0.36332591239381273}
observation time 0.000018, current best -0.918681 at iter 28
suggestion time taken 21.187050 iter 29 next_points [{'alpha': 0.04488848995794576, 'batch_size': 14, 'beta_1': 0.9439637162642412, 'beta_2': 0.9999922423689321, 'epsilon': 7.692287615793174e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 1.0669776040872867e-05, 'tol': 0.000220233378462257, 'validation_fraction': 0.1614044508901683}]
function_evaluation time 0.869518 value -0.556044 suggestion {'alpha': 0.04488848995794576, 'batch_size': 14, 'beta_1': 0.9439637162642412, 'beta_2': 0.9999922423689321, 'epsilon': 7.692287615793174e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 1.0669776040872867e-05, 'tol': 0.000220233378462257, 'validation_fraction': 0.1614044508901683}
observation time 0.000005, current best -0.918681 at iter 29
suggestion time taken 20.132876 iter 30 next_points [{'alpha': 0.023220247475262752, 'batch_size': 113, 'beta_1': 0.6355183072191032, 'beta_2': 0.999988744907849, 'epsilon': 1.4062724979908136e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.00010591393000095735, 'tol': 0.0003626482963737203, 'validation_fraction': 0.8818170735498292}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.247107 value -0.472527 suggestion {'alpha': 0.023220247475262752, 'batch_size': 113, 'beta_1': 0.6355183072191032, 'beta_2': 0.999988744907849, 'epsilon': 1.4062724979908136e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.00010591393000095735, 'tol': 0.0003626482963737203, 'validation_fraction': 0.8818170735498292}
observation time 0.000007, current best -0.918681 at iter 30
suggestion time taken 20.724871 iter 31 next_points [{'alpha': 5.100605700165343, 'batch_size': 45, 'beta_1': 0.9873695041720356, 'beta_2': 0.9943519507460009, 'epsilon': 8.274632379830899e-07, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.008361516325793563, 'tol': 0.0001413329428584714, 'validation_fraction': 0.14433178635984398}]
function_evaluation time 0.808529 value -0.892308 suggestion {'alpha': 5.100605700165343, 'batch_size': 45, 'beta_1': 0.9873695041720356, 'beta_2': 0.9943519507460009, 'epsilon': 8.274632379830899e-07, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.008361516325793563, 'tol': 0.0001413329428584714, 'validation_fraction': 0.14433178635984398}
observation time 0.000005, current best -0.918681 at iter 31
suggestion time taken 19.838106 iter 32 next_points [{'alpha': 0.5977565560312975, 'batch_size': 56, 'beta_1': 0.6928744300530241, 'beta_2': 0.9999965809950467, 'epsilon': 3.697389797118075e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 1.1205830293397313e-05, 'tol': 1.4284190530070375e-05, 'validation_fraction': 0.8493584047911433}]
function_evaluation time 0.337396 value -0.628571 suggestion {'alpha': 0.5977565560312975, 'batch_size': 56, 'beta_1': 0.6928744300530241, 'beta_2': 0.9999965809950467, 'epsilon': 3.697389797118075e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 1.1205830293397313e-05, 'tol': 1.4284190530070375e-05, 'validation_fraction': 0.8493584047911433}
observation time 0.000005, current best -0.918681 at iter 32
suggestion time taken 20.920434 iter 33 next_points [{'alpha': 4.640300296851274, 'batch_size': 113, 'beta_1': 0.8879936819797711, 'beta_2': 0.9969556455582372, 'epsilon': 7.474913362637653e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0003623864518195169, 'tol': 0.0014335802019330368, 'validation_fraction': 0.15257794797632915}]
function_evaluation time 0.997429 value -0.723077 suggestion {'alpha': 4.640300296851274, 'batch_size': 113, 'beta_1': 0.8879936819797711, 'beta_2': 0.9969556455582372, 'epsilon': 7.474913362637653e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0003623864518195169, 'tol': 0.0014335802019330368, 'validation_fraction': 0.15257794797632915}
observation time 0.000006, current best -0.918681 at iter 33
suggestion time taken 20.824602 iter 34 next_points [{'alpha': 0.0001639178478616719, 'batch_size': 11, 'beta_1': 0.9170593441177521, 'beta_2': 0.998392835688325, 'epsilon': 8.367018585336009e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.00028555746607654523, 'tol': 7.30657831683631e-05, 'validation_fraction': 0.37606731881660904}]
function_evaluation time 2.848452 value -0.883516 suggestion {'alpha': 0.0001639178478616719, 'batch_size': 11, 'beta_1': 0.9170593441177521, 'beta_2': 0.998392835688325, 'epsilon': 8.367018585336009e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.00028555746607654523, 'tol': 7.30657831683631e-05, 'validation_fraction': 0.37606731881660904}
observation time 0.000013, current best -0.918681 at iter 34
suggestion time taken 19.953496 iter 35 next_points [{'alpha': 3.5566135639677268, 'batch_size': 50, 'beta_1': 0.8485032790685478, 'beta_2': 0.9999985820730105, 'epsilon': 3.3744106245765306e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 5.622435295536902e-05, 'tol': 0.05460527245035387, 'validation_fraction': 0.27744838857728543}]
function_evaluation time 0.774696 value -0.586813 suggestion {'alpha': 3.5566135639677268, 'batch_size': 50, 'beta_1': 0.8485032790685478, 'beta_2': 0.9999985820730105, 'epsilon': 3.3744106245765306e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 5.622435295536902e-05, 'tol': 0.05460527245035387, 'validation_fraction': 0.27744838857728543}
observation time 0.000017, current best -0.918681 at iter 35
suggestion time taken 21.418073 iter 36 next_points [{'alpha': 1.3871126400949064e-05, 'batch_size': 11, 'beta_1': 0.8335650685582464, 'beta_2': 0.9798786287615129, 'epsilon': 3.817514149941705e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0008540695395963089, 'tol': 0.001961313116623693, 'validation_fraction': 0.3327354865271566}]
function_evaluation time 3.842247 value -0.918681 suggestion {'alpha': 1.3871126400949064e-05, 'batch_size': 11, 'beta_1': 0.8335650685582464, 'beta_2': 0.9798786287615129, 'epsilon': 3.817514149941705e-09, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0008540695395963089, 'tol': 0.001961313116623693, 'validation_fraction': 0.3327354865271566}
observation time 0.000012, current best -0.918681 at iter 36
suggestion time taken 19.733001 iter 37 next_points [{'alpha': 4.3211467982715135, 'batch_size': 112, 'beta_1': 0.9790253379345104, 'beta_2': 0.966765055729785, 'epsilon': 9.232144532894856e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0004673539781443951, 'tol': 0.010104821188531827, 'validation_fraction': 0.44032367762257996}]
function_evaluation time 0.591619 value -0.665934 suggestion {'alpha': 4.3211467982715135, 'batch_size': 112, 'beta_1': 0.9790253379345104, 'beta_2': 0.966765055729785, 'epsilon': 9.232144532894856e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0004673539781443951, 'tol': 0.010104821188531827, 'validation_fraction': 0.44032367762257996}
observation time 0.000005, current best -0.918681 at iter 37
suggestion time taken 21.401723 iter 38 next_points [{'alpha': 1.1320308399298478e-05, 'batch_size': 149, 'beta_1': 0.8735903622048514, 'beta_2': 0.9988325329604539, 'epsilon': 4.360918613697737e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.004992575316845923, 'tol': 0.08711228007817715, 'validation_fraction': 0.12503056030328621}]
function_evaluation time 0.201053 value -0.912088 suggestion {'alpha': 1.1320308399298478e-05, 'batch_size': 149, 'beta_1': 0.8735903622048514, 'beta_2': 0.9988325329604539, 'epsilon': 4.360918613697737e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.004992575316845923, 'tol': 0.08711228007817715, 'validation_fraction': 0.12503056030328621}
observation time 0.000004, current best -0.918681 at iter 38
suggestion time taken 19.985060 iter 39 next_points [{'alpha': 0.12176058565704907, 'batch_size': 227, 'beta_1': 0.9380462158313191, 'beta_2': 0.9999897659416211, 'epsilon': 5.014209196675653e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00048172137489262026, 'tol': 0.001135858884421006, 'validation_fraction': 0.8209909509491615}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.425436 value -0.703297 suggestion {'alpha': 0.12176058565704907, 'batch_size': 227, 'beta_1': 0.9380462158313191, 'beta_2': 0.9999897659416211, 'epsilon': 5.014209196675653e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00048172137489262026, 'tol': 0.001135858884421006, 'validation_fraction': 0.8209909509491615}
observation time 0.000005, current best -0.918681 at iter 39
suggestion time taken 21.061949 iter 40 next_points [{'alpha': 1.1196761292780188e-05, 'batch_size': 11, 'beta_1': 0.5782889665355548, 'beta_2': 0.9937438923033943, 'epsilon': 1.093124427867983e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.05597039750410844, 'tol': 0.03812472005658607, 'validation_fraction': 0.21063084472092772}]
function_evaluation time 2.693091 value -0.896703 suggestion {'alpha': 1.1196761292780188e-05, 'batch_size': 11, 'beta_1': 0.5782889665355548, 'beta_2': 0.9937438923033943, 'epsilon': 1.093124427867983e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.05597039750410844, 'tol': 0.03812472005658607, 'validation_fraction': 0.21063084472092772}
observation time 0.000006, current best -0.918681 at iter 40
suggestion time taken 20.728909 iter 41 next_points [{'alpha': 7.990238270869647, 'batch_size': 64, 'beta_1': 0.9449895936810131, 'beta_2': 0.9996923959917763, 'epsilon': 3.5841017672569486e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0013606935134449312, 'tol': 0.010186593198298998, 'validation_fraction': 0.19530949648159732}]
function_evaluation time 0.624931 value -0.905495 suggestion {'alpha': 7.990238270869647, 'batch_size': 64, 'beta_1': 0.9449895936810131, 'beta_2': 0.9996923959917763, 'epsilon': 3.5841017672569486e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0013606935134449312, 'tol': 0.010186593198298998, 'validation_fraction': 0.19530949648159732}
observation time 0.000014, current best -0.918681 at iter 41
suggestion time taken 20.005507 iter 42 next_points [{'alpha': 8.829543773659116, 'batch_size': 113, 'beta_1': 0.9840524077736783, 'beta_2': 0.9999756891223218, 'epsilon': 3.4178024482393337e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.003107559030312178, 'tol': 8.763593067275957e-05, 'validation_fraction': 0.44799152380435125}]
function_evaluation time 0.834461 value -0.909890 suggestion {'alpha': 8.829543773659116, 'batch_size': 113, 'beta_1': 0.9840524077736783, 'beta_2': 0.9999756891223218, 'epsilon': 3.4178024482393337e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.003107559030312178, 'tol': 8.763593067275957e-05, 'validation_fraction': 0.44799152380435125}
observation time 0.000006, current best -0.918681 at iter 42
suggestion time taken 21.233025 iter 43 next_points [{'alpha': 3.7509225937545363, 'batch_size': 90, 'beta_1': 0.6228317784096981, 'beta_2': 0.9929020481196917, 'epsilon': 5.572745412945713e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.006370327208917818, 'tol': 0.00012765267445381015, 'validation_fraction': 0.5316221408444345}]
function_evaluation time 0.709842 value -0.912088 suggestion {'alpha': 3.7509225937545363, 'batch_size': 90, 'beta_1': 0.6228317784096981, 'beta_2': 0.9929020481196917, 'epsilon': 5.572745412945713e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.006370327208917818, 'tol': 0.00012765267445381015, 'validation_fraction': 0.5316221408444345}
observation time 0.000009, current best -0.918681 at iter 43
suggestion time taken 19.916259 iter 44 next_points [{'alpha': 1.7055698377958357e-05, 'batch_size': 217, 'beta_1': 0.614592171634578, 'beta_2': 0.9999974513105022, 'epsilon': 8.456446545523496e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.0034192452301964986, 'tol': 5.426335074624675e-05, 'validation_fraction': 0.2957461448257751}]
function_evaluation time 0.750003 value -0.903297 suggestion {'alpha': 1.7055698377958357e-05, 'batch_size': 217, 'beta_1': 0.614592171634578, 'beta_2': 0.9999974513105022, 'epsilon': 8.456446545523496e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.0034192452301964986, 'tol': 5.426335074624675e-05, 'validation_fraction': 0.2957461448257751}
observation time 0.000005, current best -0.918681 at iter 44
saving meta data: {'args': {'--uuid': '0ae382362e6b589c9831536c8a8d6646', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
