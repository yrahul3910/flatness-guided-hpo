running: {'--uuid': '8a58bbcb66105260bcc72894901cb6a8', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 8a58bbcb66105260bcc72894901cb6a8 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.011072 iter 0 next_points [{'alpha': 1.8101052596561233, 'batch_size': 151, 'beta_1': 0.8156909338667627, 'beta_2': 0.9999855807798143, 'epsilon': 3.437181636217784e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 1.1011353385544973e-05, 'tol': 0.001992734043364081, 'validation_fraction': 0.8133132511078014}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.777308 value -0.582418 suggestion {'alpha': 1.8101052596561233, 'batch_size': 151, 'beta_1': 0.8156909338667627, 'beta_2': 0.9999855807798143, 'epsilon': 3.437181636217784e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 1.1011353385544973e-05, 'tol': 0.001992734043364081, 'validation_fraction': 0.8133132511078014}
observation time 0.000003, current best -0.582418 at iter 0
suggestion time taken 0.010077 iter 1 next_points [{'alpha': 0.00015548225715985371, 'batch_size': 96, 'beta_1': 0.9838558452450763, 'beta_2': 0.9998001893336568, 'epsilon': 8.499659079710243e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 7.914487623203872e-05, 'tol': 0.00039061253900405486, 'validation_fraction': 0.4355482457248519}]
function_evaluation time 0.614878 value -0.668132 suggestion {'alpha': 0.00015548225715985371, 'batch_size': 96, 'beta_1': 0.9838558452450763, 'beta_2': 0.9998001893336568, 'epsilon': 8.499659079710243e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 7.914487623203872e-05, 'tol': 0.00039061253900405486, 'validation_fraction': 0.4355482457248519}
observation time 0.000007, current best -0.668132 at iter 1
suggestion time taken 0.011121 iter 2 next_points [{'alpha': 0.0007678328379177236, 'batch_size': 15, 'beta_1': 0.7830676728210639, 'beta_2': 0.9965369479519112, 'epsilon': 1.1335597625186519e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.00010666924298669606, 'tol': 0.00022425576794506813, 'validation_fraction': 0.14796289051993075}]
function_evaluation time 1.516735 value -0.843956 suggestion {'alpha': 0.0007678328379177236, 'batch_size': 15, 'beta_1': 0.7830676728210639, 'beta_2': 0.9965369479519112, 'epsilon': 1.1335597625186519e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.00010666924298669606, 'tol': 0.00022425576794506813, 'validation_fraction': 0.14796289051993075}
observation time 0.000002, current best -0.843956 at iter 2
suggestion time taken 0.003614 iter 3 next_points [{'alpha': 0.07335685195173802, 'batch_size': 95, 'beta_1': 0.8210554234577361, 'beta_2': 0.9985212642784401, 'epsilon': 7.161589963565456e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.09549200971506182, 'tol': 9.421295526474873e-05, 'validation_fraction': 0.3489953344827099}]
function_evaluation time 0.720553 value -0.841758 suggestion {'alpha': 0.07335685195173802, 'batch_size': 95, 'beta_1': 0.8210554234577361, 'beta_2': 0.9985212642784401, 'epsilon': 7.161589963565456e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.09549200971506182, 'tol': 9.421295526474873e-05, 'validation_fraction': 0.3489953344827099}
observation time 0.000004, current best -0.843956 at iter 3
suggestion time taken 0.010828 iter 4 next_points [{'alpha': 0.016047365509750222, 'batch_size': 168, 'beta_1': 0.5524504849030767, 'beta_2': 0.9999757211808502, 'epsilon': 5.238468646118618e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 2.8126516691961285e-05, 'tol': 0.08979813478445924, 'validation_fraction': 0.4167280048205227}]
function_evaluation time 0.353817 value -0.527473 suggestion {'alpha': 0.016047365509750222, 'batch_size': 168, 'beta_1': 0.5524504849030767, 'beta_2': 0.9999757211808502, 'epsilon': 5.238468646118618e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 2.8126516691961285e-05, 'tol': 0.08979813478445924, 'validation_fraction': 0.4167280048205227}
observation time 0.000003, current best -0.843956 at iter 4
suggestion time taken 0.010429 iter 5 next_points [{'alpha': 0.002539135520837331, 'batch_size': 186, 'beta_1': 0.866763772564719, 'beta_2': 0.9902556511127862, 'epsilon': 1.0928119428942977e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0020448247923190994, 'tol': 0.0029983869740600184, 'validation_fraction': 0.5150431582866863}]
function_evaluation time 0.887655 value -0.835165 suggestion {'alpha': 0.002539135520837331, 'batch_size': 186, 'beta_1': 0.866763772564719, 'beta_2': 0.9902556511127862, 'epsilon': 1.0928119428942977e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0020448247923190994, 'tol': 0.0029983869740600184, 'validation_fraction': 0.5150431582866863}
observation time 0.000003, current best -0.843956 at iter 5
suggestion time taken 0.009691 iter 6 next_points [{'alpha': 0.002280530938715264, 'batch_size': 219, 'beta_1': 0.7627502492995081, 'beta_2': 0.999996611078503, 'epsilon': 1.7546159943509416e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 1.6084596943365422e-05, 'tol': 0.05163335271396842, 'validation_fraction': 0.4339123131098119}]
function_evaluation time 0.252789 value -0.582418 suggestion {'alpha': 0.002280530938715264, 'batch_size': 219, 'beta_1': 0.7627502492995081, 'beta_2': 0.999996611078503, 'epsilon': 1.7546159943509416e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 1.6084596943365422e-05, 'tol': 0.05163335271396842, 'validation_fraction': 0.4339123131098119}
observation time 0.000004, current best -0.843956 at iter 6
suggestion time taken 0.011149 iter 7 next_points [{'alpha': 0.000339829786154169, 'batch_size': 244, 'beta_1': 0.7326946267011325, 'beta_2': 0.9999950772507865, 'epsilon': 9.749002303965482e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0006341973143924253, 'tol': 2.8473942318866637e-05, 'validation_fraction': 0.7926690620334333}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.736615 value -0.815385 suggestion {'alpha': 0.000339829786154169, 'batch_size': 244, 'beta_1': 0.7326946267011325, 'beta_2': 0.9999950772507865, 'epsilon': 9.749002303965482e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0006341973143924253, 'tol': 2.8473942318866637e-05, 'validation_fraction': 0.7926690620334333}
observation time 0.000004, current best -0.843956 at iter 7
suggestion time taken 0.011594 iter 8 next_points [{'alpha': 0.5755656707103166, 'batch_size': 43, 'beta_1': 0.9503095908339546, 'beta_2': 0.9999814131288524, 'epsilon': 1.8946849697025132e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.01913856403046076, 'tol': 0.03398122342939666, 'validation_fraction': 0.4022676621870262}]
function_evaluation time 0.928867 value -0.896703 suggestion {'alpha': 0.5755656707103166, 'batch_size': 43, 'beta_1': 0.9503095908339546, 'beta_2': 0.9999814131288524, 'epsilon': 1.8946849697025132e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.01913856403046076, 'tol': 0.03398122342939666, 'validation_fraction': 0.4022676621870262}
observation time 0.000009, current best -0.896703 at iter 8
suggestion time taken 0.012267 iter 9 next_points [{'alpha': 0.0829173691564178, 'batch_size': 175, 'beta_1': 0.663592869720325, 'beta_2': 0.9990374179714975, 'epsilon': 7.4329597393149696e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.016156124542823627, 'tol': 0.00013726954364335888, 'validation_fraction': 0.6700245429366847}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.707297 value -0.907692 suggestion {'alpha': 0.0829173691564178, 'batch_size': 175, 'beta_1': 0.663592869720325, 'beta_2': 0.9990374179714975, 'epsilon': 7.4329597393149696e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.016156124542823627, 'tol': 0.00013726954364335888, 'validation_fraction': 0.6700245429366847}
observation time 0.000011, current best -0.907692 at iter 9
suggestion time taken 0.013460 iter 10 next_points [{'alpha': 0.06330521133426086, 'batch_size': 185, 'beta_1': 0.9714362420601482, 'beta_2': 0.9999662987564955, 'epsilon': 7.796682888264139e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 7.150212795401866e-05, 'tol': 0.0012570794731520522, 'validation_fraction': 0.7865669343114676}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.322241 value -0.670330 suggestion {'alpha': 0.06330521133426086, 'batch_size': 185, 'beta_1': 0.9714362420601482, 'beta_2': 0.9999662987564955, 'epsilon': 7.796682888264139e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 7.150212795401866e-05, 'tol': 0.0012570794731520522, 'validation_fraction': 0.7865669343114676}
observation time 0.000007, current best -0.907692 at iter 10
suggestion time taken 0.011872 iter 11 next_points [{'alpha': 0.0034515685533301776, 'batch_size': 121, 'beta_1': 0.966587672334209, 'beta_2': 0.9999267735741432, 'epsilon': 4.8763976080892e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0034979048647765854, 'tol': 6.739670857820925e-05, 'validation_fraction': 0.10078001579947427}]
function_evaluation time 0.726339 value -0.881319 suggestion {'alpha': 0.0034515685533301776, 'batch_size': 121, 'beta_1': 0.966587672334209, 'beta_2': 0.9999267735741432, 'epsilon': 4.8763976080892e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0034979048647765854, 'tol': 6.739670857820925e-05, 'validation_fraction': 0.10078001579947427}
observation time 0.000011, current best -0.907692 at iter 11
suggestion time taken 0.013750 iter 12 next_points [{'alpha': 2.0514442435401294e-05, 'batch_size': 48, 'beta_1': 0.7073424650268894, 'beta_2': 0.999884418986521, 'epsilon': 1.1005740074506776e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.010206599357141313, 'tol': 0.002648997779781826, 'validation_fraction': 0.25522913769484057}]
function_evaluation time 0.410082 value -0.920879 suggestion {'alpha': 2.0514442435401294e-05, 'batch_size': 48, 'beta_1': 0.7073424650268894, 'beta_2': 0.999884418986521, 'epsilon': 1.1005740074506776e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.010206599357141313, 'tol': 0.002648997779781826, 'validation_fraction': 0.25522913769484057}
observation time 0.000002, current best -0.920879 at iter 12
suggestion time taken 0.003968 iter 13 next_points [{'alpha': 0.006635441016181735, 'batch_size': 214, 'beta_1': 0.939246368392554, 'beta_2': 0.9999284555969828, 'epsilon': 3.4853168211170868e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.031170606405615073, 'tol': 0.00017062780642482757, 'validation_fraction': 0.37173741941220734}]
function_evaluation time 0.733640 value -0.898901 suggestion {'alpha': 0.006635441016181735, 'batch_size': 214, 'beta_1': 0.939246368392554, 'beta_2': 0.9999284555969828, 'epsilon': 3.4853168211170868e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.031170606405615073, 'tol': 0.00017062780642482757, 'validation_fraction': 0.37173741941220734}
observation time 0.000004, current best -0.920879 at iter 13
suggestion time taken 0.010679 iter 14 next_points [{'alpha': 0.00044058962073832074, 'batch_size': 98, 'beta_1': 0.9601698095544613, 'beta_2': 0.9999961050130777, 'epsilon': 1.3946372756170155e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.00024576447541413405, 'tol': 0.0016522784010579914, 'validation_fraction': 0.8162400916040099}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.326435 value -0.573626 suggestion {'alpha': 0.00044058962073832074, 'batch_size': 98, 'beta_1': 0.9601698095544613, 'beta_2': 0.9999961050130777, 'epsilon': 1.3946372756170155e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.00024576447541413405, 'tol': 0.0016522784010579914, 'validation_fraction': 0.8162400916040099}
observation time 0.000003, current best -0.920879 at iter 14
suggestion time taken 0.009824 iter 15 next_points [{'alpha': 0.06613632964779127, 'batch_size': 84, 'beta_1': 0.8226894336732327, 'beta_2': 0.9999087205496914, 'epsilon': 6.4496687018544414e-09, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.008069867692556389, 'tol': 0.001343573991063494, 'validation_fraction': 0.5020874026574728}]
function_evaluation time 0.819618 value -0.903297 suggestion {'alpha': 0.06613632964779127, 'batch_size': 84, 'beta_1': 0.8226894336732327, 'beta_2': 0.9999087205496914, 'epsilon': 6.4496687018544414e-09, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.008069867692556389, 'tol': 0.001343573991063494, 'validation_fraction': 0.5020874026574728}
observation time 0.000007, current best -0.920879 at iter 15
suggestion time taken 0.011743 iter 16 next_points [{'alpha': 1.0447155021706467, 'batch_size': 189, 'beta_1': 0.9603448878105465, 'beta_2': 0.958902130043256, 'epsilon': 1.1152564544725529e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.001971074736258975, 'tol': 1.6554737140711018e-05, 'validation_fraction': 0.13603815236511696}]
function_evaluation time 1.067909 value -0.874725 suggestion {'alpha': 1.0447155021706467, 'batch_size': 189, 'beta_1': 0.9603448878105465, 'beta_2': 0.958902130043256, 'epsilon': 1.1152564544725529e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.001971074736258975, 'tol': 1.6554737140711018e-05, 'validation_fraction': 0.13603815236511696}
observation time 0.000004, current best -0.920879 at iter 16
suggestion time taken 0.011388 iter 17 next_points [{'alpha': 2.0968219780032107, 'batch_size': 231, 'beta_1': 0.9096769275941818, 'beta_2': 0.9999380757069083, 'epsilon': 4.18022337752922e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.00010485754913954809, 'tol': 0.040862101745653356, 'validation_fraction': 0.5887961743461749}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.295895 value -0.582418 suggestion {'alpha': 2.0968219780032107, 'batch_size': 231, 'beta_1': 0.9096769275941818, 'beta_2': 0.9999380757069083, 'epsilon': 4.18022337752922e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.00010485754913954809, 'tol': 0.040862101745653356, 'validation_fraction': 0.5887961743461749}
observation time 0.000004, current best -0.920879 at iter 17
suggestion time taken 0.010166 iter 18 next_points [{'alpha': 2.2619723695814744, 'batch_size': 108, 'beta_1': 0.6847337133966424, 'beta_2': 0.9357827498291278, 'epsilon': 1.8500752032783004e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.080425803171029, 'tol': 0.00020155761007145843, 'validation_fraction': 0.8044928756905587}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.432236 value -0.852747 suggestion {'alpha': 2.2619723695814744, 'batch_size': 108, 'beta_1': 0.6847337133966424, 'beta_2': 0.9357827498291278, 'epsilon': 1.8500752032783004e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.080425803171029, 'tol': 0.00020155761007145843, 'validation_fraction': 0.8044928756905587}
observation time 0.000009, current best -0.920879 at iter 18
suggestion time taken 0.013309 iter 19 next_points [{'alpha': 0.0021348648712277074, 'batch_size': 147, 'beta_1': 0.8764014421116056, 'beta_2': 0.9999923079494536, 'epsilon': 2.8014627947402187e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.009022140068315055, 'tol': 1.1288387291619372e-05, 'validation_fraction': 0.6730746905967361}]
function_evaluation time 0.566375 value -0.901099 suggestion {'alpha': 0.0021348648712277074, 'batch_size': 147, 'beta_1': 0.8764014421116056, 'beta_2': 0.9999923079494536, 'epsilon': 2.8014627947402187e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.009022140068315055, 'tol': 1.1288387291619372e-05, 'validation_fraction': 0.6730746905967361}
observation time 0.000003, current best -0.920879 at iter 19
suggestion time taken 0.009638 iter 20 next_points [{'alpha': 0.00011120102911796692, 'batch_size': 37, 'beta_1': 0.5282204449349392, 'beta_2': 0.9991307069393474, 'epsilon': 3.2350838267585183e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00367024845064562, 'tol': 0.00010853752180762641, 'validation_fraction': 0.7249713896779139}]
function_evaluation time 0.863410 value -0.901099 suggestion {'alpha': 0.00011120102911796692, 'batch_size': 37, 'beta_1': 0.5282204449349392, 'beta_2': 0.9991307069393474, 'epsilon': 3.2350838267585183e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00367024845064562, 'tol': 0.00010853752180762641, 'validation_fraction': 0.7249713896779139}
observation time 0.000004, current best -0.920879 at iter 20
suggestion time taken 0.010681 iter 21 next_points [{'alpha': 1.672248165580466, 'batch_size': 187, 'beta_1': 0.8345346112253929, 'beta_2': 0.999997958235915, 'epsilon': 2.7782810794576472e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 5.7721873598065346e-05, 'tol': 0.0006002746882615721, 'validation_fraction': 0.74191129044357}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.278542 value -0.472527 suggestion {'alpha': 1.672248165580466, 'batch_size': 187, 'beta_1': 0.8345346112253929, 'beta_2': 0.999997958235915, 'epsilon': 2.7782810794576472e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 5.7721873598065346e-05, 'tol': 0.0006002746882615721, 'validation_fraction': 0.74191129044357}
observation time 0.000003, current best -0.920879 at iter 21
suggestion time taken 0.010921 iter 22 next_points [{'alpha': 2.1064575750939127, 'batch_size': 34, 'beta_1': 0.9818298816881051, 'beta_2': 0.9999980773318923, 'epsilon': 6.612932656372039e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 8.464702008085761e-05, 'tol': 0.06633166307995579, 'validation_fraction': 0.3746181666674161}]
function_evaluation time 0.813116 value -0.742857 suggestion {'alpha': 2.1064575750939127, 'batch_size': 34, 'beta_1': 0.9818298816881051, 'beta_2': 0.9999980773318923, 'epsilon': 6.612932656372039e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 8.464702008085761e-05, 'tol': 0.06633166307995579, 'validation_fraction': 0.3746181666674161}
observation time 0.000004, current best -0.920879 at iter 22
suggestion time taken 0.010094 iter 23 next_points [{'alpha': 0.8346155346449635, 'batch_size': 113, 'beta_1': 0.5765148780958169, 'beta_2': 0.9999876964622287, 'epsilon': 9.47609678022636e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0031681484534810877, 'tol': 0.0177400056662572, 'validation_fraction': 0.10338098069420716}]
function_evaluation time 0.378309 value -0.872527 suggestion {'alpha': 0.8346155346449635, 'batch_size': 113, 'beta_1': 0.5765148780958169, 'beta_2': 0.9999876964622287, 'epsilon': 9.47609678022636e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0031681484534810877, 'tol': 0.0177400056662572, 'validation_fraction': 0.10338098069420716}
observation time 0.000003, current best -0.920879 at iter 23
suggestion time taken 0.004122 iter 24 next_points [{'alpha': 3.458167309949871, 'batch_size': 150, 'beta_1': 0.9728164761538131, 'beta_2': 0.9999966667577135, 'epsilon': 2.321344269505605e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.00037038036572940755, 'tol': 0.00038472349622667125, 'validation_fraction': 0.8815766362064814}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.577796 value -0.683516 suggestion {'alpha': 3.458167309949871, 'batch_size': 150, 'beta_1': 0.9728164761538131, 'beta_2': 0.9999966667577135, 'epsilon': 2.321344269505605e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.00037038036572940755, 'tol': 0.00038472349622667125, 'validation_fraction': 0.8815766362064814}
observation time 0.000003, current best -0.920879 at iter 24
suggestion time taken 0.010147 iter 25 next_points [{'alpha': 0.0814149280208056, 'batch_size': 149, 'beta_1': 0.9293146350581892, 'beta_2': 0.9988979468171765, 'epsilon': 7.102201301830259e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.008689435951262977, 'tol': 6.898190519121611e-05, 'validation_fraction': 0.6433406956835345}]
function_evaluation time 0.807799 value -0.918681 suggestion {'alpha': 0.0814149280208056, 'batch_size': 149, 'beta_1': 0.9293146350581892, 'beta_2': 0.9988979468171765, 'epsilon': 7.102201301830259e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.008689435951262977, 'tol': 6.898190519121611e-05, 'validation_fraction': 0.6433406956835345}
observation time 0.000004, current best -0.920879 at iter 25
suggestion time taken 0.010984 iter 26 next_points [{'alpha': 8.550308168611929, 'batch_size': 131, 'beta_1': 0.9104218079536239, 'beta_2': 0.9993565043459461, 'epsilon': 2.5714163903374945e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.00019388474629039265, 'tol': 0.011314845682728412, 'validation_fraction': 0.893643797741334}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.235518 value -0.472527 suggestion {'alpha': 8.550308168611929, 'batch_size': 131, 'beta_1': 0.9104218079536239, 'beta_2': 0.9993565043459461, 'epsilon': 2.5714163903374945e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.00019388474629039265, 'tol': 0.011314845682728412, 'validation_fraction': 0.893643797741334}
observation time 0.000003, current best -0.920879 at iter 26
suggestion time taken 0.010437 iter 27 next_points [{'alpha': 3.340552560509286, 'batch_size': 182, 'beta_1': 0.9038704880478151, 'beta_2': 0.9997739959255896, 'epsilon': 3.1621579107997056e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.015720771307902025, 'tol': 0.026538803914572005, 'validation_fraction': 0.37793603364115147}]
function_evaluation time 0.503703 value -0.903297 suggestion {'alpha': 3.340552560509286, 'batch_size': 182, 'beta_1': 0.9038704880478151, 'beta_2': 0.9997739959255896, 'epsilon': 3.1621579107997056e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.015720771307902025, 'tol': 0.026538803914572005, 'validation_fraction': 0.37793603364115147}
observation time 0.000011, current best -0.920879 at iter 27
suggestion time taken 0.014186 iter 28 next_points [{'alpha': 0.00024524367243440674, 'batch_size': 87, 'beta_1': 0.8699777290457336, 'beta_2': 0.9895978512749476, 'epsilon': 1.250590256504485e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.007664285205554609, 'tol': 0.0008465207842642833, 'validation_fraction': 0.676303016160232}]
function_evaluation time 0.813560 value -0.905495 suggestion {'alpha': 0.00024524367243440674, 'batch_size': 87, 'beta_1': 0.8699777290457336, 'beta_2': 0.9895978512749476, 'epsilon': 1.250590256504485e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.007664285205554609, 'tol': 0.0008465207842642833, 'validation_fraction': 0.676303016160232}
observation time 0.000004, current best -0.920879 at iter 28
suggestion time taken 0.011240 iter 29 next_points [{'alpha': 0.027702042952055455, 'batch_size': 176, 'beta_1': 0.8392250658556785, 'beta_2': 0.9308211378014918, 'epsilon': 5.984491718059217e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.000795716022794885, 'tol': 0.024914075277311064, 'validation_fraction': 0.8503077385567268}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.283487 value -0.648352 suggestion {'alpha': 0.027702042952055455, 'batch_size': 176, 'beta_1': 0.8392250658556785, 'beta_2': 0.9308211378014918, 'epsilon': 5.984491718059217e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.000795716022794885, 'tol': 0.024914075277311064, 'validation_fraction': 0.8503077385567268}
observation time 0.000009, current best -0.920879 at iter 29
suggestion time taken 0.015944 iter 30 next_points [{'alpha': 3.3870832136468496, 'batch_size': 122, 'beta_1': 0.9861438253250461, 'beta_2': 0.9498215193737967, 'epsilon': 9.302181369827635e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 2.3116140906150602e-05, 'tol': 0.005929910229135652, 'validation_fraction': 0.7698737749522176}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.305958 value -0.472527 suggestion {'alpha': 3.3870832136468496, 'batch_size': 122, 'beta_1': 0.9861438253250461, 'beta_2': 0.9498215193737967, 'epsilon': 9.302181369827635e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 2.3116140906150602e-05, 'tol': 0.005929910229135652, 'validation_fraction': 0.7698737749522176}
observation time 0.000005, current best -0.920879 at iter 30
suggestion time taken 0.011240 iter 31 next_points [{'alpha': 0.00484669540109434, 'batch_size': 71, 'beta_1': 0.989038944155657, 'beta_2': 0.9999402227426988, 'epsilon': 1.5007686046292574e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 4.159998087192648e-05, 'tol': 0.00028919206656832905, 'validation_fraction': 0.4692394699113178}]
function_evaluation time 0.796564 value -0.619780 suggestion {'alpha': 0.00484669540109434, 'batch_size': 71, 'beta_1': 0.989038944155657, 'beta_2': 0.9999402227426988, 'epsilon': 1.5007686046292574e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 4.159998087192648e-05, 'tol': 0.00028919206656832905, 'validation_fraction': 0.4692394699113178}
observation time 0.000007, current best -0.920879 at iter 31
suggestion time taken 0.014188 iter 32 next_points [{'alpha': 0.00017114469468963568, 'batch_size': 129, 'beta_1': 0.8587460646050472, 'beta_2': 0.9992320645737021, 'epsilon': 4.467558798280296e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.035262233201842165, 'tol': 0.001948213534427927, 'validation_fraction': 0.6069955549187278}]
function_evaluation time 0.705953 value -0.848352 suggestion {'alpha': 0.00017114469468963568, 'batch_size': 129, 'beta_1': 0.8587460646050472, 'beta_2': 0.9992320645737021, 'epsilon': 4.467558798280296e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.035262233201842165, 'tol': 0.001948213534427927, 'validation_fraction': 0.6069955549187278}
observation time 0.000005, current best -0.920879 at iter 32
suggestion time taken 0.011056 iter 33 next_points [{'alpha': 0.0031854059871633212, 'batch_size': 97, 'beta_1': 0.9750397592793407, 'beta_2': 0.9974515341491174, 'epsilon': 1.4629490194963734e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.00010955533195584742, 'tol': 0.00111381204324621, 'validation_fraction': 0.11046995959593081}]
function_evaluation time 0.754157 value -0.716484 suggestion {'alpha': 0.0031854059871633212, 'batch_size': 97, 'beta_1': 0.9750397592793407, 'beta_2': 0.9974515341491174, 'epsilon': 1.4629490194963734e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.00010955533195584742, 'tol': 0.00111381204324621, 'validation_fraction': 0.11046995959593081}
observation time 0.000003, current best -0.920879 at iter 33
suggestion time taken 0.010258 iter 34 next_points [{'alpha': 2.218054003206821, 'batch_size': 121, 'beta_1': 0.7598021493373319, 'beta_2': 0.9999184690057566, 'epsilon': 7.944645019593668e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.003479063818448702, 'tol': 0.0008805666630978194, 'validation_fraction': 0.8469435050997207}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.662571 value -0.800000 suggestion {'alpha': 2.218054003206821, 'batch_size': 121, 'beta_1': 0.7598021493373319, 'beta_2': 0.9999184690057566, 'epsilon': 7.944645019593668e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.003479063818448702, 'tol': 0.0008805666630978194, 'validation_fraction': 0.8469435050997207}
observation time 0.000004, current best -0.920879 at iter 34
suggestion time taken 0.011606 iter 35 next_points [{'alpha': 0.15600028280138983, 'batch_size': 117, 'beta_1': 0.6778387710208332, 'beta_2': 0.9872030245964226, 'epsilon': 5.514800263732798e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0008940287874928324, 'tol': 0.005183078990347219, 'validation_fraction': 0.8676325061029974}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.449211 value -0.756044 suggestion {'alpha': 0.15600028280138983, 'batch_size': 117, 'beta_1': 0.6778387710208332, 'beta_2': 0.9872030245964226, 'epsilon': 5.514800263732798e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0008940287874928324, 'tol': 0.005183078990347219, 'validation_fraction': 0.8676325061029974}
observation time 0.000003, current best -0.920879 at iter 35
suggestion time taken 0.010069 iter 36 next_points [{'alpha': 0.013244889708813847, 'batch_size': 156, 'beta_1': 0.8353583250399396, 'beta_2': 0.9917062259044669, 'epsilon': 2.9138683258901397e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.005710287466313044, 'tol': 7.095196636337474e-05, 'validation_fraction': 0.8433857553188467}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.781847 value -0.901099 suggestion {'alpha': 0.013244889708813847, 'batch_size': 156, 'beta_1': 0.8353583250399396, 'beta_2': 0.9917062259044669, 'epsilon': 2.9138683258901397e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.005710287466313044, 'tol': 7.095196636337474e-05, 'validation_fraction': 0.8433857553188467}
observation time 0.000003, current best -0.920879 at iter 36
suggestion time taken 0.010180 iter 37 next_points [{'alpha': 0.003197682553347941, 'batch_size': 87, 'beta_1': 0.9445737028892349, 'beta_2': 0.9942972377560308, 'epsilon': 5.0875099198784715e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0008890624272278137, 'tol': 1.3564906449336209e-05, 'validation_fraction': 0.1336972383238505}]
function_evaluation time 0.494558 value -0.903297 suggestion {'alpha': 0.003197682553347941, 'batch_size': 87, 'beta_1': 0.9445737028892349, 'beta_2': 0.9942972377560308, 'epsilon': 5.0875099198784715e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.0008890624272278137, 'tol': 1.3564906449336209e-05, 'validation_fraction': 0.1336972383238505}
observation time 0.000005, current best -0.920879 at iter 37
suggestion time taken 0.013276 iter 38 next_points [{'alpha': 1.8131779239071162, 'batch_size': 240, 'beta_1': 0.898401825558945, 'beta_2': 0.996015982064446, 'epsilon': 4.108021235176031e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.00263412309287668, 'tol': 1.0649092956927968e-05, 'validation_fraction': 0.8080576480498396}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.800102 value -0.901099 suggestion {'alpha': 1.8131779239071162, 'batch_size': 240, 'beta_1': 0.898401825558945, 'beta_2': 0.996015982064446, 'epsilon': 4.108021235176031e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.00263412309287668, 'tol': 1.0649092956927968e-05, 'validation_fraction': 0.8080576480498396}
observation time 0.000004, current best -0.920879 at iter 38
suggestion time taken 0.010639 iter 39 next_points [{'alpha': 1.4871659546878406e-05, 'batch_size': 126, 'beta_1': 0.8880157139980834, 'beta_2': 0.9999968184728232, 'epsilon': 2.6524976218772312e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 1.3828412623684742e-05, 'tol': 0.006363834651480797, 'validation_fraction': 0.3223211955666999}]
function_evaluation time 0.194487 value -0.527473 suggestion {'alpha': 1.4871659546878406e-05, 'batch_size': 126, 'beta_1': 0.8880157139980834, 'beta_2': 0.9999968184728232, 'epsilon': 2.6524976218772312e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 1.3828412623684742e-05, 'tol': 0.006363834651480797, 'validation_fraction': 0.3223211955666999}
observation time 0.000002, current best -0.920879 at iter 39
suggestion time taken 0.004105 iter 40 next_points [{'alpha': 0.5349724770434776, 'batch_size': 92, 'beta_1': 0.9670683106263082, 'beta_2': 0.995686283529466, 'epsilon': 1.1618946033437775e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.022837681755220954, 'tol': 0.003937125007089163, 'validation_fraction': 0.5235554922975322}]
function_evaluation time 0.847945 value -0.890110 suggestion {'alpha': 0.5349724770434776, 'batch_size': 92, 'beta_1': 0.9670683106263082, 'beta_2': 0.995686283529466, 'epsilon': 1.1618946033437775e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.022837681755220954, 'tol': 0.003937125007089163, 'validation_fraction': 0.5235554922975322}
observation time 0.000005, current best -0.920879 at iter 40
suggestion time taken 0.014149 iter 41 next_points [{'alpha': 0.12533022374977063, 'batch_size': 244, 'beta_1': 0.8163046954471803, 'beta_2': 0.9581333052411264, 'epsilon': 1.5079960914889097e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.004599884076511083, 'tol': 0.002396348212027137, 'validation_fraction': 0.21799645957427083}]
function_evaluation time 0.774240 value -0.892308 suggestion {'alpha': 0.12533022374977063, 'batch_size': 244, 'beta_1': 0.8163046954471803, 'beta_2': 0.9581333052411264, 'epsilon': 1.5079960914889097e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.004599884076511083, 'tol': 0.002396348212027137, 'validation_fraction': 0.21799645957427083}
observation time 0.000003, current best -0.920879 at iter 41
suggestion time taken 0.010039 iter 42 next_points [{'alpha': 3.489712555387274e-05, 'batch_size': 235, 'beta_1': 0.5945845067597652, 'beta_2': 0.9999908389189383, 'epsilon': 9.014380676418327e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0003659378027337421, 'tol': 0.04344204509129535, 'validation_fraction': 0.5167111795765867}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.294456 value -0.624176 suggestion {'alpha': 3.489712555387274e-05, 'batch_size': 235, 'beta_1': 0.5945845067597652, 'beta_2': 0.9999908389189383, 'epsilon': 9.014380676418327e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0003659378027337421, 'tol': 0.04344204509129535, 'validation_fraction': 0.5167111795765867}
observation time 0.000004, current best -0.920879 at iter 42
suggestion time taken 0.011187 iter 43 next_points [{'alpha': 6.87510318726888, 'batch_size': 246, 'beta_1': 0.9869277454044242, 'beta_2': 0.9505015513605255, 'epsilon': 1.2932131126485034e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 5.111278301936797e-05, 'tol': 1.840448605844119e-05, 'validation_fraction': 0.3773911462544112}]
function_evaluation time 0.520424 value -0.472527 suggestion {'alpha': 6.87510318726888, 'batch_size': 246, 'beta_1': 0.9869277454044242, 'beta_2': 0.9505015513605255, 'epsilon': 1.2932131126485034e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 5.111278301936797e-05, 'tol': 1.840448605844119e-05, 'validation_fraction': 0.3773911462544112}
observation time 0.000004, current best -0.920879 at iter 43
suggestion time taken 0.011685 iter 44 next_points [{'alpha': 0.046104395982762954, 'batch_size': 241, 'beta_1': 0.8955480958820856, 'beta_2': 0.9999821454989647, 'epsilon': 2.252023945507572e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.0007678917352984286, 'tol': 0.006254537541214646, 'validation_fraction': 0.6313188807760363}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.429649 value -0.789011 suggestion {'alpha': 0.046104395982762954, 'batch_size': 241, 'beta_1': 0.8955480958820856, 'beta_2': 0.9999821454989647, 'epsilon': 2.252023945507572e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.0007678917352984286, 'tol': 0.006254537541214646, 'validation_fraction': 0.6313188807760363}
observation time 0.000004, current best -0.920879 at iter 44
saving meta data: {'args': {'--uuid': '8a58bbcb66105260bcc72894901cb6a8', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
