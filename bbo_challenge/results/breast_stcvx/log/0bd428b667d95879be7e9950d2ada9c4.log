running: {'--uuid': '0bd428b667d95879be7e9950d2ada9c4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 0bd428b667d95879be7e9950d2ada9c4 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.009773 iter 0 next_points [{'alpha': 1.9482209063376201, 'batch_size': 212, 'beta_1': 0.912027191537689, 'beta_2': 0.9463710544009728, 'epsilon': 5.356977838507011e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.00010229847468705533, 'tol': 2.7708251154662805e-05, 'validation_fraction': 0.551124623401332}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.425961 value -0.586813 suggestion {'alpha': 1.9482209063376201, 'batch_size': 212, 'beta_1': 0.912027191537689, 'beta_2': 0.9463710544009728, 'epsilon': 5.356977838507011e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.00010229847468705533, 'tol': 2.7708251154662805e-05, 'validation_fraction': 0.551124623401332}
observation time 0.000004, current best -0.586813 at iter 0
suggestion time taken 0.011431 iter 1 next_points [{'alpha': 6.885082545667347e-05, 'batch_size': 69, 'beta_1': 0.9436403895746727, 'beta_2': 0.9999640234370767, 'epsilon': 6.739858994457078e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0088685339778333, 'tol': 0.0010288931308850098, 'validation_fraction': 0.10158764621745377}]
function_evaluation time 0.329950 value -0.868132 suggestion {'alpha': 6.885082545667347e-05, 'batch_size': 69, 'beta_1': 0.9436403895746727, 'beta_2': 0.9999640234370767, 'epsilon': 6.739858994457078e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0088685339778333, 'tol': 0.0010288931308850098, 'validation_fraction': 0.10158764621745377}
observation time 0.000002, current best -0.868132 at iter 1
suggestion time taken 0.003875 iter 2 next_points [{'alpha': 0.0010879546880634878, 'batch_size': 189, 'beta_1': 0.9875238269414535, 'beta_2': 0.9969780431519211, 'epsilon': 1.4120402899223728e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.05273460010416285, 'tol': 1.3671913322177195e-05, 'validation_fraction': 0.12740567049874318}]
function_evaluation time 0.538390 value -0.806593 suggestion {'alpha': 0.0010879546880634878, 'batch_size': 189, 'beta_1': 0.9875238269414535, 'beta_2': 0.9969780431519211, 'epsilon': 1.4120402899223728e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.05273460010416285, 'tol': 1.3671913322177195e-05, 'validation_fraction': 0.12740567049874318}
observation time 0.000004, current best -0.868132 at iter 2
suggestion time taken 0.010052 iter 3 next_points [{'alpha': 0.006790507647096433, 'batch_size': 115, 'beta_1': 0.9543560286088498, 'beta_2': 0.9919531176828463, 'epsilon': 7.217831346880834e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.054590893595194354, 'tol': 0.013952279403362997, 'validation_fraction': 0.11071813442634927}]
function_evaluation time 0.580484 value -0.876923 suggestion {'alpha': 0.006790507647096433, 'batch_size': 115, 'beta_1': 0.9543560286088498, 'beta_2': 0.9919531176828463, 'epsilon': 7.217831346880834e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.054590893595194354, 'tol': 0.013952279403362997, 'validation_fraction': 0.11071813442634927}
observation time 0.000015, current best -0.876923 at iter 3
suggestion time taken 0.011632 iter 4 next_points [{'alpha': 1.0370350009411968, 'batch_size': 143, 'beta_1': 0.8330572386752494, 'beta_2': 0.9978097006351406, 'epsilon': 6.003507304712023e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 1.6962623189591746e-05, 'tol': 1.4616087857779109e-05, 'validation_fraction': 0.29763368893970193}]
function_evaluation time 0.701068 value -0.582418 suggestion {'alpha': 1.0370350009411968, 'batch_size': 143, 'beta_1': 0.8330572386752494, 'beta_2': 0.9978097006351406, 'epsilon': 6.003507304712023e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 1.6962623189591746e-05, 'tol': 1.4616087857779109e-05, 'validation_fraction': 0.29763368893970193}
observation time 0.000004, current best -0.876923 at iter 4
suggestion time taken 0.010372 iter 5 next_points [{'alpha': 0.0004228869644233298, 'batch_size': 99, 'beta_1': 0.9855007944826204, 'beta_2': 0.9999925326022187, 'epsilon': 3.5760527755200073e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.03989597906937536, 'tol': 0.0077565778535572385, 'validation_fraction': 0.8641119734197497}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.300100 value -0.718681 suggestion {'alpha': 0.0004228869644233298, 'batch_size': 99, 'beta_1': 0.9855007944826204, 'beta_2': 0.9999925326022187, 'epsilon': 3.5760527755200073e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.03989597906937536, 'tol': 0.0077565778535572385, 'validation_fraction': 0.8641119734197497}
observation time 0.000004, current best -0.876923 at iter 5
suggestion time taken 0.009945 iter 6 next_points [{'alpha': 0.00010584195788643274, 'batch_size': 141, 'beta_1': 0.647422511271391, 'beta_2': 0.9999968344856726, 'epsilon': 1.652727079686969e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0028867317869657894, 'tol': 0.0007774027260823293, 'validation_fraction': 0.39272029697365296}]
function_evaluation time 0.593529 value -0.907692 suggestion {'alpha': 0.00010584195788643274, 'batch_size': 141, 'beta_1': 0.647422511271391, 'beta_2': 0.9999968344856726, 'epsilon': 1.652727079686969e-08, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.0028867317869657894, 'tol': 0.0007774027260823293, 'validation_fraction': 0.39272029697365296}
observation time 0.000004, current best -0.907692 at iter 6
suggestion time taken 0.009835 iter 7 next_points [{'alpha': 0.00014717221654894996, 'batch_size': 55, 'beta_1': 0.6442622895450558, 'beta_2': 0.9983354439170756, 'epsilon': 7.855402752429726e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.00035977438350322347, 'tol': 1.7970126256184638e-05, 'validation_fraction': 0.30542844613982617}]
function_evaluation time 1.313624 value -0.916484 suggestion {'alpha': 0.00014717221654894996, 'batch_size': 55, 'beta_1': 0.6442622895450558, 'beta_2': 0.9983354439170756, 'epsilon': 7.855402752429726e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.00035977438350322347, 'tol': 1.7970126256184638e-05, 'validation_fraction': 0.30542844613982617}
observation time 0.000004, current best -0.916484 at iter 7
suggestion time taken 0.010261 iter 8 next_points [{'alpha': 0.014130211718039696, 'batch_size': 112, 'beta_1': 0.8484105246372244, 'beta_2': 0.9999921447309319, 'epsilon': 3.3386836911757103e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0019479490106962666, 'tol': 1.4993102154171036e-05, 'validation_fraction': 0.6798483438328153}]
function_evaluation time 0.745640 value -0.898901 suggestion {'alpha': 0.014130211718039696, 'batch_size': 112, 'beta_1': 0.8484105246372244, 'beta_2': 0.9999921447309319, 'epsilon': 3.3386836911757103e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0019479490106962666, 'tol': 1.4993102154171036e-05, 'validation_fraction': 0.6798483438328153}
observation time 0.000004, current best -0.916484 at iter 8
suggestion time taken 0.010349 iter 9 next_points [{'alpha': 2.3333405937274455e-05, 'batch_size': 91, 'beta_1': 0.9853026626134711, 'beta_2': 0.9995298580357275, 'epsilon': 1.5771024938213792e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.003732301228841324, 'tol': 6.217335970639077e-05, 'validation_fraction': 0.3181347160597697}]
function_evaluation time 0.423243 value -0.848352 suggestion {'alpha': 2.3333405937274455e-05, 'batch_size': 91, 'beta_1': 0.9853026626134711, 'beta_2': 0.9995298580357275, 'epsilon': 1.5771024938213792e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.003732301228841324, 'tol': 6.217335970639077e-05, 'validation_fraction': 0.3181347160597697}
observation time 0.000004, current best -0.916484 at iter 9
suggestion time taken 0.010301 iter 10 next_points [{'alpha': 0.03756635593984652, 'batch_size': 92, 'beta_1': 0.8187267895647341, 'beta_2': 0.9999915015712296, 'epsilon': 6.83577578856786e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.008519026898217723, 'tol': 0.0001487727989988201, 'validation_fraction': 0.14175872095622324}]
function_evaluation time 0.375854 value -0.905495 suggestion {'alpha': 0.03756635593984652, 'batch_size': 92, 'beta_1': 0.8187267895647341, 'beta_2': 0.9999915015712296, 'epsilon': 6.83577578856786e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.008519026898217723, 'tol': 0.0001487727989988201, 'validation_fraction': 0.14175872095622324}
observation time 0.000004, current best -0.916484 at iter 10
suggestion time taken 0.010320 iter 11 next_points [{'alpha': 1.1063571674677237e-05, 'batch_size': 244, 'beta_1': 0.9567672778444255, 'beta_2': 0.9999723890754249, 'epsilon': 2.0713014267629836e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 6.585639565169056e-05, 'tol': 0.0007794745056960107, 'validation_fraction': 0.12416256406383837}]
function_evaluation time 0.528096 value -0.582418 suggestion {'alpha': 1.1063571674677237e-05, 'batch_size': 244, 'beta_1': 0.9567672778444255, 'beta_2': 0.9999723890754249, 'epsilon': 2.0713014267629836e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 6.585639565169056e-05, 'tol': 0.0007794745056960107, 'validation_fraction': 0.12416256406383837}
observation time 0.000004, current best -0.916484 at iter 11
suggestion time taken 0.010168 iter 12 next_points [{'alpha': 1.3847085516265748e-05, 'batch_size': 172, 'beta_1': 0.7051225811771693, 'beta_2': 0.9279793115104421, 'epsilon': 3.0026336314356375e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.00033272645232082634, 'tol': 0.00022248135444878598, 'validation_fraction': 0.7478952098950937}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.662171 value -0.857143 suggestion {'alpha': 1.3847085516265748e-05, 'batch_size': 172, 'beta_1': 0.7051225811771693, 'beta_2': 0.9279793115104421, 'epsilon': 3.0026336314356375e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.00033272645232082634, 'tol': 0.00022248135444878598, 'validation_fraction': 0.7478952098950937}
observation time 0.000004, current best -0.916484 at iter 12
suggestion time taken 0.010378 iter 13 next_points [{'alpha': 5.5609520946364075, 'batch_size': 112, 'beta_1': 0.9204091185188606, 'beta_2': 0.9991366320416148, 'epsilon': 9.926738840438685e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.008138309451131106, 'tol': 0.007221715762665079, 'validation_fraction': 0.203180600124743}]
function_evaluation time 0.758050 value -0.898901 suggestion {'alpha': 5.5609520946364075, 'batch_size': 112, 'beta_1': 0.9204091185188606, 'beta_2': 0.9991366320416148, 'epsilon': 9.926738840438685e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.008138309451131106, 'tol': 0.007221715762665079, 'validation_fraction': 0.203180600124743}
observation time 0.000004, current best -0.916484 at iter 13
suggestion time taken 0.012156 iter 14 next_points [{'alpha': 7.259339487606408, 'batch_size': 21, 'beta_1': 0.5511974790710109, 'beta_2': 0.9999837408508153, 'epsilon': 5.376586507376033e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0004037009399203352, 'tol': 0.06946023026328177, 'validation_fraction': 0.8608253838340633}]
function_evaluation time 0.398521 value -0.630769 suggestion {'alpha': 7.259339487606408, 'batch_size': 21, 'beta_1': 0.5511974790710109, 'beta_2': 0.9999837408508153, 'epsilon': 5.376586507376033e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0004037009399203352, 'tol': 0.06946023026328177, 'validation_fraction': 0.8608253838340633}
observation time 0.000004, current best -0.916484 at iter 14
suggestion time taken 0.009804 iter 15 next_points [{'alpha': 0.0015922232968838892, 'batch_size': 74, 'beta_1': 0.7690609498622619, 'beta_2': 0.9999976810482166, 'epsilon': 1.0997554085393693e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0005284705454340658, 'tol': 6.236908106252198e-05, 'validation_fraction': 0.26552938321750247}]
function_evaluation time 0.963979 value -0.863736 suggestion {'alpha': 0.0015922232968838892, 'batch_size': 74, 'beta_1': 0.7690609498622619, 'beta_2': 0.9999976810482166, 'epsilon': 1.0997554085393693e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0005284705454340658, 'tol': 6.236908106252198e-05, 'validation_fraction': 0.26552938321750247}
observation time 0.000004, current best -0.916484 at iter 15
suggestion time taken 0.010281 iter 16 next_points [{'alpha': 0.02409300528298001, 'batch_size': 111, 'beta_1': 0.5151796019017852, 'beta_2': 0.9963902051965693, 'epsilon': 4.592076210741144e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0007117823937289184, 'tol': 0.019518663181551574, 'validation_fraction': 0.1494032371887763}]
function_evaluation time 0.733581 value -0.892308 suggestion {'alpha': 0.02409300528298001, 'batch_size': 111, 'beta_1': 0.5151796019017852, 'beta_2': 0.9963902051965693, 'epsilon': 4.592076210741144e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.0007117823937289184, 'tol': 0.019518663181551574, 'validation_fraction': 0.1494032371887763}
observation time 0.000004, current best -0.916484 at iter 16
suggestion time taken 0.010014 iter 17 next_points [{'alpha': 0.0006433443339293513, 'batch_size': 16, 'beta_1': 0.9731075844700671, 'beta_2': 0.999993937114255, 'epsilon': 3.464830910185381e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 1.1107255370308149e-05, 'tol': 1.5342079648188184e-05, 'validation_fraction': 0.5647805757111127}]
function_evaluation time 0.780576 value -0.465934 suggestion {'alpha': 0.0006433443339293513, 'batch_size': 16, 'beta_1': 0.9731075844700671, 'beta_2': 0.999993937114255, 'epsilon': 3.464830910185381e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 1.1107255370308149e-05, 'tol': 1.5342079648188184e-05, 'validation_fraction': 0.5647805757111127}
observation time 0.000004, current best -0.916484 at iter 17
suggestion time taken 0.010287 iter 18 next_points [{'alpha': 6.816740234466433, 'batch_size': 16, 'beta_1': 0.9828333366635816, 'beta_2': 0.9971832964348019, 'epsilon': 2.751789858381086e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.00033545209144084196, 'tol': 0.004605903892253344, 'validation_fraction': 0.2027404016075332}]
function_evaluation time 1.694156 value -0.896703 suggestion {'alpha': 6.816740234466433, 'batch_size': 16, 'beta_1': 0.9828333366635816, 'beta_2': 0.9971832964348019, 'epsilon': 2.751789858381086e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.00033545209144084196, 'tol': 0.004605903892253344, 'validation_fraction': 0.2027404016075332}
observation time 0.000004, current best -0.916484 at iter 18
suggestion time taken 0.010014 iter 19 next_points [{'alpha': 7.518428317420337e-05, 'batch_size': 104, 'beta_1': 0.878880049885826, 'beta_2': 0.9997195020147635, 'epsilon': 1.4464143563774284e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 7.305041491745106e-05, 'tol': 0.0004240583950244764, 'validation_fraction': 0.16897305324375791}]
function_evaluation time 0.892596 value -0.556044 suggestion {'alpha': 7.518428317420337e-05, 'batch_size': 104, 'beta_1': 0.878880049885826, 'beta_2': 0.9997195020147635, 'epsilon': 1.4464143563774284e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 7.305041491745106e-05, 'tol': 0.0004240583950244764, 'validation_fraction': 0.16897305324375791}
observation time 0.000005, current best -0.916484 at iter 19
suggestion time taken 0.010459 iter 20 next_points [{'alpha': 8.12973816734862, 'batch_size': 111, 'beta_1': 0.8262591947940628, 'beta_2': 0.9783995513298591, 'epsilon': 7.044554820496738e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 6.605437860240545e-05, 'tol': 2.0413195918412464e-05, 'validation_fraction': 0.8639496008162839}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.208644 value -0.527473 suggestion {'alpha': 8.12973816734862, 'batch_size': 111, 'beta_1': 0.8262591947940628, 'beta_2': 0.9783995513298591, 'epsilon': 7.044554820496738e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 6.605437860240545e-05, 'tol': 2.0413195918412464e-05, 'validation_fraction': 0.8639496008162839}
observation time 0.000004, current best -0.916484 at iter 20
suggestion time taken 0.010114 iter 21 next_points [{'alpha': 2.0569301780696714e-05, 'batch_size': 105, 'beta_1': 0.9422064828777132, 'beta_2': 0.9999902108483805, 'epsilon': 7.433273935203531e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 1.3857512886844355e-05, 'tol': 0.006024321189692822, 'validation_fraction': 0.693415554267845}]
function_evaluation time 0.325155 value -0.472527 suggestion {'alpha': 2.0569301780696714e-05, 'batch_size': 105, 'beta_1': 0.9422064828777132, 'beta_2': 0.9999902108483805, 'epsilon': 7.433273935203531e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 1.3857512886844355e-05, 'tol': 0.006024321189692822, 'validation_fraction': 0.693415554267845}
observation time 0.000004, current best -0.916484 at iter 21
suggestion time taken 0.012357 iter 22 next_points [{'alpha': 3.1902119015948727, 'batch_size': 197, 'beta_1': 0.7736941011371393, 'beta_2': 0.9999979481694639, 'epsilon': 7.076723612939283e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.09999823399159159, 'tol': 1.4213536193168422e-05, 'validation_fraction': 0.8305248730364124}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.428866 value -0.747253 suggestion {'alpha': 3.1902119015948727, 'batch_size': 197, 'beta_1': 0.7736941011371393, 'beta_2': 0.9999979481694639, 'epsilon': 7.076723612939283e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.09999823399159159, 'tol': 1.4213536193168422e-05, 'validation_fraction': 0.8305248730364124}
observation time 0.000005, current best -0.916484 at iter 22
suggestion time taken 0.012119 iter 23 next_points [{'alpha': 0.1420156082173955, 'batch_size': 23, 'beta_1': 0.9793452432515096, 'beta_2': 0.9999977579102753, 'epsilon': 1.1265203861973444e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0006658860030731877, 'tol': 0.0008011215454974049, 'validation_fraction': 0.13577615230916515}]
function_evaluation time 0.674755 value -0.887912 suggestion {'alpha': 0.1420156082173955, 'batch_size': 23, 'beta_1': 0.9793452432515096, 'beta_2': 0.9999977579102753, 'epsilon': 1.1265203861973444e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0006658860030731877, 'tol': 0.0008011215454974049, 'validation_fraction': 0.13577615230916515}
observation time 0.000004, current best -0.916484 at iter 23
suggestion time taken 0.010069 iter 24 next_points [{'alpha': 5.98626764966538, 'batch_size': 77, 'beta_1': 0.9827233005656002, 'beta_2': 0.99751471002413, 'epsilon': 1.4219635868856202e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0493762785474946, 'tol': 0.005860650080779355, 'validation_fraction': 0.438249332698989}]
function_evaluation time 0.832391 value -0.839560 suggestion {'alpha': 5.98626764966538, 'batch_size': 77, 'beta_1': 0.9827233005656002, 'beta_2': 0.99751471002413, 'epsilon': 1.4219635868856202e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0493762785474946, 'tol': 0.005860650080779355, 'validation_fraction': 0.438249332698989}
observation time 0.000004, current best -0.916484 at iter 24
suggestion time taken 0.010184 iter 25 next_points [{'alpha': 3.5505633155473957, 'batch_size': 106, 'beta_1': 0.8850767071718965, 'beta_2': 0.9998877976745518, 'epsilon': 9.96730937566031e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.009294747631029531, 'tol': 0.07585718645333821, 'validation_fraction': 0.20828032391780452}]
function_evaluation time 0.470752 value -0.907692 suggestion {'alpha': 3.5505633155473957, 'batch_size': 106, 'beta_1': 0.8850767071718965, 'beta_2': 0.9998877976745518, 'epsilon': 9.96730937566031e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.009294747631029531, 'tol': 0.07585718645333821, 'validation_fraction': 0.20828032391780452}
observation time 0.000004, current best -0.916484 at iter 25
suggestion time taken 0.010208 iter 26 next_points [{'alpha': 0.0007753742761184536, 'batch_size': 199, 'beta_1': 0.7135832989924142, 'beta_2': 0.9804039394265252, 'epsilon': 9.462254887460883e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.06987045100050819, 'tol': 0.09567016721927947, 'validation_fraction': 0.6160810491277234}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.311553 value -0.758242 suggestion {'alpha': 0.0007753742761184536, 'batch_size': 199, 'beta_1': 0.7135832989924142, 'beta_2': 0.9804039394265252, 'epsilon': 9.462254887460883e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.06987045100050819, 'tol': 0.09567016721927947, 'validation_fraction': 0.6160810491277234}
observation time 0.000004, current best -0.916484 at iter 26
suggestion time taken 0.010191 iter 27 next_points [{'alpha': 3.428097224341455, 'batch_size': 210, 'beta_1': 0.8992134028332748, 'beta_2': 0.9999977397577734, 'epsilon': 1.737973824933787e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.014014951544428972, 'tol': 0.006536676747012396, 'validation_fraction': 0.8978330610611135}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.431191 value -0.907692 suggestion {'alpha': 3.428097224341455, 'batch_size': 210, 'beta_1': 0.8992134028332748, 'beta_2': 0.9999977397577734, 'epsilon': 1.737973824933787e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.014014951544428972, 'tol': 0.006536676747012396, 'validation_fraction': 0.8978330610611135}
observation time 0.000004, current best -0.916484 at iter 27
suggestion time taken 0.010279 iter 28 next_points [{'alpha': 0.49688955255913025, 'batch_size': 155, 'beta_1': 0.9817504711193232, 'beta_2': 0.9999766658335139, 'epsilon': 6.157328195973651e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0001993103448849384, 'tol': 1.81744255251376e-05, 'validation_fraction': 0.7929731607319567}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.211051 value -0.443956 suggestion {'alpha': 0.49688955255913025, 'batch_size': 155, 'beta_1': 0.9817504711193232, 'beta_2': 0.9999766658335139, 'epsilon': 6.157328195973651e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0001993103448849384, 'tol': 1.81744255251376e-05, 'validation_fraction': 0.7929731607319567}
observation time 0.000004, current best -0.916484 at iter 28
suggestion time taken 0.010241 iter 29 next_points [{'alpha': 0.3751504807646865, 'batch_size': 21, 'beta_1': 0.9855443005145289, 'beta_2': 0.9997640194278924, 'epsilon': 3.958920492509885e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.025237665682936138, 'tol': 0.0009199655166444896, 'validation_fraction': 0.4745186458042512}]
function_evaluation time 1.312975 value -0.890110 suggestion {'alpha': 0.3751504807646865, 'batch_size': 21, 'beta_1': 0.9855443005145289, 'beta_2': 0.9997640194278924, 'epsilon': 3.958920492509885e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.025237665682936138, 'tol': 0.0009199655166444896, 'validation_fraction': 0.4745186458042512}
observation time 0.000004, current best -0.916484 at iter 29
suggestion time taken 0.010186 iter 30 next_points [{'alpha': 0.22254985402536406, 'batch_size': 117, 'beta_1': 0.5464293898846028, 'beta_2': 0.9999989079101016, 'epsilon': 2.719611902820907e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.006953045195080373, 'tol': 0.00018038379928299065, 'validation_fraction': 0.19726146323229837}]
function_evaluation time 0.657219 value -0.920879 suggestion {'alpha': 0.22254985402536406, 'batch_size': 117, 'beta_1': 0.5464293898846028, 'beta_2': 0.9999989079101016, 'epsilon': 2.719611902820907e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.006953045195080373, 'tol': 0.00018038379928299065, 'validation_fraction': 0.19726146323229837}
observation time 0.000004, current best -0.920879 at iter 30
suggestion time taken 0.009793 iter 31 next_points [{'alpha': 1.6897059113137485, 'batch_size': 111, 'beta_1': 0.6421751287793471, 'beta_2': 0.999972103160281, 'epsilon': 1.1172905745205874e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 3.383553240733516e-05, 'tol': 0.01736762256651804, 'validation_fraction': 0.10411169220515343}]
function_evaluation time 0.207489 value -0.529670 suggestion {'alpha': 1.6897059113137485, 'batch_size': 111, 'beta_1': 0.6421751287793471, 'beta_2': 0.999972103160281, 'epsilon': 1.1172905745205874e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 3.383553240733516e-05, 'tol': 0.01736762256651804, 'validation_fraction': 0.10411169220515343}
observation time 0.000003, current best -0.920879 at iter 31
suggestion time taken 0.003907 iter 32 next_points [{'alpha': 0.031429598938567005, 'batch_size': 43, 'beta_1': 0.8766213522768592, 'beta_2': 0.999953915269156, 'epsilon': 4.628925457493057e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.007168079999502675, 'tol': 0.008468558528009104, 'validation_fraction': 0.8336313559491048}]
function_evaluation time 0.525159 value -0.898901 suggestion {'alpha': 0.031429598938567005, 'batch_size': 43, 'beta_1': 0.8766213522768592, 'beta_2': 0.999953915269156, 'epsilon': 4.628925457493057e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.007168079999502675, 'tol': 0.008468558528009104, 'validation_fraction': 0.8336313559491048}
observation time 0.000004, current best -0.920879 at iter 32
suggestion time taken 0.010076 iter 33 next_points [{'alpha': 0.0009118302906681401, 'batch_size': 46, 'beta_1': 0.7463298897389237, 'beta_2': 0.9461472319042069, 'epsilon': 2.561125393037903e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.025123119296726202, 'tol': 0.004010030226137004, 'validation_fraction': 0.2968841351675923}]
function_evaluation time 1.066756 value -0.914286 suggestion {'alpha': 0.0009118302906681401, 'batch_size': 46, 'beta_1': 0.7463298897389237, 'beta_2': 0.9461472319042069, 'epsilon': 2.561125393037903e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.025123119296726202, 'tol': 0.004010030226137004, 'validation_fraction': 0.2968841351675923}
observation time 0.000005, current best -0.920879 at iter 33
suggestion time taken 0.010071 iter 34 next_points [{'alpha': 4.315004779581755, 'batch_size': 207, 'beta_1': 0.9593069631002004, 'beta_2': 0.999996590446149, 'epsilon': 1.0596526166238506e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0014788139177011796, 'tol': 0.0007952928018371136, 'validation_fraction': 0.31119516115863655}]
function_evaluation time 0.871093 value -0.909890 suggestion {'alpha': 4.315004779581755, 'batch_size': 207, 'beta_1': 0.9593069631002004, 'beta_2': 0.999996590446149, 'epsilon': 1.0596526166238506e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0014788139177011796, 'tol': 0.0007952928018371136, 'validation_fraction': 0.31119516115863655}
observation time 0.000004, current best -0.920879 at iter 34
suggestion time taken 0.010206 iter 35 next_points [{'alpha': 0.1987055161181004, 'batch_size': 139, 'beta_1': 0.9330358374962134, 'beta_2': 0.994224950055207, 'epsilon': 9.524391828445089e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0014785049467293588, 'tol': 0.0005209032374330392, 'validation_fraction': 0.6283351038936522}]
function_evaluation time 0.389225 value -0.795604 suggestion {'alpha': 0.1987055161181004, 'batch_size': 139, 'beta_1': 0.9330358374962134, 'beta_2': 0.994224950055207, 'epsilon': 9.524391828445089e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0014785049467293588, 'tol': 0.0005209032374330392, 'validation_fraction': 0.6283351038936522}
observation time 0.000005, current best -0.920879 at iter 35
suggestion time taken 0.009676 iter 36 next_points [{'alpha': 0.14831648523936786, 'batch_size': 105, 'beta_1': 0.9813001555774483, 'beta_2': 0.9999902164081309, 'epsilon': 1.2331126228386923e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0007532688203509383, 'tol': 0.0009651339614076565, 'validation_fraction': 0.549098866317565}]
function_evaluation time 0.696273 value -0.782418 suggestion {'alpha': 0.14831648523936786, 'batch_size': 105, 'beta_1': 0.9813001555774483, 'beta_2': 0.9999902164081309, 'epsilon': 1.2331126228386923e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0007532688203509383, 'tol': 0.0009651339614076565, 'validation_fraction': 0.549098866317565}
observation time 0.000004, current best -0.920879 at iter 36
suggestion time taken 0.009912 iter 37 next_points [{'alpha': 0.0010602785702167475, 'batch_size': 203, 'beta_1': 0.9369252594383148, 'beta_2': 0.9999331382247496, 'epsilon': 2.2966460316107193e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0003234495268899296, 'tol': 0.0005222647765721857, 'validation_fraction': 0.5678080284830769}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.316435 value -0.679121 suggestion {'alpha': 0.0010602785702167475, 'batch_size': 203, 'beta_1': 0.9369252594383148, 'beta_2': 0.9999331382247496, 'epsilon': 2.2966460316107193e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0003234495268899296, 'tol': 0.0005222647765721857, 'validation_fraction': 0.5678080284830769}
observation time 0.000003, current best -0.920879 at iter 37
suggestion time taken 0.010251 iter 38 next_points [{'alpha': 1.2590913136100164e-05, 'batch_size': 201, 'beta_1': 0.8185108852314594, 'beta_2': 0.9994630004946078, 'epsilon': 3.4017462174507963e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.01944572448718034, 'tol': 0.0014492729842875654, 'validation_fraction': 0.6681449733129217}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.428019 value -0.898901 suggestion {'alpha': 1.2590913136100164e-05, 'batch_size': 201, 'beta_1': 0.8185108852314594, 'beta_2': 0.9994630004946078, 'epsilon': 3.4017462174507963e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.01944572448718034, 'tol': 0.0014492729842875654, 'validation_fraction': 0.6681449733129217}
observation time 0.000004, current best -0.920879 at iter 38
suggestion time taken 0.010213 iter 39 next_points [{'alpha': 9.290739843016846, 'batch_size': 90, 'beta_1': 0.9457171722846799, 'beta_2': 0.998946692336352, 'epsilon': 2.29252013386718e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001491362637289575, 'tol': 0.005323181601573411, 'validation_fraction': 0.13685766443100425}]
function_evaluation time 0.311934 value -0.630769 suggestion {'alpha': 9.290739843016846, 'batch_size': 90, 'beta_1': 0.9457171722846799, 'beta_2': 0.998946692336352, 'epsilon': 2.29252013386718e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0001491362637289575, 'tol': 0.005323181601573411, 'validation_fraction': 0.13685766443100425}
observation time 0.000004, current best -0.920879 at iter 39
suggestion time taken 0.010213 iter 40 next_points [{'alpha': 2.3835398245726456, 'batch_size': 118, 'beta_1': 0.8929443859104548, 'beta_2': 0.9999960777687908, 'epsilon': 9.013899294091119e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 1.0852335901429603e-05, 'tol': 3.8946199425514686e-05, 'validation_fraction': 0.17081168019755338}]
function_evaluation time 0.684504 value -0.652747 suggestion {'alpha': 2.3835398245726456, 'batch_size': 118, 'beta_1': 0.8929443859104548, 'beta_2': 0.9999960777687908, 'epsilon': 9.013899294091119e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 1.0852335901429603e-05, 'tol': 3.8946199425514686e-05, 'validation_fraction': 0.17081168019755338}
observation time 0.000004, current best -0.920879 at iter 40
suggestion time taken 0.010160 iter 41 next_points [{'alpha': 0.00068473293573653, 'batch_size': 98, 'beta_1': 0.9782624166216116, 'beta_2': 0.9993848051196571, 'epsilon': 3.8330994207244806e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.012903866683700313, 'tol': 0.08774491124723612, 'validation_fraction': 0.8855927654805038}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.282343 value -0.802198 suggestion {'alpha': 0.00068473293573653, 'batch_size': 98, 'beta_1': 0.9782624166216116, 'beta_2': 0.9993848051196571, 'epsilon': 3.8330994207244806e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.012903866683700313, 'tol': 0.08774491124723612, 'validation_fraction': 0.8855927654805038}
observation time 0.000004, current best -0.920879 at iter 41
suggestion time taken 0.010057 iter 42 next_points [{'alpha': 0.0019936376158053485, 'batch_size': 94, 'beta_1': 0.9875788394228433, 'beta_2': 0.9997567126191889, 'epsilon': 2.162781565874615e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.00018867488949890983, 'tol': 0.00013409724985111735, 'validation_fraction': 0.713292791535066}]
function_evaluation time 0.411752 value -0.745055 suggestion {'alpha': 0.0019936376158053485, 'batch_size': 94, 'beta_1': 0.9875788394228433, 'beta_2': 0.9997567126191889, 'epsilon': 2.162781565874615e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.00018867488949890983, 'tol': 0.00013409724985111735, 'validation_fraction': 0.713292791535066}
observation time 0.000004, current best -0.920879 at iter 42
suggestion time taken 0.011463 iter 43 next_points [{'alpha': 0.004157155396344506, 'batch_size': 72, 'beta_1': 0.5706506703884179, 'beta_2': 0.9883386469432404, 'epsilon': 2.8743896859620696e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 1.4507289624304132e-05, 'tol': 0.0003817521497192805, 'validation_fraction': 0.4572710164063055}]
function_evaluation time 0.424317 value -0.437363 suggestion {'alpha': 0.004157155396344506, 'batch_size': 72, 'beta_1': 0.5706506703884179, 'beta_2': 0.9883386469432404, 'epsilon': 2.8743896859620696e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 1.4507289624304132e-05, 'tol': 0.0003817521497192805, 'validation_fraction': 0.4572710164063055}
observation time 0.000004, current best -0.920879 at iter 43
suggestion time taken 0.009994 iter 44 next_points [{'alpha': 9.276680607835086e-05, 'batch_size': 93, 'beta_1': 0.9508515068039136, 'beta_2': 0.9533396873092653, 'epsilon': 3.5072155682835363e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 1.0839077268103561e-05, 'tol': 2.4928184992013647e-05, 'validation_fraction': 0.768785015038804}]
function_evaluation time 0.238521 value -0.417582 suggestion {'alpha': 9.276680607835086e-05, 'batch_size': 93, 'beta_1': 0.9508515068039136, 'beta_2': 0.9533396873092653, 'epsilon': 3.5072155682835363e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 1.0839077268103561e-05, 'tol': 2.4928184992013647e-05, 'validation_fraction': 0.768785015038804}
observation time 0.000004, current best -0.920879 at iter 44
saving meta data: {'args': {'--uuid': '0bd428b667d95879be7e9950d2ada9c4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
