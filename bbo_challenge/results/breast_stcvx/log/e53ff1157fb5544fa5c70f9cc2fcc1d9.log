running: {'--uuid': 'e53ff1157fb5544fa5c70f9cc2fcc1d9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d breast -o strongcvx -u e53ff1157fb5544fa5c70f9cc2fcc1d9 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam breast acc 45 1
with data root: None
suggestion time taken 16.567497 iter 0 next_points [{'alpha': 0.0755776047559458, 'batch_size': 112, 'beta_1': 0.8123806799585179, 'beta_2': 0.9999104464485498, 'epsilon': 3.1370449395005106e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.07865646236539575, 'tol': 1.4150228462944816e-05, 'validation_fraction': 0.38537840890532843}]
function_evaluation time 0.556374 value -0.892308 suggestion {'alpha': 0.0755776047559458, 'batch_size': 112, 'beta_1': 0.8123806799585179, 'beta_2': 0.9999104464485498, 'epsilon': 3.1370449395005106e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.07865646236539575, 'tol': 1.4150228462944816e-05, 'validation_fraction': 0.38537840890532843}
observation time 0.000005, current best -0.892308 at iter 0
suggestion time taken 15.904051 iter 1 next_points [{'alpha': 0.0025546221004703147, 'batch_size': 14, 'beta_1': 0.9885535658285091, 'beta_2': 0.9996397462702662, 'epsilon': 1.899116274510625e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.00664733158074032, 'tol': 5.2245920677461703e-05, 'validation_fraction': 0.3503380911340377}]
function_evaluation time 1.929882 value -0.903297 suggestion {'alpha': 0.0025546221004703147, 'batch_size': 14, 'beta_1': 0.9885535658285091, 'beta_2': 0.9996397462702662, 'epsilon': 1.899116274510625e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.00664733158074032, 'tol': 5.2245920677461703e-05, 'validation_fraction': 0.3503380911340377}
observation time 0.000005, current best -0.903297 at iter 1
suggestion time taken 15.491549 iter 2 next_points [{'alpha': 0.042001967459569856, 'batch_size': 151, 'beta_1': 0.9631634092748955, 'beta_2': 0.9972348748386055, 'epsilon': 5.006464743336213e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0962991478627164, 'tol': 0.00010334635238543452, 'validation_fraction': 0.724835933559574}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.381151 value -0.850549 suggestion {'alpha': 0.042001967459569856, 'batch_size': 151, 'beta_1': 0.9631634092748955, 'beta_2': 0.9972348748386055, 'epsilon': 5.006464743336213e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0962991478627164, 'tol': 0.00010334635238543452, 'validation_fraction': 0.724835933559574}
observation time 0.000005, current best -0.903297 at iter 2
suggestion time taken 16.589749 iter 3 next_points [{'alpha': 9.529343505404514e-05, 'batch_size': 226, 'beta_1': 0.9794875444295643, 'beta_2': 0.9997964090318653, 'epsilon': 1.2326642406538803e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0013065099535232345, 'tol': 0.010501944402105738, 'validation_fraction': 0.4154613708366949}]
function_evaluation time 0.438390 value -0.701099 suggestion {'alpha': 9.529343505404514e-05, 'batch_size': 226, 'beta_1': 0.9794875444295643, 'beta_2': 0.9997964090318653, 'epsilon': 1.2326642406538803e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0013065099535232345, 'tol': 0.010501944402105738, 'validation_fraction': 0.4154613708366949}
observation time 0.000007, current best -0.903297 at iter 3
suggestion time taken 15.733183 iter 4 next_points [{'alpha': 3.69786573667926, 'batch_size': 90, 'beta_1': 0.9162377424587062, 'beta_2': 0.9999959177088658, 'epsilon': 4.844769044366623e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.004646571006020801, 'tol': 0.00017026186113551324, 'validation_fraction': 0.8954386739955654}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.546223 value -0.848352 suggestion {'alpha': 3.69786573667926, 'batch_size': 90, 'beta_1': 0.9162377424587062, 'beta_2': 0.9999959177088658, 'epsilon': 4.844769044366623e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.004646571006020801, 'tol': 0.00017026186113551324, 'validation_fraction': 0.8954386739955654}
observation time 0.000005, current best -0.903297 at iter 4
suggestion time taken 15.841776 iter 5 next_points [{'alpha': 0.3708072825667096, 'batch_size': 90, 'beta_1': 0.9888690873269524, 'beta_2': 0.9994121881074032, 'epsilon': 4.3177144020041767e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.0001705412440190379, 'tol': 0.0493560256872083, 'validation_fraction': 0.8996863033613428}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.327841 value -0.604396 suggestion {'alpha': 0.3708072825667096, 'batch_size': 90, 'beta_1': 0.9888690873269524, 'beta_2': 0.9994121881074032, 'epsilon': 4.3177144020041767e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.0001705412440190379, 'tol': 0.0493560256872083, 'validation_fraction': 0.8996863033613428}
observation time 0.000005, current best -0.903297 at iter 5
suggestion time taken 16.115820 iter 6 next_points [{'alpha': 0.025864213306960947, 'batch_size': 225, 'beta_1': 0.9650403583460262, 'beta_2': 0.9970429259177076, 'epsilon': 1.47306901718929e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.02637264301674629, 'tol': 0.01956549843930808, 'validation_fraction': 0.10858715576664622}]
function_evaluation time 0.639766 value -0.887912 suggestion {'alpha': 0.025864213306960947, 'batch_size': 225, 'beta_1': 0.9650403583460262, 'beta_2': 0.9970429259177076, 'epsilon': 1.47306901718929e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.02637264301674629, 'tol': 0.01956549843930808, 'validation_fraction': 0.10858715576664622}
observation time 0.000004, current best -0.903297 at iter 6
suggestion time taken 15.474215 iter 7 next_points [{'alpha': 1.4327197094040787, 'batch_size': 37, 'beta_1': 0.7070797657641693, 'beta_2': 0.9999532696909004, 'epsilon': 1.9954800693962673e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.002282953618298221, 'tol': 0.05758865167883395, 'validation_fraction': 0.8943739415353614}]
function_evaluation time 0.459633 value -0.907692 suggestion {'alpha': 1.4327197094040787, 'batch_size': 37, 'beta_1': 0.7070797657641693, 'beta_2': 0.9999532696909004, 'epsilon': 1.9954800693962673e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.002282953618298221, 'tol': 0.05758865167883395, 'validation_fraction': 0.8943739415353614}
observation time 0.000005, current best -0.907692 at iter 7
suggestion time taken 16.349457 iter 8 next_points [{'alpha': 0.012317352760379692, 'batch_size': 25, 'beta_1': 0.7231842578716505, 'beta_2': 0.9025879704729174, 'epsilon': 6.04281486997157e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.06418999460755835, 'tol': 1.883114763320597e-05, 'validation_fraction': 0.5351756518840551}]
function_evaluation time 1.183637 value -0.909890 suggestion {'alpha': 0.012317352760379692, 'batch_size': 25, 'beta_1': 0.7231842578716505, 'beta_2': 0.9025879704729174, 'epsilon': 6.04281486997157e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.06418999460755835, 'tol': 1.883114763320597e-05, 'validation_fraction': 0.5351756518840551}
observation time 0.000005, current best -0.909890 at iter 8
suggestion time taken 16.425017 iter 9 next_points [{'alpha': 0.0030919010669480085, 'batch_size': 56, 'beta_1': 0.8999754120296934, 'beta_2': 0.9999925045111272, 'epsilon': 1.1628403281697571e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0004614584541863388, 'tol': 0.0009108419033859045, 'validation_fraction': 0.4795157754287368}]
function_evaluation time 1.069629 value -0.793407 suggestion {'alpha': 0.0030919010669480085, 'batch_size': 56, 'beta_1': 0.8999754120296934, 'beta_2': 0.9999925045111272, 'epsilon': 1.1628403281697571e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0004614584541863388, 'tol': 0.0009108419033859045, 'validation_fraction': 0.4795157754287368}
observation time 0.000005, current best -0.909890 at iter 9
suggestion time taken 16.025662 iter 10 next_points [{'alpha': 0.11019016861809015, 'batch_size': 32, 'beta_1': 0.9822941399875419, 'beta_2': 0.9998753836334567, 'epsilon': 4.133299364485214e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.029626898938769276, 'tol': 0.0007635879267913392, 'validation_fraction': 0.38061157024330333}]
function_evaluation time 1.274765 value -0.903297 suggestion {'alpha': 0.11019016861809015, 'batch_size': 32, 'beta_1': 0.9822941399875419, 'beta_2': 0.9998753836334567, 'epsilon': 4.133299364485214e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.029626898938769276, 'tol': 0.0007635879267913392, 'validation_fraction': 0.38061157024330333}
observation time 0.000005, current best -0.909890 at iter 10
suggestion time taken 16.844029 iter 11 next_points [{'alpha': 0.0029120516699007153, 'batch_size': 221, 'beta_1': 0.9882095556797568, 'beta_2': 0.9613102790384486, 'epsilon': 1.2377286134553327e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.05750577009122402, 'tol': 0.00035138194070111, 'validation_fraction': 0.36272415963449217}]
function_evaluation time 0.642204 value -0.852747 suggestion {'alpha': 0.0029120516699007153, 'batch_size': 221, 'beta_1': 0.9882095556797568, 'beta_2': 0.9613102790384486, 'epsilon': 1.2377286134553327e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.05750577009122402, 'tol': 0.00035138194070111, 'validation_fraction': 0.36272415963449217}
observation time 0.000005, current best -0.909890 at iter 11
suggestion time taken 15.542551 iter 12 next_points [{'alpha': 3.691519623293008, 'batch_size': 151, 'beta_1': 0.8427948208925545, 'beta_2': 0.999902355063865, 'epsilon': 1.273348519655504e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.07082850354090311, 'tol': 0.08028979248446616, 'validation_fraction': 0.7746586847306092}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.346465 value -0.784615 suggestion {'alpha': 3.691519623293008, 'batch_size': 151, 'beta_1': 0.8427948208925545, 'beta_2': 0.999902355063865, 'epsilon': 1.273348519655504e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.07082850354090311, 'tol': 0.08028979248446616, 'validation_fraction': 0.7746586847306092}
observation time 0.000004, current best -0.909890 at iter 12
suggestion time taken 16.114134 iter 13 next_points [{'alpha': 4.6063292414435774e-05, 'batch_size': 226, 'beta_1': 0.5819610440974687, 'beta_2': 0.9995491827349655, 'epsilon': 1.7258686980054003e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 2.484449123796712e-05, 'tol': 8.90773005037538e-05, 'validation_fraction': 0.64549968441781}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.230402 value -0.413187 suggestion {'alpha': 4.6063292414435774e-05, 'batch_size': 226, 'beta_1': 0.5819610440974687, 'beta_2': 0.9995491827349655, 'epsilon': 1.7258686980054003e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 2.484449123796712e-05, 'tol': 8.90773005037538e-05, 'validation_fraction': 0.64549968441781}
observation time 0.000005, current best -0.909890 at iter 13
suggestion time taken 15.708168 iter 14 next_points [{'alpha': 1.1724860304777138, 'batch_size': 15, 'beta_1': 0.6204396515876924, 'beta_2': 0.9999984922274779, 'epsilon': 4.852895537453183e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.050320056202774e-05, 'tol': 4.4891265733043196e-05, 'validation_fraction': 0.1362627972344061}]
function_evaluation time 0.696087 value -0.569231 suggestion {'alpha': 1.1724860304777138, 'batch_size': 15, 'beta_1': 0.6204396515876924, 'beta_2': 0.9999984922274779, 'epsilon': 4.852895537453183e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.050320056202774e-05, 'tol': 4.4891265733043196e-05, 'validation_fraction': 0.1362627972344061}
observation time 0.000003, current best -0.909890 at iter 14
suggestion time taken 16.450865 iter 15 next_points [{'alpha': 4.183928594445817, 'batch_size': 15, 'beta_1': 0.5027844536842994, 'beta_2': 0.9999260329158696, 'epsilon': 4.6865397830581424e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0009483696804000272, 'tol': 9.266021686293692e-05, 'validation_fraction': 0.5691908210629588}]
function_evaluation time 1.584789 value -0.909890 suggestion {'alpha': 4.183928594445817, 'batch_size': 15, 'beta_1': 0.5027844536842994, 'beta_2': 0.9999260329158696, 'epsilon': 4.6865397830581424e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0009483696804000272, 'tol': 9.266021686293692e-05, 'validation_fraction': 0.5691908210629588}
observation time 0.000005, current best -0.909890 at iter 15
suggestion time taken 16.189701 iter 16 next_points [{'alpha': 0.25313826107043325, 'batch_size': 41, 'beta_1': 0.8168533429323273, 'beta_2': 0.9987498146214391, 'epsilon': 5.923626840225584e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0018317077534726945, 'tol': 0.0704020839247126, 'validation_fraction': 0.305062634202544}]
function_evaluation time 0.776429 value -0.914286 suggestion {'alpha': 0.25313826107043325, 'batch_size': 41, 'beta_1': 0.8168533429323273, 'beta_2': 0.9987498146214391, 'epsilon': 5.923626840225584e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0018317077534726945, 'tol': 0.0704020839247126, 'validation_fraction': 0.305062634202544}
observation time 0.000005, current best -0.914286 at iter 16
suggestion time taken 15.960613 iter 17 next_points [{'alpha': 0.000675451703237778, 'batch_size': 90, 'beta_1': 0.9224788774466107, 'beta_2': 0.9979129156787127, 'epsilon': 2.0372506389012254e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 4.0216837338774384e-05, 'tol': 0.0643072476008539, 'validation_fraction': 0.7634298961604337}]
function_evaluation time 0.225016 value -0.446154 suggestion {'alpha': 0.000675451703237778, 'batch_size': 90, 'beta_1': 0.9224788774466107, 'beta_2': 0.9979129156787127, 'epsilon': 2.0372506389012254e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 4.0216837338774384e-05, 'tol': 0.0643072476008539, 'validation_fraction': 0.7634298961604337}
observation time 0.000005, current best -0.914286 at iter 17
suggestion time taken 16.528689 iter 18 next_points [{'alpha': 0.19581286830860092, 'batch_size': 226, 'beta_1': 0.9793901743692606, 'beta_2': 0.9028928450595362, 'epsilon': 3.317551775461669e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.00033750085356600246, 'tol': 6.331718681487991e-05, 'validation_fraction': 0.7817522083471714}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.439803 value -0.540659 suggestion {'alpha': 0.19581286830860092, 'batch_size': 226, 'beta_1': 0.9793901743692606, 'beta_2': 0.9028928450595362, 'epsilon': 3.317551775461669e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.00033750085356600246, 'tol': 6.331718681487991e-05, 'validation_fraction': 0.7817522083471714}
observation time 0.000005, current best -0.914286 at iter 18
suggestion time taken 15.797963 iter 19 next_points [{'alpha': 2.8554434844948818e-05, 'batch_size': 75, 'beta_1': 0.9561548583267206, 'beta_2': 0.9997267680040369, 'epsilon': 1.6247129325442526e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0001385975703877103, 'tol': 0.06721156368129245, 'validation_fraction': 0.3306827640394462}]
function_evaluation time 0.539058 value -0.523077 suggestion {'alpha': 2.8554434844948818e-05, 'batch_size': 75, 'beta_1': 0.9561548583267206, 'beta_2': 0.9997267680040369, 'epsilon': 1.6247129325442526e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0001385975703877103, 'tol': 0.06721156368129245, 'validation_fraction': 0.3306827640394462}
observation time 0.000004, current best -0.914286 at iter 19
suggestion time taken 16.586287 iter 20 next_points [{'alpha': 1.113844619977801, 'batch_size': 28, 'beta_1': 0.9696762288581124, 'beta_2': 0.9999963259131948, 'epsilon': 4.083237467526829e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.003482315663642918, 'tol': 0.005041224400395488, 'validation_fraction': 0.16923736828642508}]
function_evaluation time 1.912955 value -0.918681 suggestion {'alpha': 1.113844619977801, 'batch_size': 28, 'beta_1': 0.9696762288581124, 'beta_2': 0.9999963259131948, 'epsilon': 4.083237467526829e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.003482315663642918, 'tol': 0.005041224400395488, 'validation_fraction': 0.16923736828642508}
observation time 0.000005, current best -0.918681 at iter 20
suggestion time taken 15.747352 iter 21 next_points [{'alpha': 4.4820458088896305e-05, 'batch_size': 227, 'beta_1': 0.9824087741952582, 'beta_2': 0.9976143375673346, 'epsilon': 1.3632966358752931e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 9.432961123889737e-05, 'tol': 0.0006152866282833969, 'validation_fraction': 0.8687988559093635}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.565057 value -0.621978 suggestion {'alpha': 4.4820458088896305e-05, 'batch_size': 227, 'beta_1': 0.9824087741952582, 'beta_2': 0.9976143375673346, 'epsilon': 1.3632966358752931e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 9.432961123889737e-05, 'tol': 0.0006152866282833969, 'validation_fraction': 0.8687988559093635}
observation time 0.000005, current best -0.918681 at iter 21
suggestion time taken 16.918162 iter 22 next_points [{'alpha': 0.30192630952084404, 'batch_size': 151, 'beta_1': 0.8696855532672286, 'beta_2': 0.91597872299863, 'epsilon': 1.7624941363122545e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.09979480089956133, 'tol': 1.71316556635582e-05, 'validation_fraction': 0.17839320976208756}]
function_evaluation time 0.520874 value -0.828571 suggestion {'alpha': 0.30192630952084404, 'batch_size': 151, 'beta_1': 0.8696855532672286, 'beta_2': 0.91597872299863, 'epsilon': 1.7624941363122545e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.09979480089956133, 'tol': 1.71316556635582e-05, 'validation_fraction': 0.17839320976208756}
observation time 0.000005, current best -0.918681 at iter 22
suggestion time taken 16.275043 iter 23 next_points [{'alpha': 0.16060930929482395, 'batch_size': 113, 'beta_1': 0.8981575801030333, 'beta_2': 0.9999959585618495, 'epsilon': 3.372504495707308e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.004907767845304588, 'tol': 9.067374235468832e-05, 'validation_fraction': 0.889685015816204}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.592353 value -0.909890 suggestion {'alpha': 0.16060930929482395, 'batch_size': 113, 'beta_1': 0.8981575801030333, 'beta_2': 0.9999959585618495, 'epsilon': 3.372504495707308e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.004907767845304588, 'tol': 9.067374235468832e-05, 'validation_fraction': 0.889685015816204}
observation time 0.000004, current best -0.918681 at iter 23
suggestion time taken 17.310812 iter 24 next_points [{'alpha': 4.166346284235276e-05, 'batch_size': 50, 'beta_1': 0.8987572393441503, 'beta_2': 0.9993973918778946, 'epsilon': 1.131339265965875e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.010882483779145287, 'tol': 0.08493108088750996, 'validation_fraction': 0.7277601268402424}]
function_evaluation time 0.419881 value -0.901099 suggestion {'alpha': 4.166346284235276e-05, 'batch_size': 50, 'beta_1': 0.8987572393441503, 'beta_2': 0.9993973918778946, 'epsilon': 1.131339265965875e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.010882483779145287, 'tol': 0.08493108088750996, 'validation_fraction': 0.7277601268402424}
observation time 0.000005, current best -0.918681 at iter 24
suggestion time taken 16.429959 iter 25 next_points [{'alpha': 0.0019072311490294569, 'batch_size': 151, 'beta_1': 0.9721047184169606, 'beta_2': 0.9943280436541295, 'epsilon': 7.563137182543574e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.023860241415789643, 'tol': 3.648045143227214e-05, 'validation_fraction': 0.5447963638968268}]
function_evaluation time 0.609299 value -0.894505 suggestion {'alpha': 0.0019072311490294569, 'batch_size': 151, 'beta_1': 0.9721047184169606, 'beta_2': 0.9943280436541295, 'epsilon': 7.563137182543574e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.023860241415789643, 'tol': 3.648045143227214e-05, 'validation_fraction': 0.5447963638968268}
observation time 0.000005, current best -0.918681 at iter 25
suggestion time taken 17.342940 iter 26 next_points [{'alpha': 0.15462469816630622, 'batch_size': 10, 'beta_1': 0.9388970700204332, 'beta_2': 0.9954110896910747, 'epsilon': 2.1827772044701315e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.010529989736389807, 'tol': 0.0049499924587578445, 'validation_fraction': 0.8822510385433839}]
function_evaluation time 0.985171 value -0.901099 suggestion {'alpha': 0.15462469816630622, 'batch_size': 10, 'beta_1': 0.9388970700204332, 'beta_2': 0.9954110896910747, 'epsilon': 2.1827772044701315e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.010529989736389807, 'tol': 0.0049499924587578445, 'validation_fraction': 0.8822510385433839}
observation time 0.000005, current best -0.918681 at iter 26
suggestion time taken 16.340328 iter 27 next_points [{'alpha': 0.37805527837148717, 'batch_size': 15, 'beta_1': 0.9864571748203143, 'beta_2': 0.9866655437385123, 'epsilon': 7.901437418076362e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.04892088585403929, 'tol': 1.3292058339345774e-05, 'validation_fraction': 0.13384216550952127}]
function_evaluation time 1.878435 value -0.854945 suggestion {'alpha': 0.37805527837148717, 'batch_size': 15, 'beta_1': 0.9864571748203143, 'beta_2': 0.9866655437385123, 'epsilon': 7.901437418076362e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.04892088585403929, 'tol': 1.3292058339345774e-05, 'validation_fraction': 0.13384216550952127}
observation time 0.000004, current best -0.918681 at iter 27
suggestion time taken 16.956108 iter 28 next_points [{'alpha': 0.10788769951747472, 'batch_size': 226, 'beta_1': 0.8882706162401066, 'beta_2': 0.998329392641626, 'epsilon': 4.227377325070298e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.00024334357755982552, 'tol': 1.1267061093344583e-05, 'validation_fraction': 0.8993300599750433}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.274606 value -0.650549 suggestion {'alpha': 0.10788769951747472, 'batch_size': 226, 'beta_1': 0.8882706162401066, 'beta_2': 0.998329392641626, 'epsilon': 4.227377325070298e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.00024334357755982552, 'tol': 1.1267061093344583e-05, 'validation_fraction': 0.8993300599750433}
observation time 0.000005, current best -0.918681 at iter 28
suggestion time taken 15.868503 iter 29 next_points [{'alpha': 0.017720526771422513, 'batch_size': 45, 'beta_1': 0.8009637770764988, 'beta_2': 0.9999966139836306, 'epsilon': 3.0348083578300678e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00014037284068286202, 'tol': 0.037773292285010245, 'validation_fraction': 0.2524307221681521}]
function_evaluation time 0.244534 value -0.567033 suggestion {'alpha': 0.017720526771422513, 'batch_size': 45, 'beta_1': 0.8009637770764988, 'beta_2': 0.9999966139836306, 'epsilon': 3.0348083578300678e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.00014037284068286202, 'tol': 0.037773292285010245, 'validation_fraction': 0.2524307221681521}
observation time 0.000004, current best -0.918681 at iter 29
suggestion time taken 16.736740 iter 30 next_points [{'alpha': 0.00012459899526341328, 'batch_size': 90, 'beta_1': 0.9742768620713832, 'beta_2': 0.971324284578206, 'epsilon': 4.0163796091680835e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.005000398434357735, 'tol': 0.0005295604709339346, 'validation_fraction': 0.16751863498675554}]
function_evaluation time 0.798439 value -0.890110 suggestion {'alpha': 0.00012459899526341328, 'batch_size': 90, 'beta_1': 0.9742768620713832, 'beta_2': 0.971324284578206, 'epsilon': 4.0163796091680835e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.005000398434357735, 'tol': 0.0005295604709339346, 'validation_fraction': 0.16751863498675554}
observation time 0.000005, current best -0.918681 at iter 30
suggestion time taken 15.936764 iter 31 next_points [{'alpha': 0.4975459660243454, 'batch_size': 75, 'beta_1': 0.8884537342819524, 'beta_2': 0.9984948643064429, 'epsilon': 2.1026491123315887e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 4.3163579245470206e-05, 'tol': 0.002338185493313415, 'validation_fraction': 0.6369929532599601}]
function_evaluation time 0.456832 value -0.538462 suggestion {'alpha': 0.4975459660243454, 'batch_size': 75, 'beta_1': 0.8884537342819524, 'beta_2': 0.9984948643064429, 'epsilon': 2.1026491123315887e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 4.3163579245470206e-05, 'tol': 0.002338185493313415, 'validation_fraction': 0.6369929532599601}
observation time 0.000005, current best -0.918681 at iter 31
suggestion time taken 16.862106 iter 32 next_points [{'alpha': 0.0862284398413821, 'batch_size': 32, 'beta_1': 0.8816298048085464, 'beta_2': 0.9999649687580784, 'epsilon': 3.738101025571478e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.0020323217010125, 'tol': 5.500543663039922e-05, 'validation_fraction': 0.24263462788542728}]
function_evaluation time 1.649873 value -0.901099 suggestion {'alpha': 0.0862284398413821, 'batch_size': 32, 'beta_1': 0.8816298048085464, 'beta_2': 0.9999649687580784, 'epsilon': 3.738101025571478e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.0020323217010125, 'tol': 5.500543663039922e-05, 'validation_fraction': 0.24263462788542728}
observation time 0.000005, current best -0.918681 at iter 32
suggestion time taken 16.453143 iter 33 next_points [{'alpha': 0.0013645853259305221, 'batch_size': 15, 'beta_1': 0.9781603480044199, 'beta_2': 0.9999326996626274, 'epsilon': 7.004629558696322e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.00035268777293306344, 'tol': 7.547100723780859e-05, 'validation_fraction': 0.8765999015414546}]
function_evaluation time 1.312476 value -0.846154 suggestion {'alpha': 0.0013645853259305221, 'batch_size': 15, 'beta_1': 0.9781603480044199, 'beta_2': 0.9999326996626274, 'epsilon': 7.004629558696322e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.00035268777293306344, 'tol': 7.547100723780859e-05, 'validation_fraction': 0.8765999015414546}
observation time 0.000005, current best -0.918681 at iter 33
suggestion time taken 16.574301 iter 34 next_points [{'alpha': 0.0007357274653322093, 'batch_size': 30, 'beta_1': 0.9613311245071764, 'beta_2': 0.9996869167858324, 'epsilon': 8.827845043665394e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.00038077887220441966, 'tol': 0.001987633018969415, 'validation_fraction': 0.422966328928606}]
function_evaluation time 1.636942 value -0.876923 suggestion {'alpha': 0.0007357274653322093, 'batch_size': 30, 'beta_1': 0.9613311245071764, 'beta_2': 0.9996869167858324, 'epsilon': 8.827845043665394e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.00038077887220441966, 'tol': 0.001987633018969415, 'validation_fraction': 0.422966328928606}
observation time 0.000005, current best -0.918681 at iter 34
suggestion time taken 15.859110 iter 35 next_points [{'alpha': 0.7328602805122982, 'batch_size': 56, 'beta_1': 0.7824422560043438, 'beta_2': 0.9999887493576493, 'epsilon': 2.8580127549111607e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.02209486044040693, 'tol': 0.003029321612045794, 'validation_fraction': 0.26869673583789094}]
function_evaluation time 1.110273 value -0.903297 suggestion {'alpha': 0.7328602805122982, 'batch_size': 56, 'beta_1': 0.7824422560043438, 'beta_2': 0.9999887493576493, 'epsilon': 2.8580127549111607e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.02209486044040693, 'tol': 0.003029321612045794, 'validation_fraction': 0.26869673583789094}
observation time 0.000004, current best -0.918681 at iter 35
suggestion time taken 17.223177 iter 36 next_points [{'alpha': 0.2543768414053658, 'batch_size': 18, 'beta_1': 0.7683324978244256, 'beta_2': 0.9920890876638571, 'epsilon': 1.4357686951116127e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 4.4928144693853755e-05, 'tol': 6.136832048496041e-05, 'validation_fraction': 0.21575096991586923}]
function_evaluation time 2.426830 value -0.729670 suggestion {'alpha': 0.2543768414053658, 'batch_size': 18, 'beta_1': 0.7683324978244256, 'beta_2': 0.9920890876638571, 'epsilon': 1.4357686951116127e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 4.4928144693853755e-05, 'tol': 6.136832048496041e-05, 'validation_fraction': 0.21575096991586923}
observation time 0.000005, current best -0.918681 at iter 36
suggestion time taken 16.812155 iter 37 next_points [{'alpha': 1.0915848583272083, 'batch_size': 10, 'beta_1': 0.9631166733909342, 'beta_2': 0.9868007828489147, 'epsilon': 3.245894678166132e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 1.1739343398333261e-05, 'tol': 0.007246235620188203, 'validation_fraction': 0.8574070790830535}]
function_evaluation time 0.653479 value -0.525275 suggestion {'alpha': 1.0915848583272083, 'batch_size': 10, 'beta_1': 0.9631166733909342, 'beta_2': 0.9868007828489147, 'epsilon': 3.245894678166132e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 1.1739343398333261e-05, 'tol': 0.007246235620188203, 'validation_fraction': 0.8574070790830535}
observation time 0.000005, current best -0.918681 at iter 37
suggestion time taken 16.093038 iter 38 next_points [{'alpha': 0.09264057325915115, 'batch_size': 112, 'beta_1': 0.7354119379164885, 'beta_2': 0.9999607484679699, 'epsilon': 9.907058328775654e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 1.0901063032911652e-05, 'tol': 3.5465492324972335e-05, 'validation_fraction': 0.3460723618834614}]
function_evaluation time 0.435014 value -0.472527 suggestion {'alpha': 0.09264057325915115, 'batch_size': 112, 'beta_1': 0.7354119379164885, 'beta_2': 0.9999607484679699, 'epsilon': 9.907058328775654e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 1.0901063032911652e-05, 'tol': 3.5465492324972335e-05, 'validation_fraction': 0.3460723618834614}
observation time 0.000005, current best -0.918681 at iter 38
suggestion time taken 17.217155 iter 39 next_points [{'alpha': 0.0023088677375589658, 'batch_size': 75, 'beta_1': 0.817986528607663, 'beta_2': 0.99997074284795, 'epsilon': 1.579758041254535e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.00028712410975151743, 'tol': 0.03993505309039067, 'validation_fraction': 0.6747210130193293}]
function_evaluation time 0.355023 value -0.745055 suggestion {'alpha': 0.0023088677375589658, 'batch_size': 75, 'beta_1': 0.817986528607663, 'beta_2': 0.99997074284795, 'epsilon': 1.579758041254535e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.00028712410975151743, 'tol': 0.03993505309039067, 'validation_fraction': 0.6747210130193293}
observation time 0.000005, current best -0.918681 at iter 39
suggestion time taken 16.797937 iter 40 next_points [{'alpha': 0.7879503238124483, 'batch_size': 50, 'beta_1': 0.922410116420233, 'beta_2': 0.9998291498191908, 'epsilon': 3.7344171382472974e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.00029391250116067336, 'tol': 0.07060425312064822, 'validation_fraction': 0.1762057288497306}]
function_evaluation time 0.863013 value -0.903297 suggestion {'alpha': 0.7879503238124483, 'batch_size': 50, 'beta_1': 0.922410116420233, 'beta_2': 0.9998291498191908, 'epsilon': 3.7344171382472974e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.00029391250116067336, 'tol': 0.07060425312064822, 'validation_fraction': 0.1762057288497306}
observation time 0.000005, current best -0.918681 at iter 40
suggestion time taken 17.438473 iter 41 next_points [{'alpha': 0.002032439104824753, 'batch_size': 41, 'beta_1': 0.7640776513603953, 'beta_2': 0.9973209842680603, 'epsilon': 7.144177079945937e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 2.864963923345635e-05, 'tol': 0.00012450938966812917, 'validation_fraction': 0.28068629715171817}]
function_evaluation time 0.273917 value -0.472527 suggestion {'alpha': 0.002032439104824753, 'batch_size': 41, 'beta_1': 0.7640776513603953, 'beta_2': 0.9973209842680603, 'epsilon': 7.144177079945937e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 2.864963923345635e-05, 'tol': 0.00012450938966812917, 'validation_fraction': 0.28068629715171817}
observation time 0.000003, current best -0.918681 at iter 41
suggestion time taken 16.624468 iter 42 next_points [{'alpha': 9.336174764102143, 'batch_size': 18, 'beta_1': 0.8916147918206149, 'beta_2': 0.9939263738979014, 'epsilon': 9.998728880294563e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.09972886707798456, 'tol': 0.03207832944292771, 'validation_fraction': 0.22286851194897128}]
function_evaluation time 1.698542 value -0.791209 suggestion {'alpha': 9.336174764102143, 'batch_size': 18, 'beta_1': 0.8916147918206149, 'beta_2': 0.9939263738979014, 'epsilon': 9.998728880294563e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.09972886707798456, 'tol': 0.03207832944292771, 'validation_fraction': 0.22286851194897128}
observation time 0.000005, current best -0.918681 at iter 42
suggestion time taken 16.253658 iter 43 next_points [{'alpha': 0.09276792668283115, 'batch_size': 227, 'beta_1': 0.5561779120530105, 'beta_2': 0.9999638116999298, 'epsilon': 6.44378369086759e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.00851066647915438, 'tol': 0.02603502913508087, 'validation_fraction': 0.7331510049489158}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.409285 value -0.905495 suggestion {'alpha': 0.09276792668283115, 'batch_size': 227, 'beta_1': 0.5561779120530105, 'beta_2': 0.9999638116999298, 'epsilon': 6.44378369086759e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.00851066647915438, 'tol': 0.02603502913508087, 'validation_fraction': 0.7331510049489158}
observation time 0.000005, current best -0.918681 at iter 43
suggestion time taken 17.440321 iter 44 next_points [{'alpha': 0.0012274588907691295, 'batch_size': 226, 'beta_1': 0.5355504873232284, 'beta_2': 0.9917383863168856, 'epsilon': 1.6954039622813522e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.5291889718948886e-05, 'tol': 0.010118439398116305, 'validation_fraction': 0.407263780331028}]
function_evaluation time 0.256850 value -0.602198 suggestion {'alpha': 0.0012274588907691295, 'batch_size': 226, 'beta_1': 0.5355504873232284, 'beta_2': 0.9917383863168856, 'epsilon': 1.6954039622813522e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.5291889718948886e-05, 'tol': 0.010118439398116305, 'validation_fraction': 0.407263780331028}
observation time 0.000005, current best -0.918681 at iter 44
saving meta data: {'args': {'--uuid': 'e53ff1157fb5544fa5c70f9cc2fcc1d9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
