running: {'--uuid': '9aa6f934909d5a05a5fce76a558318e3', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 9aa6f934909d5a05a5fce76a558318e3 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.011611 iter 0 next_points [{'alpha': 0.012136792348544862, 'batch_size': 128, 'beta_1': 0.9851791878395783, 'beta_2': 0.9999935841481179, 'epsilon': 4.863283656889566e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.01868993024526115, 'tol': 2.870578055096021e-05, 'validation_fraction': 0.15640233997571265}]
function_evaluation time 0.782302 value -0.907692 suggestion {'alpha': 0.012136792348544862, 'batch_size': 128, 'beta_1': 0.9851791878395783, 'beta_2': 0.9999935841481179, 'epsilon': 4.863283656889566e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.01868993024526115, 'tol': 2.870578055096021e-05, 'validation_fraction': 0.15640233997571265}
observation time 0.000011, current best -0.907692 at iter 0
suggestion time taken 0.011773 iter 1 next_points [{'alpha': 0.36437675945967507, 'batch_size': 188, 'beta_1': 0.6500171164994788, 'beta_2': 0.9888503484924204, 'epsilon': 6.179665166851386e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.002449608641391548, 'tol': 0.0005090802359139017, 'validation_fraction': 0.21184631591797354}]
function_evaluation time 0.784412 value -0.898901 suggestion {'alpha': 0.36437675945967507, 'batch_size': 188, 'beta_1': 0.6500171164994788, 'beta_2': 0.9888503484924204, 'epsilon': 6.179665166851386e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.002449608641391548, 'tol': 0.0005090802359139017, 'validation_fraction': 0.21184631591797354}
observation time 0.000013, current best -0.907692 at iter 1
suggestion time taken 0.014168 iter 2 next_points [{'alpha': 0.0005585778596074352, 'batch_size': 208, 'beta_1': 0.6107541715154058, 'beta_2': 0.9999170887368978, 'epsilon': 7.454721197953669e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 3.468815942337736e-05, 'tol': 0.006951855279581102, 'validation_fraction': 0.6359604193070636}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.302271 value -0.472527 suggestion {'alpha': 0.0005585778596074352, 'batch_size': 208, 'beta_1': 0.6107541715154058, 'beta_2': 0.9999170887368978, 'epsilon': 7.454721197953669e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 3.468815942337736e-05, 'tol': 0.006951855279581102, 'validation_fraction': 0.6359604193070636}
observation time 0.000008, current best -0.907692 at iter 2
suggestion time taken 0.010984 iter 3 next_points [{'alpha': 4.318168727517453e-05, 'batch_size': 183, 'beta_1': 0.9358158954810316, 'beta_2': 0.9997591478410728, 'epsilon': 5.487187477862175e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.004232324148873225, 'tol': 0.00018320938611011191, 'validation_fraction': 0.5101773123603842}]
function_evaluation time 0.657854 value -0.854945 suggestion {'alpha': 4.318168727517453e-05, 'batch_size': 183, 'beta_1': 0.9358158954810316, 'beta_2': 0.9997591478410728, 'epsilon': 5.487187477862175e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.004232324148873225, 'tol': 0.00018320938611011191, 'validation_fraction': 0.5101773123603842}
observation time 0.000011, current best -0.907692 at iter 3
suggestion time taken 0.013953 iter 4 next_points [{'alpha': 0.0029824487694966946, 'batch_size': 21, 'beta_1': 0.6252903438637424, 'beta_2': 0.9981503865216256, 'epsilon': 8.70078788167159e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.0076685112144625305, 'tol': 9.55797408123723e-05, 'validation_fraction': 0.23420108532237785}]
function_evaluation time 1.832851 value -0.918681 suggestion {'alpha': 0.0029824487694966946, 'batch_size': 21, 'beta_1': 0.6252903438637424, 'beta_2': 0.9981503865216256, 'epsilon': 8.70078788167159e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.0076685112144625305, 'tol': 9.55797408123723e-05, 'validation_fraction': 0.23420108532237785}
observation time 0.000006, current best -0.918681 at iter 4
suggestion time taken 0.011418 iter 5 next_points [{'alpha': 0.4272274202549463, 'batch_size': 100, 'beta_1': 0.919362950039517, 'beta_2': 0.9999523532663149, 'epsilon': 1.7251265724160871e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.004445340182986658, 'tol': 0.01943695686975255, 'validation_fraction': 0.5709096110595131}]
function_evaluation time 0.644267 value -0.920879 suggestion {'alpha': 0.4272274202549463, 'batch_size': 100, 'beta_1': 0.919362950039517, 'beta_2': 0.9999523532663149, 'epsilon': 1.7251265724160871e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.004445340182986658, 'tol': 0.01943695686975255, 'validation_fraction': 0.5709096110595131}
observation time 0.000005, current best -0.920879 at iter 5
suggestion time taken 0.010608 iter 6 next_points [{'alpha': 0.007057456541693421, 'batch_size': 113, 'beta_1': 0.9848291691228904, 'beta_2': 0.9774949315569094, 'epsilon': 2.532881833284298e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 1.2999533304693394e-05, 'tol': 0.0008399733958078051, 'validation_fraction': 0.12802221455151575}]
function_evaluation time 0.931425 value -0.641758 suggestion {'alpha': 0.007057456541693421, 'batch_size': 113, 'beta_1': 0.9848291691228904, 'beta_2': 0.9774949315569094, 'epsilon': 2.532881833284298e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 1.2999533304693394e-05, 'tol': 0.0008399733958078051, 'validation_fraction': 0.12802221455151575}
observation time 0.000012, current best -0.920879 at iter 6
suggestion time taken 0.011834 iter 7 next_points [{'alpha': 7.422112838454185e-05, 'batch_size': 199, 'beta_1': 0.9572472301427203, 'beta_2': 0.9520910493839395, 'epsilon': 7.4423788132711465e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.031672187169813244, 'tol': 0.04365205964244111, 'validation_fraction': 0.8552175198287534}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.386868 value -0.905495 suggestion {'alpha': 7.422112838454185e-05, 'batch_size': 199, 'beta_1': 0.9572472301427203, 'beta_2': 0.9520910493839395, 'epsilon': 7.4423788132711465e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.031672187169813244, 'tol': 0.04365205964244111, 'validation_fraction': 0.8552175198287534}
observation time 0.000005, current best -0.920879 at iter 7
suggestion time taken 0.011200 iter 8 next_points [{'alpha': 0.0046449223893074475, 'batch_size': 47, 'beta_1': 0.986483041493756, 'beta_2': 0.9999970048832595, 'epsilon': 1.646588957277224e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00703005258923369, 'tol': 0.017841934756690943, 'validation_fraction': 0.3058516190384729}]
function_evaluation time 0.867738 value -0.909890 suggestion {'alpha': 0.0046449223893074475, 'batch_size': 47, 'beta_1': 0.986483041493756, 'beta_2': 0.9999970048832595, 'epsilon': 1.646588957277224e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00703005258923369, 'tol': 0.017841934756690943, 'validation_fraction': 0.3058516190384729}
observation time 0.000004, current best -0.920879 at iter 8
suggestion time taken 0.009509 iter 9 next_points [{'alpha': 0.045676205593202845, 'batch_size': 215, 'beta_1': 0.7143103046575707, 'beta_2': 0.9993814922151205, 'epsilon': 1.8247195391323412e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0005426375486516931, 'tol': 0.021231568764641773, 'validation_fraction': 0.1860063620476004}]
function_evaluation time 0.892323 value -0.865934 suggestion {'alpha': 0.045676205593202845, 'batch_size': 215, 'beta_1': 0.7143103046575707, 'beta_2': 0.9993814922151205, 'epsilon': 1.8247195391323412e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0005426375486516931, 'tol': 0.021231568764641773, 'validation_fraction': 0.1860063620476004}
observation time 0.000005, current best -0.920879 at iter 9
suggestion time taken 0.011172 iter 10 next_points [{'alpha': 0.8765469605224108, 'batch_size': 116, 'beta_1': 0.5340402186884151, 'beta_2': 0.9999964423716028, 'epsilon': 1.274710340455575e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.049266905418555204, 'tol': 0.00026504626041711095, 'validation_fraction': 0.20508379654180883}]
function_evaluation time 0.347617 value -0.901099 suggestion {'alpha': 0.8765469605224108, 'batch_size': 116, 'beta_1': 0.5340402186884151, 'beta_2': 0.9999964423716028, 'epsilon': 1.274710340455575e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.049266905418555204, 'tol': 0.00026504626041711095, 'validation_fraction': 0.20508379654180883}
observation time 0.000003, current best -0.920879 at iter 10
suggestion time taken 0.004002 iter 11 next_points [{'alpha': 0.0001028682492054155, 'batch_size': 118, 'beta_1': 0.9660404907723351, 'beta_2': 0.9990761787896485, 'epsilon': 1.547741656384132e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 9.994030047497527e-05, 'tol': 0.0430364736885319, 'validation_fraction': 0.25710987443583844}]
function_evaluation time 0.738668 value -0.725275 suggestion {'alpha': 0.0001028682492054155, 'batch_size': 118, 'beta_1': 0.9660404907723351, 'beta_2': 0.9990761787896485, 'epsilon': 1.547741656384132e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 9.994030047497527e-05, 'tol': 0.0430364736885319, 'validation_fraction': 0.25710987443583844}
observation time 0.000004, current best -0.920879 at iter 11
suggestion time taken 0.009924 iter 12 next_points [{'alpha': 0.14054609284338843, 'batch_size': 144, 'beta_1': 0.8859600136008313, 'beta_2': 0.9999839338223788, 'epsilon': 5.1195017201959626e-09, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.005878685611875062, 'tol': 2.1711859200288922e-05, 'validation_fraction': 0.7051631293461599}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.793026 value -0.846154 suggestion {'alpha': 0.14054609284338843, 'batch_size': 144, 'beta_1': 0.8859600136008313, 'beta_2': 0.9999839338223788, 'epsilon': 5.1195017201959626e-09, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.005878685611875062, 'tol': 2.1711859200288922e-05, 'validation_fraction': 0.7051631293461599}
observation time 0.000005, current best -0.920879 at iter 12
suggestion time taken 0.010722 iter 13 next_points [{'alpha': 0.2299115317900017, 'batch_size': 212, 'beta_1': 0.947749646081564, 'beta_2': 0.948032513303626, 'epsilon': 5.711275996502773e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.05702274722374311, 'tol': 2.96113205145929e-05, 'validation_fraction': 0.19771493915573657}]
function_evaluation time 0.584497 value -0.868132 suggestion {'alpha': 0.2299115317900017, 'batch_size': 212, 'beta_1': 0.947749646081564, 'beta_2': 0.948032513303626, 'epsilon': 5.711275996502773e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.05702274722374311, 'tol': 2.96113205145929e-05, 'validation_fraction': 0.19771493915573657}
observation time 0.000005, current best -0.920879 at iter 13
suggestion time taken 0.011155 iter 14 next_points [{'alpha': 0.0037073949703540095, 'batch_size': 229, 'beta_1': 0.6282761011636203, 'beta_2': 0.9999961519220828, 'epsilon': 1.042612607066578e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.002639925909202085, 'tol': 0.002740078027803164, 'validation_fraction': 0.7587494444701922}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.786518 value -0.907692 suggestion {'alpha': 0.0037073949703540095, 'batch_size': 229, 'beta_1': 0.6282761011636203, 'beta_2': 0.9999961519220828, 'epsilon': 1.042612607066578e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.002639925909202085, 'tol': 0.002740078027803164, 'validation_fraction': 0.7587494444701922}
observation time 0.000004, current best -0.920879 at iter 14
suggestion time taken 0.009698 iter 15 next_points [{'alpha': 0.0006258474403074547, 'batch_size': 124, 'beta_1': 0.8122631586057729, 'beta_2': 0.9918205330584992, 'epsilon': 2.8041269250034705e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.001952518406633531, 'tol': 0.0302521672899696, 'validation_fraction': 0.1573765608607003}]
function_evaluation time 0.757248 value -0.920879 suggestion {'alpha': 0.0006258474403074547, 'batch_size': 124, 'beta_1': 0.8122631586057729, 'beta_2': 0.9918205330584992, 'epsilon': 2.8041269250034705e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.001952518406633531, 'tol': 0.0302521672899696, 'validation_fraction': 0.1573765608607003}
observation time 0.000005, current best -0.920879 at iter 15
suggestion time taken 0.010229 iter 16 next_points [{'alpha': 8.468409345888439, 'batch_size': 39, 'beta_1': 0.9866209686671823, 'beta_2': 0.9727617164463128, 'epsilon': 1.3785833607699274e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.09585812343834846, 'tol': 0.010141499532309967, 'validation_fraction': 0.7507879183939644}]
function_evaluation time 0.540406 value -0.872527 suggestion {'alpha': 8.468409345888439, 'batch_size': 39, 'beta_1': 0.9866209686671823, 'beta_2': 0.9727617164463128, 'epsilon': 1.3785833607699274e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.09585812343834846, 'tol': 0.010141499532309967, 'validation_fraction': 0.7507879183939644}
observation time 0.000013, current best -0.920879 at iter 16
suggestion time taken 0.013935 iter 17 next_points [{'alpha': 8.418992031018728, 'batch_size': 75, 'beta_1': 0.5621892908573587, 'beta_2': 0.9552463094802367, 'epsilon': 3.1402677644749467e-07, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.006427155468767735, 'tol': 0.05803781452040325, 'validation_fraction': 0.509317654101664}]
function_evaluation time 0.567873 value -0.914286 suggestion {'alpha': 8.418992031018728, 'batch_size': 75, 'beta_1': 0.5621892908573587, 'beta_2': 0.9552463094802367, 'epsilon': 3.1402677644749467e-07, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.006427155468767735, 'tol': 0.05803781452040325, 'validation_fraction': 0.509317654101664}
observation time 0.000004, current best -0.920879 at iter 17
suggestion time taken 0.010665 iter 18 next_points [{'alpha': 1.239518655144059, 'batch_size': 131, 'beta_1': 0.8479679752695914, 'beta_2': 0.9991836052839466, 'epsilon': 6.253080404817113e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 1.3709613376860485e-05, 'tol': 0.0018498881065737377, 'validation_fraction': 0.8802581285237344}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.238641 value -0.470330 suggestion {'alpha': 1.239518655144059, 'batch_size': 131, 'beta_1': 0.8479679752695914, 'beta_2': 0.9991836052839466, 'epsilon': 6.253080404817113e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 1.3709613376860485e-05, 'tol': 0.0018498881065737377, 'validation_fraction': 0.8802581285237344}
observation time 0.000007, current best -0.920879 at iter 18
suggestion time taken 0.011098 iter 19 next_points [{'alpha': 0.003298823888351792, 'batch_size': 207, 'beta_1': 0.9735395043914296, 'beta_2': 0.9999658317322203, 'epsilon': 3.8375537537796703e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 3.479107275674233e-05, 'tol': 0.03156540301809641, 'validation_fraction': 0.312517145193131}]
function_evaluation time 0.420397 value -0.558242 suggestion {'alpha': 0.003298823888351792, 'batch_size': 207, 'beta_1': 0.9735395043914296, 'beta_2': 0.9999658317322203, 'epsilon': 3.8375537537796703e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 3.479107275674233e-05, 'tol': 0.03156540301809641, 'validation_fraction': 0.312517145193131}
observation time 0.000005, current best -0.920879 at iter 19
suggestion time taken 0.010719 iter 20 next_points [{'alpha': 0.5706602432525006, 'batch_size': 145, 'beta_1': 0.9830844293451353, 'beta_2': 0.9999874719557692, 'epsilon': 1.528624070304598e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 4.7043068964204556e-05, 'tol': 0.016153166300084815, 'validation_fraction': 0.21387038155089946}]
function_evaluation time 0.434712 value -0.527473 suggestion {'alpha': 0.5706602432525006, 'batch_size': 145, 'beta_1': 0.9830844293451353, 'beta_2': 0.9999874719557692, 'epsilon': 1.528624070304598e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 4.7043068964204556e-05, 'tol': 0.016153166300084815, 'validation_fraction': 0.21387038155089946}
observation time 0.000004, current best -0.920879 at iter 20
suggestion time taken 0.010256 iter 21 next_points [{'alpha': 3.6978936823498088, 'batch_size': 49, 'beta_1': 0.9045767003517078, 'beta_2': 0.9999950938196955, 'epsilon': 2.296890425082283e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.00012375770081399467, 'tol': 0.00012375345373256318, 'validation_fraction': 0.8866018018402002}]
function_evaluation time 0.523615 value -0.498901 suggestion {'alpha': 3.6978936823498088, 'batch_size': 49, 'beta_1': 0.9045767003517078, 'beta_2': 0.9999950938196955, 'epsilon': 2.296890425082283e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.00012375770081399467, 'tol': 0.00012375345373256318, 'validation_fraction': 0.8866018018402002}
observation time 0.000006, current best -0.920879 at iter 21
suggestion time taken 0.010747 iter 22 next_points [{'alpha': 0.0002562979235064107, 'batch_size': 81, 'beta_1': 0.509911007188772, 'beta_2': 0.9999988807438405, 'epsilon': 5.0246121946389704e-09, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.00014037768624094104, 'tol': 0.00016025420854705154, 'validation_fraction': 0.8415617138718152}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.316442 value -0.736264 suggestion {'alpha': 0.0002562979235064107, 'batch_size': 81, 'beta_1': 0.509911007188772, 'beta_2': 0.9999988807438405, 'epsilon': 5.0246121946389704e-09, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.00014037768624094104, 'tol': 0.00016025420854705154, 'validation_fraction': 0.8415617138718152}
observation time 0.000004, current best -0.920879 at iter 22
suggestion time taken 0.009751 iter 23 next_points [{'alpha': 0.493817462975001, 'batch_size': 30, 'beta_1': 0.9757794202676309, 'beta_2': 0.9999985587656507, 'epsilon': 6.455938404542849e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.001427651537681874, 'tol': 2.982105356482131e-05, 'validation_fraction': 0.8993954872084077}]
function_evaluation time 0.567127 value -0.789011 suggestion {'alpha': 0.493817462975001, 'batch_size': 30, 'beta_1': 0.9757794202676309, 'beta_2': 0.9999985587656507, 'epsilon': 6.455938404542849e-08, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.001427651537681874, 'tol': 2.982105356482131e-05, 'validation_fraction': 0.8993954872084077}
observation time 0.000010, current best -0.920879 at iter 23
suggestion time taken 0.014060 iter 24 next_points [{'alpha': 1.6705354079499726, 'batch_size': 215, 'beta_1': 0.6648445166364951, 'beta_2': 0.9999790927498461, 'epsilon': 2.1745041995455636e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.06253706877936735, 'tol': 0.009418633310788257, 'validation_fraction': 0.8925478106492437}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.466428 value -0.848352 suggestion {'alpha': 1.6705354079499726, 'batch_size': 215, 'beta_1': 0.6648445166364951, 'beta_2': 0.9999790927498461, 'epsilon': 2.1745041995455636e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.06253706877936735, 'tol': 0.009418633310788257, 'validation_fraction': 0.8925478106492437}
observation time 0.000004, current best -0.920879 at iter 24
suggestion time taken 0.010280 iter 25 next_points [{'alpha': 0.012737876907542934, 'batch_size': 123, 'beta_1': 0.6129042586854012, 'beta_2': 0.997072854795929, 'epsilon': 3.8591179141410957e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.010274956170669638, 'tol': 0.0140261773713609, 'validation_fraction': 0.31175275096044647}]
function_evaluation time 0.305465 value -0.896703 suggestion {'alpha': 0.012737876907542934, 'batch_size': 123, 'beta_1': 0.6129042586854012, 'beta_2': 0.997072854795929, 'epsilon': 3.8591179141410957e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.010274956170669638, 'tol': 0.0140261773713609, 'validation_fraction': 0.31175275096044647}
observation time 0.000002, current best -0.920879 at iter 25
suggestion time taken 0.003917 iter 26 next_points [{'alpha': 0.00994539720544092, 'batch_size': 128, 'beta_1': 0.7853027218490163, 'beta_2': 0.9994495788538299, 'epsilon': 8.715701597444586e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0002545574253202933, 'tol': 0.0795520948592652, 'validation_fraction': 0.5636120393258538}]
function_evaluation time 0.443388 value -0.529670 suggestion {'alpha': 0.00994539720544092, 'batch_size': 128, 'beta_1': 0.7853027218490163, 'beta_2': 0.9994495788538299, 'epsilon': 8.715701597444586e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0002545574253202933, 'tol': 0.0795520948592652, 'validation_fraction': 0.5636120393258538}
observation time 0.000005, current best -0.920879 at iter 26
suggestion time taken 0.010915 iter 27 next_points [{'alpha': 0.002323472218957749, 'batch_size': 31, 'beta_1': 0.8591956766473446, 'beta_2': 0.9006821047951329, 'epsilon': 1.650998096103322e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.011461646664330213, 'tol': 0.00567331390621643, 'validation_fraction': 0.7979955798251602}]
function_evaluation time 0.686827 value -0.898901 suggestion {'alpha': 0.002323472218957749, 'batch_size': 31, 'beta_1': 0.8591956766473446, 'beta_2': 0.9006821047951329, 'epsilon': 1.650998096103322e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.011461646664330213, 'tol': 0.00567331390621643, 'validation_fraction': 0.7979955798251602}
observation time 0.000009, current best -0.920879 at iter 27
suggestion time taken 0.014047 iter 28 next_points [{'alpha': 0.021263026542880197, 'batch_size': 229, 'beta_1': 0.8319232892134669, 'beta_2': 0.9971362563300429, 'epsilon': 1.3587963689195874e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.0019103592054067354, 'tol': 0.0664429232479455, 'validation_fraction': 0.32047699045247857}]
function_evaluation time 0.593647 value -0.894505 suggestion {'alpha': 0.021263026542880197, 'batch_size': 229, 'beta_1': 0.8319232892134669, 'beta_2': 0.9971362563300429, 'epsilon': 1.3587963689195874e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.0019103592054067354, 'tol': 0.0664429232479455, 'validation_fraction': 0.32047699045247857}
observation time 0.000003, current best -0.920879 at iter 28
suggestion time taken 0.012259 iter 29 next_points [{'alpha': 0.4974278428112086, 'batch_size': 57, 'beta_1': 0.986132099868131, 'beta_2': 0.9999635506085556, 'epsilon': 4.332524384547995e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.00019749809949656685, 'tol': 0.0006976099338292912, 'validation_fraction': 0.7754002368054953}]
function_evaluation time 0.347041 value -0.619780 suggestion {'alpha': 0.4974278428112086, 'batch_size': 57, 'beta_1': 0.986132099868131, 'beta_2': 0.9999635506085556, 'epsilon': 4.332524384547995e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.00019749809949656685, 'tol': 0.0006976099338292912, 'validation_fraction': 0.7754002368054953}
observation time 0.000007, current best -0.920879 at iter 29
suggestion time taken 0.013424 iter 30 next_points [{'alpha': 0.00017397457063241962, 'batch_size': 51, 'beta_1': 0.6987165297329393, 'beta_2': 0.999998457123325, 'epsilon': 1.9844112695891636e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.001209768544835011, 'tol': 0.00010861886383138732, 'validation_fraction': 0.24893061806843714}]
function_evaluation time 1.348639 value -0.898901 suggestion {'alpha': 0.00017397457063241962, 'batch_size': 51, 'beta_1': 0.6987165297329393, 'beta_2': 0.999998457123325, 'epsilon': 1.9844112695891636e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.001209768544835011, 'tol': 0.00010861886383138732, 'validation_fraction': 0.24893061806843714}
observation time 0.000005, current best -0.920879 at iter 30
suggestion time taken 0.010685 iter 31 next_points [{'alpha': 0.00026452510669042965, 'batch_size': 125, 'beta_1': 0.9294433141894826, 'beta_2': 0.9991859766837659, 'epsilon': 6.500998858657767e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 5.8909739489527285e-05, 'tol': 0.001672261256964009, 'validation_fraction': 0.8856625380794361}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.241863 value -0.446154 suggestion {'alpha': 0.00026452510669042965, 'batch_size': 125, 'beta_1': 0.9294433141894826, 'beta_2': 0.9991859766837659, 'epsilon': 6.500998858657767e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 5.8909739489527285e-05, 'tol': 0.001672261256964009, 'validation_fraction': 0.8856625380794361}
observation time 0.000011, current best -0.920879 at iter 31
suggestion time taken 0.012140 iter 32 next_points [{'alpha': 0.16379777470531864, 'batch_size': 191, 'beta_1': 0.8999027370582853, 'beta_2': 0.9999082246186324, 'epsilon': 5.039341009802416e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.00044839555875173556, 'tol': 0.012349097793535557, 'validation_fraction': 0.5558993969062713}]
function_evaluation time 0.295653 value -0.531868 suggestion {'alpha': 0.16379777470531864, 'batch_size': 191, 'beta_1': 0.8999027370582853, 'beta_2': 0.9999082246186324, 'epsilon': 5.039341009802416e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.00044839555875173556, 'tol': 0.012349097793535557, 'validation_fraction': 0.5558993969062713}
observation time 0.000004, current best -0.920879 at iter 32
suggestion time taken 0.010407 iter 33 next_points [{'alpha': 2.403161334109497, 'batch_size': 46, 'beta_1': 0.938925940185743, 'beta_2': 0.9869649009032152, 'epsilon': 3.867462661758188e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 9.989612481087558e-05, 'tol': 2.938897135741397e-05, 'validation_fraction': 0.12716341584073743}]
function_evaluation time 1.049854 value -0.745055 suggestion {'alpha': 2.403161334109497, 'batch_size': 46, 'beta_1': 0.938925940185743, 'beta_2': 0.9869649009032152, 'epsilon': 3.867462661758188e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 9.989612481087558e-05, 'tol': 2.938897135741397e-05, 'validation_fraction': 0.12716341584073743}
observation time 0.000005, current best -0.920879 at iter 33
suggestion time taken 0.009936 iter 34 next_points [{'alpha': 1.633606879328908e-05, 'batch_size': 95, 'beta_1': 0.9883721880548356, 'beta_2': 0.9999914120463916, 'epsilon': 1.022564271789537e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 7.045886122023817e-05, 'tol': 0.028593221527658044, 'validation_fraction': 0.21839189774512596}]
function_evaluation time 0.767696 value -0.562637 suggestion {'alpha': 1.633606879328908e-05, 'batch_size': 95, 'beta_1': 0.9883721880548356, 'beta_2': 0.9999914120463916, 'epsilon': 1.022564271789537e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 7.045886122023817e-05, 'tol': 0.028593221527658044, 'validation_fraction': 0.21839189774512596}
observation time 0.000009, current best -0.920879 at iter 34
suggestion time taken 0.011796 iter 35 next_points [{'alpha': 4.5178617502744505, 'batch_size': 225, 'beta_1': 0.5561594855282591, 'beta_2': 0.996807171068461, 'epsilon': 4.135729099563701e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.0004375400841419828, 'tol': 0.0006951400364768499, 'validation_fraction': 0.13534915634856456}]
function_evaluation time 1.116114 value -0.914286 suggestion {'alpha': 4.5178617502744505, 'batch_size': 225, 'beta_1': 0.5561594855282591, 'beta_2': 0.996807171068461, 'epsilon': 4.135729099563701e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.0004375400841419828, 'tol': 0.0006951400364768499, 'validation_fraction': 0.13534915634856456}
observation time 0.000004, current best -0.920879 at iter 35
suggestion time taken 0.011268 iter 36 next_points [{'alpha': 0.0003322157961390555, 'batch_size': 245, 'beta_1': 0.7364162260502726, 'beta_2': 0.9817578408588014, 'epsilon': 7.707226415894763e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.009425866455049572, 'tol': 1.1441731595301561e-05, 'validation_fraction': 0.1466764320760174}]
function_evaluation time 0.833739 value -0.903297 suggestion {'alpha': 0.0003322157961390555, 'batch_size': 245, 'beta_1': 0.7364162260502726, 'beta_2': 0.9817578408588014, 'epsilon': 7.707226415894763e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.009425866455049572, 'tol': 1.1441731595301561e-05, 'validation_fraction': 0.1466764320760174}
observation time 0.000005, current best -0.920879 at iter 36
suggestion time taken 0.010709 iter 37 next_points [{'alpha': 0.1514816530057446, 'batch_size': 129, 'beta_1': 0.5701852989286196, 'beta_2': 0.9999944835068768, 'epsilon': 2.192912334199211e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.00026011786606667945, 'tol': 0.0011761154455727464, 'validation_fraction': 0.45410907793759303}]
function_evaluation time 1.034853 value -0.850549 suggestion {'alpha': 0.1514816530057446, 'batch_size': 129, 'beta_1': 0.5701852989286196, 'beta_2': 0.9999944835068768, 'epsilon': 2.192912334199211e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.00026011786606667945, 'tol': 0.0011761154455727464, 'validation_fraction': 0.45410907793759303}
observation time 0.000005, current best -0.920879 at iter 37
suggestion time taken 0.010719 iter 38 next_points [{'alpha': 0.03777824586756931, 'batch_size': 79, 'beta_1': 0.9091679995504176, 'beta_2': 0.920607553642727, 'epsilon': 1.7938547799642933e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.04910686178289464, 'tol': 0.005775787892834116, 'validation_fraction': 0.8705846332948537}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.502725 value -0.854945 suggestion {'alpha': 0.03777824586756931, 'batch_size': 79, 'beta_1': 0.9091679995504176, 'beta_2': 0.920607553642727, 'epsilon': 1.7938547799642933e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.04910686178289464, 'tol': 0.005775787892834116, 'validation_fraction': 0.8705846332948537}
observation time 0.000003, current best -0.920879 at iter 38
suggestion time taken 0.009666 iter 39 next_points [{'alpha': 0.46853829903336397, 'batch_size': 116, 'beta_1': 0.738255409153198, 'beta_2': 0.994431432242749, 'epsilon': 9.929444888272036e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 2.76216650898972e-05, 'tol': 0.00038591775335652554, 'validation_fraction': 0.16521643035752495}]
function_evaluation time 0.509003 value -0.490110 suggestion {'alpha': 0.46853829903336397, 'batch_size': 116, 'beta_1': 0.738255409153198, 'beta_2': 0.994431432242749, 'epsilon': 9.929444888272036e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 2.76216650898972e-05, 'tol': 0.00038591775335652554, 'validation_fraction': 0.16521643035752495}
observation time 0.000006, current best -0.920879 at iter 39
suggestion time taken 0.010592 iter 40 next_points [{'alpha': 6.246689297973369e-05, 'batch_size': 166, 'beta_1': 0.679765407944447, 'beta_2': 0.9995079699761482, 'epsilon': 1.8427199686943463e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0025813782596646063, 'tol': 2.1805163001844192e-05, 'validation_fraction': 0.7154988117746995}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.720215 value -0.887912 suggestion {'alpha': 6.246689297973369e-05, 'batch_size': 166, 'beta_1': 0.679765407944447, 'beta_2': 0.9995079699761482, 'epsilon': 1.8427199686943463e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0025813782596646063, 'tol': 2.1805163001844192e-05, 'validation_fraction': 0.7154988117746995}
observation time 0.000007, current best -0.920879 at iter 40
suggestion time taken 0.011082 iter 41 next_points [{'alpha': 0.0002247941804884375, 'batch_size': 212, 'beta_1': 0.6249493124162058, 'beta_2': 0.9999939658233259, 'epsilon': 2.5034785941406005e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00026736355552514217, 'tol': 0.01814681048033594, 'validation_fraction': 0.4408169922048751}]
function_evaluation time 0.351196 value -0.428571 suggestion {'alpha': 0.0002247941804884375, 'batch_size': 212, 'beta_1': 0.6249493124162058, 'beta_2': 0.9999939658233259, 'epsilon': 2.5034785941406005e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00026736355552514217, 'tol': 0.01814681048033594, 'validation_fraction': 0.4408169922048751}
observation time 0.000005, current best -0.920879 at iter 41
suggestion time taken 0.010694 iter 42 next_points [{'alpha': 0.012156943853393047, 'batch_size': 22, 'beta_1': 0.9887384639197395, 'beta_2': 0.9866943680505836, 'epsilon': 4.124021138280446e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.009750827622637863, 'tol': 0.0003776857967058437, 'validation_fraction': 0.7875868111458655}]
function_evaluation time 0.920110 value -0.905495 suggestion {'alpha': 0.012156943853393047, 'batch_size': 22, 'beta_1': 0.9887384639197395, 'beta_2': 0.9866943680505836, 'epsilon': 4.124021138280446e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.009750827622637863, 'tol': 0.0003776857967058437, 'validation_fraction': 0.7875868111458655}
observation time 0.000009, current best -0.920879 at iter 42
suggestion time taken 0.013736 iter 43 next_points [{'alpha': 3.320948296156102, 'batch_size': 200, 'beta_1': 0.5085940465745535, 'beta_2': 0.9999563945667291, 'epsilon': 1.0316692594386068e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 4.81170065574052e-05, 'tol': 0.010595009640365648, 'validation_fraction': 0.10920889823357348}]
function_evaluation time 0.576801 value -0.472527 suggestion {'alpha': 3.320948296156102, 'batch_size': 200, 'beta_1': 0.5085940465745535, 'beta_2': 0.9999563945667291, 'epsilon': 1.0316692594386068e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 4.81170065574052e-05, 'tol': 0.010595009640365648, 'validation_fraction': 0.10920889823357348}
observation time 0.000004, current best -0.920879 at iter 43
suggestion time taken 0.009465 iter 44 next_points [{'alpha': 3.827459496394903, 'batch_size': 177, 'beta_1': 0.9857806095102579, 'beta_2': 0.9999359003304785, 'epsilon': 4.342010864834073e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 1.898888004622292e-05, 'tol': 0.0009707262280190568, 'validation_fraction': 0.7887128652018698}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.557618 value -0.578022 suggestion {'alpha': 3.827459496394903, 'batch_size': 177, 'beta_1': 0.9857806095102579, 'beta_2': 0.9999359003304785, 'epsilon': 4.342010864834073e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 1.898888004622292e-05, 'tol': 0.0009707262280190568, 'validation_fraction': 0.7887128652018698}
observation time 0.000005, current best -0.920879 at iter 44
saving meta data: {'args': {'--uuid': '9aa6f934909d5a05a5fce76a558318e3', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
