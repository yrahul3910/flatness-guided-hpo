running: {'--uuid': '1645cd443b9a5c9b9928e1289a562f13', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 1645cd443b9a5c9b9928e1289a562f13 -m nll -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast nll 45 1
with data root: None
suggestion time taken 0.010309 iter 0 next_points [{'alpha': 0.000173297776070438, 'batch_size': 73, 'beta_1': 0.9690630208678823, 'beta_2': 0.9998460044665644, 'epsilon': 6.695639488350891e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 8.93632154757301e-05, 'tol': 8.541222477253732e-05, 'validation_fraction': 0.363154840702142}]
function_evaluation time 0.597509 value 16.269468 suggestion {'alpha': 0.000173297776070438, 'batch_size': 73, 'beta_1': 0.9690630208678823, 'beta_2': 0.9998460044665644, 'epsilon': 6.695639488350891e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 8.93632154757301e-05, 'tol': 8.541222477253732e-05, 'validation_fraction': 0.363154840702142}
observation time 0.000004, current best 16.269468 at iter 0
suggestion time taken 0.010922 iter 1 next_points [{'alpha': 0.011741866370831756, 'batch_size': 150, 'beta_1': 0.9459774410110637, 'beta_2': 0.9999967640553478, 'epsilon': 9.374174126580215e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.0007371473482001214, 'tol': 0.0008035043735656856, 'validation_fraction': 0.8807836956999734}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.403864 value 7.677513 suggestion {'alpha': 0.011741866370831756, 'batch_size': 150, 'beta_1': 0.9459774410110637, 'beta_2': 0.9999967640553478, 'epsilon': 9.374174126580215e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.0007371473482001214, 'tol': 0.0008035043735656856, 'validation_fraction': 0.8807836956999734}
observation time 0.000003, current best 7.677513 at iter 1
suggestion time taken 0.010186 iter 2 next_points [{'alpha': 5.793382397526622, 'batch_size': 149, 'beta_1': 0.9255369690635109, 'beta_2': 0.9997835255517514, 'epsilon': 6.260563752558446e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.0004933797483526432, 'tol': 0.044364528817644466, 'validation_fraction': 0.7583295620832641}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.388947 value 5.928979 suggestion {'alpha': 5.793382397526622, 'batch_size': 149, 'beta_1': 0.9255369690635109, 'beta_2': 0.9997835255517514, 'epsilon': 6.260563752558446e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.0004933797483526432, 'tol': 0.044364528817644466, 'validation_fraction': 0.7583295620832641}
observation time 0.000008, current best 5.928979 at iter 2
suggestion time taken 0.013760 iter 3 next_points [{'alpha': 1.3109135646750363, 'batch_size': 102, 'beta_1': 0.6964694935243927, 'beta_2': 0.9846469942839952, 'epsilon': 8.528032053011321e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.003967470888501121, 'tol': 0.00014510158516196662, 'validation_fraction': 0.25433463255889943}]
function_evaluation time 0.871828 value 0.411184 suggestion {'alpha': 1.3109135646750363, 'batch_size': 102, 'beta_1': 0.6964694935243927, 'beta_2': 0.9846469942839952, 'epsilon': 8.528032053011321e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.003967470888501121, 'tol': 0.00014510158516196662, 'validation_fraction': 0.25433463255889943}
observation time 0.000004, current best 0.411184 at iter 3
suggestion time taken 0.011227 iter 4 next_points [{'alpha': 1.65789858244693e-05, 'batch_size': 32, 'beta_1': 0.9135868612678916, 'beta_2': 0.9999891546141184, 'epsilon': 1.979977815564796e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.03699236518298233, 'tol': 0.0023922483722769354, 'validation_fraction': 0.6233820463373906}]
function_evaluation time 1.314633 value 0.401601 suggestion {'alpha': 1.65789858244693e-05, 'batch_size': 32, 'beta_1': 0.9135868612678916, 'beta_2': 0.9999891546141184, 'epsilon': 1.979977815564796e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.03699236518298233, 'tol': 0.0023922483722769354, 'validation_fraction': 0.6233820463373906}
observation time 0.000008, current best 0.401601 at iter 4
suggestion time taken 0.013140 iter 5 next_points [{'alpha': 0.6026066340529743, 'batch_size': 149, 'beta_1': 0.8990004613676859, 'beta_2': 0.9901732466936483, 'epsilon': 2.1695064757372457e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00045316895938334636, 'tol': 0.004418806443853301, 'validation_fraction': 0.8667386876755935}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.363004 value 13.481227 suggestion {'alpha': 0.6026066340529743, 'batch_size': 149, 'beta_1': 0.8990004613676859, 'beta_2': 0.9901732466936483, 'epsilon': 2.1695064757372457e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00045316895938334636, 'tol': 0.004418806443853301, 'validation_fraction': 0.8667386876755935}
observation time 0.000011, current best 0.401601 at iter 5
suggestion time taken 0.012003 iter 6 next_points [{'alpha': 0.0008492396206987227, 'batch_size': 206, 'beta_1': 0.6331407774099601, 'beta_2': 0.965481406527524, 'epsilon': 3.1258907686386064e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 9.556491657884968e-05, 'tol': 0.035235981690200334, 'validation_fraction': 0.11564603022041942}]
function_evaluation time 0.465597 value 15.876125 suggestion {'alpha': 0.0008492396206987227, 'batch_size': 206, 'beta_1': 0.6331407774099601, 'beta_2': 0.965481406527524, 'epsilon': 3.1258907686386064e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 9.556491657884968e-05, 'tol': 0.035235981690200334, 'validation_fraction': 0.11564603022041942}
observation time 0.000004, current best 0.401601 at iter 6
suggestion time taken 0.011676 iter 7 next_points [{'alpha': 5.773512725466458, 'batch_size': 74, 'beta_1': 0.9463203149039412, 'beta_2': 0.9506976295916758, 'epsilon': 1.8580494762921343e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.009141232170782406, 'tol': 3.592287936745527e-05, 'validation_fraction': 0.7263153919292643}]
function_evaluation time 0.784370 value 0.968753 suggestion {'alpha': 5.773512725466458, 'batch_size': 74, 'beta_1': 0.9463203149039412, 'beta_2': 0.9506976295916758, 'epsilon': 1.8580494762921343e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.009141232170782406, 'tol': 3.592287936745527e-05, 'validation_fraction': 0.7263153919292643}
observation time 0.000003, current best 0.401601 at iter 7
suggestion time taken 0.010289 iter 8 next_points [{'alpha': 0.000229813397935338, 'batch_size': 162, 'beta_1': 0.9230237889085809, 'beta_2': 0.9926525666949203, 'epsilon': 2.577976468266056e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0129095280957632, 'tol': 0.001990998067622863, 'validation_fraction': 0.28758312698151356}]
function_evaluation time 0.281023 value 1.155108 suggestion {'alpha': 0.000229813397935338, 'batch_size': 162, 'beta_1': 0.9230237889085809, 'beta_2': 0.9926525666949203, 'epsilon': 2.577976468266056e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0129095280957632, 'tol': 0.001990998067622863, 'validation_fraction': 0.28758312698151356}
observation time 0.000003, current best 0.401601 at iter 8
suggestion time taken 0.004045 iter 9 next_points [{'alpha': 2.8560413062424947, 'batch_size': 80, 'beta_1': 0.941997845651387, 'beta_2': 0.9999701168885695, 'epsilon': 1.6183665068929338e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 2.8309600609908124e-05, 'tol': 0.00018561583397602212, 'validation_fraction': 0.2584468518099455}]
function_evaluation time 0.823297 value 12.125393 suggestion {'alpha': 2.8560413062424947, 'batch_size': 80, 'beta_1': 0.941997845651387, 'beta_2': 0.9999701168885695, 'epsilon': 1.6183665068929338e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 2.8309600609908124e-05, 'tol': 0.00018561583397602212, 'validation_fraction': 0.2584468518099455}
observation time 0.000003, current best 0.401601 at iter 9
suggestion time taken 0.010414 iter 10 next_points [{'alpha': 0.0005787182706987097, 'batch_size': 190, 'beta_1': 0.9857132385003727, 'beta_2': 0.998289566782311, 'epsilon': 4.92985158528096e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.0014007670505281225, 'tol': 1.4754635773564159e-05, 'validation_fraction': 0.735987544430715}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.489027 value 8.170521 suggestion {'alpha': 0.0005787182706987097, 'batch_size': 190, 'beta_1': 0.9857132385003727, 'beta_2': 0.998289566782311, 'epsilon': 4.92985158528096e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.0014007670505281225, 'tol': 1.4754635773564159e-05, 'validation_fraction': 0.735987544430715}
observation time 0.000010, current best 0.401601 at iter 10
suggestion time taken 0.015737 iter 11 next_points [{'alpha': 1.7153794756761331, 'batch_size': 42, 'beta_1': 0.9803627708415352, 'beta_2': 0.9985953077557622, 'epsilon': 1.3958519107715292e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 2.7534787474734395e-05, 'tol': 0.018953493373693647, 'validation_fraction': 0.3594529082155709}]
function_evaluation time 1.346683 value 8.132312 suggestion {'alpha': 1.7153794756761331, 'batch_size': 42, 'beta_1': 0.9803627708415352, 'beta_2': 0.9985953077557622, 'epsilon': 1.3958519107715292e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 2.7534787474734395e-05, 'tol': 0.018953493373693647, 'validation_fraction': 0.3594529082155709}
observation time 0.000007, current best 0.401601 at iter 11
suggestion time taken 0.012390 iter 12 next_points [{'alpha': 3.5463883320143106, 'batch_size': 97, 'beta_1': 0.550862607153201, 'beta_2': 0.999983486694381, 'epsilon': 1.905283837232709e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0007555250067446517, 'tol': 0.0013229236499161083, 'validation_fraction': 0.41424173125694513}]
function_evaluation time 1.462459 value 0.255263 suggestion {'alpha': 3.5463883320143106, 'batch_size': 97, 'beta_1': 0.550862607153201, 'beta_2': 0.999983486694381, 'epsilon': 1.905283837232709e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0007555250067446517, 'tol': 0.0013229236499161083, 'validation_fraction': 0.41424173125694513}
observation time 0.000003, current best 0.255263 at iter 12
suggestion time taken 0.011267 iter 13 next_points [{'alpha': 2.9138627065873135, 'batch_size': 178, 'beta_1': 0.5529920143252297, 'beta_2': 0.9862271094432248, 'epsilon': 1.3581752783414764e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.00016950216137363654, 'tol': 0.007604912151679353, 'validation_fraction': 0.6660392603949417}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.412305 value 11.599610 suggestion {'alpha': 2.9138627065873135, 'batch_size': 178, 'beta_1': 0.5529920143252297, 'beta_2': 0.9862271094432248, 'epsilon': 1.3581752783414764e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.00016950216137363654, 'tol': 0.007604912151679353, 'validation_fraction': 0.6660392603949417}
observation time 0.000004, current best 0.255263 at iter 13
suggestion time taken 0.011516 iter 14 next_points [{'alpha': 0.019496234767673155, 'batch_size': 165, 'beta_1': 0.9448260711720151, 'beta_2': 0.9709319423104281, 'epsilon': 5.221294745073181e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.00022198448629673, 'tol': 0.03903257857569511, 'validation_fraction': 0.6707274212702208}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.309188 value 8.061341 suggestion {'alpha': 0.019496234767673155, 'batch_size': 165, 'beta_1': 0.9448260711720151, 'beta_2': 0.9709319423104281, 'epsilon': 5.221294745073181e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.00022198448629673, 'tol': 0.03903257857569511, 'validation_fraction': 0.6707274212702208}
observation time 0.000003, current best 0.255263 at iter 14
suggestion time taken 0.010847 iter 15 next_points [{'alpha': 0.4995666372954453, 'batch_size': 77, 'beta_1': 0.946983266164963, 'beta_2': 0.9999982640615969, 'epsilon': 1.3747614047584263e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 5.840397542742169e-05, 'tol': 0.000704337215878293, 'validation_fraction': 0.3725253999699536}]
function_evaluation time 0.384112 value 12.003390 suggestion {'alpha': 0.4995666372954453, 'batch_size': 77, 'beta_1': 0.946983266164963, 'beta_2': 0.9999982640615969, 'epsilon': 1.3747614047584263e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 5.840397542742169e-05, 'tol': 0.000704337215878293, 'validation_fraction': 0.3725253999699536}
observation time 0.000005, current best 0.255263 at iter 15
suggestion time taken 0.011458 iter 16 next_points [{'alpha': 2.5674919495715738e-05, 'batch_size': 214, 'beta_1': 0.9894090396460566, 'beta_2': 0.9999617458597861, 'epsilon': 2.0244633340407651e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0003603739600666776, 'tol': 0.004294234345154853, 'validation_fraction': 0.17179000552519055}]
function_evaluation time 0.630672 value 8.716253 suggestion {'alpha': 2.5674919495715738e-05, 'batch_size': 214, 'beta_1': 0.9894090396460566, 'beta_2': 0.9999617458597861, 'epsilon': 2.0244633340407651e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0003603739600666776, 'tol': 0.004294234345154853, 'validation_fraction': 0.17179000552519055}
observation time 0.000003, current best 0.255263 at iter 16
suggestion time taken 0.009777 iter 17 next_points [{'alpha': 1.282808011332279, 'batch_size': 174, 'beta_1': 0.9897353617467054, 'beta_2': 0.998194856522958, 'epsilon': 2.0417523383051036e-09, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.006872092071213057, 'tol': 0.000911600593552688, 'validation_fraction': 0.10571390768178623}]
function_evaluation time 0.732650 value 0.712917 suggestion {'alpha': 1.282808011332279, 'batch_size': 174, 'beta_1': 0.9897353617467054, 'beta_2': 0.998194856522958, 'epsilon': 2.0417523383051036e-09, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.006872092071213057, 'tol': 0.000911600593552688, 'validation_fraction': 0.10571390768178623}
observation time 0.000004, current best 0.255263 at iter 17
suggestion time taken 0.011742 iter 18 next_points [{'alpha': 0.03549954734485249, 'batch_size': 123, 'beta_1': 0.9791822522122925, 'beta_2': 0.9962716736042476, 'epsilon': 5.719005848547772e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0007429106817526222, 'tol': 1.3774118013605953e-05, 'validation_fraction': 0.8672045231228317}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.306010 value 12.061132 suggestion {'alpha': 0.03549954734485249, 'batch_size': 123, 'beta_1': 0.9791822522122925, 'beta_2': 0.9962716736042476, 'epsilon': 5.719005848547772e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0007429106817526222, 'tol': 1.3774118013605953e-05, 'validation_fraction': 0.8672045231228317}
observation time 0.000003, current best 0.255263 at iter 18
suggestion time taken 0.010286 iter 19 next_points [{'alpha': 0.00026821778409987857, 'batch_size': 123, 'beta_1': 0.5108758572137841, 'beta_2': 0.9999953909096136, 'epsilon': 2.798441545593837e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0319009182340791, 'tol': 0.0003197767624420035, 'validation_fraction': 0.5692497629022729}]
function_evaluation time 0.661936 value 0.938003 suggestion {'alpha': 0.00026821778409987857, 'batch_size': 123, 'beta_1': 0.5108758572137841, 'beta_2': 0.9999953909096136, 'epsilon': 2.798441545593837e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0319009182340791, 'tol': 0.0003197767624420035, 'validation_fraction': 0.5692497629022729}
observation time 0.000007, current best 0.255263 at iter 19
suggestion time taken 0.012009 iter 20 next_points [{'alpha': 0.00021837334529169254, 'batch_size': 206, 'beta_1': 0.6036168591482947, 'beta_2': 0.9531303531973716, 'epsilon': 5.561926438565082e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0009436494221376313, 'tol': 0.0708524300918438, 'validation_fraction': 0.8579264069815367}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.347334 value 2.788007 suggestion {'alpha': 0.00021837334529169254, 'batch_size': 206, 'beta_1': 0.6036168591482947, 'beta_2': 0.9531303531973716, 'epsilon': 5.561926438565082e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0009436494221376313, 'tol': 0.0708524300918438, 'validation_fraction': 0.8579264069815367}
observation time 0.000004, current best 0.255263 at iter 20
suggestion time taken 0.011738 iter 21 next_points [{'alpha': 1.9783697335028656e-05, 'batch_size': 99, 'beta_1': 0.9473513430814328, 'beta_2': 0.9246933203562004, 'epsilon': 1.3973371089895348e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.00025368589140489567, 'tol': 0.004682520273908922, 'validation_fraction': 0.7579233210787534}]
function_evaluation time 0.449047 value 7.661322 suggestion {'alpha': 1.9783697335028656e-05, 'batch_size': 99, 'beta_1': 0.9473513430814328, 'beta_2': 0.9246933203562004, 'epsilon': 1.3973371089895348e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.00025368589140489567, 'tol': 0.004682520273908922, 'validation_fraction': 0.7579233210787534}
observation time 0.000005, current best 0.255263 at iter 21
suggestion time taken 0.011796 iter 22 next_points [{'alpha': 5.912963924074689, 'batch_size': 112, 'beta_1': 0.9866662383373933, 'beta_2': 0.999989781992416, 'epsilon': 3.820775026511954e-07, 'hidden_layer_sizes': 153, 'learning_rate_init': 1.7263907725531392e-05, 'tol': 0.01601082751796131, 'validation_fraction': 0.3091070581385191}]
function_evaluation time 0.585438 value 13.716778 suggestion {'alpha': 5.912963924074689, 'batch_size': 112, 'beta_1': 0.9866662383373933, 'beta_2': 0.999989781992416, 'epsilon': 3.820775026511954e-07, 'hidden_layer_sizes': 153, 'learning_rate_init': 1.7263907725531392e-05, 'tol': 0.01601082751796131, 'validation_fraction': 0.3091070581385191}
observation time 0.000004, current best 0.255263 at iter 22
suggestion time taken 0.010399 iter 23 next_points [{'alpha': 1.216507316955713, 'batch_size': 120, 'beta_1': 0.6271982924883452, 'beta_2': 0.9999963508850841, 'epsilon': 1.016164989450573e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.005211725294313726, 'tol': 2.6048142198852616e-05, 'validation_fraction': 0.20250813942030618}]
function_evaluation time 0.365386 value 0.388646 suggestion {'alpha': 1.216507316955713, 'batch_size': 120, 'beta_1': 0.6271982924883452, 'beta_2': 0.9999963508850841, 'epsilon': 1.016164989450573e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.005211725294313726, 'tol': 2.6048142198852616e-05, 'validation_fraction': 0.20250813942030618}
observation time 0.000002, current best 0.255263 at iter 23
suggestion time taken 0.004076 iter 24 next_points [{'alpha': 0.0425830270549409, 'batch_size': 80, 'beta_1': 0.6404464696889703, 'beta_2': 0.9999749750692368, 'epsilon': 1.2572111994656797e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 3.9426510262430384e-05, 'tol': 8.200470119875247e-05, 'validation_fraction': 0.7541023753855344}]
function_evaluation time 0.420866 value 19.695128 suggestion {'alpha': 0.0425830270549409, 'batch_size': 80, 'beta_1': 0.6404464696889703, 'beta_2': 0.9999749750692368, 'epsilon': 1.2572111994656797e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 3.9426510262430384e-05, 'tol': 8.200470119875247e-05, 'validation_fraction': 0.7541023753855344}
observation time 0.000002, current best 0.255263 at iter 24
suggestion time taken 0.010539 iter 25 next_points [{'alpha': 9.371937275341038, 'batch_size': 163, 'beta_1': 0.985226178225969, 'beta_2': 0.9999985447531726, 'epsilon': 6.819059775780026e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.04911333675013638, 'tol': 7.051563639943768e-05, 'validation_fraction': 0.1558941194782417}]
function_evaluation time 0.767350 value 3.035070 suggestion {'alpha': 9.371937275341038, 'batch_size': 163, 'beta_1': 0.985226178225969, 'beta_2': 0.9999985447531726, 'epsilon': 6.819059775780026e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.04911333675013638, 'tol': 7.051563639943768e-05, 'validation_fraction': 0.1558941194782417}
observation time 0.000007, current best 0.255263 at iter 25
suggestion time taken 0.013609 iter 26 next_points [{'alpha': 0.6872331218616968, 'batch_size': 196, 'beta_1': 0.7598209277854103, 'beta_2': 0.9106988597395084, 'epsilon': 7.595241026166143e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.009471571887594465, 'tol': 4.473736622734945e-05, 'validation_fraction': 0.30961905557832303}]
function_evaluation time 0.658046 value 0.506098 suggestion {'alpha': 0.6872331218616968, 'batch_size': 196, 'beta_1': 0.7598209277854103, 'beta_2': 0.9106988597395084, 'epsilon': 7.595241026166143e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.009471571887594465, 'tol': 4.473736622734945e-05, 'validation_fraction': 0.30961905557832303}
observation time 0.000003, current best 0.255263 at iter 26
suggestion time taken 0.010334 iter 27 next_points [{'alpha': 0.17079765843706396, 'batch_size': 18, 'beta_1': 0.9603733459485745, 'beta_2': 0.9829873803839564, 'epsilon': 1.0364100870268678e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.00010530319167439187, 'tol': 9.700466354429944e-05, 'validation_fraction': 0.6965111113015283}]
function_evaluation time 2.230894 value 2.826968 suggestion {'alpha': 0.17079765843706396, 'batch_size': 18, 'beta_1': 0.9603733459485745, 'beta_2': 0.9829873803839564, 'epsilon': 1.0364100870268678e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.00010530319167439187, 'tol': 9.700466354429944e-05, 'validation_fraction': 0.6965111113015283}
observation time 0.000004, current best 0.255263 at iter 27
suggestion time taken 0.011176 iter 28 next_points [{'alpha': 3.786319685208339e-05, 'batch_size': 174, 'beta_1': 0.932048201523787, 'beta_2': 0.9843007151943698, 'epsilon': 1.7073469224358494e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.00018421148918549557, 'tol': 7.475646578421258e-05, 'validation_fraction': 0.3363516045442666}]
function_evaluation time 0.920549 value 7.128588 suggestion {'alpha': 3.786319685208339e-05, 'batch_size': 174, 'beta_1': 0.932048201523787, 'beta_2': 0.9843007151943698, 'epsilon': 1.7073469224358494e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.00018421148918549557, 'tol': 7.475646578421258e-05, 'validation_fraction': 0.3363516045442666}
observation time 0.000003, current best 0.255263 at iter 28
suggestion time taken 0.010084 iter 29 next_points [{'alpha': 0.5920653870942706, 'batch_size': 186, 'beta_1': 0.5245648352988105, 'beta_2': 0.999994220361516, 'epsilon': 1.4015553732431363e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.00016155819400973665, 'tol': 0.01817935341087925, 'validation_fraction': 0.20709048217308965}]
function_evaluation time 0.585358 value 18.217119 suggestion {'alpha': 0.5920653870942706, 'batch_size': 186, 'beta_1': 0.5245648352988105, 'beta_2': 0.999994220361516, 'epsilon': 1.4015553732431363e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.00016155819400973665, 'tol': 0.01817935341087925, 'validation_fraction': 0.20709048217308965}
observation time 0.000004, current best 0.255263 at iter 29
suggestion time taken 0.010588 iter 30 next_points [{'alpha': 1.1183286369794874, 'batch_size': 76, 'beta_1': 0.9705802081631516, 'beta_2': 0.9999926991832097, 'epsilon': 8.78440637869388e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.00012513674065537422, 'tol': 0.00016790606354164672, 'validation_fraction': 0.2913827417494261}]
function_evaluation time 0.391477 value 7.203253 suggestion {'alpha': 1.1183286369794874, 'batch_size': 76, 'beta_1': 0.9705802081631516, 'beta_2': 0.9999926991832097, 'epsilon': 8.78440637869388e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.00012513674065537422, 'tol': 0.00016790606354164672, 'validation_fraction': 0.2913827417494261}
observation time 0.000003, current best 0.255263 at iter 30
suggestion time taken 0.010102 iter 31 next_points [{'alpha': 0.0004761220374029106, 'batch_size': 85, 'beta_1': 0.9802066037108895, 'beta_2': 0.9784722645657249, 'epsilon': 4.66154701287211e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.017920118236964624, 'tol': 0.0005006479466606991, 'validation_fraction': 0.6233686382019129}]
function_evaluation time 0.710486 value 1.339699 suggestion {'alpha': 0.0004761220374029106, 'batch_size': 85, 'beta_1': 0.9802066037108895, 'beta_2': 0.9784722645657249, 'epsilon': 4.66154701287211e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.017920118236964624, 'tol': 0.0005006479466606991, 'validation_fraction': 0.6233686382019129}
observation time 0.000003, current best 0.255263 at iter 31
suggestion time taken 0.010760 iter 32 next_points [{'alpha': 6.148085533189933e-05, 'batch_size': 97, 'beta_1': 0.8337502536619019, 'beta_2': 0.9999613929949935, 'epsilon': 6.202558130210405e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.010619456405473487, 'tol': 0.045376197864596395, 'validation_fraction': 0.6177222567529266}]
function_evaluation time 0.421828 value 0.523581 suggestion {'alpha': 6.148085533189933e-05, 'batch_size': 97, 'beta_1': 0.8337502536619019, 'beta_2': 0.9999613929949935, 'epsilon': 6.202558130210405e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.010619456405473487, 'tol': 0.045376197864596395, 'validation_fraction': 0.6177222567529266}
observation time 0.000003, current best 0.255263 at iter 32
suggestion time taken 0.010043 iter 33 next_points [{'alpha': 5.1262123320239774e-05, 'batch_size': 65, 'beta_1': 0.5062768264244797, 'beta_2': 0.999919097090122, 'epsilon': 7.019540852785221e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.036433123229202544, 'tol': 0.008547292175968274, 'validation_fraction': 0.7876182102220225}]
function_evaluation time 0.648192 value 0.593003 suggestion {'alpha': 5.1262123320239774e-05, 'batch_size': 65, 'beta_1': 0.5062768264244797, 'beta_2': 0.999919097090122, 'epsilon': 7.019540852785221e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 0.036433123229202544, 'tol': 0.008547292175968274, 'validation_fraction': 0.7876182102220225}
observation time 0.000004, current best 0.255263 at iter 33
suggestion time taken 0.010731 iter 34 next_points [{'alpha': 6.713930266726074e-05, 'batch_size': 83, 'beta_1': 0.6958953560522143, 'beta_2': 0.9998449573172176, 'epsilon': 1.3836530259594752e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.002841845940688585, 'tol': 6.046370567035208e-05, 'validation_fraction': 0.7306189199586676}]
function_evaluation time 0.727173 value 0.453996 suggestion {'alpha': 6.713930266726074e-05, 'batch_size': 83, 'beta_1': 0.6958953560522143, 'beta_2': 0.9998449573172176, 'epsilon': 1.3836530259594752e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.002841845940688585, 'tol': 6.046370567035208e-05, 'validation_fraction': 0.7306189199586676}
observation time 0.000008, current best 0.255263 at iter 34
suggestion time taken 0.013675 iter 35 next_points [{'alpha': 0.00022848157253726973, 'batch_size': 120, 'beta_1': 0.9640112683130103, 'beta_2': 0.9963637688598026, 'epsilon': 4.760731864400016e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.012803333691361348, 'tol': 5.650889835581289e-05, 'validation_fraction': 0.7996336361138728}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.614450 value 0.910563 suggestion {'alpha': 0.00022848157253726973, 'batch_size': 120, 'beta_1': 0.9640112683130103, 'beta_2': 0.9963637688598026, 'epsilon': 4.760731864400016e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.012803333691361348, 'tol': 5.650889835581289e-05, 'validation_fraction': 0.7996336361138728}
observation time 0.000004, current best 0.255263 at iter 35
suggestion time taken 0.010329 iter 36 next_points [{'alpha': 5.23344231577941e-05, 'batch_size': 134, 'beta_1': 0.9790790639954527, 'beta_2': 0.9999340764624293, 'epsilon': 3.500758564486994e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.004570930126803933, 'tol': 0.0249966728617119, 'validation_fraction': 0.8374237687094476}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.584079 value 1.922422 suggestion {'alpha': 5.23344231577941e-05, 'batch_size': 134, 'beta_1': 0.9790790639954527, 'beta_2': 0.9999340764624293, 'epsilon': 3.500758564486994e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.004570930126803933, 'tol': 0.0249966728617119, 'validation_fraction': 0.8374237687094476}
observation time 0.000005, current best 0.255263 at iter 36
suggestion time taken 0.010638 iter 37 next_points [{'alpha': 0.45119793577747264, 'batch_size': 132, 'beta_1': 0.989552682632743, 'beta_2': 0.9999983080935357, 'epsilon': 2.682190079388402e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.06959391868334097, 'tol': 0.01047833853794258, 'validation_fraction': 0.7918979635272007}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.416245 value 7.747196 suggestion {'alpha': 0.45119793577747264, 'batch_size': 132, 'beta_1': 0.989552682632743, 'beta_2': 0.9999983080935357, 'epsilon': 2.682190079388402e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.06959391868334097, 'tol': 0.01047833853794258, 'validation_fraction': 0.7918979635272007}
observation time 0.000003, current best 0.255263 at iter 37
suggestion time taken 0.010164 iter 38 next_points [{'alpha': 0.0005938244371351954, 'batch_size': 70, 'beta_1': 0.9048057280996892, 'beta_2': 0.9760521609506778, 'epsilon': 1.9167334156314874e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.00027580976990805746, 'tol': 0.00017318644329618167, 'validation_fraction': 0.22275641172643745}]
function_evaluation time 1.548888 value 0.394483 suggestion {'alpha': 0.0005938244371351954, 'batch_size': 70, 'beta_1': 0.9048057280996892, 'beta_2': 0.9760521609506778, 'epsilon': 1.9167334156314874e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.00027580976990805746, 'tol': 0.00017318644329618167, 'validation_fraction': 0.22275641172643745}
observation time 0.000007, current best 0.255263 at iter 38
suggestion time taken 0.013601 iter 39 next_points [{'alpha': 4.839952815927868, 'batch_size': 243, 'beta_1': 0.6795068440379969, 'beta_2': 0.9999984581262744, 'epsilon': 1.2240912315884593e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.003422330658818421, 'tol': 2.415559840176414e-05, 'validation_fraction': 0.272160458041935}]
function_evaluation time 0.754841 value 0.426374 suggestion {'alpha': 4.839952815927868, 'batch_size': 243, 'beta_1': 0.6795068440379969, 'beta_2': 0.9999984581262744, 'epsilon': 1.2240912315884593e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.003422330658818421, 'tol': 2.415559840176414e-05, 'validation_fraction': 0.272160458041935}
observation time 0.000004, current best 0.255263 at iter 39
suggestion time taken 0.010701 iter 40 next_points [{'alpha': 0.005817851934942269, 'batch_size': 246, 'beta_1': 0.9508997182227925, 'beta_2': 0.999998104651365, 'epsilon': 4.853170779023843e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.00031142632331476044, 'tol': 0.03479157133733679, 'validation_fraction': 0.1966479066033479}]
function_evaluation time 0.539858 value 13.901009 suggestion {'alpha': 0.005817851934942269, 'batch_size': 246, 'beta_1': 0.9508997182227925, 'beta_2': 0.999998104651365, 'epsilon': 4.853170779023843e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.00031142632331476044, 'tol': 0.03479157133733679, 'validation_fraction': 0.1966479066033479}
observation time 0.000004, current best 0.255263 at iter 40
suggestion time taken 0.010744 iter 41 next_points [{'alpha': 9.374216780548839, 'batch_size': 13, 'beta_1': 0.5118021418696759, 'beta_2': 0.9987074393595332, 'epsilon': 4.975179401094175e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.09283030914703252, 'tol': 4.35838444435674e-05, 'validation_fraction': 0.3292009991182212}]
function_evaluation time 2.188004 value 0.303970 suggestion {'alpha': 9.374216780548839, 'batch_size': 13, 'beta_1': 0.5118021418696759, 'beta_2': 0.9987074393595332, 'epsilon': 4.975179401094175e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.09283030914703252, 'tol': 4.35838444435674e-05, 'validation_fraction': 0.3292009991182212}
observation time 0.000004, current best 0.255263 at iter 41
suggestion time taken 0.011013 iter 42 next_points [{'alpha': 0.001702565595855039, 'batch_size': 48, 'beta_1': 0.8985213350381311, 'beta_2': 0.999429115380976, 'epsilon': 3.85562982148582e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.004558784302163617, 'tol': 0.0006234785902644482, 'validation_fraction': 0.20387236261725203}]
function_evaluation time 1.237046 value 0.579459 suggestion {'alpha': 0.001702565595855039, 'batch_size': 48, 'beta_1': 0.8985213350381311, 'beta_2': 0.999429115380976, 'epsilon': 3.85562982148582e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.004558784302163617, 'tol': 0.0006234785902644482, 'validation_fraction': 0.20387236261725203}
observation time 0.000004, current best 0.255263 at iter 42
suggestion time taken 0.011016 iter 43 next_points [{'alpha': 2.0752083129753824e-05, 'batch_size': 14, 'beta_1': 0.9627828330187073, 'beta_2': 0.985389866972082, 'epsilon': 1.3333498432879878e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.008855895032473755, 'tol': 0.0015879736247916985, 'validation_fraction': 0.6775885454701357}]
function_evaluation time 1.292517 value 0.840075 suggestion {'alpha': 2.0752083129753824e-05, 'batch_size': 14, 'beta_1': 0.9627828330187073, 'beta_2': 0.985389866972082, 'epsilon': 1.3333498432879878e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.008855895032473755, 'tol': 0.0015879736247916985, 'validation_fraction': 0.6775885454701357}
observation time 0.000003, current best 0.255263 at iter 43
suggestion time taken 0.012367 iter 44 next_points [{'alpha': 0.038758076672345584, 'batch_size': 151, 'beta_1': 0.871054114011848, 'beta_2': 0.9381437978092254, 'epsilon': 3.7167683188321306e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 1.5468303114753903e-05, 'tol': 0.09852206382548334, 'validation_fraction': 0.1904305260300482}]
function_evaluation time 0.481523 value 17.014592 suggestion {'alpha': 0.038758076672345584, 'batch_size': 151, 'beta_1': 0.871054114011848, 'beta_2': 0.9381437978092254, 'epsilon': 3.7167683188321306e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 1.5468303114753903e-05, 'tol': 0.09852206382548334, 'validation_fraction': 0.1904305260300482}
observation time 0.000004, current best 0.255263 at iter 44
saving meta data: {'args': {'--uuid': '1645cd443b9a5c9b9928e1289a562f13', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])}
saving results
saving timing
saving suggest log
done
