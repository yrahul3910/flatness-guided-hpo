running: {'--uuid': '4816898b5a11581eb213fe7a86330cb4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d breast -o strongcvx -u 4816898b5a11581eb213fe7a86330cb4 -m nll -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam breast nll 45 1
with data root: None
suggestion time taken 14.624607 iter 0 next_points [{'alpha': 0.0001652629416185648, 'batch_size': 50, 'beta_1': 0.8846775776888103, 'beta_2': 0.9965291758231363, 'epsilon': 4.488648601778874e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 1.0087295887977345e-05, 'tol': 0.008188569399990792, 'validation_fraction': 0.3162382737855932}]
function_evaluation time 0.610737 value 16.054837 suggestion {'alpha': 0.0001652629416185648, 'batch_size': 50, 'beta_1': 0.8846775776888103, 'beta_2': 0.9965291758231363, 'epsilon': 4.488648601778874e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 1.0087295887977345e-05, 'tol': 0.008188569399990792, 'validation_fraction': 0.3162382737855932}
observation time 0.000004, current best 16.054837 at iter 0
suggestion time taken 14.571926 iter 1 next_points [{'alpha': 0.018988811854703358, 'batch_size': 28, 'beta_1': 0.7878632488453529, 'beta_2': 0.9995675893561164, 'epsilon': 1.5251604099061186e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.0010781168066849335, 'tol': 0.012464472963255013, 'validation_fraction': 0.6391980690063112}]
function_evaluation time 0.858651 value 0.279244 suggestion {'alpha': 0.018988811854703358, 'batch_size': 28, 'beta_1': 0.7878632488453529, 'beta_2': 0.9995675893561164, 'epsilon': 1.5251604099061186e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.0010781168066849335, 'tol': 0.012464472963255013, 'validation_fraction': 0.6391980690063112}
observation time 0.000005, current best 0.279244 at iter 1
suggestion time taken 14.130032 iter 2 next_points [{'alpha': 0.19670275109019794, 'batch_size': 226, 'beta_1': 0.8226653998845985, 'beta_2': 0.9990866241098868, 'epsilon': 1.560943248330251e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.001221230020152463, 'tol': 2.876867668062497e-05, 'validation_fraction': 0.7802833496428608}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.483666 value 5.265583 suggestion {'alpha': 0.19670275109019794, 'batch_size': 226, 'beta_1': 0.8226653998845985, 'beta_2': 0.9990866241098868, 'epsilon': 1.560943248330251e-09, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.001221230020152463, 'tol': 2.876867668062497e-05, 'validation_fraction': 0.7802833496428608}
observation time 0.000004, current best 0.279244 at iter 2
suggestion time taken 14.682362 iter 3 next_points [{'alpha': 0.007121971595214041, 'batch_size': 150, 'beta_1': 0.6013854228651526, 'beta_2': 0.9998472391387025, 'epsilon': 4.3468782177668556e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0017883119994285032, 'tol': 0.0038717684592177825, 'validation_fraction': 0.8275795687796027}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.357361 value 4.666948 suggestion {'alpha': 0.007121971595214041, 'batch_size': 150, 'beta_1': 0.6013854228651526, 'beta_2': 0.9998472391387025, 'epsilon': 4.3468782177668556e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0017883119994285032, 'tol': 0.0038717684592177825, 'validation_fraction': 0.8275795687796027}
observation time 0.000004, current best 0.279244 at iter 3
suggestion time taken 14.297607 iter 4 next_points [{'alpha': 0.0005613205722567283, 'batch_size': 227, 'beta_1': 0.950948755751659, 'beta_2': 0.9996886330061968, 'epsilon': 1.5089931730555913e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 5.925747634868117e-05, 'tol': 0.050928844382660717, 'validation_fraction': 0.6734279458247703}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.239819 value 14.094008 suggestion {'alpha': 0.0005613205722567283, 'batch_size': 227, 'beta_1': 0.950948755751659, 'beta_2': 0.9996886330061968, 'epsilon': 1.5089931730555913e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 5.925747634868117e-05, 'tol': 0.050928844382660717, 'validation_fraction': 0.6734279458247703}
observation time 0.000005, current best 0.279244 at iter 4
suggestion time taken 14.957339 iter 5 next_points [{'alpha': 0.0024511415428236506, 'batch_size': 32, 'beta_1': 0.9842716823858304, 'beta_2': 0.9918391498845884, 'epsilon': 1.4187801730033875e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.003875406705887585, 'tol': 0.000347848374959129, 'validation_fraction': 0.4186410027874459}]
function_evaluation time 1.003195 value 0.919092 suggestion {'alpha': 0.0024511415428236506, 'batch_size': 32, 'beta_1': 0.9842716823858304, 'beta_2': 0.9918391498845884, 'epsilon': 1.4187801730033875e-07, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.003875406705887585, 'tol': 0.000347848374959129, 'validation_fraction': 0.4186410027874459}
observation time 0.000004, current best 0.279244 at iter 5
suggestion time taken 14.845830 iter 6 next_points [{'alpha': 0.13107247340714628, 'batch_size': 15, 'beta_1': 0.9205772786904455, 'beta_2': 0.9999556452427554, 'epsilon': 1.0688398615645455e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 3.912853134545756e-05, 'tol': 0.02641307046468974, 'validation_fraction': 0.7443323689234687}]
function_evaluation time 0.536430 value 11.978422 suggestion {'alpha': 0.13107247340714628, 'batch_size': 15, 'beta_1': 0.9205772786904455, 'beta_2': 0.9999556452427554, 'epsilon': 1.0688398615645455e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 3.912853134545756e-05, 'tol': 0.02641307046468974, 'validation_fraction': 0.7443323689234687}
observation time 0.000005, current best 0.279244 at iter 6
suggestion time taken 14.524461 iter 7 next_points [{'alpha': 0.008969156033592173, 'batch_size': 12, 'beta_1': 0.5615926227599047, 'beta_2': 0.9937146244645577, 'epsilon': 9.631533739669863e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.0017403792585595763, 'tol': 0.0008579609738877425, 'validation_fraction': 0.7924467709116982}]
function_evaluation time 1.285161 value 0.517257 suggestion {'alpha': 0.008969156033592173, 'batch_size': 12, 'beta_1': 0.5615926227599047, 'beta_2': 0.9937146244645577, 'epsilon': 9.631533739669863e-09, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.0017403792585595763, 'tol': 0.0008579609738877425, 'validation_fraction': 0.7924467709116982}
observation time 0.000005, current best 0.279244 at iter 7
suggestion time taken 14.876555 iter 8 next_points [{'alpha': 0.261383155202198, 'batch_size': 11, 'beta_1': 0.7309702404471059, 'beta_2': 0.9884273287103835, 'epsilon': 2.722786760323226e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.018453920404964276, 'tol': 0.00010180586920005506, 'validation_fraction': 0.8489313542339921}]
function_evaluation time 0.924945 value 1.022924 suggestion {'alpha': 0.261383155202198, 'batch_size': 11, 'beta_1': 0.7309702404471059, 'beta_2': 0.9884273287103835, 'epsilon': 2.722786760323226e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.018453920404964276, 'tol': 0.00010180586920005506, 'validation_fraction': 0.8489313542339921}
observation time 0.000005, current best 0.279244 at iter 8
suggestion time taken 14.365672 iter 9 next_points [{'alpha': 1.101350822646087, 'batch_size': 11, 'beta_1': 0.6717948349808862, 'beta_2': 0.9986797939016167, 'epsilon': 1.3746451303270954e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0021323781688433584, 'tol': 0.08564034779774446, 'validation_fraction': 0.8719725155344121}]
function_evaluation time 0.513998 value 0.395651 suggestion {'alpha': 1.101350822646087, 'batch_size': 11, 'beta_1': 0.6717948349808862, 'beta_2': 0.9986797939016167, 'epsilon': 1.3746451303270954e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0021323781688433584, 'tol': 0.08564034779774446, 'validation_fraction': 0.8719725155344121}
observation time 0.000004, current best 0.279244 at iter 9
suggestion time taken 15.038883 iter 10 next_points [{'alpha': 0.034815195999691455, 'batch_size': 151, 'beta_1': 0.9889723154963875, 'beta_2': 0.9892268316609156, 'epsilon': 4.441062671490776e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.004172781671195552, 'tol': 0.00015051810831590205, 'validation_fraction': 0.8655603755399017}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.534778 value 0.574046 suggestion {'alpha': 0.034815195999691455, 'batch_size': 151, 'beta_1': 0.9889723154963875, 'beta_2': 0.9892268316609156, 'epsilon': 4.441062671490776e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.004172781671195552, 'tol': 0.00015051810831590205, 'validation_fraction': 0.8655603755399017}
observation time 0.000005, current best 0.279244 at iter 10
suggestion time taken 14.760333 iter 11 next_points [{'alpha': 0.08838207919243717, 'batch_size': 151, 'beta_1': 0.9785848093994185, 'beta_2': 0.9950596984926862, 'epsilon': 2.1185680394430582e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.0004884629860782553, 'tol': 0.0007219625851513182, 'validation_fraction': 0.8986014114740954}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.240325 value 7.637236 suggestion {'alpha': 0.08838207919243717, 'batch_size': 151, 'beta_1': 0.9785848093994185, 'beta_2': 0.9950596984926862, 'epsilon': 2.1185680394430582e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.0004884629860782553, 'tol': 0.0007219625851513182, 'validation_fraction': 0.8986014114740954}
observation time 0.000004, current best 0.279244 at iter 11
suggestion time taken 15.388774 iter 12 next_points [{'alpha': 0.0196391120280473, 'batch_size': 56, 'beta_1': 0.9768674714898168, 'beta_2': 0.9088921119313625, 'epsilon': 2.3466158478269385e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0011631411550396785, 'tol': 0.0008221698602499617, 'validation_fraction': 0.6319565930995855}]
function_evaluation time 0.876978 value 2.931171 suggestion {'alpha': 0.0196391120280473, 'batch_size': 56, 'beta_1': 0.9768674714898168, 'beta_2': 0.9088921119313625, 'epsilon': 2.3466158478269385e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.0011631411550396785, 'tol': 0.0008221698602499617, 'validation_fraction': 0.6319565930995855}
observation time 0.000004, current best 0.279244 at iter 12
suggestion time taken 16.998326 iter 13 next_points [{'alpha': 0.0019468287608899462, 'batch_size': 151, 'beta_1': 0.5547850858274133, 'beta_2': 0.9959967925379473, 'epsilon': 1.0660718382702312e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0397975323030885, 'tol': 0.02396428532200525, 'validation_fraction': 0.10173727963036404}]
function_evaluation time 0.709937 value 0.887041 suggestion {'alpha': 0.0019468287608899462, 'batch_size': 151, 'beta_1': 0.5547850858274133, 'beta_2': 0.9959967925379473, 'epsilon': 1.0660718382702312e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0397975323030885, 'tol': 0.02396428532200525, 'validation_fraction': 0.10173727963036404}
observation time 0.000006, current best 0.279244 at iter 13
suggestion time taken 19.768678 iter 14 next_points [{'alpha': 8.130387095032459, 'batch_size': 111, 'beta_1': 0.8279265870586445, 'beta_2': 0.9324031381493746, 'epsilon': 6.45213149890761e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0020440479823583477, 'tol': 0.02262592839575265, 'validation_fraction': 0.12978010505345275}]
function_evaluation time 0.294867 value 0.747377 suggestion {'alpha': 8.130387095032459, 'batch_size': 111, 'beta_1': 0.8279265870586445, 'beta_2': 0.9324031381493746, 'epsilon': 6.45213149890761e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0020440479823583477, 'tol': 0.02262592839575265, 'validation_fraction': 0.12978010505345275}
observation time 0.000003, current best 0.279244 at iter 14
suggestion time taken 20.852596 iter 15 next_points [{'alpha': 0.00027891588060703035, 'batch_size': 227, 'beta_1': 0.9645051979752346, 'beta_2': 0.9855321985201447, 'epsilon': 1.7504484534581625e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 4.5283493345863355e-05, 'tol': 0.012379114826861047, 'validation_fraction': 0.3082815920579028}]
function_evaluation time 0.412620 value 14.396870 suggestion {'alpha': 0.00027891588060703035, 'batch_size': 227, 'beta_1': 0.9645051979752346, 'beta_2': 0.9855321985201447, 'epsilon': 1.7504484534581625e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 4.5283493345863355e-05, 'tol': 0.012379114826861047, 'validation_fraction': 0.3082815920579028}
observation time 0.000006, current best 0.279244 at iter 15
suggestion time taken 19.800923 iter 16 next_points [{'alpha': 0.004326960130711179, 'batch_size': 90, 'beta_1': 0.7497185043771724, 'beta_2': 0.94389331814254, 'epsilon': 1.4499723783380303e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0008077824024556085, 'tol': 0.00740904015511255, 'validation_fraction': 0.1571398728342735}]
function_evaluation time 0.387647 value 0.342383 suggestion {'alpha': 0.004326960130711179, 'batch_size': 90, 'beta_1': 0.7497185043771724, 'beta_2': 0.94389331814254, 'epsilon': 1.4499723783380303e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.0008077824024556085, 'tol': 0.00740904015511255, 'validation_fraction': 0.1571398728342735}
observation time 0.000005, current best 0.279244 at iter 16
suggestion time taken 20.862088 iter 17 next_points [{'alpha': 6.497409011236877, 'batch_size': 227, 'beta_1': 0.9468723866896586, 'beta_2': 0.9999881215376112, 'epsilon': 3.777618990744196e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0028605610460598787, 'tol': 0.0018509961711698142, 'validation_fraction': 0.7473812143708228}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.484942 value 5.663611 suggestion {'alpha': 6.497409011236877, 'batch_size': 227, 'beta_1': 0.9468723866896586, 'beta_2': 0.9999881215376112, 'epsilon': 3.777618990744196e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.0028605610460598787, 'tol': 0.0018509961711698142, 'validation_fraction': 0.7473812143708228}
observation time 0.000006, current best 0.279244 at iter 17
suggestion time taken 20.667819 iter 18 next_points [{'alpha': 0.0006738812900805891, 'batch_size': 45, 'beta_1': 0.9301075828135265, 'beta_2': 0.9998754892214552, 'epsilon': 2.198970488588429e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0008182174789435329, 'tol': 1.8099077014615894e-05, 'validation_fraction': 0.1719414469177459}]
function_evaluation time 0.599109 value 2.789214 suggestion {'alpha': 0.0006738812900805891, 'batch_size': 45, 'beta_1': 0.9301075828135265, 'beta_2': 0.9998754892214552, 'epsilon': 2.198970488588429e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0008182174789435329, 'tol': 1.8099077014615894e-05, 'validation_fraction': 0.1719414469177459}
observation time 0.000004, current best 0.279244 at iter 18
suggestion time taken 20.430555 iter 19 next_points [{'alpha': 4.986515795535592e-05, 'batch_size': 41, 'beta_1': 0.9890142081808173, 'beta_2': 0.9937802998541083, 'epsilon': 6.591997682472497e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 3.3174429796618195e-05, 'tol': 9.098969562623021e-05, 'validation_fraction': 0.6585222906852735}]
function_evaluation time 0.561611 value 12.525341 suggestion {'alpha': 4.986515795535592e-05, 'batch_size': 41, 'beta_1': 0.9890142081808173, 'beta_2': 0.9937802998541083, 'epsilon': 6.591997682472497e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 3.3174429796618195e-05, 'tol': 9.098969562623021e-05, 'validation_fraction': 0.6585222906852735}
observation time 0.000005, current best 0.279244 at iter 19
suggestion time taken 19.370318 iter 20 next_points [{'alpha': 3.1828569163787055, 'batch_size': 17, 'beta_1': 0.8116719717068925, 'beta_2': 0.9998929783177757, 'epsilon': 1.861612673065187e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.031192865012728412, 'tol': 3.9255705563728376e-05, 'validation_fraction': 0.7216147975732999}]
function_evaluation time 0.896652 value 0.811176 suggestion {'alpha': 3.1828569163787055, 'batch_size': 17, 'beta_1': 0.8116719717068925, 'beta_2': 0.9998929783177757, 'epsilon': 1.861612673065187e-08, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.031192865012728412, 'tol': 3.9255705563728376e-05, 'validation_fraction': 0.7216147975732999}
observation time 0.000005, current best 0.279244 at iter 20
suggestion time taken 20.850278 iter 21 next_points [{'alpha': 0.4904782260371843, 'batch_size': 28, 'beta_1': 0.6531137226812818, 'beta_2': 0.9681872747765926, 'epsilon': 4.6261164810594824e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.006817350292303138, 'tol': 0.008698253082112925, 'validation_fraction': 0.6707028080918455}]
function_evaluation time 0.880004 value 0.800983 suggestion {'alpha': 0.4904782260371843, 'batch_size': 28, 'beta_1': 0.6531137226812818, 'beta_2': 0.9681872747765926, 'epsilon': 4.6261164810594824e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.006817350292303138, 'tol': 0.008698253082112925, 'validation_fraction': 0.6707028080918455}
observation time 0.000010, current best 0.279244 at iter 21
suggestion time taken 19.682868 iter 22 next_points [{'alpha': 4.061277231094695, 'batch_size': 25, 'beta_1': 0.9883510501334896, 'beta_2': 0.9983571816844367, 'epsilon': 3.824452571112729e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.005148297125715168, 'tol': 0.05906546064247148, 'validation_fraction': 0.1314941833552303}]
function_evaluation time 0.542499 value 1.347901 suggestion {'alpha': 4.061277231094695, 'batch_size': 25, 'beta_1': 0.9883510501334896, 'beta_2': 0.9983571816844367, 'epsilon': 3.824452571112729e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.005148297125715168, 'tol': 0.05906546064247148, 'validation_fraction': 0.1314941833552303}
observation time 0.000014, current best 0.279244 at iter 22
suggestion time taken 21.288746 iter 23 next_points [{'alpha': 5.573553887774714, 'batch_size': 113, 'beta_1': 0.9873783971042172, 'beta_2': 0.9950311746737425, 'epsilon': 1.796208258572523e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.06067011195471829, 'tol': 0.0006069775356286017, 'validation_fraction': 0.5064521577780212}]
function_evaluation time 0.754858 value 2.917098 suggestion {'alpha': 5.573553887774714, 'batch_size': 113, 'beta_1': 0.9873783971042172, 'beta_2': 0.9950311746737425, 'epsilon': 1.796208258572523e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.06067011195471829, 'tol': 0.0006069775356286017, 'validation_fraction': 0.5064521577780212}
observation time 0.000005, current best 0.279244 at iter 23
suggestion time taken 19.838974 iter 24 next_points [{'alpha': 0.0723423558712311, 'batch_size': 75, 'beta_1': 0.9733427096827121, 'beta_2': 0.9979981831590291, 'epsilon': 1.79517220697875e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0003378101466327251, 'tol': 0.0010112799329087207, 'validation_fraction': 0.710615494859293}]
function_evaluation time 0.560090 value 9.245301 suggestion {'alpha': 0.0723423558712311, 'batch_size': 75, 'beta_1': 0.9733427096827121, 'beta_2': 0.9979981831590291, 'epsilon': 1.79517220697875e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0003378101466327251, 'tol': 0.0010112799329087207, 'validation_fraction': 0.710615494859293}
observation time 0.000012, current best 0.279244 at iter 24
suggestion time taken 21.289469 iter 25 next_points [{'alpha': 0.4251489390258536, 'batch_size': 151, 'beta_1': 0.9748927416769463, 'beta_2': 0.9999974958897593, 'epsilon': 3.472396795526332e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0006665316844517993, 'tol': 0.0010715978426215494, 'validation_fraction': 0.1991951236219056}]
function_evaluation time 0.849479 value 5.297211 suggestion {'alpha': 0.4251489390258536, 'batch_size': 151, 'beta_1': 0.9748927416769463, 'beta_2': 0.9999974958897593, 'epsilon': 3.472396795526332e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0006665316844517993, 'tol': 0.0010715978426215494, 'validation_fraction': 0.1991951236219056}
observation time 0.000006, current best 0.279244 at iter 25
suggestion time taken 19.658918 iter 26 next_points [{'alpha': 0.24850172554107272, 'batch_size': 151, 'beta_1': 0.8990118982259953, 'beta_2': 0.9998057359197094, 'epsilon': 4.15776772159864e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.00046308552141640307, 'tol': 0.005090899359272415, 'validation_fraction': 0.550868357053772}]
function_evaluation time 0.999562 value 2.917836 suggestion {'alpha': 0.24850172554107272, 'batch_size': 151, 'beta_1': 0.8990118982259953, 'beta_2': 0.9998057359197094, 'epsilon': 4.15776772159864e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.00046308552141640307, 'tol': 0.005090899359272415, 'validation_fraction': 0.550868357053772}
observation time 0.000015, current best 0.279244 at iter 26
suggestion time taken 20.997043 iter 27 next_points [{'alpha': 0.04779558416883753, 'batch_size': 113, 'beta_1': 0.9274804333010537, 'beta_2': 0.9999975535743288, 'epsilon': 3.7235664544407608e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.09099634721538785, 'tol': 0.025398136419899908, 'validation_fraction': 0.18982367511129747}]
function_evaluation time 0.761547 value 5.284936 suggestion {'alpha': 0.04779558416883753, 'batch_size': 113, 'beta_1': 0.9274804333010537, 'beta_2': 0.9999975535743288, 'epsilon': 3.7235664544407608e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.09099634721538785, 'tol': 0.025398136419899908, 'validation_fraction': 0.18982367511129747}
observation time 0.000006, current best 0.279244 at iter 27
suggestion time taken 19.735931 iter 28 next_points [{'alpha': 0.1764498789459328, 'batch_size': 14, 'beta_1': 0.9329131208074447, 'beta_2': 0.9999965433836062, 'epsilon': 3.204606506575804e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.00011971427398176783, 'tol': 0.00016397221292423634, 'validation_fraction': 0.2772085318127139}]
function_evaluation time 3.335807 value 2.787398 suggestion {'alpha': 0.1764498789459328, 'batch_size': 14, 'beta_1': 0.9329131208074447, 'beta_2': 0.9999965433836062, 'epsilon': 3.204606506575804e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.00011971427398176783, 'tol': 0.00016397221292423634, 'validation_fraction': 0.2772085318127139}
observation time 0.000005, current best 0.279244 at iter 28
suggestion time taken 21.635693 iter 29 next_points [{'alpha': 0.5816513221261941, 'batch_size': 11, 'beta_1': 0.8586793929287264, 'beta_2': 0.9991759293991122, 'epsilon': 4.424719147086945e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.00013584679932609459, 'tol': 0.0003380113752337456, 'validation_fraction': 0.15006159447696035}]
function_evaluation time 4.402039 value 0.328019 suggestion {'alpha': 0.5816513221261941, 'batch_size': 11, 'beta_1': 0.8586793929287264, 'beta_2': 0.9991759293991122, 'epsilon': 4.424719147086945e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.00013584679932609459, 'tol': 0.0003380113752337456, 'validation_fraction': 0.15006159447696035}
observation time 0.000005, current best 0.279244 at iter 29
suggestion time taken 20.366557 iter 30 next_points [{'alpha': 0.0003310198955371106, 'batch_size': 32, 'beta_1': 0.87838225469449, 'beta_2': 0.9995604576175701, 'epsilon': 1.4783519479429776e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 1.2015066216581932e-05, 'tol': 0.0002123557774077091, 'validation_fraction': 0.2608143378481284}]
function_evaluation time 1.002237 value 17.629137 suggestion {'alpha': 0.0003310198955371106, 'batch_size': 32, 'beta_1': 0.87838225469449, 'beta_2': 0.9995604576175701, 'epsilon': 1.4783519479429776e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 1.2015066216581932e-05, 'tol': 0.0002123557774077091, 'validation_fraction': 0.2608143378481284}
observation time 0.000015, current best 0.279244 at iter 30
suggestion time taken 21.098020 iter 31 next_points [{'alpha': 2.4149817743317158e-05, 'batch_size': 227, 'beta_1': 0.9161761344707287, 'beta_2': 0.99959484928708, 'epsilon': 7.629139594168461e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0004456898845961362, 'tol': 0.021659828131667558, 'validation_fraction': 0.2941182992553752}]
function_evaluation time 0.414277 value 8.951651 suggestion {'alpha': 2.4149817743317158e-05, 'batch_size': 227, 'beta_1': 0.9161761344707287, 'beta_2': 0.99959484928708, 'epsilon': 7.629139594168461e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0004456898845961362, 'tol': 0.021659828131667558, 'validation_fraction': 0.2941182992553752}
observation time 0.000005, current best 0.279244 at iter 31
suggestion time taken 19.515387 iter 32 next_points [{'alpha': 2.27636862525733, 'batch_size': 151, 'beta_1': 0.5151629637288132, 'beta_2': 0.9997745352992738, 'epsilon': 6.482701000921043e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0003097934405537394, 'tol': 0.00011820807657592067, 'validation_fraction': 0.11009668462171406}]
function_evaluation time 0.828231 value 2.931167 suggestion {'alpha': 2.27636862525733, 'batch_size': 151, 'beta_1': 0.5151629637288132, 'beta_2': 0.9997745352992738, 'epsilon': 6.482701000921043e-07, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0003097934405537394, 'tol': 0.00011820807657592067, 'validation_fraction': 0.11009668462171406}
observation time 0.000009, current best 0.279244 at iter 32
suggestion time taken 21.554506 iter 33 next_points [{'alpha': 8.105112182573606, 'batch_size': 224, 'beta_1': 0.9749844885093533, 'beta_2': 0.9999718557348904, 'epsilon': 1.3937563656649007e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 1.1148483252738192e-05, 'tol': 0.0002339514006291373, 'validation_fraction': 0.5212917491454998}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.336423 value 13.707390 suggestion {'alpha': 8.105112182573606, 'batch_size': 224, 'beta_1': 0.9749844885093533, 'beta_2': 0.9999718557348904, 'epsilon': 1.3937563656649007e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 1.1148483252738192e-05, 'tol': 0.0002339514006291373, 'validation_fraction': 0.5212917491454998}
observation time 0.000006, current best 0.279244 at iter 33
suggestion time taken 20.062069 iter 34 next_points [{'alpha': 0.1536609464888216, 'batch_size': 25, 'beta_1': 0.968473925394364, 'beta_2': 0.9471344159106126, 'epsilon': 4.0891921685285884e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 2.4117633577194025e-05, 'tol': 0.00048418644662590846, 'validation_fraction': 0.25840189651251827}]
function_evaluation time 3.798024 value 4.680313 suggestion {'alpha': 0.1536609464888216, 'batch_size': 25, 'beta_1': 0.968473925394364, 'beta_2': 0.9471344159106126, 'epsilon': 4.0891921685285884e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 2.4117633577194025e-05, 'tol': 0.00048418644662590846, 'validation_fraction': 0.25840189651251827}
observation time 0.000013, current best 0.279244 at iter 34
suggestion time taken 21.492012 iter 35 next_points [{'alpha': 0.26725677385442503, 'batch_size': 151, 'beta_1': 0.8735127925301946, 'beta_2': 0.96495156143891, 'epsilon': 5.575608927366935e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0004208097585501277, 'tol': 0.0074392844050413034, 'validation_fraction': 0.7494557436722195}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.427516 value 4.967520 suggestion {'alpha': 0.26725677385442503, 'batch_size': 151, 'beta_1': 0.8735127925301946, 'beta_2': 0.96495156143891, 'epsilon': 5.575608927366935e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0004208097585501277, 'tol': 0.0074392844050413034, 'validation_fraction': 0.7494557436722195}
observation time 0.000005, current best 0.279244 at iter 35
suggestion time taken 20.370593 iter 36 next_points [{'alpha': 0.033821563613900416, 'batch_size': 15, 'beta_1': 0.8404063113146667, 'beta_2': 0.9984366454431592, 'epsilon': 1.1045256099001028e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.014439476955584991, 'tol': 5.378836861926474e-05, 'validation_fraction': 0.7387038320990391}]
function_evaluation time 1.281731 value 0.955657 suggestion {'alpha': 0.033821563613900416, 'batch_size': 15, 'beta_1': 0.8404063113146667, 'beta_2': 0.9984366454431592, 'epsilon': 1.1045256099001028e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.014439476955584991, 'tol': 5.378836861926474e-05, 'validation_fraction': 0.7387038320990391}
observation time 0.000005, current best 0.279244 at iter 36
suggestion time taken 19.788464 iter 37 next_points [{'alpha': 0.0031141149044032882, 'batch_size': 223, 'beta_1': 0.9120019384941335, 'beta_2': 0.9990880197034683, 'epsilon': 5.724619536858925e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.03393793127250701, 'tol': 0.00014240272775937088, 'validation_fraction': 0.43055293850746884}]
function_evaluation time 0.413198 value 3.264435 suggestion {'alpha': 0.0031141149044032882, 'batch_size': 223, 'beta_1': 0.9120019384941335, 'beta_2': 0.9990880197034683, 'epsilon': 5.724619536858925e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.03393793127250701, 'tol': 0.00014240272775937088, 'validation_fraction': 0.43055293850746884}
observation time 0.000005, current best 0.279244 at iter 37
suggestion time taken 21.804358 iter 38 next_points [{'alpha': 1.0861353736185886e-05, 'batch_size': 226, 'beta_1': 0.8416341373092215, 'beta_2': 0.9999115092120013, 'epsilon': 8.192859985865251e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.00035041175361467947, 'tol': 0.07301231840483209, 'validation_fraction': 0.8091395509652836}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.261536 value 10.353335 suggestion {'alpha': 1.0861353736185886e-05, 'batch_size': 226, 'beta_1': 0.8416341373092215, 'beta_2': 0.9999115092120013, 'epsilon': 8.192859985865251e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.00035041175361467947, 'tol': 0.07301231840483209, 'validation_fraction': 0.8091395509652836}
observation time 0.000005, current best 0.279244 at iter 38
suggestion time taken 20.238993 iter 39 next_points [{'alpha': 1.0340105015556983e-05, 'batch_size': 15, 'beta_1': 0.9494446151418203, 'beta_2': 0.9323857178046094, 'epsilon': 8.53272518873221e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0011126965035114802, 'tol': 0.0006554676866141108, 'validation_fraction': 0.6908019673498251}]
function_evaluation time 1.694688 value 0.609928 suggestion {'alpha': 1.0340105015556983e-05, 'batch_size': 15, 'beta_1': 0.9494446151418203, 'beta_2': 0.9323857178046094, 'epsilon': 8.53272518873221e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0011126965035114802, 'tol': 0.0006554676866141108, 'validation_fraction': 0.6908019673498251}
observation time 0.000005, current best 0.279244 at iter 39
suggestion time taken 21.677782 iter 40 next_points [{'alpha': 0.002271518787321249, 'batch_size': 151, 'beta_1': 0.8501605381544491, 'beta_2': 0.9999989144605093, 'epsilon': 3.5475504311597776e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 3.681194187512118e-05, 'tol': 1.7761287809428706e-05, 'validation_fraction': 0.79901324787563}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.306516 value 14.423019 suggestion {'alpha': 0.002271518787321249, 'batch_size': 151, 'beta_1': 0.8501605381544491, 'beta_2': 0.9999989144605093, 'epsilon': 3.5475504311597776e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 3.681194187512118e-05, 'tol': 1.7761287809428706e-05, 'validation_fraction': 0.79901324787563}
observation time 0.000005, current best 0.279244 at iter 40
suggestion time taken 20.525245 iter 41 next_points [{'alpha': 0.11217888235664919, 'batch_size': 44, 'beta_1': 0.9851304721539978, 'beta_2': 0.9987926874780371, 'epsilon': 2.65774052712463e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0005493238069093891, 'tol': 0.003529659149182501, 'validation_fraction': 0.515920203231815}]
function_evaluation time 1.474419 value 2.888015 suggestion {'alpha': 0.11217888235664919, 'batch_size': 44, 'beta_1': 0.9851304721539978, 'beta_2': 0.9987926874780371, 'epsilon': 2.65774052712463e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0005493238069093891, 'tol': 0.003529659149182501, 'validation_fraction': 0.515920203231815}
observation time 0.000005, current best 0.279244 at iter 41
suggestion time taken 20.877380 iter 42 next_points [{'alpha': 1.427198539241819, 'batch_size': 18, 'beta_1': 0.5689188833977432, 'beta_2': 0.9496246184684822, 'epsilon': 1.0330963309871577e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0013904753752577768, 'tol': 0.0004609171763117683, 'validation_fraction': 0.2682542048126732}]
function_evaluation time 2.751973 value 0.316592 suggestion {'alpha': 1.427198539241819, 'batch_size': 18, 'beta_1': 0.5689188833977432, 'beta_2': 0.9496246184684822, 'epsilon': 1.0330963309871577e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0013904753752577768, 'tol': 0.0004609171763117683, 'validation_fraction': 0.2682542048126732}
observation time 0.000005, current best 0.279244 at iter 42
suggestion time taken 20.956825 iter 43 next_points [{'alpha': 3.1410331153698263, 'batch_size': 16, 'beta_1': 0.8631360314605637, 'beta_2': 0.9994300872772269, 'epsilon': 5.137118202177156e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0005581225755701487, 'tol': 0.038250105013786055, 'validation_fraction': 0.7013090584631796}]
function_evaluation time 1.065500 value 0.385634 suggestion {'alpha': 3.1410331153698263, 'batch_size': 16, 'beta_1': 0.8631360314605637, 'beta_2': 0.9994300872772269, 'epsilon': 5.137118202177156e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.0005581225755701487, 'tol': 0.038250105013786055, 'validation_fraction': 0.7013090584631796}
observation time 0.000009, current best 0.279244 at iter 43
suggestion time taken 20.780421 iter 44 next_points [{'alpha': 0.044780851433675106, 'batch_size': 12, 'beta_1': 0.5149305639370388, 'beta_2': 0.9999497601106417, 'epsilon': 1.0970879260525047e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.07940652518329465, 'tol': 0.001080034415059249, 'validation_fraction': 0.5340000527362335}]
function_evaluation time 2.496288 value 0.284368 suggestion {'alpha': 0.044780851433675106, 'batch_size': 12, 'beta_1': 0.5149305639370388, 'beta_2': 0.9999497601106417, 'epsilon': 1.0970879260525047e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.07940652518329465, 'tol': 0.001080034415059249, 'validation_fraction': 0.5340000527362335}
observation time 0.000005, current best 0.279244 at iter 44
saving meta data: {'args': {'--uuid': '4816898b5a11581eb213fe7a86330cb4', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])}
saving results
saving timing
saving suggest log
done
