running: {'--uuid': 'b9c708e9293c54d9b7a4633a6d8ea8d6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d breast -o strongcvx -u b9c708e9293c54d9b7a4633a6d8ea8d6 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam breast acc 45 1
with data root: None
suggestion time taken 19.937529 iter 0 next_points [{'alpha': 0.12564367551379632, 'batch_size': 32, 'beta_1': 0.8813791975663607, 'beta_2': 0.9752819135847822, 'epsilon': 3.179681166303542e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.003563087086320403, 'tol': 0.016579060658481398, 'validation_fraction': 0.10702223581502934}]
function_evaluation time 0.523403 value -0.901099 suggestion {'alpha': 0.12564367551379632, 'batch_size': 32, 'beta_1': 0.8813791975663607, 'beta_2': 0.9752819135847822, 'epsilon': 3.179681166303542e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.003563087086320403, 'tol': 0.016579060658481398, 'validation_fraction': 0.10702223581502934}
observation time 0.000005, current best -0.901099 at iter 0
suggestion time taken 19.653619 iter 1 next_points [{'alpha': 0.0022521899507479373, 'batch_size': 151, 'beta_1': 0.8073875715873653, 'beta_2': 0.9999942238924774, 'epsilon': 6.44456986869929e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 3.7966620103513286e-05, 'tol': 0.021849616476126214, 'validation_fraction': 0.6377945106294107}]
function_evaluation time 0.255584 value -0.527473 suggestion {'alpha': 0.0022521899507479373, 'batch_size': 151, 'beta_1': 0.8073875715873653, 'beta_2': 0.9999942238924774, 'epsilon': 6.44456986869929e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 3.7966620103513286e-05, 'tol': 0.021849616476126214, 'validation_fraction': 0.6377945106294107}
observation time 0.000005, current best -0.901099 at iter 1
suggestion time taken 18.707794 iter 2 next_points [{'alpha': 6.918763302096101e-05, 'batch_size': 14, 'beta_1': 0.9458123081406674, 'beta_2': 0.982816245192465, 'epsilon': 1.5548360389850132e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 2.3297909877806753e-05, 'tol': 0.007358636728024513, 'validation_fraction': 0.6315376664432943}]
function_evaluation time 0.850841 value -0.441758 suggestion {'alpha': 6.918763302096101e-05, 'batch_size': 14, 'beta_1': 0.9458123081406674, 'beta_2': 0.982816245192465, 'epsilon': 1.5548360389850132e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 2.3297909877806753e-05, 'tol': 0.007358636728024513, 'validation_fraction': 0.6315376664432943}
observation time 0.000010, current best -0.901099 at iter 2
suggestion time taken 20.490247 iter 3 next_points [{'alpha': 0.0023087021376862592, 'batch_size': 226, 'beta_1': 0.8793930238240767, 'beta_2': 0.9970396530517496, 'epsilon': 2.792752388201972e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.00023616103012072572, 'tol': 0.00022361348472620059, 'validation_fraction': 0.34063951695510286}]
function_evaluation time 1.176434 value -0.821978 suggestion {'alpha': 0.0023087021376862592, 'batch_size': 226, 'beta_1': 0.8793930238240767, 'beta_2': 0.9970396530517496, 'epsilon': 2.792752388201972e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.00023616103012072572, 'tol': 0.00022361348472620059, 'validation_fraction': 0.34063951695510286}
observation time 0.000014, current best -0.901099 at iter 3
suggestion time taken 19.230880 iter 4 next_points [{'alpha': 0.6076032000557706, 'batch_size': 25, 'beta_1': 0.915359159210342, 'beta_2': 0.9917148635761968, 'epsilon': 1.0927798358874646e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.010763676460985165, 'tol': 0.0013039852759158433, 'validation_fraction': 0.6274664032363076}]
function_evaluation time 1.079951 value -0.898901 suggestion {'alpha': 0.6076032000557706, 'batch_size': 25, 'beta_1': 0.915359159210342, 'beta_2': 0.9917148635761968, 'epsilon': 1.0927798358874646e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.010763676460985165, 'tol': 0.0013039852759158433, 'validation_fraction': 0.6274664032363076}
observation time 0.000005, current best -0.901099 at iter 4
suggestion time taken 20.077594 iter 5 next_points [{'alpha': 4.150352215030742e-05, 'batch_size': 30, 'beta_1': 0.9685696363280494, 'beta_2': 0.9978464402503068, 'epsilon': 3.784844077720387e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.07384923783511847, 'tol': 0.0009388000767202978, 'validation_fraction': 0.3689414470985979}]
function_evaluation time 0.924889 value -0.745055 suggestion {'alpha': 4.150352215030742e-05, 'batch_size': 30, 'beta_1': 0.9685696363280494, 'beta_2': 0.9978464402503068, 'epsilon': 3.784844077720387e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.07384923783511847, 'tol': 0.0009388000767202978, 'validation_fraction': 0.3689414470985979}
observation time 0.000005, current best -0.901099 at iter 5
suggestion time taken 19.810939 iter 6 next_points [{'alpha': 0.00013265857092859695, 'batch_size': 226, 'beta_1': 0.8556751766558834, 'beta_2': 0.9999980232287257, 'epsilon': 3.288365394776579e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0016663263633643903, 'tol': 0.0002907295106966396, 'validation_fraction': 0.14945577625637146}]
function_evaluation time 1.006627 value -0.892308 suggestion {'alpha': 0.00013265857092859695, 'batch_size': 226, 'beta_1': 0.8556751766558834, 'beta_2': 0.9999980232287257, 'epsilon': 3.288365394776579e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0016663263633643903, 'tol': 0.0002907295106966396, 'validation_fraction': 0.14945577625637146}
observation time 0.000006, current best -0.901099 at iter 6
suggestion time taken 18.982438 iter 7 next_points [{'alpha': 2.1232697815589268e-05, 'batch_size': 227, 'beta_1': 0.9844381189750661, 'beta_2': 0.9999705118125997, 'epsilon': 3.3714034318155843e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 2.171111084756117e-05, 'tol': 3.1624158766995916e-05, 'validation_fraction': 0.5322546658768255}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.292022 value -0.417582 suggestion {'alpha': 2.1232697815589268e-05, 'batch_size': 227, 'beta_1': 0.9844381189750661, 'beta_2': 0.9999705118125997, 'epsilon': 3.3714034318155843e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 2.171111084756117e-05, 'tol': 3.1624158766995916e-05, 'validation_fraction': 0.5322546658768255}
observation time 0.000005, current best -0.901099 at iter 7
suggestion time taken 19.913723 iter 8 next_points [{'alpha': 3.373881009181234, 'batch_size': 18, 'beta_1': 0.9379620481198978, 'beta_2': 0.9999108598636027, 'epsilon': 1.6082261901646388e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.09132967916185773, 'tol': 0.030797871350334675, 'validation_fraction': 0.14305284837088156}]
function_evaluation time 1.420349 value -0.894505 suggestion {'alpha': 3.373881009181234, 'batch_size': 18, 'beta_1': 0.9379620481198978, 'beta_2': 0.9999108598636027, 'epsilon': 1.6082261901646388e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.09132967916185773, 'tol': 0.030797871350334675, 'validation_fraction': 0.14305284837088156}
observation time 0.000006, current best -0.901099 at iter 8
suggestion time taken 19.007529 iter 9 next_points [{'alpha': 1.9208266769049393e-05, 'batch_size': 41, 'beta_1': 0.9264156001910056, 'beta_2': 0.9906795326969582, 'epsilon': 1.3101917919518029e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.017558703414126114, 'tol': 0.0005143856677083617, 'validation_fraction': 0.15146566757998514}]
function_evaluation time 1.066596 value -0.903297 suggestion {'alpha': 1.9208266769049393e-05, 'batch_size': 41, 'beta_1': 0.9264156001910056, 'beta_2': 0.9906795326969582, 'epsilon': 1.3101917919518029e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.017558703414126114, 'tol': 0.0005143856677083617, 'validation_fraction': 0.15146566757998514}
observation time 0.000020, current best -0.903297 at iter 9
suggestion time taken 20.342900 iter 10 next_points [{'alpha': 0.014065792272757902, 'batch_size': 222, 'beta_1': 0.9689000153430337, 'beta_2': 0.9973646174731133, 'epsilon': 4.062698267342859e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.00015546442024375385, 'tol': 0.09960491864618654, 'validation_fraction': 0.16352489678103085}]
function_evaluation time 0.416270 value -0.584615 suggestion {'alpha': 0.014065792272757902, 'batch_size': 222, 'beta_1': 0.9689000153430337, 'beta_2': 0.9973646174731133, 'epsilon': 4.062698267342859e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.00015546442024375385, 'tol': 0.09960491864618654, 'validation_fraction': 0.16352489678103085}
observation time 0.000005, current best -0.903297 at iter 10
suggestion time taken 20.098780 iter 11 next_points [{'alpha': 0.24907022907940454, 'batch_size': 227, 'beta_1': 0.8101556918827695, 'beta_2': 0.999678808568231, 'epsilon': 2.4569785595156522e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 4.4913310204085246e-05, 'tol': 0.00033673484441581054, 'validation_fraction': 0.6044096937134756}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.327790 value -0.582418 suggestion {'alpha': 0.24907022907940454, 'batch_size': 227, 'beta_1': 0.8101556918827695, 'beta_2': 0.999678808568231, 'epsilon': 2.4569785595156522e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 4.4913310204085246e-05, 'tol': 0.00033673484441581054, 'validation_fraction': 0.6044096937134756}
observation time 0.000007, current best -0.903297 at iter 11
suggestion time taken 19.578607 iter 12 next_points [{'alpha': 2.59115806057473, 'batch_size': 89, 'beta_1': 0.5965684475346803, 'beta_2': 0.9618812608018456, 'epsilon': 6.177774004658026e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 9.526931803338198e-05, 'tol': 2.6875782141518008e-05, 'validation_fraction': 0.5173955929981848}]
function_evaluation time 0.510838 value -0.661538 suggestion {'alpha': 2.59115806057473, 'batch_size': 89, 'beta_1': 0.5965684475346803, 'beta_2': 0.9618812608018456, 'epsilon': 6.177774004658026e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 9.526931803338198e-05, 'tol': 2.6875782141518008e-05, 'validation_fraction': 0.5173955929981848}
observation time 0.000004, current best -0.903297 at iter 12
suggestion time taken 20.316029 iter 13 next_points [{'alpha': 0.03546195249997619, 'batch_size': 50, 'beta_1': 0.7236944210730771, 'beta_2': 0.9999977646652946, 'epsilon': 1.567899448917568e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 3.322097816600673e-05, 'tol': 0.0004062228042122762, 'validation_fraction': 0.22371556041319013}]
function_evaluation time 0.594023 value -0.582418 suggestion {'alpha': 0.03546195249997619, 'batch_size': 50, 'beta_1': 0.7236944210730771, 'beta_2': 0.9999977646652946, 'epsilon': 1.567899448917568e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 3.322097816600673e-05, 'tol': 0.0004062228042122762, 'validation_fraction': 0.22371556041319013}
observation time 0.000007, current best -0.903297 at iter 13
suggestion time taken 19.620712 iter 14 next_points [{'alpha': 0.0010788792337623316, 'batch_size': 226, 'beta_1': 0.9615220062929772, 'beta_2': 0.9495467991220549, 'epsilon': 1.8066056622792428e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0026206846040347878, 'tol': 0.019428233919263016, 'validation_fraction': 0.18246339429658742}]
function_evaluation time 0.624923 value -0.874725 suggestion {'alpha': 0.0010788792337623316, 'batch_size': 226, 'beta_1': 0.9615220062929772, 'beta_2': 0.9495467991220549, 'epsilon': 1.8066056622792428e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0026206846040347878, 'tol': 0.019428233919263016, 'validation_fraction': 0.18246339429658742}
observation time 0.000005, current best -0.903297 at iter 14
suggestion time taken 20.543150 iter 15 next_points [{'alpha': 0.006404860133400393, 'batch_size': 50, 'beta_1': 0.6023389955357985, 'beta_2': 0.99999744124765, 'epsilon': 1.3241992363798037e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.026578525262454748, 'tol': 0.011507844021814921, 'validation_fraction': 0.42302715203678265}]
function_evaluation time 1.064135 value -0.914286 suggestion {'alpha': 0.006404860133400393, 'batch_size': 50, 'beta_1': 0.6023389955357985, 'beta_2': 0.99999744124765, 'epsilon': 1.3241992363798037e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.026578525262454748, 'tol': 0.011507844021814921, 'validation_fraction': 0.42302715203678265}
observation time 0.000005, current best -0.914286 at iter 15
suggestion time taken 20.117972 iter 16 next_points [{'alpha': 0.0099187482353651, 'batch_size': 227, 'beta_1': 0.6253754625801715, 'beta_2': 0.9999981171627786, 'epsilon': 3.754436203922234e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.005883221777474593, 'tol': 0.05316802776764775, 'validation_fraction': 0.20506680981214148}]
function_evaluation time 0.556518 value -0.907692 suggestion {'alpha': 0.0099187482353651, 'batch_size': 227, 'beta_1': 0.6253754625801715, 'beta_2': 0.9999981171627786, 'epsilon': 3.754436203922234e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.005883221777474593, 'tol': 0.05316802776764775, 'validation_fraction': 0.20506680981214148}
observation time 0.000007, current best -0.914286 at iter 16
suggestion time taken 19.269015 iter 17 next_points [{'alpha': 1.1950599896303782, 'batch_size': 225, 'beta_1': 0.9717050000542872, 'beta_2': 0.9999658114335659, 'epsilon': 2.1324146181333276e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0012502480550126984, 'tol': 0.0001914588003788938, 'validation_fraction': 0.21295506414270404}]
function_evaluation time 0.949058 value -0.912088 suggestion {'alpha': 1.1950599896303782, 'batch_size': 225, 'beta_1': 0.9717050000542872, 'beta_2': 0.9999658114335659, 'epsilon': 2.1324146181333276e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0012502480550126984, 'tol': 0.0001914588003788938, 'validation_fraction': 0.21295506414270404}
observation time 0.000005, current best -0.914286 at iter 17
suggestion time taken 15.615255 iter 18 next_points [{'alpha': 5.168210456857558, 'batch_size': 222, 'beta_1': 0.7254036457611192, 'beta_2': 0.9992959459741185, 'epsilon': 3.093544023089312e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.00019222651869118198, 'tol': 0.0012791577195363504, 'validation_fraction': 0.8369467845534686}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.233101 value -0.527473 suggestion {'alpha': 5.168210456857558, 'batch_size': 222, 'beta_1': 0.7254036457611192, 'beta_2': 0.9992959459741185, 'epsilon': 3.093544023089312e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.00019222651869118198, 'tol': 0.0012791577195363504, 'validation_fraction': 0.8369467845534686}
observation time 0.000005, current best -0.914286 at iter 18
suggestion time taken 15.263487 iter 19 next_points [{'alpha': 0.3386681118715734, 'batch_size': 226, 'beta_1': 0.6767084270049295, 'beta_2': 0.9998051321006051, 'epsilon': 1.598317410182915e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.001593462029388456, 'tol': 0.00012828595817530362, 'validation_fraction': 0.8639159967740736}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.441129 value -0.839560 suggestion {'alpha': 0.3386681118715734, 'batch_size': 226, 'beta_1': 0.6767084270049295, 'beta_2': 0.9998051321006051, 'epsilon': 1.598317410182915e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.001593462029388456, 'tol': 0.00012828595817530362, 'validation_fraction': 0.8639159967740736}
observation time 0.000005, current best -0.914286 at iter 19
suggestion time taken 15.778082 iter 20 next_points [{'alpha': 3.912270203312573e-05, 'batch_size': 227, 'beta_1': 0.9460482987331063, 'beta_2': 0.9999987406723955, 'epsilon': 9.870745835887182e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.000390117525450531, 'tol': 0.000686430323916553, 'validation_fraction': 0.6031474673172086}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.580557 value -0.740659 suggestion {'alpha': 3.912270203312573e-05, 'batch_size': 227, 'beta_1': 0.9460482987331063, 'beta_2': 0.9999987406723955, 'epsilon': 9.870745835887182e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.000390117525450531, 'tol': 0.000686430323916553, 'validation_fraction': 0.6031474673172086}
observation time 0.000005, current best -0.914286 at iter 20
suggestion time taken 15.692364 iter 21 next_points [{'alpha': 5.7717678827720506e-05, 'batch_size': 25, 'beta_1': 0.9790386064204976, 'beta_2': 0.9999940265859182, 'epsilon': 1.3855951869566475e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 3.290128556080254e-05, 'tol': 0.0069164355843404765, 'validation_fraction': 0.5476773530165403}]
function_evaluation time 0.731162 value -0.549451 suggestion {'alpha': 5.7717678827720506e-05, 'batch_size': 25, 'beta_1': 0.9790386064204976, 'beta_2': 0.9999940265859182, 'epsilon': 1.3855951869566475e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 3.290128556080254e-05, 'tol': 0.0069164355843404765, 'validation_fraction': 0.5476773530165403}
observation time 0.000005, current best -0.914286 at iter 21
suggestion time taken 15.365987 iter 22 next_points [{'alpha': 6.249622134531379, 'batch_size': 151, 'beta_1': 0.8105221986798271, 'beta_2': 0.9999765762202942, 'epsilon': 1.254297784180118e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.008166922967657107, 'tol': 0.0003399519892837229, 'validation_fraction': 0.6443493619672171}]
function_evaluation time 0.562711 value -0.909890 suggestion {'alpha': 6.249622134531379, 'batch_size': 151, 'beta_1': 0.8105221986798271, 'beta_2': 0.9999765762202942, 'epsilon': 1.254297784180118e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.008166922967657107, 'tol': 0.0003399519892837229, 'validation_fraction': 0.6443493619672171}
observation time 0.000005, current best -0.914286 at iter 22
suggestion time taken 20.091099 iter 23 next_points [{'alpha': 2.8156268335201582e-05, 'batch_size': 14, 'beta_1': 0.6633309567951404, 'beta_2': 0.9599607780680769, 'epsilon': 1.6449282844948367e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00021441395911521492, 'tol': 0.04134614054022315, 'validation_fraction': 0.3661053096919383}]
function_evaluation time 1.892231 value -0.887912 suggestion {'alpha': 2.8156268335201582e-05, 'batch_size': 14, 'beta_1': 0.6633309567951404, 'beta_2': 0.9599607780680769, 'epsilon': 1.6449282844948367e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00021441395911521492, 'tol': 0.04134614054022315, 'validation_fraction': 0.3661053096919383}
observation time 0.000006, current best -0.914286 at iter 23
suggestion time taken 19.520731 iter 24 next_points [{'alpha': 0.17121914344879882, 'batch_size': 11, 'beta_1': 0.8628805720173782, 'beta_2': 0.998045741868804, 'epsilon': 4.876223209922639e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 1.1166743341557346e-05, 'tol': 0.007699258917862495, 'validation_fraction': 0.1723432964691917}]
function_evaluation time 2.247185 value -0.463736 suggestion {'alpha': 0.17121914344879882, 'batch_size': 11, 'beta_1': 0.8628805720173782, 'beta_2': 0.998045741868804, 'epsilon': 4.876223209922639e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 1.1166743341557346e-05, 'tol': 0.007699258917862495, 'validation_fraction': 0.1723432964691917}
observation time 0.000011, current best -0.914286 at iter 24
suggestion time taken 21.074485 iter 25 next_points [{'alpha': 2.1335482261459346, 'batch_size': 15, 'beta_1': 0.8859925170176302, 'beta_2': 0.9835370927760411, 'epsilon': 2.1633306950091424e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.06097791041376856, 'tol': 1.4797476442834408e-05, 'validation_fraction': 0.624780498877622}]
function_evaluation time 1.951607 value -0.791209 suggestion {'alpha': 2.1335482261459346, 'batch_size': 15, 'beta_1': 0.8859925170176302, 'beta_2': 0.9835370927760411, 'epsilon': 2.1633306950091424e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.06097791041376856, 'tol': 1.4797476442834408e-05, 'validation_fraction': 0.624780498877622}
observation time 0.000007, current best -0.914286 at iter 25
suggestion time taken 19.807186 iter 26 next_points [{'alpha': 0.0009265601072575931, 'batch_size': 90, 'beta_1': 0.5761048901977974, 'beta_2': 0.9971468221160081, 'epsilon': 3.153398458329203e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 3.369473473879574e-05, 'tol': 0.08818007584737547, 'validation_fraction': 0.2131787483511555}]
function_evaluation time 0.647166 value -0.547253 suggestion {'alpha': 0.0009265601072575931, 'batch_size': 90, 'beta_1': 0.5761048901977974, 'beta_2': 0.9971468221160081, 'epsilon': 3.153398458329203e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 3.369473473879574e-05, 'tol': 0.08818007584737547, 'validation_fraction': 0.2131787483511555}
observation time 0.000015, current best -0.914286 at iter 26
suggestion time taken 21.011355 iter 27 next_points [{'alpha': 1.0068403572598648e-05, 'batch_size': 14, 'beta_1': 0.9680474530468266, 'beta_2': 0.999976073405975, 'epsilon': 7.936676532670681e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0002167103680477096, 'tol': 0.002425479282754772, 'validation_fraction': 0.8761604183976561}]
function_evaluation time 0.609567 value -0.621978 suggestion {'alpha': 1.0068403572598648e-05, 'batch_size': 14, 'beta_1': 0.9680474530468266, 'beta_2': 0.999976073405975, 'epsilon': 7.936676532670681e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0002167103680477096, 'tol': 0.002425479282754772, 'validation_fraction': 0.8761604183976561}
observation time 0.000006, current best -0.914286 at iter 27
suggestion time taken 19.591371 iter 28 next_points [{'alpha': 0.05987477710355205, 'batch_size': 30, 'beta_1': 0.8823381390502854, 'beta_2': 0.9601309099227987, 'epsilon': 1.2439540422612757e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00039383945727748286, 'tol': 4.380623145497018e-05, 'validation_fraction': 0.3940792925474829}]
function_evaluation time 1.051453 value -0.892308 suggestion {'alpha': 0.05987477710355205, 'batch_size': 30, 'beta_1': 0.8823381390502854, 'beta_2': 0.9601309099227987, 'epsilon': 1.2439540422612757e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.00039383945727748286, 'tol': 4.380623145497018e-05, 'validation_fraction': 0.3940792925474829}
observation time 0.000005, current best -0.914286 at iter 28
suggestion time taken 22.558881 iter 29 next_points [{'alpha': 0.02533259726142361, 'batch_size': 56, 'beta_1': 0.8728571920808419, 'beta_2': 0.9947169802834278, 'epsilon': 1.3895247803755252e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0694375269193187, 'tol': 0.04866414793232101, 'validation_fraction': 0.7539193945553667}]
function_evaluation time 0.621926 value -0.857143 suggestion {'alpha': 0.02533259726142361, 'batch_size': 56, 'beta_1': 0.8728571920808419, 'beta_2': 0.9947169802834278, 'epsilon': 1.3895247803755252e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0694375269193187, 'tol': 0.04866414793232101, 'validation_fraction': 0.7539193945553667}
observation time 0.000006, current best -0.914286 at iter 29
suggestion time taken 19.964961 iter 30 next_points [{'alpha': 0.015183053301039345, 'batch_size': 25, 'beta_1': 0.9459657016277924, 'beta_2': 0.9285944908130465, 'epsilon': 3.5689912396940307e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0019253559380856778, 'tol': 1.3885323366737938e-05, 'validation_fraction': 0.19689368636673332}]
function_evaluation time 1.151115 value -0.896703 suggestion {'alpha': 0.015183053301039345, 'batch_size': 25, 'beta_1': 0.9459657016277924, 'beta_2': 0.9285944908130465, 'epsilon': 3.5689912396940307e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0019253559380856778, 'tol': 1.3885323366737938e-05, 'validation_fraction': 0.19689368636673332}
observation time 0.000008, current best -0.914286 at iter 30
suggestion time taken 21.264032 iter 31 next_points [{'alpha': 4.4666154373183415, 'batch_size': 20, 'beta_1': 0.8768727591222288, 'beta_2': 0.9629261973781883, 'epsilon': 8.54104910789301e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.00711228181121355, 'tol': 0.0017686057254884494, 'validation_fraction': 0.410564746187689}]
function_evaluation time 1.828388 value -0.914286 suggestion {'alpha': 4.4666154373183415, 'batch_size': 20, 'beta_1': 0.8768727591222288, 'beta_2': 0.9629261973781883, 'epsilon': 8.54104910789301e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.00711228181121355, 'tol': 0.0017686057254884494, 'validation_fraction': 0.410564746187689}
observation time 0.000007, current best -0.914286 at iter 31
suggestion time taken 19.672611 iter 32 next_points [{'alpha': 1.2093324903974589e-05, 'batch_size': 223, 'beta_1': 0.8743987840877893, 'beta_2': 0.9999804220669801, 'epsilon': 2.3576826561330618e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 5.4094793178576395e-05, 'tol': 0.09839958051369094, 'validation_fraction': 0.892022397669885}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.249084 value -0.527473 suggestion {'alpha': 1.2093324903974589e-05, 'batch_size': 223, 'beta_1': 0.8743987840877893, 'beta_2': 0.9999804220669801, 'epsilon': 2.3576826561330618e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 5.4094793178576395e-05, 'tol': 0.09839958051369094, 'validation_fraction': 0.892022397669885}
observation time 0.000006, current best -0.914286 at iter 32
suggestion time taken 20.983352 iter 33 next_points [{'alpha': 1.6385082741436494, 'batch_size': 151, 'beta_1': 0.8467333627710112, 'beta_2': 0.9999959408576021, 'epsilon': 1.2622299159389064e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.06895973677661654, 'tol': 0.010088158289369362, 'validation_fraction': 0.8084829671001186}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.453912 value -0.804396 suggestion {'alpha': 1.6385082741436494, 'batch_size': 151, 'beta_1': 0.8467333627710112, 'beta_2': 0.9999959408576021, 'epsilon': 1.2622299159389064e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.06895973677661654, 'tol': 0.010088158289369362, 'validation_fraction': 0.8084829671001186}
observation time 0.000017, current best -0.914286 at iter 33
suggestion time taken 19.870804 iter 34 next_points [{'alpha': 0.000529003814540775, 'batch_size': 227, 'beta_1': 0.9206282718595574, 'beta_2': 0.9581516113686556, 'epsilon': 2.0288734026329447e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.002301661351574995, 'tol': 0.0032668518684247426, 'validation_fraction': 0.8629145296036198}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.418803 value -0.773626 suggestion {'alpha': 0.000529003814540775, 'batch_size': 227, 'beta_1': 0.9206282718595574, 'beta_2': 0.9581516113686556, 'epsilon': 2.0288734026329447e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.002301661351574995, 'tol': 0.0032668518684247426, 'validation_fraction': 0.8629145296036198}
observation time 0.000010, current best -0.914286 at iter 34
suggestion time taken 21.588284 iter 35 next_points [{'alpha': 0.006392618913780363, 'batch_size': 151, 'beta_1': 0.956091826097432, 'beta_2': 0.9999440790466698, 'epsilon': 1.007764321631074e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.00021380707620161958, 'tol': 8.634380453774629e-05, 'validation_fraction': 0.8517419424346538}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.277683 value -0.417582 suggestion {'alpha': 0.006392618913780363, 'batch_size': 151, 'beta_1': 0.956091826097432, 'beta_2': 0.9999440790466698, 'epsilon': 1.007764321631074e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.00021380707620161958, 'tol': 8.634380453774629e-05, 'validation_fraction': 0.8517419424346538}
observation time 0.000014, current best -0.914286 at iter 35
suggestion time taken 20.148279 iter 36 next_points [{'alpha': 0.000246728270364918, 'batch_size': 149, 'beta_1': 0.8960732562074383, 'beta_2': 0.9636162562624541, 'epsilon': 1.2485719331310486e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0005847282442522429, 'tol': 3.105015636106509e-05, 'validation_fraction': 0.5245607114482641}]
function_evaluation time 0.678502 value -0.736264 suggestion {'alpha': 0.000246728270364918, 'batch_size': 149, 'beta_1': 0.8960732562074383, 'beta_2': 0.9636162562624541, 'epsilon': 1.2485719331310486e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0005847282442522429, 'tol': 3.105015636106509e-05, 'validation_fraction': 0.5245607114482641}
observation time 0.000008, current best -0.914286 at iter 36
suggestion time taken 20.894007 iter 37 next_points [{'alpha': 8.962136568544212, 'batch_size': 111, 'beta_1': 0.9266495309304628, 'beta_2': 0.9483595702703521, 'epsilon': 7.209785574215318e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 5.779992197543449e-05, 'tol': 5.116896825275528e-05, 'validation_fraction': 0.11444370910196972}]
function_evaluation time 0.882932 value -0.637363 suggestion {'alpha': 8.962136568544212, 'batch_size': 111, 'beta_1': 0.9266495309304628, 'beta_2': 0.9483595702703521, 'epsilon': 7.209785574215318e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 5.779992197543449e-05, 'tol': 5.116896825275528e-05, 'validation_fraction': 0.11444370910196972}
observation time 0.000011, current best -0.914286 at iter 37
suggestion time taken 20.412793 iter 38 next_points [{'alpha': 2.809550748797995, 'batch_size': 113, 'beta_1': 0.9509166321087394, 'beta_2': 0.9298590971356862, 'epsilon': 1.2145782479942085e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 1.1711000445279825e-05, 'tol': 0.012270921909833395, 'validation_fraction': 0.5607970601612355}]
function_evaluation time 0.357227 value -0.415385 suggestion {'alpha': 2.809550748797995, 'batch_size': 113, 'beta_1': 0.9509166321087394, 'beta_2': 0.9298590971356862, 'epsilon': 1.2145782479942085e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 1.1711000445279825e-05, 'tol': 0.012270921909833395, 'validation_fraction': 0.5607970601612355}
observation time 0.000005, current best -0.914286 at iter 38
suggestion time taken 19.581711 iter 39 next_points [{'alpha': 0.0008483377102306686, 'batch_size': 226, 'beta_1': 0.6984332118427724, 'beta_2': 0.9538442009898754, 'epsilon': 4.63227510916815e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.001337471904474622, 'tol': 0.011920299594531853, 'validation_fraction': 0.542716746994308}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.692255 value -0.843956 suggestion {'alpha': 0.0008483377102306686, 'batch_size': 226, 'beta_1': 0.6984332118427724, 'beta_2': 0.9538442009898754, 'epsilon': 4.63227510916815e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.001337471904474622, 'tol': 0.011920299594531853, 'validation_fraction': 0.542716746994308}
observation time 0.000006, current best -0.914286 at iter 39
suggestion time taken 21.232878 iter 40 next_points [{'alpha': 0.011497590602376585, 'batch_size': 112, 'beta_1': 0.9702850512030703, 'beta_2': 0.9999972066367953, 'epsilon': 2.2796896721262876e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.022119253329893167, 'tol': 1.0713508356797855e-05, 'validation_fraction': 0.667487519800929}]
function_evaluation time 0.865562 value -0.892308 suggestion {'alpha': 0.011497590602376585, 'batch_size': 112, 'beta_1': 0.9702850512030703, 'beta_2': 0.9999972066367953, 'epsilon': 2.2796896721262876e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.022119253329893167, 'tol': 1.0713508356797855e-05, 'validation_fraction': 0.667487519800929}
observation time 0.000005, current best -0.914286 at iter 40
suggestion time taken 21.134636 iter 41 next_points [{'alpha': 0.0009651913471551329, 'batch_size': 16, 'beta_1': 0.9667725796881422, 'beta_2': 0.9669871357469156, 'epsilon': 7.182008578378913e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.00040473183048711785, 'tol': 0.0049711717977073445, 'validation_fraction': 0.8333159969289888}]
function_evaluation time 1.066957 value -0.850549 suggestion {'alpha': 0.0009651913471551329, 'batch_size': 16, 'beta_1': 0.9667725796881422, 'beta_2': 0.9669871357469156, 'epsilon': 7.182008578378913e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.00040473183048711785, 'tol': 0.0049711717977073445, 'validation_fraction': 0.8333159969289888}
observation time 0.000006, current best -0.914286 at iter 41
suggestion time taken 19.918069 iter 42 next_points [{'alpha': 0.0010438835049189229, 'batch_size': 227, 'beta_1': 0.9739742356567981, 'beta_2': 0.9999966856136664, 'epsilon': 1.1508771746567138e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 5.395250133833284e-05, 'tol': 0.014546772270169534, 'validation_fraction': 0.7818873162926113}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.252449 value -0.474725 suggestion {'alpha': 0.0010438835049189229, 'batch_size': 227, 'beta_1': 0.9739742356567981, 'beta_2': 0.9999966856136664, 'epsilon': 1.1508771746567138e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 5.395250133833284e-05, 'tol': 0.014546772270169534, 'validation_fraction': 0.7818873162926113}
observation time 0.000005, current best -0.914286 at iter 42
suggestion time taken 21.547089 iter 43 next_points [{'alpha': 1.4953111926256463e-05, 'batch_size': 90, 'beta_1': 0.9643592854624297, 'beta_2': 0.9999929160007381, 'epsilon': 9.99809624790139e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0003483389852516889, 'tol': 0.0039572657708816655, 'validation_fraction': 0.2935085265806995}]
function_evaluation time 0.407387 value -0.650549 suggestion {'alpha': 1.4953111926256463e-05, 'batch_size': 90, 'beta_1': 0.9643592854624297, 'beta_2': 0.9999929160007381, 'epsilon': 9.99809624790139e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0003483389852516889, 'tol': 0.0039572657708816655, 'validation_fraction': 0.2935085265806995}
observation time 0.000017, current best -0.914286 at iter 43
suggestion time taken 19.960661 iter 44 next_points [{'alpha': 1.4838527810701865e-05, 'batch_size': 25, 'beta_1': 0.9786084967172993, 'beta_2': 0.9999975287112213, 'epsilon': 7.382394831063516e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.06986310110887278, 'tol': 4.023959092412343e-05, 'validation_fraction': 0.38271201150787315}]
function_evaluation time 1.183016 value -0.775824 suggestion {'alpha': 1.4838527810701865e-05, 'batch_size': 25, 'beta_1': 0.9786084967172993, 'beta_2': 0.9999975287112213, 'epsilon': 7.382394831063516e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.06986310110887278, 'tol': 4.023959092412343e-05, 'validation_fraction': 0.38271201150787315}
observation time 0.000012, current best -0.914286 at iter 44
saving meta data: {'args': {'--uuid': 'b9c708e9293c54d9b7a4633a6d8ea8d6', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
