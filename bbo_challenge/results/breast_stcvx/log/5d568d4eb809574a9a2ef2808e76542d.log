running: {'--uuid': '5d568d4eb809574a9a2ef2808e76542d', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d breast -o strongcvx -u 5d568d4eb809574a9a2ef2808e76542d -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam breast acc 45 1
with data root: None
suggestion time taken 19.580573 iter 0 next_points [{'alpha': 0.0002412056104549055, 'batch_size': 25, 'beta_1': 0.7648033240219402, 'beta_2': 0.9999970230725296, 'epsilon': 1.5230593163575575e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0009508957637673782, 'tol': 3.0266004992384105e-05, 'validation_fraction': 0.23071902373732261}]
function_evaluation time 1.956349 value -0.903297 suggestion {'alpha': 0.0002412056104549055, 'batch_size': 25, 'beta_1': 0.7648033240219402, 'beta_2': 0.9999970230725296, 'epsilon': 1.5230593163575575e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0009508957637673782, 'tol': 3.0266004992384105e-05, 'validation_fraction': 0.23071902373732261}
observation time 0.000010, current best -0.903297 at iter 0
suggestion time taken 19.379333 iter 1 next_points [{'alpha': 0.0037427770898955646, 'batch_size': 151, 'beta_1': 0.9847968584420708, 'beta_2': 0.9992234701720311, 'epsilon': 1.629541467393979e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0005006500749630065, 'tol': 0.0022435276145688398, 'validation_fraction': 0.5275732733941189}]
function_evaluation time 0.506176 value -0.701099 suggestion {'alpha': 0.0037427770898955646, 'batch_size': 151, 'beta_1': 0.9847968584420708, 'beta_2': 0.9992234701720311, 'epsilon': 1.629541467393979e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0005006500749630065, 'tol': 0.0022435276145688398, 'validation_fraction': 0.5275732733941189}
observation time 0.000005, current best -0.903297 at iter 1
suggestion time taken 19.282234 iter 2 next_points [{'alpha': 0.020391527344284892, 'batch_size': 64, 'beta_1': 0.909125355575742, 'beta_2': 0.9999854014178473, 'epsilon': 7.330391886749588e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 1.5153506106645825e-05, 'tol': 0.0010384039906392365, 'validation_fraction': 0.7151397696779344}]
function_evaluation time 0.310889 value -0.582418 suggestion {'alpha': 0.020391527344284892, 'batch_size': 64, 'beta_1': 0.909125355575742, 'beta_2': 0.9999854014178473, 'epsilon': 7.330391886749588e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 1.5153506106645825e-05, 'tol': 0.0010384039906392365, 'validation_fraction': 0.7151397696779344}
observation time 0.000009, current best -0.903297 at iter 2
suggestion time taken 19.909235 iter 3 next_points [{'alpha': 2.1977133987270213e-05, 'batch_size': 64, 'beta_1': 0.9004497182480184, 'beta_2': 0.9999960512260089, 'epsilon': 8.740152780794035e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0027361094294418306, 'tol': 0.03758305087673029, 'validation_fraction': 0.47306385337726414}]
function_evaluation time 0.710186 value -0.909890 suggestion {'alpha': 2.1977133987270213e-05, 'batch_size': 64, 'beta_1': 0.9004497182480184, 'beta_2': 0.9999960512260089, 'epsilon': 8.740152780794035e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.0027361094294418306, 'tol': 0.03758305087673029, 'validation_fraction': 0.47306385337726414}
observation time 0.000006, current best -0.909890 at iter 3
suggestion time taken 19.346480 iter 4 next_points [{'alpha': 0.0018207943199472726, 'batch_size': 227, 'beta_1': 0.5877587373297674, 'beta_2': 0.9999947798278496, 'epsilon': 1.436871501726188e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.003601031493536019, 'tol': 0.013092374106929166, 'validation_fraction': 0.21358953208838227}]
function_evaluation time 0.578438 value -0.901099 suggestion {'alpha': 0.0018207943199472726, 'batch_size': 227, 'beta_1': 0.5877587373297674, 'beta_2': 0.9999947798278496, 'epsilon': 1.436871501726188e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.003601031493536019, 'tol': 0.013092374106929166, 'validation_fraction': 0.21358953208838227}
observation time 0.000009, current best -0.909890 at iter 4
suggestion time taken 19.998922 iter 5 next_points [{'alpha': 0.00026762897029518443, 'batch_size': 227, 'beta_1': 0.518839281624178, 'beta_2': 0.9999934154977141, 'epsilon': 8.082777041754612e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.07664028876625838, 'tol': 0.09935195530356739, 'validation_fraction': 0.2612551504565993}]
function_evaluation time 0.632147 value -0.898901 suggestion {'alpha': 0.00026762897029518443, 'batch_size': 227, 'beta_1': 0.518839281624178, 'beta_2': 0.9999934154977141, 'epsilon': 8.082777041754612e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.07664028876625838, 'tol': 0.09935195530356739, 'validation_fraction': 0.2612551504565993}
observation time 0.000012, current best -0.909890 at iter 5
suggestion time taken 19.968394 iter 6 next_points [{'alpha': 0.44726929342737615, 'batch_size': 11, 'beta_1': 0.5844002746260272, 'beta_2': 0.9999776141114664, 'epsilon': 1.8527038261753466e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 3.2120900721192426e-05, 'tol': 0.00717920389454747, 'validation_fraction': 0.8258608733555411}]
function_evaluation time 1.027945 value -0.621978 suggestion {'alpha': 0.44726929342737615, 'batch_size': 11, 'beta_1': 0.5844002746260272, 'beta_2': 0.9999776141114664, 'epsilon': 1.8527038261753466e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 3.2120900721192426e-05, 'tol': 0.00717920389454747, 'validation_fraction': 0.8258608733555411}
observation time 0.000004, current best -0.909890 at iter 6
suggestion time taken 19.811481 iter 7 next_points [{'alpha': 0.008379129340004392, 'batch_size': 30, 'beta_1': 0.5669918912655745, 'beta_2': 0.9999930254687339, 'epsilon': 8.610188086216217e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 1.892733626120876e-05, 'tol': 0.004664547136584255, 'validation_fraction': 0.13184664139647317}]
function_evaluation time 0.955807 value -0.652747 suggestion {'alpha': 0.008379129340004392, 'batch_size': 30, 'beta_1': 0.5669918912655745, 'beta_2': 0.9999930254687339, 'epsilon': 8.610188086216217e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 1.892733626120876e-05, 'tol': 0.004664547136584255, 'validation_fraction': 0.13184664139647317}
observation time 0.000010, current best -0.909890 at iter 7
suggestion time taken 20.162586 iter 8 next_points [{'alpha': 0.0011049716413138889, 'batch_size': 227, 'beta_1': 0.9855053667863144, 'beta_2': 0.9416125145601528, 'epsilon': 8.128426305058725e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 1.5086352286904181e-05, 'tol': 0.0008559728994658486, 'validation_fraction': 0.12040226604806652}]
function_evaluation time 0.516421 value -0.472527 suggestion {'alpha': 0.0011049716413138889, 'batch_size': 227, 'beta_1': 0.9855053667863144, 'beta_2': 0.9416125145601528, 'epsilon': 8.128426305058725e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 1.5086352286904181e-05, 'tol': 0.0008559728994658486, 'validation_fraction': 0.12040226604806652}
observation time 0.000005, current best -0.909890 at iter 8
suggestion time taken 19.274975 iter 9 next_points [{'alpha': 0.23720823618238976, 'batch_size': 23, 'beta_1': 0.7650929825979161, 'beta_2': 0.9912653476582819, 'epsilon': 3.64361623459675e-09, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.0003153276776774897, 'tol': 0.0015852252864111873, 'validation_fraction': 0.7895115930836125}]
function_evaluation time 1.048039 value -0.824176 suggestion {'alpha': 0.23720823618238976, 'batch_size': 23, 'beta_1': 0.7650929825979161, 'beta_2': 0.9912653476582819, 'epsilon': 3.64361623459675e-09, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.0003153276776774897, 'tol': 0.0015852252864111873, 'validation_fraction': 0.7895115930836125}
observation time 0.000007, current best -0.909890 at iter 9
suggestion time taken 20.212305 iter 10 next_points [{'alpha': 0.2568984120374858, 'batch_size': 225, 'beta_1': 0.6275938522918904, 'beta_2': 0.9997428886460626, 'epsilon': 2.2283805642879386e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 1.5445820981449993e-05, 'tol': 0.0012118220096537955, 'validation_fraction': 0.2852991554263924}]
function_evaluation time 0.461946 value -0.582418 suggestion {'alpha': 0.2568984120374858, 'batch_size': 225, 'beta_1': 0.6275938522918904, 'beta_2': 0.9997428886460626, 'epsilon': 2.2283805642879386e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 1.5445820981449993e-05, 'tol': 0.0012118220096537955, 'validation_fraction': 0.2852991554263924}
observation time 0.000020, current best -0.909890 at iter 10
suggestion time taken 19.356336 iter 11 next_points [{'alpha': 2.570599372718051, 'batch_size': 28, 'beta_1': 0.9410650872285649, 'beta_2': 0.9995045444295996, 'epsilon': 1.4505391856652053e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0008778512814622454, 'tol': 0.00023695146151991118, 'validation_fraction': 0.7159423133414021}]
function_evaluation time 1.147734 value -0.857143 suggestion {'alpha': 2.570599372718051, 'batch_size': 28, 'beta_1': 0.9410650872285649, 'beta_2': 0.9995045444295996, 'epsilon': 1.4505391856652053e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0008778512814622454, 'tol': 0.00023695146151991118, 'validation_fraction': 0.7159423133414021}
observation time 0.000014, current best -0.909890 at iter 11
suggestion time taken 20.318914 iter 12 next_points [{'alpha': 9.13410614620058e-05, 'batch_size': 151, 'beta_1': 0.9647107925857681, 'beta_2': 0.999510920901016, 'epsilon': 8.864346160563008e-07, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.0020182403180351825, 'tol': 0.03279226536321903, 'validation_fraction': 0.3099209174837813}]
function_evaluation time 0.768101 value -0.903297 suggestion {'alpha': 9.13410614620058e-05, 'batch_size': 151, 'beta_1': 0.9647107925857681, 'beta_2': 0.999510920901016, 'epsilon': 8.864346160563008e-07, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.0020182403180351825, 'tol': 0.03279226536321903, 'validation_fraction': 0.3099209174837813}
observation time 0.000008, current best -0.909890 at iter 12
suggestion time taken 20.206291 iter 13 next_points [{'alpha': 1.3909683095911945e-05, 'batch_size': 227, 'beta_1': 0.9690711926339735, 'beta_2': 0.9998828279421621, 'epsilon': 6.297681374311133e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 2.2531495324652058e-05, 'tol': 0.007263503985627466, 'validation_fraction': 0.886438695636338}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.216888 value -0.527473 suggestion {'alpha': 1.3909683095911945e-05, 'batch_size': 227, 'beta_1': 0.9690711926339735, 'beta_2': 0.9998828279421621, 'epsilon': 6.297681374311133e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 2.2531495324652058e-05, 'tol': 0.007263503985627466, 'validation_fraction': 0.886438695636338}
observation time 0.000006, current best -0.909890 at iter 13
suggestion time taken 19.515734 iter 14 next_points [{'alpha': 0.0006206018522566973, 'batch_size': 41, 'beta_1': 0.8523830088981259, 'beta_2': 0.9970606885278355, 'epsilon': 2.9337117597735136e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.01460997138691785, 'tol': 1.632229589005815e-05, 'validation_fraction': 0.13199153118210805}]
function_evaluation time 0.417253 value -0.905495 suggestion {'alpha': 0.0006206018522566973, 'batch_size': 41, 'beta_1': 0.8523830088981259, 'beta_2': 0.9970606885278355, 'epsilon': 2.9337117597735136e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.01460997138691785, 'tol': 1.632229589005815e-05, 'validation_fraction': 0.13199153118210805}
observation time 0.000003, current best -0.909890 at iter 14
suggestion time taken 20.599266 iter 15 next_points [{'alpha': 0.060123862458845344, 'batch_size': 30, 'beta_1': 0.7192073912086647, 'beta_2': 0.9644150453869781, 'epsilon': 2.3337798986155987e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 6.987771789839768e-05, 'tol': 1.624695002486328e-05, 'validation_fraction': 0.6921569102384089}]
function_evaluation time 1.193029 value -0.687912 suggestion {'alpha': 0.060123862458845344, 'batch_size': 30, 'beta_1': 0.7192073912086647, 'beta_2': 0.9644150453869781, 'epsilon': 2.3337798986155987e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 6.987771789839768e-05, 'tol': 1.624695002486328e-05, 'validation_fraction': 0.6921569102384089}
observation time 0.000004, current best -0.909890 at iter 15
suggestion time taken 19.679471 iter 16 next_points [{'alpha': 0.00020726717093800384, 'batch_size': 18, 'beta_1': 0.9319359009251574, 'beta_2': 0.9808396356056739, 'epsilon': 5.897686661788259e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0018880711775082616, 'tol': 0.036917558980915914, 'validation_fraction': 0.3872855767255243}]
function_evaluation time 1.303262 value -0.907692 suggestion {'alpha': 0.00020726717093800384, 'batch_size': 18, 'beta_1': 0.9319359009251574, 'beta_2': 0.9808396356056739, 'epsilon': 5.897686661788259e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0018880711775082616, 'tol': 0.036917558980915914, 'validation_fraction': 0.3872855767255243}
observation time 0.000011, current best -0.909890 at iter 16
suggestion time taken 21.001784 iter 17 next_points [{'alpha': 0.00047844344673611154, 'batch_size': 41, 'beta_1': 0.8588468696774567, 'beta_2': 0.9950860615265565, 'epsilon': 1.0103561503823427e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0011487644635928924, 'tol': 0.0020813661534138895, 'validation_fraction': 0.7228478508734357}]
function_evaluation time 0.798934 value -0.848352 suggestion {'alpha': 0.00047844344673611154, 'batch_size': 41, 'beta_1': 0.8588468696774567, 'beta_2': 0.9950860615265565, 'epsilon': 1.0103561503823427e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0011487644635928924, 'tol': 0.0020813661534138895, 'validation_fraction': 0.7228478508734357}
observation time 0.000006, current best -0.909890 at iter 17
suggestion time taken 19.852740 iter 18 next_points [{'alpha': 0.0001881976078855876, 'batch_size': 113, 'beta_1': 0.898059426806849, 'beta_2': 0.9999989963518999, 'epsilon': 5.044720450339718e-07, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.00013167715784117827, 'tol': 0.020335201818530744, 'validation_fraction': 0.16292985624367856}]
function_evaluation time 0.725713 value -0.729670 suggestion {'alpha': 0.0001881976078855876, 'batch_size': 113, 'beta_1': 0.898059426806849, 'beta_2': 0.9999989963518999, 'epsilon': 5.044720450339718e-07, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.00013167715784117827, 'tol': 0.020335201818530744, 'validation_fraction': 0.16292985624367856}
observation time 0.000005, current best -0.909890 at iter 18
suggestion time taken 20.583748 iter 19 next_points [{'alpha': 2.67144114583361e-05, 'batch_size': 45, 'beta_1': 0.8259515881283461, 'beta_2': 0.9999513411845844, 'epsilon': 2.2791442416853117e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0003908417613371261, 'tol': 0.001307033466288454, 'validation_fraction': 0.6074412775032517}]
function_evaluation time 1.243639 value -0.778022 suggestion {'alpha': 2.67144114583361e-05, 'batch_size': 45, 'beta_1': 0.8259515881283461, 'beta_2': 0.9999513411845844, 'epsilon': 2.2791442416853117e-07, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.0003908417613371261, 'tol': 0.001307033466288454, 'validation_fraction': 0.6074412775032517}
observation time 0.000007, current best -0.909890 at iter 19
suggestion time taken 19.605231 iter 20 next_points [{'alpha': 2.031494085603025, 'batch_size': 90, 'beta_1': 0.8150153391793046, 'beta_2': 0.9814579218717137, 'epsilon': 1.131235275109286e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 3.167727908997674e-05, 'tol': 0.039983797968895785, 'validation_fraction': 0.8775588298774238}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.187831 value -0.562637 suggestion {'alpha': 2.031494085603025, 'batch_size': 90, 'beta_1': 0.8150153391793046, 'beta_2': 0.9814579218717137, 'epsilon': 1.131235275109286e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 3.167727908997674e-05, 'tol': 0.039983797968895785, 'validation_fraction': 0.8775588298774238}
observation time 0.000005, current best -0.909890 at iter 20
suggestion time taken 21.188954 iter 21 next_points [{'alpha': 2.2787285100301213e-05, 'batch_size': 227, 'beta_1': 0.920610668629807, 'beta_2': 0.9989234793790295, 'epsilon': 6.32076618478798e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00017250115807210996, 'tol': 0.0002340287603008802, 'validation_fraction': 0.7153634016977375}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.360981 value -0.606593 suggestion {'alpha': 2.2787285100301213e-05, 'batch_size': 227, 'beta_1': 0.920610668629807, 'beta_2': 0.9989234793790295, 'epsilon': 6.32076618478798e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00017250115807210996, 'tol': 0.0002340287603008802, 'validation_fraction': 0.7153634016977375}
observation time 0.000005, current best -0.909890 at iter 21
suggestion time taken 19.567746 iter 22 next_points [{'alpha': 0.0034481697528275027, 'batch_size': 227, 'beta_1': 0.5909191148520395, 'beta_2': 0.9999655588749512, 'epsilon': 3.440860643740769e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.00862983458126649, 'tol': 0.007184051795370308, 'validation_fraction': 0.6206169605682458}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.567124 value -0.905495 suggestion {'alpha': 0.0034481697528275027, 'batch_size': 227, 'beta_1': 0.5909191148520395, 'beta_2': 0.9999655588749512, 'epsilon': 3.440860643740769e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.00862983458126649, 'tol': 0.007184051795370308, 'validation_fraction': 0.6206169605682458}
observation time 0.000013, current best -0.909890 at iter 22
suggestion time taken 21.596723 iter 23 next_points [{'alpha': 4.1905297006354114e-05, 'batch_size': 16, 'beta_1': 0.9893124472856496, 'beta_2': 0.9997636840513494, 'epsilon': 6.827282415067174e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 1.174611050121153e-05, 'tol': 7.585906052465974e-05, 'validation_fraction': 0.4197599901003566}]
function_evaluation time 1.675246 value -0.545055 suggestion {'alpha': 4.1905297006354114e-05, 'batch_size': 16, 'beta_1': 0.9893124472856496, 'beta_2': 0.9997636840513494, 'epsilon': 6.827282415067174e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 1.174611050121153e-05, 'tol': 7.585906052465974e-05, 'validation_fraction': 0.4197599901003566}
observation time 0.000014, current best -0.909890 at iter 23
suggestion time taken 19.792337 iter 24 next_points [{'alpha': 0.00022443408536532836, 'batch_size': 14, 'beta_1': 0.8258617771707639, 'beta_2': 0.9999989361902794, 'epsilon': 8.108453624285098e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 3.1660279485569994e-05, 'tol': 0.010307317918626342, 'validation_fraction': 0.8785596608668285}]
function_evaluation time 0.581432 value -0.553846 suggestion {'alpha': 0.00022443408536532836, 'batch_size': 14, 'beta_1': 0.8258617771707639, 'beta_2': 0.9999989361902794, 'epsilon': 8.108453624285098e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 3.1660279485569994e-05, 'tol': 0.010307317918626342, 'validation_fraction': 0.8785596608668285}
observation time 0.000015, current best -0.909890 at iter 24
suggestion time taken 21.458355 iter 25 next_points [{'alpha': 0.11116726032237956, 'batch_size': 18, 'beta_1': 0.7909159187877006, 'beta_2': 0.9591211023955202, 'epsilon': 1.8699557328956514e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.017232895150746427, 'tol': 0.0004906111607072126, 'validation_fraction': 0.13950347002654898}]
function_evaluation time 2.849319 value -0.892308 suggestion {'alpha': 0.11116726032237956, 'batch_size': 18, 'beta_1': 0.7909159187877006, 'beta_2': 0.9591211023955202, 'epsilon': 1.8699557328956514e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.017232895150746427, 'tol': 0.0004906111607072126, 'validation_fraction': 0.13950347002654898}
observation time 0.000005, current best -0.909890 at iter 25
suggestion time taken 19.854539 iter 26 next_points [{'alpha': 7.530035648756085, 'batch_size': 151, 'beta_1': 0.6270259205697754, 'beta_2': 0.9998049080397088, 'epsilon': 3.0808849654847024e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.007132509987998841, 'tol': 0.026524861785601588, 'validation_fraction': 0.691657757939895}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.592014 value -0.905495 suggestion {'alpha': 7.530035648756085, 'batch_size': 151, 'beta_1': 0.6270259205697754, 'beta_2': 0.9998049080397088, 'epsilon': 3.0808849654847024e-08, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.007132509987998841, 'tol': 0.026524861785601588, 'validation_fraction': 0.691657757939895}
observation time 0.000011, current best -0.909890 at iter 26
suggestion time taken 20.887370 iter 27 next_points [{'alpha': 0.02667066893030489, 'batch_size': 151, 'beta_1': 0.5125332042861366, 'beta_2': 0.9926423835759587, 'epsilon': 7.388381829626876e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0032449745114586535, 'tol': 0.00789961235682093, 'validation_fraction': 0.138873438578221}]
function_evaluation time 0.730333 value -0.909890 suggestion {'alpha': 0.02667066893030489, 'batch_size': 151, 'beta_1': 0.5125332042861366, 'beta_2': 0.9926423835759587, 'epsilon': 7.388381829626876e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0032449745114586535, 'tol': 0.00789961235682093, 'validation_fraction': 0.138873438578221}
observation time 0.000005, current best -0.909890 at iter 27
suggestion time taken 19.862757 iter 28 next_points [{'alpha': 0.02512104829506446, 'batch_size': 151, 'beta_1': 0.9862768118299112, 'beta_2': 0.9990393763309656, 'epsilon': 3.020096450784091e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 3.0371515899383873e-05, 'tol': 1.0466739835320595e-05, 'validation_fraction': 0.15258523744756486}]
function_evaluation time 0.436491 value -0.472527 suggestion {'alpha': 0.02512104829506446, 'batch_size': 151, 'beta_1': 0.9862768118299112, 'beta_2': 0.9990393763309656, 'epsilon': 3.020096450784091e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 3.0371515899383873e-05, 'tol': 1.0466739835320595e-05, 'validation_fraction': 0.15258523744756486}
observation time 0.000006, current best -0.909890 at iter 28
suggestion time taken 21.427150 iter 29 next_points [{'alpha': 6.369375904039418e-05, 'batch_size': 30, 'beta_1': 0.9757849834922738, 'beta_2': 0.9989403074775006, 'epsilon': 1.0803947703482314e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0031728393549949755, 'tol': 0.0009149941792057645, 'validation_fraction': 0.21687808931068964}]
function_evaluation time 1.891067 value -0.896703 suggestion {'alpha': 6.369375904039418e-05, 'batch_size': 30, 'beta_1': 0.9757849834922738, 'beta_2': 0.9989403074775006, 'epsilon': 1.0803947703482314e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0031728393549949755, 'tol': 0.0009149941792057645, 'validation_fraction': 0.21687808931068964}
observation time 0.000004, current best -0.909890 at iter 29
suggestion time taken 19.787058 iter 30 next_points [{'alpha': 0.00021124831101013253, 'batch_size': 45, 'beta_1': 0.8807889641467389, 'beta_2': 0.9911499672445668, 'epsilon': 5.214156989876892e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.028980029212887455, 'tol': 0.0007527738935925732, 'validation_fraction': 0.6969329418635809}]
function_evaluation time 0.638742 value -0.914286 suggestion {'alpha': 0.00021124831101013253, 'batch_size': 45, 'beta_1': 0.8807889641467389, 'beta_2': 0.9911499672445668, 'epsilon': 5.214156989876892e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.028980029212887455, 'tol': 0.0007527738935925732, 'validation_fraction': 0.6969329418635809}
observation time 0.000007, current best -0.914286 at iter 30
suggestion time taken 21.479315 iter 31 next_points [{'alpha': 0.00031052016130219355, 'batch_size': 56, 'beta_1': 0.5125313549369197, 'beta_2': 0.9999931574004413, 'epsilon': 2.7768294839962008e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 3.620008466232735e-05, 'tol': 0.0938155471227898, 'validation_fraction': 0.43058690378924336}]
function_evaluation time 0.628828 value -0.525275 suggestion {'alpha': 0.00031052016130219355, 'batch_size': 56, 'beta_1': 0.5125313549369197, 'beta_2': 0.9999931574004413, 'epsilon': 2.7768294839962008e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 3.620008466232735e-05, 'tol': 0.0938155471227898, 'validation_fraction': 0.43058690378924336}
observation time 0.000008, current best -0.914286 at iter 31
suggestion time taken 19.779820 iter 32 next_points [{'alpha': 4.452390710498228, 'batch_size': 224, 'beta_1': 0.9185138464270031, 'beta_2': 0.9997454504465563, 'epsilon': 1.1227008069951772e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.00038633861598755693, 'tol': 0.06915479750152512, 'validation_fraction': 0.41981276870299944}]
function_evaluation time 0.298438 value -0.327473 suggestion {'alpha': 4.452390710498228, 'batch_size': 224, 'beta_1': 0.9185138464270031, 'beta_2': 0.9997454504465563, 'epsilon': 1.1227008069951772e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.00038633861598755693, 'tol': 0.06915479750152512, 'validation_fraction': 0.41981276870299944}
observation time 0.000006, current best -0.914286 at iter 32
suggestion time taken 21.295186 iter 33 next_points [{'alpha': 0.014429915582087768, 'batch_size': 112, 'beta_1': 0.893297186376209, 'beta_2': 0.9493365318265752, 'epsilon': 1.3234471066719124e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 1.2977262276886176e-05, 'tol': 0.026848892446973572, 'validation_fraction': 0.15617144456099633}]
function_evaluation time 0.569623 value -0.527473 suggestion {'alpha': 0.014429915582087768, 'batch_size': 112, 'beta_1': 0.893297186376209, 'beta_2': 0.9493365318265752, 'epsilon': 1.3234471066719124e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 1.2977262276886176e-05, 'tol': 0.026848892446973572, 'validation_fraction': 0.15617144456099633}
observation time 0.000006, current best -0.914286 at iter 33
suggestion time taken 20.394021 iter 34 next_points [{'alpha': 1.383870204401778e-05, 'batch_size': 227, 'beta_1': 0.9888857096965027, 'beta_2': 0.9324993671609123, 'epsilon': 5.107520195764827e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.013641481173537664, 'tol': 0.02394918948182495, 'validation_fraction': 0.4597670539584909}]
function_evaluation time 0.681672 value -0.848352 suggestion {'alpha': 1.383870204401778e-05, 'batch_size': 227, 'beta_1': 0.9888857096965027, 'beta_2': 0.9324993671609123, 'epsilon': 5.107520195764827e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.013641481173537664, 'tol': 0.02394918948182495, 'validation_fraction': 0.4597670539584909}
observation time 0.000006, current best -0.914286 at iter 34
suggestion time taken 21.700536 iter 35 next_points [{'alpha': 2.4439802550502777e-05, 'batch_size': 15, 'beta_1': 0.8287145514844119, 'beta_2': 0.9897793084531814, 'epsilon': 9.231170911122642e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.0011123709846058447, 'tol': 0.0001626083819545702, 'validation_fraction': 0.4989913281355704}]
function_evaluation time 2.968792 value -0.914286 suggestion {'alpha': 2.4439802550502777e-05, 'batch_size': 15, 'beta_1': 0.8287145514844119, 'beta_2': 0.9897793084531814, 'epsilon': 9.231170911122642e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.0011123709846058447, 'tol': 0.0001626083819545702, 'validation_fraction': 0.4989913281355704}
observation time 0.000005, current best -0.914286 at iter 35
suggestion time taken 20.047823 iter 36 next_points [{'alpha': 0.9958791258810605, 'batch_size': 90, 'beta_1': 0.9875871908249441, 'beta_2': 0.9999950408000514, 'epsilon': 3.3945647655949684e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0003992013303749445, 'tol': 0.0016518874744725106, 'validation_fraction': 0.31599055251903546}]
function_evaluation time 1.195602 value -0.753846 suggestion {'alpha': 0.9958791258810605, 'batch_size': 90, 'beta_1': 0.9875871908249441, 'beta_2': 0.9999950408000514, 'epsilon': 3.3945647655949684e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0003992013303749445, 'tol': 0.0016518874744725106, 'validation_fraction': 0.31599055251903546}
observation time 0.000004, current best -0.914286 at iter 36
suggestion time taken 18.796679 iter 37 next_points [{'alpha': 0.0007303926696769731, 'batch_size': 151, 'beta_1': 0.9383006199607883, 'beta_2': 0.9488023798284786, 'epsilon': 3.901588607928276e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0018495848380729947, 'tol': 0.040164486803172084, 'validation_fraction': 0.8101133332136182}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.255592 value -0.753846 suggestion {'alpha': 0.0007303926696769731, 'batch_size': 151, 'beta_1': 0.9383006199607883, 'beta_2': 0.9488023798284786, 'epsilon': 3.901588607928276e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0018495848380729947, 'tol': 0.040164486803172084, 'validation_fraction': 0.8101133332136182}
observation time 0.000005, current best -0.914286 at iter 37
suggestion time taken 15.906359 iter 38 next_points [{'alpha': 0.4977593354391707, 'batch_size': 32, 'beta_1': 0.676979671935809, 'beta_2': 0.9999966810855665, 'epsilon': 2.188080889964371e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0009160797852381852, 'tol': 0.02672007314184139, 'validation_fraction': 0.8079108841905429}]
function_evaluation time 0.457356 value -0.782418 suggestion {'alpha': 0.4977593354391707, 'batch_size': 32, 'beta_1': 0.676979671935809, 'beta_2': 0.9999966810855665, 'epsilon': 2.188080889964371e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0009160797852381852, 'tol': 0.02672007314184139, 'validation_fraction': 0.8079108841905429}
observation time 0.000004, current best -0.914286 at iter 38
suggestion time taken 15.013602 iter 39 next_points [{'alpha': 0.0014051211193759638, 'batch_size': 227, 'beta_1': 0.764481295845079, 'beta_2': 0.9999869763587399, 'epsilon': 2.511482403867756e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 1.5914764187948097e-05, 'tol': 1.959231901120476e-05, 'validation_fraction': 0.8315570300305146}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.217458 value -0.378022 suggestion {'alpha': 0.0014051211193759638, 'batch_size': 227, 'beta_1': 0.764481295845079, 'beta_2': 0.9999869763587399, 'epsilon': 2.511482403867756e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 1.5914764187948097e-05, 'tol': 1.959231901120476e-05, 'validation_fraction': 0.8315570300305146}
observation time 0.000005, current best -0.914286 at iter 39
suggestion time taken 15.956400 iter 40 next_points [{'alpha': 0.0003784842015158038, 'batch_size': 223, 'beta_1': 0.6973126668729454, 'beta_2': 0.9940915446204538, 'epsilon': 3.8920359984831264e-08, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.0006076901075564771, 'tol': 0.005916231930658791, 'validation_fraction': 0.7157856556685582}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.368498 value -0.659341 suggestion {'alpha': 0.0003784842015158038, 'batch_size': 223, 'beta_1': 0.6973126668729454, 'beta_2': 0.9940915446204538, 'epsilon': 3.8920359984831264e-08, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.0006076901075564771, 'tol': 0.005916231930658791, 'validation_fraction': 0.7157856556685582}
observation time 0.000005, current best -0.914286 at iter 40
suggestion time taken 15.756814 iter 41 next_points [{'alpha': 1.4992776693820298, 'batch_size': 151, 'beta_1': 0.5850963715288313, 'beta_2': 0.9999909333354615, 'epsilon': 8.758676754585837e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0035196411252716346, 'tol': 0.0030107654533553306, 'validation_fraction': 0.3606434893610447}]
function_evaluation time 0.479098 value -0.907692 suggestion {'alpha': 1.4992776693820298, 'batch_size': 151, 'beta_1': 0.5850963715288313, 'beta_2': 0.9999909333354615, 'epsilon': 8.758676754585837e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0035196411252716346, 'tol': 0.0030107654533553306, 'validation_fraction': 0.3606434893610447}
observation time 0.000004, current best -0.914286 at iter 41
suggestion time taken 15.867749 iter 42 next_points [{'alpha': 0.028188504221482714, 'batch_size': 14, 'beta_1': 0.8326081462083134, 'beta_2': 0.9994461289452514, 'epsilon': 1.493169500630463e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0006477293257914192, 'tol': 0.00011355099849904519, 'validation_fraction': 0.39549048392796726}]
function_evaluation time 2.775805 value -0.918681 suggestion {'alpha': 0.028188504221482714, 'batch_size': 14, 'beta_1': 0.8326081462083134, 'beta_2': 0.9994461289452514, 'epsilon': 1.493169500630463e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0006477293257914192, 'tol': 0.00011355099849904519, 'validation_fraction': 0.39549048392796726}
observation time 0.000004, current best -0.918681 at iter 42
suggestion time taken 19.608793 iter 43 next_points [{'alpha': 5.8554728275355, 'batch_size': 227, 'beta_1': 0.8437188441250992, 'beta_2': 0.9104986240910085, 'epsilon': 1.0999660205338793e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.021922071586805068, 'tol': 0.0006169334677752293, 'validation_fraction': 0.6517841524021559}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.688319 value -0.841758 suggestion {'alpha': 5.8554728275355, 'batch_size': 227, 'beta_1': 0.8437188441250992, 'beta_2': 0.9104986240910085, 'epsilon': 1.0999660205338793e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.021922071586805068, 'tol': 0.0006169334677752293, 'validation_fraction': 0.6517841524021559}
observation time 0.000004, current best -0.918681 at iter 43
suggestion time taken 19.987794 iter 44 next_points [{'alpha': 0.10064842806096941, 'batch_size': 227, 'beta_1': 0.9547843015240827, 'beta_2': 0.998846705627832, 'epsilon': 3.167435206885651e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0033232681400493565, 'tol': 1.3970065575106634e-05, 'validation_fraction': 0.15338813293752496}]
function_evaluation time 0.848581 value -0.907692 suggestion {'alpha': 0.10064842806096941, 'batch_size': 227, 'beta_1': 0.9547843015240827, 'beta_2': 0.998846705627832, 'epsilon': 3.167435206885651e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.0033232681400493565, 'tol': 1.3970065575106634e-05, 'validation_fraction': 0.15338813293752496}
observation time 0.000005, current best -0.918681 at iter 44
saving meta data: {'args': {'--uuid': '5d568d4eb809574a9a2ef2808e76542d', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
