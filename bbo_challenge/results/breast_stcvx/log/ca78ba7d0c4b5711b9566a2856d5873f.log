running: {'--uuid': 'ca78ba7d0c4b5711b9566a2856d5873f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u ca78ba7d0c4b5711b9566a2856d5873f -m nll -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast nll 45 1
with data root: None
suggestion time taken 0.010384 iter 0 next_points [{'alpha': 0.007322187019813375, 'batch_size': 20, 'beta_1': 0.9835636323045461, 'beta_2': 0.9999921543921815, 'epsilon': 6.77069680250817e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.0003819144069467597, 'tol': 0.0001925119196979227, 'validation_fraction': 0.13539947436309943}]
function_evaluation time 1.214939 value 0.948918 suggestion {'alpha': 0.007322187019813375, 'batch_size': 20, 'beta_1': 0.9835636323045461, 'beta_2': 0.9999921543921815, 'epsilon': 6.77069680250817e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.0003819144069467597, 'tol': 0.0001925119196979227, 'validation_fraction': 0.13539947436309943}
observation time 0.000004, current best 0.948918 at iter 0
suggestion time taken 0.010396 iter 1 next_points [{'alpha': 0.1152287265329965, 'batch_size': 178, 'beta_1': 0.5383627729457137, 'beta_2': 0.9486081519980305, 'epsilon': 1.811224434806373e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0016901168057790526, 'tol': 2.4653040887995832e-05, 'validation_fraction': 0.8784706800486638}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.468262 value 0.737828 suggestion {'alpha': 0.1152287265329965, 'batch_size': 178, 'beta_1': 0.5383627729457137, 'beta_2': 0.9486081519980305, 'epsilon': 1.811224434806373e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0016901168057790526, 'tol': 2.4653040887995832e-05, 'validation_fraction': 0.8784706800486638}
observation time 0.000003, current best 0.737828 at iter 1
suggestion time taken 0.010335 iter 2 next_points [{'alpha': 0.00014647504290415394, 'batch_size': 37, 'beta_1': 0.8212069030041488, 'beta_2': 0.999975685304561, 'epsilon': 3.63518969643338e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0005815548509592179, 'tol': 0.00026282945505936753, 'validation_fraction': 0.15120778630926612}]
function_evaluation time 0.746581 value 0.378499 suggestion {'alpha': 0.00014647504290415394, 'batch_size': 37, 'beta_1': 0.8212069030041488, 'beta_2': 0.999975685304561, 'epsilon': 3.63518969643338e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.0005815548509592179, 'tol': 0.00026282945505936753, 'validation_fraction': 0.15120778630926612}
observation time 0.000002, current best 0.378499 at iter 2
suggestion time taken 0.003888 iter 3 next_points [{'alpha': 0.0003206052195597991, 'batch_size': 119, 'beta_1': 0.9865319267711549, 'beta_2': 0.9999983712489727, 'epsilon': 7.35496016011121e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 2.423732544558563e-05, 'tol': 2.226147244934624e-05, 'validation_fraction': 0.24602688857568447}]
function_evaluation time 0.381912 value 12.510778 suggestion {'alpha': 0.0003206052195597991, 'batch_size': 119, 'beta_1': 0.9865319267711549, 'beta_2': 0.9999983712489727, 'epsilon': 7.35496016011121e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 2.423732544558563e-05, 'tol': 2.226147244934624e-05, 'validation_fraction': 0.24602688857568447}
observation time 0.000003, current best 0.378499 at iter 3
suggestion time taken 0.010295 iter 4 next_points [{'alpha': 1.4076873969849477e-05, 'batch_size': 132, 'beta_1': 0.7563472381679909, 'beta_2': 0.9997460551113627, 'epsilon': 2.447916329840728e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.005148382818119461, 'tol': 0.06012324440779552, 'validation_fraction': 0.12062999890321992}]
function_evaluation time 0.565088 value 0.576684 suggestion {'alpha': 1.4076873969849477e-05, 'batch_size': 132, 'beta_1': 0.7563472381679909, 'beta_2': 0.9997460551113627, 'epsilon': 2.447916329840728e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.005148382818119461, 'tol': 0.06012324440779552, 'validation_fraction': 0.12062999890321992}
observation time 0.000003, current best 0.378499 at iter 4
suggestion time taken 0.010425 iter 5 next_points [{'alpha': 1.6566475714531607e-05, 'batch_size': 237, 'beta_1': 0.9699429961205611, 'beta_2': 0.972705102428252, 'epsilon': 1.4643188620468206e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.005826137185520318, 'tol': 2.7485661004865943e-05, 'validation_fraction': 0.25454408411187646}]
function_evaluation time 0.692923 value 0.748709 suggestion {'alpha': 1.6566475714531607e-05, 'batch_size': 237, 'beta_1': 0.9699429961205611, 'beta_2': 0.972705102428252, 'epsilon': 1.4643188620468206e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.005826137185520318, 'tol': 2.7485661004865943e-05, 'validation_fraction': 0.25454408411187646}
observation time 0.000002, current best 0.378499 at iter 5
suggestion time taken 0.010365 iter 6 next_points [{'alpha': 0.07341834254474493, 'batch_size': 169, 'beta_1': 0.9563086657322452, 'beta_2': 0.9999975983380637, 'epsilon': 7.950549018003386e-07, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.022462673738898785, 'tol': 0.0027995798078530305, 'validation_fraction': 0.31031820423843415}]
function_evaluation time 0.726183 value 0.941045 suggestion {'alpha': 0.07341834254474493, 'batch_size': 169, 'beta_1': 0.9563086657322452, 'beta_2': 0.9999975983380637, 'epsilon': 7.950549018003386e-07, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.022462673738898785, 'tol': 0.0027995798078530305, 'validation_fraction': 0.31031820423843415}
observation time 0.000003, current best 0.378499 at iter 6
suggestion time taken 0.010286 iter 7 next_points [{'alpha': 0.0014445350865552723, 'batch_size': 58, 'beta_1': 0.9626456420393055, 'beta_2': 0.9999450824896853, 'epsilon': 8.142437005087817e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 4.45283225026914e-05, 'tol': 0.008101815849973533, 'validation_fraction': 0.8409106742622442}]
function_evaluation time 0.257879 value 18.003184 suggestion {'alpha': 0.0014445350865552723, 'batch_size': 58, 'beta_1': 0.9626456420393055, 'beta_2': 0.9999450824896853, 'epsilon': 8.142437005087817e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 4.45283225026914e-05, 'tol': 0.008101815849973533, 'validation_fraction': 0.8409106742622442}
observation time 0.000003, current best 0.378499 at iter 7
suggestion time taken 0.010245 iter 8 next_points [{'alpha': 0.00010602629083553693, 'batch_size': 167, 'beta_1': 0.7969512996591105, 'beta_2': 0.991491360283373, 'epsilon': 1.963864819110128e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.00012754996526104256, 'tol': 0.0007152265295985354, 'validation_fraction': 0.6128479314514541}]
function_evaluation time 0.303877 value 13.837549 suggestion {'alpha': 0.00010602629083553693, 'batch_size': 167, 'beta_1': 0.7969512996591105, 'beta_2': 0.991491360283373, 'epsilon': 1.963864819110128e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.00012754996526104256, 'tol': 0.0007152265295985354, 'validation_fraction': 0.6128479314514541}
observation time 0.000003, current best 0.378499 at iter 8
suggestion time taken 0.010379 iter 9 next_points [{'alpha': 0.3586821333893004, 'batch_size': 102, 'beta_1': 0.9610539549875842, 'beta_2': 0.9902740326696957, 'epsilon': 1.4111358521321606e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.017348213916459437, 'tol': 5.473945224201052e-05, 'validation_fraction': 0.1577692858650683}]
function_evaluation time 0.726523 value 1.078344 suggestion {'alpha': 0.3586821333893004, 'batch_size': 102, 'beta_1': 0.9610539549875842, 'beta_2': 0.9902740326696957, 'epsilon': 1.4111358521321606e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.017348213916459437, 'tol': 5.473945224201052e-05, 'validation_fraction': 0.1577692858650683}
observation time 0.000003, current best 0.378499 at iter 9
suggestion time taken 0.010294 iter 10 next_points [{'alpha': 1.8231572849698936, 'batch_size': 236, 'beta_1': 0.8773130380079546, 'beta_2': 0.9990804563329552, 'epsilon': 4.231383890607422e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 7.291800046894325e-05, 'tol': 0.07211034264370787, 'validation_fraction': 0.5779557984019659}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.285499 value 15.974521 suggestion {'alpha': 1.8231572849698936, 'batch_size': 236, 'beta_1': 0.8773130380079546, 'beta_2': 0.9990804563329552, 'epsilon': 4.231383890607422e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 7.291800046894325e-05, 'tol': 0.07211034264370787, 'validation_fraction': 0.5779557984019659}
observation time 0.000003, current best 0.378499 at iter 10
suggestion time taken 0.010372 iter 11 next_points [{'alpha': 0.04558668337641861, 'batch_size': 240, 'beta_1': 0.9537087819874045, 'beta_2': 0.9999869628340542, 'epsilon': 3.5117602041167397e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.6982695710953247e-05, 'tol': 0.00010544438893698389, 'validation_fraction': 0.18468481513431545}]
function_evaluation time 0.435525 value 13.343179 suggestion {'alpha': 0.04558668337641861, 'batch_size': 240, 'beta_1': 0.9537087819874045, 'beta_2': 0.9999869628340542, 'epsilon': 3.5117602041167397e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.6982695710953247e-05, 'tol': 0.00010544438893698389, 'validation_fraction': 0.18468481513431545}
observation time 0.000003, current best 0.378499 at iter 11
suggestion time taken 0.010349 iter 12 next_points [{'alpha': 0.0006923289416610295, 'batch_size': 218, 'beta_1': 0.9884020893371712, 'beta_2': 0.9999222820071121, 'epsilon': 1.0012839452185407e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.0058720751600810405, 'tol': 0.000548475446835613, 'validation_fraction': 0.18768332237017823}]
function_evaluation time 0.678144 value 1.270739 suggestion {'alpha': 0.0006923289416610295, 'batch_size': 218, 'beta_1': 0.9884020893371712, 'beta_2': 0.9999222820071121, 'epsilon': 1.0012839452185407e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.0058720751600810405, 'tol': 0.000548475446835613, 'validation_fraction': 0.18768332237017823}
observation time 0.000003, current best 0.378499 at iter 12
suggestion time taken 0.010446 iter 13 next_points [{'alpha': 0.40136492846315847, 'batch_size': 22, 'beta_1': 0.5501940875459276, 'beta_2': 0.9999615307514497, 'epsilon': 5.353494334959954e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0018723095082921984, 'tol': 0.001006338577093057, 'validation_fraction': 0.19527620027907497}]
function_evaluation time 1.728572 value 0.400977 suggestion {'alpha': 0.40136492846315847, 'batch_size': 22, 'beta_1': 0.5501940875459276, 'beta_2': 0.9999615307514497, 'epsilon': 5.353494334959954e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0018723095082921984, 'tol': 0.001006338577093057, 'validation_fraction': 0.19527620027907497}
observation time 0.000003, current best 0.378499 at iter 13
suggestion time taken 0.010325 iter 14 next_points [{'alpha': 1.9315389899480644, 'batch_size': 133, 'beta_1': 0.6512307601363455, 'beta_2': 0.9999973220892325, 'epsilon': 5.4058491585501805e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.00023139555458475547, 'tol': 0.08438218666069518, 'validation_fraction': 0.13049892782100214}]
function_evaluation time 0.426448 value 9.546003 suggestion {'alpha': 1.9315389899480644, 'batch_size': 133, 'beta_1': 0.6512307601363455, 'beta_2': 0.9999973220892325, 'epsilon': 5.4058491585501805e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.00023139555458475547, 'tol': 0.08438218666069518, 'validation_fraction': 0.13049892782100214}
observation time 0.000003, current best 0.378499 at iter 14
suggestion time taken 0.010362 iter 15 next_points [{'alpha': 2.537847379836183e-05, 'batch_size': 100, 'beta_1': 0.5545612773523252, 'beta_2': 0.9999321960837072, 'epsilon': 6.969523078660665e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.5041861090332988e-05, 'tol': 1.573585618370788e-05, 'validation_fraction': 0.8050249236996951}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.226875 value 17.152910 suggestion {'alpha': 2.537847379836183e-05, 'batch_size': 100, 'beta_1': 0.5545612773523252, 'beta_2': 0.9999321960837072, 'epsilon': 6.969523078660665e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 1.5041861090332988e-05, 'tol': 1.573585618370788e-05, 'validation_fraction': 0.8050249236996951}
observation time 0.000003, current best 0.378499 at iter 15
suggestion time taken 0.010281 iter 16 next_points [{'alpha': 1.0091156132974148, 'batch_size': 128, 'beta_1': 0.9389644043905502, 'beta_2': 0.9999935172485561, 'epsilon': 1.356446338117922e-07, 'hidden_layer_sizes': 68, 'learning_rate_init': 4.361099552833403e-05, 'tol': 0.020622612829818112, 'validation_fraction': 0.5911229523369973}]
function_evaluation time 0.285870 value 17.339341 suggestion {'alpha': 1.0091156132974148, 'batch_size': 128, 'beta_1': 0.9389644043905502, 'beta_2': 0.9999935172485561, 'epsilon': 1.356446338117922e-07, 'hidden_layer_sizes': 68, 'learning_rate_init': 4.361099552833403e-05, 'tol': 0.020622612829818112, 'validation_fraction': 0.5911229523369973}
observation time 0.000003, current best 0.378499 at iter 16
suggestion time taken 0.010298 iter 17 next_points [{'alpha': 0.027149957280130945, 'batch_size': 220, 'beta_1': 0.9233955578861228, 'beta_2': 0.9864780966722876, 'epsilon': 2.0969842639661435e-07, 'hidden_layer_sizes': 200, 'learning_rate_init': 6.158638477209597e-05, 'tol': 0.0035528518640020362, 'validation_fraction': 0.3688886595971885}]
function_evaluation time 0.412901 value 12.014007 suggestion {'alpha': 0.027149957280130945, 'batch_size': 220, 'beta_1': 0.9233955578861228, 'beta_2': 0.9864780966722876, 'epsilon': 2.0969842639661435e-07, 'hidden_layer_sizes': 200, 'learning_rate_init': 6.158638477209597e-05, 'tol': 0.0035528518640020362, 'validation_fraction': 0.3688886595971885}
observation time 0.000003, current best 0.378499 at iter 17
suggestion time taken 0.010958 iter 18 next_points [{'alpha': 0.07132981790335129, 'batch_size': 227, 'beta_1': 0.6838712438071157, 'beta_2': 0.9997049287774536, 'epsilon': 7.454605368103781e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 5.609324029451113e-05, 'tol': 0.07861329398268957, 'validation_fraction': 0.5475269117688101}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.288893 value 14.312269 suggestion {'alpha': 0.07132981790335129, 'batch_size': 227, 'beta_1': 0.6838712438071157, 'beta_2': 0.9997049287774536, 'epsilon': 7.454605368103781e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 5.609324029451113e-05, 'tol': 0.07861329398268957, 'validation_fraction': 0.5475269117688101}
observation time 0.000003, current best 0.378499 at iter 18
suggestion time taken 0.010763 iter 19 next_points [{'alpha': 0.10422284095793104, 'batch_size': 237, 'beta_1': 0.561100336019581, 'beta_2': 0.9999674658430081, 'epsilon': 7.2159738536549015e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.002504112779559349, 'tol': 0.0017270513811464946, 'validation_fraction': 0.18611516961155503}]
function_evaluation time 0.789805 value 0.507095 suggestion {'alpha': 0.10422284095793104, 'batch_size': 237, 'beta_1': 0.561100336019581, 'beta_2': 0.9999674658430081, 'epsilon': 7.2159738536549015e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.002504112779559349, 'tol': 0.0017270513811464946, 'validation_fraction': 0.18611516961155503}
observation time 0.000003, current best 0.378499 at iter 19
suggestion time taken 0.010466 iter 20 next_points [{'alpha': 1.6060640904939927e-05, 'batch_size': 133, 'beta_1': 0.5186942472020444, 'beta_2': 0.9999369807613709, 'epsilon': 3.279169020630998e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0016530715916360345, 'tol': 0.004555918402871442, 'validation_fraction': 0.8201437254909985}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.430408 value 2.846902 suggestion {'alpha': 1.6060640904939927e-05, 'batch_size': 133, 'beta_1': 0.5186942472020444, 'beta_2': 0.9999369807613709, 'epsilon': 3.279169020630998e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0016530715916360345, 'tol': 0.004555918402871442, 'validation_fraction': 0.8201437254909985}
observation time 0.000003, current best 0.378499 at iter 20
suggestion time taken 0.010406 iter 21 next_points [{'alpha': 3.027454914404781, 'batch_size': 208, 'beta_1': 0.5604138428860903, 'beta_2': 0.999984529092378, 'epsilon': 4.144680387918869e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0020902343722445644, 'tol': 0.009257373413759946, 'validation_fraction': 0.6272466022753963}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.483927 value 0.773777 suggestion {'alpha': 3.027454914404781, 'batch_size': 208, 'beta_1': 0.5604138428860903, 'beta_2': 0.999984529092378, 'epsilon': 4.144680387918869e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0020902343722445644, 'tol': 0.009257373413759946, 'validation_fraction': 0.6272466022753963}
observation time 0.000003, current best 0.378499 at iter 21
suggestion time taken 0.010350 iter 22 next_points [{'alpha': 2.480127967833738, 'batch_size': 72, 'beta_1': 0.9790810188959406, 'beta_2': 0.9999962571006916, 'epsilon': 2.112015868635566e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.024703564368595998, 'tol': 0.00035869241989472796, 'validation_fraction': 0.6578391133599951}]
function_evaluation time 0.834564 value 1.229437 suggestion {'alpha': 2.480127967833738, 'batch_size': 72, 'beta_1': 0.9790810188959406, 'beta_2': 0.9999962571006916, 'epsilon': 2.112015868635566e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.024703564368595998, 'tol': 0.00035869241989472796, 'validation_fraction': 0.6578391133599951}
observation time 0.000003, current best 0.378499 at iter 22
suggestion time taken 0.010254 iter 23 next_points [{'alpha': 0.0015517393285909141, 'batch_size': 77, 'beta_1': 0.9408441304666048, 'beta_2': 0.9989274329955442, 'epsilon': 2.4500446614209713e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0032387176852209858, 'tol': 7.029716840332226e-05, 'validation_fraction': 0.16239653098580245}]
function_evaluation time 0.973965 value 0.623022 suggestion {'alpha': 0.0015517393285909141, 'batch_size': 77, 'beta_1': 0.9408441304666048, 'beta_2': 0.9989274329955442, 'epsilon': 2.4500446614209713e-08, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.0032387176852209858, 'tol': 7.029716840332226e-05, 'validation_fraction': 0.16239653098580245}
observation time 0.000003, current best 0.378499 at iter 23
suggestion time taken 0.010285 iter 24 next_points [{'alpha': 0.00235538452685258, 'batch_size': 109, 'beta_1': 0.8313700394754404, 'beta_2': 0.9993557074525135, 'epsilon': 5.350922093768153e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00012512391792379097, 'tol': 2.755247487408266e-05, 'validation_fraction': 0.8980159842581157}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.208066 value 20.068202 suggestion {'alpha': 0.00235538452685258, 'batch_size': 109, 'beta_1': 0.8313700394754404, 'beta_2': 0.9993557074525135, 'epsilon': 5.350922093768153e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00012512391792379097, 'tol': 2.755247487408266e-05, 'validation_fraction': 0.8980159842581157}
observation time 0.000003, current best 0.378499 at iter 24
suggestion time taken 0.010275 iter 25 next_points [{'alpha': 1.3138490123840417e-05, 'batch_size': 77, 'beta_1': 0.5480717902280591, 'beta_2': 0.9995125641418301, 'epsilon': 3.8957589699412865e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.05053811372312505, 'tol': 0.027349513324505106, 'validation_fraction': 0.860347812511947}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.377666 value 0.468021 suggestion {'alpha': 1.3138490123840417e-05, 'batch_size': 77, 'beta_1': 0.5480717902280591, 'beta_2': 0.9995125641418301, 'epsilon': 3.8957589699412865e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.05053811372312505, 'tol': 0.027349513324505106, 'validation_fraction': 0.860347812511947}
observation time 0.000003, current best 0.378499 at iter 25
suggestion time taken 0.010378 iter 26 next_points [{'alpha': 0.01657789741705662, 'batch_size': 115, 'beta_1': 0.9346489697079148, 'beta_2': 0.9999951552961164, 'epsilon': 4.4248723626041463e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.0001632912542198307, 'tol': 0.02845376846827922, 'validation_fraction': 0.3544917564757538}]
function_evaluation time 0.484429 value 11.495598 suggestion {'alpha': 0.01657789741705662, 'batch_size': 115, 'beta_1': 0.9346489697079148, 'beta_2': 0.9999951552961164, 'epsilon': 4.4248723626041463e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.0001632912542198307, 'tol': 0.02845376846827922, 'validation_fraction': 0.3544917564757538}
observation time 0.000004, current best 0.378499 at iter 26
suggestion time taken 0.010345 iter 27 next_points [{'alpha': 0.277692662166937, 'batch_size': 245, 'beta_1': 0.9715322558833434, 'beta_2': 0.9999963393558731, 'epsilon': 3.876919497994009e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 2.1697481527536373e-05, 'tol': 0.0007289793102360856, 'validation_fraction': 0.5835665720222222}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.276995 value 20.072276 suggestion {'alpha': 0.277692662166937, 'batch_size': 245, 'beta_1': 0.9715322558833434, 'beta_2': 0.9999963393558731, 'epsilon': 3.876919497994009e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 2.1697481527536373e-05, 'tol': 0.0007289793102360856, 'validation_fraction': 0.5835665720222222}
observation time 0.000003, current best 0.378499 at iter 27
suggestion time taken 0.010381 iter 28 next_points [{'alpha': 0.0001714616005289335, 'batch_size': 73, 'beta_1': 0.9169658595240715, 'beta_2': 0.9993285026104984, 'epsilon': 1.3096838141710049e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 1.2341710777206897e-05, 'tol': 0.0001126174785761806, 'validation_fraction': 0.13369419914259423}]
function_evaluation time 0.957633 value 9.182498 suggestion {'alpha': 0.0001714616005289335, 'batch_size': 73, 'beta_1': 0.9169658595240715, 'beta_2': 0.9993285026104984, 'epsilon': 1.3096838141710049e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 1.2341710777206897e-05, 'tol': 0.0001126174785761806, 'validation_fraction': 0.13369419914259423}
observation time 0.000004, current best 0.378499 at iter 28
suggestion time taken 0.010176 iter 29 next_points [{'alpha': 0.024005157901166054, 'batch_size': 46, 'beta_1': 0.7029277200204898, 'beta_2': 0.9999924360002354, 'epsilon': 1.0825976775516811e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.018759761448962887, 'tol': 0.00015675806951406362, 'validation_fraction': 0.11976668843115658}]
function_evaluation time 0.850118 value 0.757901 suggestion {'alpha': 0.024005157901166054, 'batch_size': 46, 'beta_1': 0.7029277200204898, 'beta_2': 0.9999924360002354, 'epsilon': 1.0825976775516811e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.018759761448962887, 'tol': 0.00015675806951406362, 'validation_fraction': 0.11976668843115658}
observation time 0.000003, current best 0.378499 at iter 29
suggestion time taken 0.010248 iter 30 next_points [{'alpha': 0.022884027500480714, 'batch_size': 213, 'beta_1': 0.930705620841525, 'beta_2': 0.9999988199926029, 'epsilon': 4.772449131328993e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.05214645125619144, 'tol': 2.8865006426447715e-05, 'validation_fraction': 0.19672268308379812}]
function_evaluation time 0.662964 value 0.591852 suggestion {'alpha': 0.022884027500480714, 'batch_size': 213, 'beta_1': 0.930705620841525, 'beta_2': 0.9999988199926029, 'epsilon': 4.772449131328993e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.05214645125619144, 'tol': 2.8865006426447715e-05, 'validation_fraction': 0.19672268308379812}
observation time 0.000003, current best 0.378499 at iter 30
suggestion time taken 0.010676 iter 31 next_points [{'alpha': 0.003312723470941226, 'batch_size': 176, 'beta_1': 0.9568668325432003, 'beta_2': 0.9957985678442409, 'epsilon': 1.0010332104444618e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0003297336932844263, 'tol': 0.01059203987623082, 'validation_fraction': 0.18438468545241546}]
function_evaluation time 0.609208 value 8.799715 suggestion {'alpha': 0.003312723470941226, 'batch_size': 176, 'beta_1': 0.9568668325432003, 'beta_2': 0.9957985678442409, 'epsilon': 1.0010332104444618e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0003297336932844263, 'tol': 0.01059203987623082, 'validation_fraction': 0.18438468545241546}
observation time 0.000003, current best 0.378499 at iter 31
suggestion time taken 0.010244 iter 32 next_points [{'alpha': 2.784646979847674e-05, 'batch_size': 104, 'beta_1': 0.7844493629942393, 'beta_2': 0.9925610106184065, 'epsilon': 1.3936570202679313e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.03559533356124608, 'tol': 0.00011665444907695683, 'validation_fraction': 0.6624566698338283}]
function_evaluation time 0.634742 value 0.997817 suggestion {'alpha': 2.784646979847674e-05, 'batch_size': 104, 'beta_1': 0.7844493629942393, 'beta_2': 0.9925610106184065, 'epsilon': 1.3936570202679313e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.03559533356124608, 'tol': 0.00011665444907695683, 'validation_fraction': 0.6624566698338283}
observation time 0.000003, current best 0.378499 at iter 32
suggestion time taken 0.010375 iter 33 next_points [{'alpha': 0.00019509459901132685, 'batch_size': 156, 'beta_1': 0.9712725805273207, 'beta_2': 0.9888674042545302, 'epsilon': 1.0399792674322591e-09, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.026028163071030862, 'tol': 0.0004745606018635941, 'validation_fraction': 0.11693661878198018}]
function_evaluation time 0.836867 value 0.857473 suggestion {'alpha': 0.00019509459901132685, 'batch_size': 156, 'beta_1': 0.9712725805273207, 'beta_2': 0.9888674042545302, 'epsilon': 1.0399792674322591e-09, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.026028163071030862, 'tol': 0.0004745606018635941, 'validation_fraction': 0.11693661878198018}
observation time 0.000003, current best 0.378499 at iter 33
suggestion time taken 0.010215 iter 34 next_points [{'alpha': 0.06428537020650678, 'batch_size': 183, 'beta_1': 0.939682218545755, 'beta_2': 0.999998968643477, 'epsilon': 2.5638748554628265e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.014120158000510563, 'tol': 0.03960835611121984, 'validation_fraction': 0.1855349534401021}]
function_evaluation time 0.621554 value 1.328057 suggestion {'alpha': 0.06428537020650678, 'batch_size': 183, 'beta_1': 0.939682218545755, 'beta_2': 0.999998968643477, 'epsilon': 2.5638748554628265e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.014120158000510563, 'tol': 0.03960835611121984, 'validation_fraction': 0.1855349534401021}
observation time 0.000003, current best 0.378499 at iter 34
suggestion time taken 0.010269 iter 35 next_points [{'alpha': 0.0009032138479050522, 'batch_size': 38, 'beta_1': 0.9390444114342353, 'beta_2': 0.9574395344724389, 'epsilon': 3.2984019362759795e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 1.0019066024290766e-05, 'tol': 8.553229235601266e-05, 'validation_fraction': 0.4944395051992602}]
function_evaluation time 0.492411 value 16.712739 suggestion {'alpha': 0.0009032138479050522, 'batch_size': 38, 'beta_1': 0.9390444114342353, 'beta_2': 0.9574395344724389, 'epsilon': 3.2984019362759795e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 1.0019066024290766e-05, 'tol': 8.553229235601266e-05, 'validation_fraction': 0.4944395051992602}
observation time 0.000003, current best 0.378499 at iter 35
suggestion time taken 0.010213 iter 36 next_points [{'alpha': 0.0011000071666384917, 'batch_size': 228, 'beta_1': 0.9199610150000287, 'beta_2': 0.9960202813624911, 'epsilon': 2.4618412519698575e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0006548750245265878, 'tol': 0.0015827528550981503, 'validation_fraction': 0.11480560775861799}]
function_evaluation time 0.795309 value 2.777820 suggestion {'alpha': 0.0011000071666384917, 'batch_size': 228, 'beta_1': 0.9199610150000287, 'beta_2': 0.9960202813624911, 'epsilon': 2.4618412519698575e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.0006548750245265878, 'tol': 0.0015827528550981503, 'validation_fraction': 0.11480560775861799}
observation time 0.000003, current best 0.378499 at iter 36
suggestion time taken 0.010334 iter 37 next_points [{'alpha': 0.000810039819141485, 'batch_size': 188, 'beta_1': 0.970992753144926, 'beta_2': 0.9994542645038634, 'epsilon': 1.0409084908591331e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.016677430097324798, 'tol': 4.0721827840892156e-05, 'validation_fraction': 0.6711503310188085}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.471088 value 0.980855 suggestion {'alpha': 0.000810039819141485, 'batch_size': 188, 'beta_1': 0.970992753144926, 'beta_2': 0.9994542645038634, 'epsilon': 1.0409084908591331e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.016677430097324798, 'tol': 4.0721827840892156e-05, 'validation_fraction': 0.6711503310188085}
observation time 0.000002, current best 0.378499 at iter 37
suggestion time taken 0.010254 iter 38 next_points [{'alpha': 0.00024341099052466625, 'batch_size': 14, 'beta_1': 0.9676267121793493, 'beta_2': 0.9915002555735396, 'epsilon': 9.95519966282543e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.008314736308613147, 'tol': 6.93651555677263e-05, 'validation_fraction': 0.8891901774997492}]
function_evaluation time 0.795170 value 0.741967 suggestion {'alpha': 0.00024341099052466625, 'batch_size': 14, 'beta_1': 0.9676267121793493, 'beta_2': 0.9915002555735396, 'epsilon': 9.95519966282543e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.008314736308613147, 'tol': 6.93651555677263e-05, 'validation_fraction': 0.8891901774997492}
observation time 0.000003, current best 0.378499 at iter 38
suggestion time taken 0.010300 iter 39 next_points [{'alpha': 0.08983901753036569, 'batch_size': 74, 'beta_1': 0.8995891358652223, 'beta_2': 0.9999936484066282, 'epsilon': 3.3581427388052153e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 5.6394320592912734e-05, 'tol': 0.0004270103581636628, 'validation_fraction': 0.127613078049981}]
function_evaluation time 0.936798 value 5.228331 suggestion {'alpha': 0.08983901753036569, 'batch_size': 74, 'beta_1': 0.8995891358652223, 'beta_2': 0.9999936484066282, 'epsilon': 3.3581427388052153e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 5.6394320592912734e-05, 'tol': 0.0004270103581636628, 'validation_fraction': 0.127613078049981}
observation time 0.000003, current best 0.378499 at iter 39
suggestion time taken 0.010148 iter 40 next_points [{'alpha': 0.023587926575144715, 'batch_size': 160, 'beta_1': 0.9747842522620135, 'beta_2': 0.9999986331515383, 'epsilon': 5.042950880549539e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0023372020410655945, 'tol': 0.029223978889857477, 'validation_fraction': 0.5867420015704081}]
function_evaluation time 0.301270 value 10.159211 suggestion {'alpha': 0.023587926575144715, 'batch_size': 160, 'beta_1': 0.9747842522620135, 'beta_2': 0.9999986331515383, 'epsilon': 5.042950880549539e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0023372020410655945, 'tol': 0.029223978889857477, 'validation_fraction': 0.5867420015704081}
observation time 0.000003, current best 0.378499 at iter 40
suggestion time taken 0.010265 iter 41 next_points [{'alpha': 1.2827157009901106e-05, 'batch_size': 155, 'beta_1': 0.5492202430431476, 'beta_2': 0.9990694149381263, 'epsilon': 3.8130729053536316e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 1.816040886474431e-05, 'tol': 0.0014133240725286256, 'validation_fraction': 0.19432655949363342}]
function_evaluation time 0.494170 value 15.608545 suggestion {'alpha': 1.2827157009901106e-05, 'batch_size': 155, 'beta_1': 0.5492202430431476, 'beta_2': 0.9990694149381263, 'epsilon': 3.8130729053536316e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 1.816040886474431e-05, 'tol': 0.0014133240725286256, 'validation_fraction': 0.19432655949363342}
observation time 0.000003, current best 0.378499 at iter 41
suggestion time taken 0.010268 iter 42 next_points [{'alpha': 5.60869660427638e-05, 'batch_size': 85, 'beta_1': 0.5580231035834439, 'beta_2': 0.9999263923827966, 'epsilon': 4.125370426497122e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0003979874260730014, 'tol': 7.50612684472257e-05, 'validation_fraction': 0.47538043683139386}]
function_evaluation time 0.534638 value 5.545660 suggestion {'alpha': 5.60869660427638e-05, 'batch_size': 85, 'beta_1': 0.5580231035834439, 'beta_2': 0.9999263923827966, 'epsilon': 4.125370426497122e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0003979874260730014, 'tol': 7.50612684472257e-05, 'validation_fraction': 0.47538043683139386}
observation time 0.000003, current best 0.378499 at iter 42
suggestion time taken 0.010348 iter 43 next_points [{'alpha': 6.908695985371769, 'batch_size': 104, 'beta_1': 0.934695895117145, 'beta_2': 0.9999746545658318, 'epsilon': 1.2065221693168872e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.05437856773414871, 'tol': 0.0017076700473609872, 'validation_fraction': 0.1396133813626284}]
function_evaluation time 0.976567 value 0.508080 suggestion {'alpha': 6.908695985371769, 'batch_size': 104, 'beta_1': 0.934695895117145, 'beta_2': 0.9999746545658318, 'epsilon': 1.2065221693168872e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.05437856773414871, 'tol': 0.0017076700473609872, 'validation_fraction': 0.1396133813626284}
observation time 0.000003, current best 0.378499 at iter 43
suggestion time taken 0.010326 iter 44 next_points [{'alpha': 7.598809223785673e-05, 'batch_size': 80, 'beta_1': 0.7877007080263098, 'beta_2': 0.9999859428365054, 'epsilon': 4.628239276038842e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.0019871979900794212, 'tol': 0.0004261648716925222, 'validation_fraction': 0.16284440992147653}]
function_evaluation time 0.855213 value 0.411832 suggestion {'alpha': 7.598809223785673e-05, 'batch_size': 80, 'beta_1': 0.7877007080263098, 'beta_2': 0.9999859428365054, 'epsilon': 4.628239276038842e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.0019871979900794212, 'tol': 0.0004261648716925222, 'validation_fraction': 0.16284440992147653}
observation time 0.000003, current best 0.378499 at iter 44
saving meta data: {'args': {'--uuid': 'ca78ba7d0c4b5711b9566a2856d5873f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])}
saving results
saving timing
saving suggest log
done
