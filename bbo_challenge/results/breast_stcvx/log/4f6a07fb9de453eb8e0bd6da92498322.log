running: {'--uuid': '4f6a07fb9de453eb8e0bd6da92498322', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 4f6a07fb9de453eb8e0bd6da92498322 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.010556 iter 0 next_points [{'alpha': 0.0918053749152371, 'batch_size': 174, 'beta_1': 0.9833127028394498, 'beta_2': 0.9999973708093777, 'epsilon': 3.810816277335785e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.005178479331014363, 'tol': 0.0030135639624484837, 'validation_fraction': 0.6032971879695641}]
function_evaluation time 0.604110 value -0.905495 suggestion {'alpha': 0.0918053749152371, 'batch_size': 174, 'beta_1': 0.9833127028394498, 'beta_2': 0.9999973708093777, 'epsilon': 3.810816277335785e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.005178479331014363, 'tol': 0.0030135639624484837, 'validation_fraction': 0.6032971879695641}
observation time 0.000006, current best -0.905495 at iter 0
suggestion time taken 0.010683 iter 1 next_points [{'alpha': 0.022537924793076, 'batch_size': 30, 'beta_1': 0.9584482958113533, 'beta_2': 0.9921434791333308, 'epsilon': 1.9437494889408577e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.00011853920785146375, 'tol': 0.00024311221163971367, 'validation_fraction': 0.22426947991669652}]
function_evaluation time 2.214430 value -0.848352 suggestion {'alpha': 0.022537924793076, 'batch_size': 30, 'beta_1': 0.9584482958113533, 'beta_2': 0.9921434791333308, 'epsilon': 1.9437494889408577e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.00011853920785146375, 'tol': 0.00024311221163971367, 'validation_fraction': 0.22426947991669652}
observation time 0.000005, current best -0.905495 at iter 1
suggestion time taken 0.010493 iter 2 next_points [{'alpha': 0.004080474502971201, 'batch_size': 11, 'beta_1': 0.796450133090613, 'beta_2': 0.9889073749970015, 'epsilon': 3.222477396822716e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.005254390766185603, 'tol': 0.00021640559039378142, 'validation_fraction': 0.36285378182318795}]
function_evaluation time 2.274559 value -0.909890 suggestion {'alpha': 0.004080474502971201, 'batch_size': 11, 'beta_1': 0.796450133090613, 'beta_2': 0.9889073749970015, 'epsilon': 3.222477396822716e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.005254390766185603, 'tol': 0.00021640559039378142, 'validation_fraction': 0.36285378182318795}
observation time 0.000004, current best -0.909890 at iter 2
suggestion time taken 0.010524 iter 3 next_points [{'alpha': 2.0020575263126436e-05, 'batch_size': 180, 'beta_1': 0.9071785248877854, 'beta_2': 0.9922268349403685, 'epsilon': 6.890363597216578e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00018304106990231793, 'tol': 0.059803889348042684, 'validation_fraction': 0.17044765901796324}]
function_evaluation time 0.625951 value -0.589011 suggestion {'alpha': 2.0020575263126436e-05, 'batch_size': 180, 'beta_1': 0.9071785248877854, 'beta_2': 0.9922268349403685, 'epsilon': 6.890363597216578e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00018304106990231793, 'tol': 0.059803889348042684, 'validation_fraction': 0.17044765901796324}
observation time 0.000005, current best -0.909890 at iter 3
suggestion time taken 0.010834 iter 4 next_points [{'alpha': 0.8825298734784545, 'batch_size': 46, 'beta_1': 0.6893479481891599, 'beta_2': 0.9999952194461444, 'epsilon': 2.9560794646441268e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0006428105470864658, 'tol': 2.6675245853289978e-05, 'validation_fraction': 0.6504025522638845}]
function_evaluation time 1.074290 value -0.914286 suggestion {'alpha': 0.8825298734784545, 'batch_size': 46, 'beta_1': 0.6893479481891599, 'beta_2': 0.9999952194461444, 'epsilon': 2.9560794646441268e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0006428105470864658, 'tol': 2.6675245853289978e-05, 'validation_fraction': 0.6504025522638845}
observation time 0.000005, current best -0.914286 at iter 4
suggestion time taken 0.012874 iter 5 next_points [{'alpha': 1.887991491910643e-05, 'batch_size': 63, 'beta_1': 0.8107208415990714, 'beta_2': 0.9257432682503451, 'epsilon': 8.690830929520459e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.06597712764760785, 'tol': 9.607573101566557e-05, 'validation_fraction': 0.2248081080266411}]
function_evaluation time 1.236790 value -0.916484 suggestion {'alpha': 1.887991491910643e-05, 'batch_size': 63, 'beta_1': 0.8107208415990714, 'beta_2': 0.9257432682503451, 'epsilon': 8.690830929520459e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.06597712764760785, 'tol': 9.607573101566557e-05, 'validation_fraction': 0.2248081080266411}
observation time 0.000005, current best -0.916484 at iter 5
suggestion time taken 0.012022 iter 6 next_points [{'alpha': 0.006694624031277709, 'batch_size': 157, 'beta_1': 0.8958183127576402, 'beta_2': 0.999929705580399, 'epsilon': 8.324159556035961e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.03836476995854958, 'tol': 0.00031000490132715767, 'validation_fraction': 0.47148076784910325}]
function_evaluation time 0.750798 value -0.905495 suggestion {'alpha': 0.006694624031277709, 'batch_size': 157, 'beta_1': 0.8958183127576402, 'beta_2': 0.999929705580399, 'epsilon': 8.324159556035961e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.03836476995854958, 'tol': 0.00031000490132715767, 'validation_fraction': 0.47148076784910325}
observation time 0.000005, current best -0.916484 at iter 6
suggestion time taken 0.013848 iter 7 next_points [{'alpha': 2.3478524675999832, 'batch_size': 164, 'beta_1': 0.9524246187525958, 'beta_2': 0.9913584197064289, 'epsilon': 5.192769549403959e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.03874002997598064, 'tol': 0.00013731488228802322, 'validation_fraction': 0.8441972373532438}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.602421 value -0.786813 suggestion {'alpha': 2.3478524675999832, 'batch_size': 164, 'beta_1': 0.9524246187525958, 'beta_2': 0.9913584197064289, 'epsilon': 5.192769549403959e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.03874002997598064, 'tol': 0.00013731488228802322, 'validation_fraction': 0.8441972373532438}
observation time 0.000004, current best -0.916484 at iter 7
suggestion time taken 0.012517 iter 8 next_points [{'alpha': 0.019860349760700412, 'batch_size': 132, 'beta_1': 0.7381775642557991, 'beta_2': 0.9106927256648438, 'epsilon': 1.0292739536601605e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.004084709106510133, 'tol': 0.005133561404752187, 'validation_fraction': 0.20243482359498258}]
function_evaluation time 0.666985 value -0.905495 suggestion {'alpha': 0.019860349760700412, 'batch_size': 132, 'beta_1': 0.7381775642557991, 'beta_2': 0.9106927256648438, 'epsilon': 1.0292739536601605e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.004084709106510133, 'tol': 0.005133561404752187, 'validation_fraction': 0.20243482359498258}
observation time 0.000005, current best -0.916484 at iter 8
suggestion time taken 0.011859 iter 9 next_points [{'alpha': 3.80128856170441, 'batch_size': 200, 'beta_1': 0.9839731653401753, 'beta_2': 0.9999787364326013, 'epsilon': 2.285177859938266e-09, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.011865163279482917, 'tol': 0.015647860568918766, 'validation_fraction': 0.12908965962749114}]
function_evaluation time 0.754116 value -0.892308 suggestion {'alpha': 3.80128856170441, 'batch_size': 200, 'beta_1': 0.9839731653401753, 'beta_2': 0.9999787364326013, 'epsilon': 2.285177859938266e-09, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.011865163279482917, 'tol': 0.015647860568918766, 'validation_fraction': 0.12908965962749114}
observation time 0.000004, current best -0.916484 at iter 9
suggestion time taken 0.012028 iter 10 next_points [{'alpha': 0.1137852138950514, 'batch_size': 126, 'beta_1': 0.8370521295620311, 'beta_2': 0.9750780401288526, 'epsilon': 1.2512970767743599e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.00038117086888292287, 'tol': 2.2172411145900712e-05, 'validation_fraction': 0.3406721704152897}]
function_evaluation time 0.736798 value -0.698901 suggestion {'alpha': 0.1137852138950514, 'batch_size': 126, 'beta_1': 0.8370521295620311, 'beta_2': 0.9750780401288526, 'epsilon': 1.2512970767743599e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.00038117086888292287, 'tol': 2.2172411145900712e-05, 'validation_fraction': 0.3406721704152897}
observation time 0.000005, current best -0.916484 at iter 10
suggestion time taken 0.012124 iter 11 next_points [{'alpha': 0.10518511018885783, 'batch_size': 96, 'beta_1': 0.907034693044462, 'beta_2': 0.9976102019381204, 'epsilon': 3.037409451490299e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.001521535896216357, 'tol': 2.8015943480880006e-05, 'validation_fraction': 0.518598732588993}]
function_evaluation time 1.139953 value -0.863736 suggestion {'alpha': 0.10518511018885783, 'batch_size': 96, 'beta_1': 0.907034693044462, 'beta_2': 0.9976102019381204, 'epsilon': 3.037409451490299e-09, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.001521535896216357, 'tol': 2.8015943480880006e-05, 'validation_fraction': 0.518598732588993}
observation time 0.000005, current best -0.916484 at iter 11
suggestion time taken 0.012454 iter 12 next_points [{'alpha': 0.01697213823939789, 'batch_size': 68, 'beta_1': 0.7935341822754531, 'beta_2': 0.9986706395757556, 'epsilon': 2.607991720629988e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.00038964397788301546, 'tol': 0.0003197996606396511, 'validation_fraction': 0.35207775194741675}]
function_evaluation time 0.596027 value -0.868132 suggestion {'alpha': 0.01697213823939789, 'batch_size': 68, 'beta_1': 0.7935341822754531, 'beta_2': 0.9986706395757556, 'epsilon': 2.607991720629988e-09, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.00038964397788301546, 'tol': 0.0003197996606396511, 'validation_fraction': 0.35207775194741675}
observation time 0.000003, current best -0.916484 at iter 12
suggestion time taken 0.004984 iter 13 next_points [{'alpha': 0.0003275925169595278, 'batch_size': 162, 'beta_1': 0.916351055771802, 'beta_2': 0.9999247356105755, 'epsilon': 6.455381779030235e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0006805075843004242, 'tol': 0.003687299257597842, 'validation_fraction': 0.8617987285576257}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.398669 value -0.738462 suggestion {'alpha': 0.0003275925169595278, 'batch_size': 162, 'beta_1': 0.916351055771802, 'beta_2': 0.9999247356105755, 'epsilon': 6.455381779030235e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0006805075843004242, 'tol': 0.003687299257597842, 'validation_fraction': 0.8617987285576257}
observation time 0.000005, current best -0.916484 at iter 13
suggestion time taken 0.011378 iter 14 next_points [{'alpha': 8.156622279732336, 'batch_size': 195, 'beta_1': 0.8055530585698562, 'beta_2': 0.9550274374041312, 'epsilon': 3.4677051767990557e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.09073251413961853, 'tol': 0.0005392130641285156, 'validation_fraction': 0.770006163361552}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.649923 value -0.916484 suggestion {'alpha': 8.156622279732336, 'batch_size': 195, 'beta_1': 0.8055530585698562, 'beta_2': 0.9550274374041312, 'epsilon': 3.4677051767990557e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.09073251413961853, 'tol': 0.0005392130641285156, 'validation_fraction': 0.770006163361552}
observation time 0.000005, current best -0.916484 at iter 14
suggestion time taken 0.011380 iter 15 next_points [{'alpha': 0.000881834211854178, 'batch_size': 230, 'beta_1': 0.9876954883364305, 'beta_2': 0.9996240180974777, 'epsilon': 3.48020632985834e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.00041747541054356924, 'tol': 0.07032241720360122, 'validation_fraction': 0.4327286827842778}]
function_evaluation time 0.284116 value -0.683516 suggestion {'alpha': 0.000881834211854178, 'batch_size': 230, 'beta_1': 0.9876954883364305, 'beta_2': 0.9996240180974777, 'epsilon': 3.48020632985834e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.00041747541054356924, 'tol': 0.07032241720360122, 'validation_fraction': 0.4327286827842778}
observation time 0.000005, current best -0.916484 at iter 15
suggestion time taken 0.011891 iter 16 next_points [{'alpha': 0.3080055892558324, 'batch_size': 41, 'beta_1': 0.5055345887003182, 'beta_2': 0.99977633312561, 'epsilon': 4.316654484621974e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0011402766145088893, 'tol': 7.388126010682953e-05, 'validation_fraction': 0.14297224345101645}]
function_evaluation time 0.699270 value -0.898901 suggestion {'alpha': 0.3080055892558324, 'batch_size': 41, 'beta_1': 0.5055345887003182, 'beta_2': 0.99977633312561, 'epsilon': 4.316654484621974e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0011402766145088893, 'tol': 7.388126010682953e-05, 'validation_fraction': 0.14297224345101645}
observation time 0.000003, current best -0.916484 at iter 16
suggestion time taken 0.004203 iter 17 next_points [{'alpha': 0.08776340988805076, 'batch_size': 42, 'beta_1': 0.7233998000809042, 'beta_2': 0.999998668734479, 'epsilon': 4.162799756768056e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.009669702347573453, 'tol': 0.05295500596666981, 'validation_fraction': 0.7843748254160706}]
function_evaluation time 0.480146 value -0.916484 suggestion {'alpha': 0.08776340988805076, 'batch_size': 42, 'beta_1': 0.7233998000809042, 'beta_2': 0.999998668734479, 'epsilon': 4.162799756768056e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.009669702347573453, 'tol': 0.05295500596666981, 'validation_fraction': 0.7843748254160706}
observation time 0.000004, current best -0.916484 at iter 17
suggestion time taken 0.012761 iter 18 next_points [{'alpha': 0.26688334756437404, 'batch_size': 181, 'beta_1': 0.9587097360988284, 'beta_2': 0.9981138477728851, 'epsilon': 2.8303102874877754e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0005234521229814678, 'tol': 0.07931844010534048, 'validation_fraction': 0.11795778222183946}]
function_evaluation time 0.415436 value -0.670330 suggestion {'alpha': 0.26688334756437404, 'batch_size': 181, 'beta_1': 0.9587097360988284, 'beta_2': 0.9981138477728851, 'epsilon': 2.8303102874877754e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0005234521229814678, 'tol': 0.07931844010534048, 'validation_fraction': 0.11795778222183946}
observation time 0.000005, current best -0.916484 at iter 18
suggestion time taken 0.012940 iter 19 next_points [{'alpha': 0.28586283821473046, 'batch_size': 245, 'beta_1': 0.7986374054354477, 'beta_2': 0.999053745916529, 'epsilon': 2.881617045663912e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0004331744928151593, 'tol': 0.00012137143060220868, 'validation_fraction': 0.14638615127151353}]
function_evaluation time 0.482738 value -0.670330 suggestion {'alpha': 0.28586283821473046, 'batch_size': 245, 'beta_1': 0.7986374054354477, 'beta_2': 0.999053745916529, 'epsilon': 2.881617045663912e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.0004331744928151593, 'tol': 0.00012137143060220868, 'validation_fraction': 0.14638615127151353}
observation time 0.000005, current best -0.916484 at iter 19
suggestion time taken 0.011618 iter 20 next_points [{'alpha': 0.12915827281817177, 'batch_size': 153, 'beta_1': 0.9762524349908879, 'beta_2': 0.9999918458157906, 'epsilon': 3.274693547587846e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 4.809635481303125e-05, 'tol': 0.007233852724007869, 'validation_fraction': 0.4143207143625137}]
function_evaluation time 0.430031 value -0.465934 suggestion {'alpha': 0.12915827281817177, 'batch_size': 153, 'beta_1': 0.9762524349908879, 'beta_2': 0.9999918458157906, 'epsilon': 3.274693547587846e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 4.809635481303125e-05, 'tol': 0.007233852724007869, 'validation_fraction': 0.4143207143625137}
observation time 0.000004, current best -0.916484 at iter 20
suggestion time taken 0.012779 iter 21 next_points [{'alpha': 0.35181893504387823, 'batch_size': 117, 'beta_1': 0.9624231776350486, 'beta_2': 0.9999355235930133, 'epsilon': 7.109372820902882e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.04296889508722786, 'tol': 0.0006808857938404943, 'validation_fraction': 0.342681115089535}]
function_evaluation time 0.912038 value -0.890110 suggestion {'alpha': 0.35181893504387823, 'batch_size': 117, 'beta_1': 0.9624231776350486, 'beta_2': 0.9999355235930133, 'epsilon': 7.109372820902882e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.04296889508722786, 'tol': 0.0006808857938404943, 'validation_fraction': 0.342681115089535}
observation time 0.000005, current best -0.916484 at iter 21
suggestion time taken 0.011310 iter 22 next_points [{'alpha': 2.8370558083688933e-05, 'batch_size': 129, 'beta_1': 0.9281189797701634, 'beta_2': 0.9992426985534061, 'epsilon': 1.3425642326333926e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.04072578993942201, 'tol': 3.4141320809944145e-05, 'validation_fraction': 0.3792794206788478}]
function_evaluation time 0.810016 value -0.907692 suggestion {'alpha': 2.8370558083688933e-05, 'batch_size': 129, 'beta_1': 0.9281189797701634, 'beta_2': 0.9992426985534061, 'epsilon': 1.3425642326333926e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.04072578993942201, 'tol': 3.4141320809944145e-05, 'validation_fraction': 0.3792794206788478}
observation time 0.000005, current best -0.916484 at iter 22
suggestion time taken 0.012689 iter 23 next_points [{'alpha': 2.556527474183891e-05, 'batch_size': 90, 'beta_1': 0.8224428073177746, 'beta_2': 0.9999954822487078, 'epsilon': 8.417850597109856e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0004412359833801668, 'tol': 0.002692315050565324, 'validation_fraction': 0.8026517654579018}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.276063 value -0.670330 suggestion {'alpha': 2.556527474183891e-05, 'batch_size': 90, 'beta_1': 0.8224428073177746, 'beta_2': 0.9999954822487078, 'epsilon': 8.417850597109856e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0004412359833801668, 'tol': 0.002692315050565324, 'validation_fraction': 0.8026517654579018}
observation time 0.000005, current best -0.916484 at iter 23
suggestion time taken 0.011142 iter 24 next_points [{'alpha': 0.02063364478698234, 'batch_size': 129, 'beta_1': 0.7505372901451148, 'beta_2': 0.9999552949381534, 'epsilon': 1.2127124234893012e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 2.0616262053822243e-05, 'tol': 0.009613868643046235, 'validation_fraction': 0.15763151246212662}]
function_evaluation time 1.042691 value -0.549451 suggestion {'alpha': 0.02063364478698234, 'batch_size': 129, 'beta_1': 0.7505372901451148, 'beta_2': 0.9999552949381534, 'epsilon': 1.2127124234893012e-07, 'hidden_layer_sizes': 134, 'learning_rate_init': 2.0616262053822243e-05, 'tol': 0.009613868643046235, 'validation_fraction': 0.15763151246212662}
observation time 0.000011, current best -0.916484 at iter 24
suggestion time taken 0.012058 iter 25 next_points [{'alpha': 9.16781477211414, 'batch_size': 87, 'beta_1': 0.9899471795873357, 'beta_2': 0.9994925327071532, 'epsilon': 2.0178713206100374e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0005080558393774104, 'tol': 0.0006604327897030275, 'validation_fraction': 0.21561003098986892}]
function_evaluation time 0.545233 value -0.865934 suggestion {'alpha': 9.16781477211414, 'batch_size': 87, 'beta_1': 0.9899471795873357, 'beta_2': 0.9994925327071532, 'epsilon': 2.0178713206100374e-07, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0005080558393774104, 'tol': 0.0006604327897030275, 'validation_fraction': 0.21561003098986892}
observation time 0.000003, current best -0.916484 at iter 25
suggestion time taken 0.004155 iter 26 next_points [{'alpha': 0.0013171466362135564, 'batch_size': 149, 'beta_1': 0.970917211667611, 'beta_2': 0.999941286861095, 'epsilon': 9.169960435905286e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.006829954287482316, 'tol': 0.02133569702493507, 'validation_fraction': 0.18829088470231733}]
function_evaluation time 0.830894 value -0.907692 suggestion {'alpha': 0.0013171466362135564, 'batch_size': 149, 'beta_1': 0.970917211667611, 'beta_2': 0.999941286861095, 'epsilon': 9.169960435905286e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.006829954287482316, 'tol': 0.02133569702493507, 'validation_fraction': 0.18829088470231733}
observation time 0.000005, current best -0.916484 at iter 26
suggestion time taken 0.011929 iter 27 next_points [{'alpha': 1.0002745147882342e-05, 'batch_size': 115, 'beta_1': 0.8745120899599481, 'beta_2': 0.9999274255171822, 'epsilon': 1.9942209091671182e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00015591783529943497, 'tol': 0.0016663283078951323, 'validation_fraction': 0.6476591004690018}]
function_evaluation time 0.404272 value -0.529670 suggestion {'alpha': 1.0002745147882342e-05, 'batch_size': 115, 'beta_1': 0.8745120899599481, 'beta_2': 0.9999274255171822, 'epsilon': 1.9942209091671182e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00015591783529943497, 'tol': 0.0016663283078951323, 'validation_fraction': 0.6476591004690018}
observation time 0.000005, current best -0.916484 at iter 27
suggestion time taken 0.012386 iter 28 next_points [{'alpha': 0.029342576805032106, 'batch_size': 198, 'beta_1': 0.6525070113407991, 'beta_2': 0.999987855440165, 'epsilon': 1.1385269199182945e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.024974372738897816, 'tol': 0.00011077778940213322, 'validation_fraction': 0.6124237684271016}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.529423 value -0.901099 suggestion {'alpha': 0.029342576805032106, 'batch_size': 198, 'beta_1': 0.6525070113407991, 'beta_2': 0.999987855440165, 'epsilon': 1.1385269199182945e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.024974372738897816, 'tol': 0.00011077778940213322, 'validation_fraction': 0.6124237684271016}
observation time 0.000005, current best -0.916484 at iter 28
suggestion time taken 0.010242 iter 29 next_points [{'alpha': 0.0018478684260864414, 'batch_size': 66, 'beta_1': 0.9813445308717336, 'beta_2': 0.9302232625524889, 'epsilon': 2.480623933026089e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0001432273885812683, 'tol': 0.0006342550445281479, 'validation_fraction': 0.8863185058675709}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.290382 value -0.562637 suggestion {'alpha': 0.0018478684260864414, 'batch_size': 66, 'beta_1': 0.9813445308717336, 'beta_2': 0.9302232625524889, 'epsilon': 2.480623933026089e-07, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0001432273885812683, 'tol': 0.0006342550445281479, 'validation_fraction': 0.8863185058675709}
observation time 0.000005, current best -0.916484 at iter 29
suggestion time taken 0.010403 iter 30 next_points [{'alpha': 0.008368069679271905, 'batch_size': 56, 'beta_1': 0.9713496076087946, 'beta_2': 0.9999369380948784, 'epsilon': 6.62225150291451e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 9.77929745690594e-05, 'tol': 0.008155516923441608, 'validation_fraction': 0.35551768480543233}]
function_evaluation time 0.322392 value -0.586813 suggestion {'alpha': 0.008368069679271905, 'batch_size': 56, 'beta_1': 0.9713496076087946, 'beta_2': 0.9999369380948784, 'epsilon': 6.62225150291451e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 9.77929745690594e-05, 'tol': 0.008155516923441608, 'validation_fraction': 0.35551768480543233}
observation time 0.000004, current best -0.916484 at iter 30
suggestion time taken 0.010393 iter 31 next_points [{'alpha': 9.164154105524404e-05, 'batch_size': 188, 'beta_1': 0.9701424508648016, 'beta_2': 0.9994879918706876, 'epsilon': 2.386656921212427e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0015091471138968986, 'tol': 1.3189185894503424e-05, 'validation_fraction': 0.31187080903365366}]
function_evaluation time 0.716972 value -0.797802 suggestion {'alpha': 9.164154105524404e-05, 'batch_size': 188, 'beta_1': 0.9701424508648016, 'beta_2': 0.9994879918706876, 'epsilon': 2.386656921212427e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.0015091471138968986, 'tol': 1.3189185894503424e-05, 'validation_fraction': 0.31187080903365366}
observation time 0.000004, current best -0.916484 at iter 31
suggestion time taken 0.010389 iter 32 next_points [{'alpha': 0.00035348329043532757, 'batch_size': 67, 'beta_1': 0.86832711908232, 'beta_2': 0.9951179223188549, 'epsilon': 2.9210701315658567e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.009140468110047676, 'tol': 0.007801780836310136, 'validation_fraction': 0.15511829002074592}]
function_evaluation time 0.327582 value -0.905495 suggestion {'alpha': 0.00035348329043532757, 'batch_size': 67, 'beta_1': 0.86832711908232, 'beta_2': 0.9951179223188549, 'epsilon': 2.9210701315658567e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.009140468110047676, 'tol': 0.007801780836310136, 'validation_fraction': 0.15511829002074592}
observation time 0.000004, current best -0.916484 at iter 32
suggestion time taken 0.010426 iter 33 next_points [{'alpha': 1.8742113494669877e-05, 'batch_size': 135, 'beta_1': 0.9859099953836027, 'beta_2': 0.9998779302625161, 'epsilon': 1.530579508179256e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.048866197051026364, 'tol': 6.597348717513148e-05, 'validation_fraction': 0.5924748854680859}]
function_evaluation time 0.616521 value -0.898901 suggestion {'alpha': 1.8742113494669877e-05, 'batch_size': 135, 'beta_1': 0.9859099953836027, 'beta_2': 0.9998779302625161, 'epsilon': 1.530579508179256e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.048866197051026364, 'tol': 6.597348717513148e-05, 'validation_fraction': 0.5924748854680859}
observation time 0.000005, current best -0.916484 at iter 33
suggestion time taken 0.010436 iter 34 next_points [{'alpha': 0.003437493469573418, 'batch_size': 85, 'beta_1': 0.9590433253985242, 'beta_2': 0.9999905731753246, 'epsilon': 5.0401068977956975e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.00212673159142145, 'tol': 0.01162977052905622, 'validation_fraction': 0.8965720631994559}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.446907 value -0.887912 suggestion {'alpha': 0.003437493469573418, 'batch_size': 85, 'beta_1': 0.9590433253985242, 'beta_2': 0.9999905731753246, 'epsilon': 5.0401068977956975e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.00212673159142145, 'tol': 0.01162977052905622, 'validation_fraction': 0.8965720631994559}
observation time 0.000005, current best -0.916484 at iter 34
suggestion time taken 0.010403 iter 35 next_points [{'alpha': 1.632937402259544, 'batch_size': 27, 'beta_1': 0.9343895574505773, 'beta_2': 0.9525066845805525, 'epsilon': 7.790348388435626e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.013203393831870918, 'tol': 0.00041835969172583436, 'validation_fraction': 0.25441440457161885}]
function_evaluation time 1.423829 value -0.894505 suggestion {'alpha': 1.632937402259544, 'batch_size': 27, 'beta_1': 0.9343895574505773, 'beta_2': 0.9525066845805525, 'epsilon': 7.790348388435626e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.013203393831870918, 'tol': 0.00041835969172583436, 'validation_fraction': 0.25441440457161885}
observation time 0.000005, current best -0.916484 at iter 35
suggestion time taken 0.010431 iter 36 next_points [{'alpha': 2.4847485647869476, 'batch_size': 224, 'beta_1': 0.9048096304858668, 'beta_2': 0.9998268530895298, 'epsilon': 7.835235324238357e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.00025871761225489874, 'tol': 0.00130118468763652, 'validation_fraction': 0.11918962289585122}]
function_evaluation time 0.636291 value -0.687912 suggestion {'alpha': 2.4847485647869476, 'batch_size': 224, 'beta_1': 0.9048096304858668, 'beta_2': 0.9998268530895298, 'epsilon': 7.835235324238357e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.00025871761225489874, 'tol': 0.00130118468763652, 'validation_fraction': 0.11918962289585122}
observation time 0.000004, current best -0.916484 at iter 36
suggestion time taken 0.010324 iter 37 next_points [{'alpha': 0.0007826860297932051, 'batch_size': 231, 'beta_1': 0.5529549408521709, 'beta_2': 0.9603746039020808, 'epsilon': 5.651288586346255e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.00019664724169519304, 'tol': 0.03170083777353281, 'validation_fraction': 0.25593906838737257}]
function_evaluation time 0.419733 value -0.575824 suggestion {'alpha': 0.0007826860297932051, 'batch_size': 231, 'beta_1': 0.5529549408521709, 'beta_2': 0.9603746039020808, 'epsilon': 5.651288586346255e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.00019664724169519304, 'tol': 0.03170083777353281, 'validation_fraction': 0.25593906838737257}
observation time 0.000005, current best -0.916484 at iter 37
suggestion time taken 0.010378 iter 38 next_points [{'alpha': 0.055026264786951065, 'batch_size': 228, 'beta_1': 0.9848352274254011, 'beta_2': 0.9999984676942494, 'epsilon': 2.6470046897819553e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00010035399351622431, 'tol': 5.888419684650064e-05, 'validation_fraction': 0.8892521856357016}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.299361 value -0.602198 suggestion {'alpha': 0.055026264786951065, 'batch_size': 228, 'beta_1': 0.9848352274254011, 'beta_2': 0.9999984676942494, 'epsilon': 2.6470046897819553e-09, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00010035399351622431, 'tol': 5.888419684650064e-05, 'validation_fraction': 0.8892521856357016}
observation time 0.000005, current best -0.916484 at iter 38
suggestion time taken 0.010295 iter 39 next_points [{'alpha': 1.6744706149655353, 'batch_size': 156, 'beta_1': 0.8858802400403724, 'beta_2': 0.999472039076438, 'epsilon': 2.1723651528965087e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0001951608890815622, 'tol': 0.00016368540865415156, 'validation_fraction': 0.6001142515956167}]
function_evaluation time 0.483749 value -0.637363 suggestion {'alpha': 1.6744706149655353, 'batch_size': 156, 'beta_1': 0.8858802400403724, 'beta_2': 0.999472039076438, 'epsilon': 2.1723651528965087e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0001951608890815622, 'tol': 0.00016368540865415156, 'validation_fraction': 0.6001142515956167}
observation time 0.000005, current best -0.916484 at iter 39
suggestion time taken 0.010208 iter 40 next_points [{'alpha': 5.191286978061743, 'batch_size': 142, 'beta_1': 0.6997697351859051, 'beta_2': 0.9999272799172486, 'epsilon': 2.849412310514256e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.006965663219041384, 'tol': 0.05276589930642824, 'validation_fraction': 0.33199539602582223}]
function_evaluation time 0.439315 value -0.894505 suggestion {'alpha': 5.191286978061743, 'batch_size': 142, 'beta_1': 0.6997697351859051, 'beta_2': 0.9999272799172486, 'epsilon': 2.849412310514256e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.006965663219041384, 'tol': 0.05276589930642824, 'validation_fraction': 0.33199539602582223}
observation time 0.000005, current best -0.916484 at iter 40
suggestion time taken 0.010520 iter 41 next_points [{'alpha': 2.9750446087044207e-05, 'batch_size': 228, 'beta_1': 0.9822948431916166, 'beta_2': 0.997977212329241, 'epsilon': 4.7214031197515585e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.013043159848991629, 'tol': 0.002044538913923523, 'validation_fraction': 0.19717458606793092}]
function_evaluation time 0.597648 value -0.890110 suggestion {'alpha': 2.9750446087044207e-05, 'batch_size': 228, 'beta_1': 0.9822948431916166, 'beta_2': 0.997977212329241, 'epsilon': 4.7214031197515585e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.013043159848991629, 'tol': 0.002044538913923523, 'validation_fraction': 0.19717458606793092}
observation time 0.000005, current best -0.916484 at iter 41
suggestion time taken 0.010665 iter 42 next_points [{'alpha': 2.459756918886898e-05, 'batch_size': 74, 'beta_1': 0.9834322316147044, 'beta_2': 0.9999815251523307, 'epsilon': 6.970298004947194e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 2.2822169969579738e-05, 'tol': 2.2533784811279857e-05, 'validation_fraction': 0.8748366269011926}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.256269 value -0.472527 suggestion {'alpha': 2.459756918886898e-05, 'batch_size': 74, 'beta_1': 0.9834322316147044, 'beta_2': 0.9999815251523307, 'epsilon': 6.970298004947194e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 2.2822169969579738e-05, 'tol': 2.2533784811279857e-05, 'validation_fraction': 0.8748366269011926}
observation time 0.000004, current best -0.916484 at iter 42
suggestion time taken 0.010415 iter 43 next_points [{'alpha': 1.605119464986259e-05, 'batch_size': 130, 'beta_1': 0.7920610478022003, 'beta_2': 0.9999961434794247, 'epsilon': 5.2651361255198246e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 9.778716205194814e-05, 'tol': 0.06915195517389168, 'validation_fraction': 0.3893904998407399}]
function_evaluation time 0.404775 value -0.514286 suggestion {'alpha': 1.605119464986259e-05, 'batch_size': 130, 'beta_1': 0.7920610478022003, 'beta_2': 0.9999961434794247, 'epsilon': 5.2651361255198246e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 9.778716205194814e-05, 'tol': 0.06915195517389168, 'validation_fraction': 0.3893904998407399}
observation time 0.000005, current best -0.916484 at iter 43
suggestion time taken 0.010443 iter 44 next_points [{'alpha': 0.0009308686007295132, 'batch_size': 112, 'beta_1': 0.791216352946757, 'beta_2': 0.9983221063795844, 'epsilon': 3.798626699296671e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 5.308955532748159e-05, 'tol': 9.93470860359866e-05, 'validation_fraction': 0.30954965211314156}]
function_evaluation time 0.504874 value -0.432967 suggestion {'alpha': 0.0009308686007295132, 'batch_size': 112, 'beta_1': 0.791216352946757, 'beta_2': 0.9983221063795844, 'epsilon': 3.798626699296671e-09, 'hidden_layer_sizes': 136, 'learning_rate_init': 5.308955532748159e-05, 'tol': 9.93470860359866e-05, 'validation_fraction': 0.30954965211314156}
observation time 0.000004, current best -0.916484 at iter 44
saving meta data: {'args': {'--uuid': '4f6a07fb9de453eb8e0bd6da92498322', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
