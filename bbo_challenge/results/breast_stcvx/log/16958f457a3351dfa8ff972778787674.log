running: {'--uuid': '16958f457a3351dfa8ff972778787674', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d breast -o strongcvx -u 16958f457a3351dfa8ff972778787674 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam breast acc 45 1
with data root: None
suggestion time taken 15.954423 iter 0 next_points [{'alpha': 5.813424624811107, 'batch_size': 227, 'beta_1': 0.9651736341722361, 'beta_2': 0.935075885766234, 'epsilon': 7.694196832397986e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.00021308860292786462, 'tol': 0.00018866393229991722, 'validation_fraction': 0.8872617637572204}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.257107 value -0.523077 suggestion {'alpha': 5.813424624811107, 'batch_size': 227, 'beta_1': 0.9651736341722361, 'beta_2': 0.935075885766234, 'epsilon': 7.694196832397986e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.00021308860292786462, 'tol': 0.00018866393229991722, 'validation_fraction': 0.8872617637572204}
observation time 0.000005, current best -0.523077 at iter 0
suggestion time taken 15.694638 iter 1 next_points [{'alpha': 0.1815972916083019, 'batch_size': 45, 'beta_1': 0.8667122321792134, 'beta_2': 0.9999978222403019, 'epsilon': 9.95128520841493e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 3.453246377619793e-05, 'tol': 1.6577110137663757e-05, 'validation_fraction': 0.5468167632834848}]
function_evaluation time 0.442238 value -0.637363 suggestion {'alpha': 0.1815972916083019, 'batch_size': 45, 'beta_1': 0.8667122321792134, 'beta_2': 0.9999978222403019, 'epsilon': 9.95128520841493e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 3.453246377619793e-05, 'tol': 1.6577110137663757e-05, 'validation_fraction': 0.5468167632834848}
observation time 0.000005, current best -0.637363 at iter 1
suggestion time taken 15.422689 iter 2 next_points [{'alpha': 0.12491841429102986, 'batch_size': 11, 'beta_1': 0.6223662165958209, 'beta_2': 0.9999980067964132, 'epsilon': 1.2831792234934135e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 5.011791970102938e-05, 'tol': 0.000273946141999542, 'validation_fraction': 0.7677685746266389}]
function_evaluation time 1.039886 value -0.485714 suggestion {'alpha': 0.12491841429102986, 'batch_size': 11, 'beta_1': 0.6223662165958209, 'beta_2': 0.9999980067964132, 'epsilon': 1.2831792234934135e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 5.011791970102938e-05, 'tol': 0.000273946141999542, 'validation_fraction': 0.7677685746266389}
observation time 0.000005, current best -0.637363 at iter 2
suggestion time taken 15.826061 iter 3 next_points [{'alpha': 8.00660409052126, 'batch_size': 75, 'beta_1': 0.9688231279141405, 'beta_2': 0.9878769035071943, 'epsilon': 1.3066736147423893e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.003831116422853631, 'tol': 0.0015070172456300298, 'validation_fraction': 0.41959567196640135}]
function_evaluation time 0.811918 value -0.909890 suggestion {'alpha': 8.00660409052126, 'batch_size': 75, 'beta_1': 0.9688231279141405, 'beta_2': 0.9878769035071943, 'epsilon': 1.3066736147423893e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.003831116422853631, 'tol': 0.0015070172456300298, 'validation_fraction': 0.41959567196640135}
observation time 0.000005, current best -0.909890 at iter 3
suggestion time taken 16.351072 iter 4 next_points [{'alpha': 0.00045553977220462406, 'batch_size': 25, 'beta_1': 0.5894468948283866, 'beta_2': 0.9940419705438348, 'epsilon': 3.145091141426062e-09, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.07127015221452564, 'tol': 1.1763887165813186e-05, 'validation_fraction': 0.8922563090290213}]
function_evaluation time 0.732667 value -0.903297 suggestion {'alpha': 0.00045553977220462406, 'batch_size': 25, 'beta_1': 0.5894468948283866, 'beta_2': 0.9940419705438348, 'epsilon': 3.145091141426062e-09, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.07127015221452564, 'tol': 1.1763887165813186e-05, 'validation_fraction': 0.8922563090290213}
observation time 0.000005, current best -0.909890 at iter 4
suggestion time taken 16.252152 iter 5 next_points [{'alpha': 4.03573933184799, 'batch_size': 25, 'beta_1': 0.818644588250974, 'beta_2': 0.9997940713213254, 'epsilon': 4.037900300601853e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.0007949871951298788, 'tol': 0.0004868486368729277, 'validation_fraction': 0.29738426807096596}]
function_evaluation time 1.763772 value -0.905495 suggestion {'alpha': 4.03573933184799, 'batch_size': 25, 'beta_1': 0.818644588250974, 'beta_2': 0.9997940713213254, 'epsilon': 4.037900300601853e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.0007949871951298788, 'tol': 0.0004868486368729277, 'validation_fraction': 0.29738426807096596}
observation time 0.000005, current best -0.909890 at iter 5
suggestion time taken 16.814219 iter 6 next_points [{'alpha': 0.015133948953673551, 'batch_size': 41, 'beta_1': 0.8138071929044075, 'beta_2': 0.9999805056260274, 'epsilon': 1.6745481516662242e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 1.5184867402982202e-05, 'tol': 6.289110463731241e-05, 'validation_fraction': 0.34467478338403246}]
function_evaluation time 0.584501 value -0.417582 suggestion {'alpha': 0.015133948953673551, 'batch_size': 41, 'beta_1': 0.8138071929044075, 'beta_2': 0.9999805056260274, 'epsilon': 1.6745481516662242e-09, 'hidden_layer_sizes': 93, 'learning_rate_init': 1.5184867402982202e-05, 'tol': 6.289110463731241e-05, 'validation_fraction': 0.34467478338403246}
observation time 0.000005, current best -0.909890 at iter 6
suggestion time taken 15.775983 iter 7 next_points [{'alpha': 0.0001064456662909738, 'batch_size': 227, 'beta_1': 0.9534774192047525, 'beta_2': 0.9990693327079545, 'epsilon': 9.079657467762502e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.03598285006985788, 'tol': 0.0002851763740238425, 'validation_fraction': 0.5602856397618091}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.335626 value -0.848352 suggestion {'alpha': 0.0001064456662909738, 'batch_size': 227, 'beta_1': 0.9534774192047525, 'beta_2': 0.9990693327079545, 'epsilon': 9.079657467762502e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.03598285006985788, 'tol': 0.0002851763740238425, 'validation_fraction': 0.5602856397618091}
observation time 0.000004, current best -0.909890 at iter 7
suggestion time taken 15.978483 iter 8 next_points [{'alpha': 0.001624691755200803, 'batch_size': 227, 'beta_1': 0.5584763845770212, 'beta_2': 0.9999733296517378, 'epsilon': 5.84072922096983e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0032838003565757927, 'tol': 2.9330624747152014e-05, 'validation_fraction': 0.3902583194811835}]
function_evaluation time 0.636260 value -0.898901 suggestion {'alpha': 0.001624691755200803, 'batch_size': 227, 'beta_1': 0.5584763845770212, 'beta_2': 0.9999733296517378, 'epsilon': 5.84072922096983e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0032838003565757927, 'tol': 2.9330624747152014e-05, 'validation_fraction': 0.3902583194811835}
observation time 0.000005, current best -0.909890 at iter 8
suggestion time taken 15.841594 iter 9 next_points [{'alpha': 5.29073405935938e-05, 'batch_size': 113, 'beta_1': 0.9806328123361052, 'beta_2': 0.9999945437921014, 'epsilon': 3.647270503089875e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.0017233820383902448, 'tol': 1.0290287627537078e-05, 'validation_fraction': 0.17966346434984276}]
function_evaluation time 1.212574 value -0.890110 suggestion {'alpha': 5.29073405935938e-05, 'batch_size': 113, 'beta_1': 0.9806328123361052, 'beta_2': 0.9999945437921014, 'epsilon': 3.647270503089875e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.0017233820383902448, 'tol': 1.0290287627537078e-05, 'validation_fraction': 0.17966346434984276}
observation time 0.000005, current best -0.909890 at iter 9
suggestion time taken 16.484606 iter 10 next_points [{'alpha': 6.77412145732753, 'batch_size': 224, 'beta_1': 0.9491060150307339, 'beta_2': 0.9677556130307607, 'epsilon': 4.0149875509199e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.0005430322730956994, 'tol': 0.0009951447559991976, 'validation_fraction': 0.6700419444523822}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.329592 value -0.635165 suggestion {'alpha': 6.77412145732753, 'batch_size': 224, 'beta_1': 0.9491060150307339, 'beta_2': 0.9677556130307607, 'epsilon': 4.0149875509199e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.0005430322730956994, 'tol': 0.0009951447559991976, 'validation_fraction': 0.6700419444523822}
observation time 0.000005, current best -0.909890 at iter 10
suggestion time taken 16.615098 iter 11 next_points [{'alpha': 0.0008308507798168061, 'batch_size': 11, 'beta_1': 0.7189919355653137, 'beta_2': 0.9999801704186009, 'epsilon': 1.4581301224594062e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.09931917825837895, 'tol': 0.0038994648356344658, 'validation_fraction': 0.8424447101195502}]
function_evaluation time 0.796885 value -0.898901 suggestion {'alpha': 0.0008308507798168061, 'batch_size': 11, 'beta_1': 0.7189919355653137, 'beta_2': 0.9999801704186009, 'epsilon': 1.4581301224594062e-07, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.09931917825837895, 'tol': 0.0038994648356344658, 'validation_fraction': 0.8424447101195502}
observation time 0.000004, current best -0.909890 at iter 11
suggestion time taken 15.988562 iter 12 next_points [{'alpha': 0.0277274395116559, 'batch_size': 151, 'beta_1': 0.9607798392342713, 'beta_2': 0.998943405891545, 'epsilon': 4.3724998110263e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.07983502313722213, 'tol': 0.00016855368945274955, 'validation_fraction': 0.1385332193472686}]
function_evaluation time 0.445404 value -0.637363 suggestion {'alpha': 0.0277274395116559, 'batch_size': 151, 'beta_1': 0.9607798392342713, 'beta_2': 0.998943405891545, 'epsilon': 4.3724998110263e-08, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.07983502313722213, 'tol': 0.00016855368945274955, 'validation_fraction': 0.1385332193472686}
observation time 0.000004, current best -0.909890 at iter 12
suggestion time taken 16.463381 iter 13 next_points [{'alpha': 0.0044397288399379035, 'batch_size': 14, 'beta_1': 0.6178361553826707, 'beta_2': 0.9999951579148487, 'epsilon': 3.766811797016134e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.0014748034902432915, 'tol': 0.0005476847533849488, 'validation_fraction': 0.5647114639011368}]
function_evaluation time 1.885653 value -0.903297 suggestion {'alpha': 0.0044397288399379035, 'batch_size': 14, 'beta_1': 0.6178361553826707, 'beta_2': 0.9999951579148487, 'epsilon': 3.766811797016134e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.0014748034902432915, 'tol': 0.0005476847533849488, 'validation_fraction': 0.5647114639011368}
observation time 0.000004, current best -0.909890 at iter 13
suggestion time taken 15.708840 iter 14 next_points [{'alpha': 1.413914493941218, 'batch_size': 50, 'beta_1': 0.6507233767707059, 'beta_2': 0.9999013279491262, 'epsilon': 4.3207580109365326e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0031168708427363376, 'tol': 0.04483809519039579, 'validation_fraction': 0.17880440554775018}]
function_evaluation time 0.569575 value -0.909890 suggestion {'alpha': 1.413914493941218, 'batch_size': 50, 'beta_1': 0.6507233767707059, 'beta_2': 0.9999013279491262, 'epsilon': 4.3207580109365326e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0031168708427363376, 'tol': 0.04483809519039579, 'validation_fraction': 0.17880440554775018}
observation time 0.000004, current best -0.909890 at iter 14
suggestion time taken 16.609881 iter 15 next_points [{'alpha': 1.8601409692501238, 'batch_size': 226, 'beta_1': 0.6410242004057647, 'beta_2': 0.999998799459052, 'epsilon': 3.35879152609707e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.07729467944529216, 'tol': 0.0021838227359319406, 'validation_fraction': 0.13943180368741143}]
function_evaluation time 0.579494 value -0.898901 suggestion {'alpha': 1.8601409692501238, 'batch_size': 226, 'beta_1': 0.6410242004057647, 'beta_2': 0.999998799459052, 'epsilon': 3.35879152609707e-07, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.07729467944529216, 'tol': 0.0021838227359319406, 'validation_fraction': 0.13943180368741143}
observation time 0.000004, current best -0.909890 at iter 15
suggestion time taken 15.785792 iter 16 next_points [{'alpha': 0.00926444633020682, 'batch_size': 226, 'beta_1': 0.9127372584628143, 'beta_2': 0.999988317952088, 'epsilon': 2.646357094819278e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.012964536903139244, 'tol': 0.011264755734183163, 'validation_fraction': 0.24567924785120962}]
function_evaluation time 0.539509 value -0.905495 suggestion {'alpha': 0.00926444633020682, 'batch_size': 226, 'beta_1': 0.9127372584628143, 'beta_2': 0.999988317952088, 'epsilon': 2.646357094819278e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.012964536903139244, 'tol': 0.011264755734183163, 'validation_fraction': 0.24567924785120962}
observation time 0.000005, current best -0.909890 at iter 16
suggestion time taken 16.628047 iter 17 next_points [{'alpha': 0.02994045990004357, 'batch_size': 227, 'beta_1': 0.9408653314955053, 'beta_2': 0.98630753595397, 'epsilon': 1.5002264784791447e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.08489401175709821, 'tol': 0.015353306358093805, 'validation_fraction': 0.7968810738833887}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.321380 value -0.824176 suggestion {'alpha': 0.02994045990004357, 'batch_size': 227, 'beta_1': 0.9408653314955053, 'beta_2': 0.98630753595397, 'epsilon': 1.5002264784791447e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.08489401175709821, 'tol': 0.015353306358093805, 'validation_fraction': 0.7968810738833887}
observation time 0.000005, current best -0.909890 at iter 17
suggestion time taken 16.572189 iter 18 next_points [{'alpha': 0.009551471712648772, 'batch_size': 41, 'beta_1': 0.9827989284965982, 'beta_2': 0.99295643848058, 'epsilon': 3.778139412282239e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.000457934897772557, 'tol': 0.0013171693249231168, 'validation_fraction': 0.7784098708034791}]
function_evaluation time 0.450284 value -0.784615 suggestion {'alpha': 0.009551471712648772, 'batch_size': 41, 'beta_1': 0.9827989284965982, 'beta_2': 0.99295643848058, 'epsilon': 3.778139412282239e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.000457934897772557, 'tol': 0.0013171693249231168, 'validation_fraction': 0.7784098708034791}
observation time 0.000004, current best -0.909890 at iter 18
suggestion time taken 15.957487 iter 19 next_points [{'alpha': 0.01238100431380161, 'batch_size': 75, 'beta_1': 0.9818389432789768, 'beta_2': 0.998833614920215, 'epsilon': 7.740826204295492e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 1.3379838691724888e-05, 'tol': 0.08936671386790268, 'validation_fraction': 0.8348003266008316}]
function_evaluation time 0.219662 value -0.637363 suggestion {'alpha': 0.01238100431380161, 'batch_size': 75, 'beta_1': 0.9818389432789768, 'beta_2': 0.998833614920215, 'epsilon': 7.740826204295492e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 1.3379838691724888e-05, 'tol': 0.08936671386790268, 'validation_fraction': 0.8348003266008316}
observation time 0.000005, current best -0.909890 at iter 19
suggestion time taken 16.162672 iter 20 next_points [{'alpha': 4.961262640467721e-05, 'batch_size': 227, 'beta_1': 0.864594310410615, 'beta_2': 0.978396263372159, 'epsilon': 1.251857485076525e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.004717134985591516, 'tol': 4.3191041538987636e-05, 'validation_fraction': 0.6793310045376191}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.510990 value -0.846154 suggestion {'alpha': 4.961262640467721e-05, 'batch_size': 227, 'beta_1': 0.864594310410615, 'beta_2': 0.978396263372159, 'epsilon': 1.251857485076525e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.004717134985591516, 'tol': 4.3191041538987636e-05, 'validation_fraction': 0.6793310045376191}
observation time 0.000004, current best -0.909890 at iter 20
suggestion time taken 16.084785 iter 21 next_points [{'alpha': 0.07504214268178558, 'batch_size': 45, 'beta_1': 0.5306408794392348, 'beta_2': 0.9999973622785234, 'epsilon': 4.033403428114959e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.04250844366957709, 'tol': 0.0001847101605515798, 'validation_fraction': 0.7228943896990627}]
function_evaluation time 0.631989 value -0.894505 suggestion {'alpha': 0.07504214268178558, 'batch_size': 45, 'beta_1': 0.5306408794392348, 'beta_2': 0.9999973622785234, 'epsilon': 4.033403428114959e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.04250844366957709, 'tol': 0.0001847101605515798, 'validation_fraction': 0.7228943896990627}
observation time 0.000005, current best -0.909890 at iter 21
suggestion time taken 16.568955 iter 22 next_points [{'alpha': 5.428968359603935, 'batch_size': 11, 'beta_1': 0.7055080610827057, 'beta_2': 0.9998109606110908, 'epsilon': 1.632395783456192e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.0005959048524229646, 'tol': 5.77507525777269e-05, 'validation_fraction': 0.10485382492570149}]
function_evaluation time 1.637349 value -0.901099 suggestion {'alpha': 5.428968359603935, 'batch_size': 11, 'beta_1': 0.7055080610827057, 'beta_2': 0.9998109606110908, 'epsilon': 1.632395783456192e-08, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.0005959048524229646, 'tol': 5.77507525777269e-05, 'validation_fraction': 0.10485382492570149}
observation time 0.000017, current best -0.909890 at iter 22
suggestion time taken 15.828406 iter 23 next_points [{'alpha': 6.044730713025475, 'batch_size': 113, 'beta_1': 0.9770151983095933, 'beta_2': 0.9958612561015536, 'epsilon': 5.4106401175404675e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0007674006140674985, 'tol': 8.245613903437036e-05, 'validation_fraction': 0.23203324403947342}]
function_evaluation time 0.239393 value -0.729670 suggestion {'alpha': 6.044730713025475, 'batch_size': 113, 'beta_1': 0.9770151983095933, 'beta_2': 0.9958612561015536, 'epsilon': 5.4106401175404675e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.0007674006140674985, 'tol': 8.245613903437036e-05, 'validation_fraction': 0.23203324403947342}
observation time 0.000003, current best -0.909890 at iter 23
suggestion time taken 16.351756 iter 24 next_points [{'alpha': 4.379194449637918, 'batch_size': 226, 'beta_1': 0.7476118841093075, 'beta_2': 0.9999926071366235, 'epsilon': 9.006238917845915e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.004441006397858015, 'tol': 0.002408822300906735, 'validation_fraction': 0.7570627543962707}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.427101 value -0.857143 suggestion {'alpha': 4.379194449637918, 'batch_size': 226, 'beta_1': 0.7476118841093075, 'beta_2': 0.9999926071366235, 'epsilon': 9.006238917845915e-08, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.004441006397858015, 'tol': 0.002408822300906735, 'validation_fraction': 0.7570627543962707}
observation time 0.000005, current best -0.909890 at iter 24
suggestion time taken 15.802672 iter 25 next_points [{'alpha': 4.340560771076062e-05, 'batch_size': 16, 'beta_1': 0.9826968341566726, 'beta_2': 0.9386006341999958, 'epsilon': 1.5310345507157566e-07, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.04866291240021659, 'tol': 0.012339094114305978, 'validation_fraction': 0.8140325961594747}]
function_evaluation time 0.696690 value -0.903297 suggestion {'alpha': 4.340560771076062e-05, 'batch_size': 16, 'beta_1': 0.9826968341566726, 'beta_2': 0.9386006341999958, 'epsilon': 1.5310345507157566e-07, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.04866291240021659, 'tol': 0.012339094114305978, 'validation_fraction': 0.8140325961594747}
observation time 0.000005, current best -0.909890 at iter 25
suggestion time taken 16.517314 iter 26 next_points [{'alpha': 0.019448932912959332, 'batch_size': 224, 'beta_1': 0.9000224711864391, 'beta_2': 0.9969763176723101, 'epsilon': 3.5714714615840725e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.007872969410216831, 'tol': 0.07707356879421924, 'validation_fraction': 0.7455098915978381}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.320128 value -0.848352 suggestion {'alpha': 0.019448932912959332, 'batch_size': 224, 'beta_1': 0.9000224711864391, 'beta_2': 0.9969763176723101, 'epsilon': 3.5714714615840725e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.007872969410216831, 'tol': 0.07707356879421924, 'validation_fraction': 0.7455098915978381}
observation time 0.000004, current best -0.909890 at iter 26
suggestion time taken 16.047530 iter 27 next_points [{'alpha': 4.7120284745066165e-05, 'batch_size': 227, 'beta_1': 0.949290564740322, 'beta_2': 0.9999913820473116, 'epsilon': 2.746326269665841e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0003245638476331424, 'tol': 0.0029005506562776577, 'validation_fraction': 0.8463602481367801}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.286316 value -0.690110 suggestion {'alpha': 4.7120284745066165e-05, 'batch_size': 227, 'beta_1': 0.949290564740322, 'beta_2': 0.9999913820473116, 'epsilon': 2.746326269665841e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0003245638476331424, 'tol': 0.0029005506562776577, 'validation_fraction': 0.8463602481367801}
observation time 0.000005, current best -0.909890 at iter 27
suggestion time taken 16.428996 iter 28 next_points [{'alpha': 0.39531937716248655, 'batch_size': 113, 'beta_1': 0.9800264242757798, 'beta_2': 0.999881063635788, 'epsilon': 1.6789028810771563e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.004519440044251951, 'tol': 0.016788033107601286, 'validation_fraction': 0.7201203610980166}]
function_evaluation time 0.351983 value -0.802198 suggestion {'alpha': 0.39531937716248655, 'batch_size': 113, 'beta_1': 0.9800264242757798, 'beta_2': 0.999881063635788, 'epsilon': 1.6789028810771563e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.004519440044251951, 'tol': 0.016788033107601286, 'validation_fraction': 0.7201203610980166}
observation time 0.000005, current best -0.909890 at iter 28
suggestion time taken 16.261365 iter 29 next_points [{'alpha': 0.00016456372057642232, 'batch_size': 15, 'beta_1': 0.7988088579733229, 'beta_2': 0.9999794647982188, 'epsilon': 2.772358454933786e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0064815413829723235, 'tol': 4.2402659153448286e-05, 'validation_fraction': 0.6542694126085371}]
function_evaluation time 1.337004 value -0.934066 suggestion {'alpha': 0.00016456372057642232, 'batch_size': 15, 'beta_1': 0.7988088579733229, 'beta_2': 0.9999794647982188, 'epsilon': 2.772358454933786e-07, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0064815413829723235, 'tol': 4.2402659153448286e-05, 'validation_fraction': 0.6542694126085371}
observation time 0.000005, current best -0.934066 at iter 29
suggestion time taken 16.446067 iter 30 next_points [{'alpha': 0.0010905995608920603, 'batch_size': 12, 'beta_1': 0.9571736022623504, 'beta_2': 0.9999792296043167, 'epsilon': 3.399657463103619e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.0018958581522210598, 'tol': 0.05818517867145251, 'validation_fraction': 0.2610736365177713}]
function_evaluation time 0.829909 value -0.909890 suggestion {'alpha': 0.0010905995608920603, 'batch_size': 12, 'beta_1': 0.9571736022623504, 'beta_2': 0.9999792296043167, 'epsilon': 3.399657463103619e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.0018958581522210598, 'tol': 0.05818517867145251, 'validation_fraction': 0.2610736365177713}
observation time 0.000005, current best -0.934066 at iter 30
suggestion time taken 16.259698 iter 31 next_points [{'alpha': 0.0026988950869290354, 'batch_size': 30, 'beta_1': 0.5704204659099292, 'beta_2': 0.9999895307703279, 'epsilon': 3.689400719067115e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0001000734270721202, 'tol': 7.864385056099555e-05, 'validation_fraction': 0.2566862813320566}]
function_evaluation time 1.849723 value -0.742857 suggestion {'alpha': 0.0026988950869290354, 'batch_size': 30, 'beta_1': 0.5704204659099292, 'beta_2': 0.9999895307703279, 'epsilon': 3.689400719067115e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0001000734270721202, 'tol': 7.864385056099555e-05, 'validation_fraction': 0.2566862813320566}
observation time 0.000005, current best -0.934066 at iter 31
suggestion time taken 16.384604 iter 32 next_points [{'alpha': 2.1599682712423908e-05, 'batch_size': 227, 'beta_1': 0.9528036428979547, 'beta_2': 0.9900033258655847, 'epsilon': 1.854567385080508e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 1.211797510038242e-05, 'tol': 0.012394013905203151, 'validation_fraction': 0.8434610942957473}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.240347 value -0.485714 suggestion {'alpha': 2.1599682712423908e-05, 'batch_size': 227, 'beta_1': 0.9528036428979547, 'beta_2': 0.9900033258655847, 'epsilon': 1.854567385080508e-09, 'hidden_layer_sizes': 152, 'learning_rate_init': 1.211797510038242e-05, 'tol': 0.012394013905203151, 'validation_fraction': 0.8434610942957473}
observation time 0.000005, current best -0.934066 at iter 32
suggestion time taken 16.095552 iter 33 next_points [{'alpha': 0.2959768626601539, 'batch_size': 151, 'beta_1': 0.977581151441502, 'beta_2': 0.9999514592551764, 'epsilon': 9.994545310845888e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0005263023540591457, 'tol': 0.0012457496293540472, 'validation_fraction': 0.12787599204528421}]
function_evaluation time 0.339017 value -0.712088 suggestion {'alpha': 0.2959768626601539, 'batch_size': 151, 'beta_1': 0.977581151441502, 'beta_2': 0.9999514592551764, 'epsilon': 9.994545310845888e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0005263023540591457, 'tol': 0.0012457496293540472, 'validation_fraction': 0.12787599204528421}
observation time 0.000003, current best -0.934066 at iter 33
suggestion time taken 15.829571 iter 34 next_points [{'alpha': 0.010068390212868952, 'batch_size': 75, 'beta_1': 0.9220575575513318, 'beta_2': 0.9999585699141773, 'epsilon': 1.0102018565634544e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0663567436508036, 'tol': 0.0016921854010398696, 'validation_fraction': 0.38539296745656226}]
function_evaluation time 0.889166 value -0.907692 suggestion {'alpha': 0.010068390212868952, 'batch_size': 75, 'beta_1': 0.9220575575513318, 'beta_2': 0.9999585699141773, 'epsilon': 1.0102018565634544e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0663567436508036, 'tol': 0.0016921854010398696, 'validation_fraction': 0.38539296745656226}
observation time 0.000004, current best -0.934066 at iter 34
suggestion time taken 16.738686 iter 35 next_points [{'alpha': 6.829170484695139, 'batch_size': 151, 'beta_1': 0.9447752152188639, 'beta_2': 0.9999961604328348, 'epsilon': 3.4858049969242576e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.03531212280596968, 'tol': 0.00015394139117899381, 'validation_fraction': 0.5630141714034581}]
function_evaluation time 0.652531 value -0.901099 suggestion {'alpha': 6.829170484695139, 'batch_size': 151, 'beta_1': 0.9447752152188639, 'beta_2': 0.9999961604328348, 'epsilon': 3.4858049969242576e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.03531212280596968, 'tol': 0.00015394139117899381, 'validation_fraction': 0.5630141714034581}
observation time 0.000005, current best -0.934066 at iter 35
suggestion time taken 15.976128 iter 36 next_points [{'alpha': 0.0022662843787216876, 'batch_size': 226, 'beta_1': 0.9444332900919901, 'beta_2': 0.9816260608133748, 'epsilon': 4.899259993535709e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.00011910002432944816, 'tol': 9.424714501619333e-05, 'validation_fraction': 0.887657768079559}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.308427 value -0.619780 suggestion {'alpha': 0.0022662843787216876, 'batch_size': 226, 'beta_1': 0.9444332900919901, 'beta_2': 0.9816260608133748, 'epsilon': 4.899259993535709e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.00011910002432944816, 'tol': 9.424714501619333e-05, 'validation_fraction': 0.887657768079559}
observation time 0.000005, current best -0.934066 at iter 36
suggestion time taken 16.925550 iter 37 next_points [{'alpha': 1.0976783295803553e-05, 'batch_size': 149, 'beta_1': 0.8172320701876294, 'beta_2': 0.9968353070520067, 'epsilon': 2.609241109633982e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.001197780842499443, 'tol': 4.9501508067362195e-05, 'validation_fraction': 0.2528584581329484}]
function_evaluation time 0.819254 value -0.894505 suggestion {'alpha': 1.0976783295803553e-05, 'batch_size': 149, 'beta_1': 0.8172320701876294, 'beta_2': 0.9968353070520067, 'epsilon': 2.609241109633982e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.001197780842499443, 'tol': 4.9501508067362195e-05, 'validation_fraction': 0.2528584581329484}
observation time 0.000005, current best -0.934066 at iter 37
suggestion time taken 16.132212 iter 38 next_points [{'alpha': 0.281918403259949, 'batch_size': 90, 'beta_1': 0.9735313781478471, 'beta_2': 0.9997065707744217, 'epsilon': 8.781719226632661e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0015528315386815349, 'tol': 3.4339107785508266e-05, 'validation_fraction': 0.3607118525347216}]
function_evaluation time 1.056561 value -0.909890 suggestion {'alpha': 0.281918403259949, 'batch_size': 90, 'beta_1': 0.9735313781478471, 'beta_2': 0.9997065707744217, 'epsilon': 8.781719226632661e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0015528315386815349, 'tol': 3.4339107785508266e-05, 'validation_fraction': 0.3607118525347216}
observation time 0.000005, current best -0.934066 at iter 38
suggestion time taken 16.837443 iter 39 next_points [{'alpha': 6.035609215327428, 'batch_size': 149, 'beta_1': 0.965709944530616, 'beta_2': 0.9966831847307789, 'epsilon': 6.718586764087822e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0002326288029235841, 'tol': 0.0001552033207858375, 'validation_fraction': 0.2098767747818813}]
function_evaluation time 0.428311 value -0.676923 suggestion {'alpha': 6.035609215327428, 'batch_size': 149, 'beta_1': 0.965709944530616, 'beta_2': 0.9966831847307789, 'epsilon': 6.718586764087822e-09, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.0002326288029235841, 'tol': 0.0001552033207858375, 'validation_fraction': 0.2098767747818813}
observation time 0.000005, current best -0.934066 at iter 39
suggestion time taken 16.675250 iter 40 next_points [{'alpha': 0.0006995129211711394, 'batch_size': 90, 'beta_1': 0.9871846988386327, 'beta_2': 0.9999500499949137, 'epsilon': 1.3086088038843553e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 9.126539592271585e-05, 'tol': 0.0001418938459995788, 'validation_fraction': 0.674627047360281}]
function_evaluation time 0.378626 value -0.569231 suggestion {'alpha': 0.0006995129211711394, 'batch_size': 90, 'beta_1': 0.9871846988386327, 'beta_2': 0.9999500499949137, 'epsilon': 1.3086088038843553e-08, 'hidden_layer_sizes': 168, 'learning_rate_init': 9.126539592271585e-05, 'tol': 0.0001418938459995788, 'validation_fraction': 0.674627047360281}
observation time 0.000004, current best -0.934066 at iter 40
suggestion time taken 16.178915 iter 41 next_points [{'alpha': 0.03801364908190523, 'batch_size': 227, 'beta_1': 0.9569913083857349, 'beta_2': 0.9979033032333835, 'epsilon': 6.048595456850633e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.008782053932005741, 'tol': 0.00019830787669000165, 'validation_fraction': 0.8077296560015772}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.546777 value -0.896703 suggestion {'alpha': 0.03801364908190523, 'batch_size': 227, 'beta_1': 0.9569913083857349, 'beta_2': 0.9979033032333835, 'epsilon': 6.048595456850633e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.008782053932005741, 'tol': 0.00019830787669000165, 'validation_fraction': 0.8077296560015772}
observation time 0.000005, current best -0.934066 at iter 41
suggestion time taken 17.324542 iter 42 next_points [{'alpha': 0.12448320559128606, 'batch_size': 112, 'beta_1': 0.9811274301375857, 'beta_2': 0.9972207847590723, 'epsilon': 3.8948195469425175e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.009401454167677514, 'tol': 0.00026548465514583376, 'validation_fraction': 0.8934357748658059}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.508744 value -0.916484 suggestion {'alpha': 0.12448320559128606, 'batch_size': 112, 'beta_1': 0.9811274301375857, 'beta_2': 0.9972207847590723, 'epsilon': 3.8948195469425175e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.009401454167677514, 'tol': 0.00026548465514583376, 'validation_fraction': 0.8934357748658059}
observation time 0.000005, current best -0.934066 at iter 42
suggestion time taken 17.022967 iter 43 next_points [{'alpha': 0.00037522555228299606, 'batch_size': 113, 'beta_1': 0.9664558358612731, 'beta_2': 0.9998410781261633, 'epsilon': 9.84005283612611e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 2.7306665128816088e-05, 'tol': 3.947463959962184e-05, 'validation_fraction': 0.29133807480813206}]
function_evaluation time 0.452886 value -0.527473 suggestion {'alpha': 0.00037522555228299606, 'batch_size': 113, 'beta_1': 0.9664558358612731, 'beta_2': 0.9998410781261633, 'epsilon': 9.84005283612611e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 2.7306665128816088e-05, 'tol': 3.947463959962184e-05, 'validation_fraction': 0.29133807480813206}
observation time 0.000005, current best -0.934066 at iter 43
suggestion time taken 17.191144 iter 44 next_points [{'alpha': 0.3915067238316566, 'batch_size': 90, 'beta_1': 0.8277467827479519, 'beta_2': 0.9997634594176749, 'epsilon': 1.7652155689764878e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.06615259838412026, 'tol': 0.0016286019562210172, 'validation_fraction': 0.8056211070119536}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.533397 value -0.846154 suggestion {'alpha': 0.3915067238316566, 'batch_size': 90, 'beta_1': 0.8277467827479519, 'beta_2': 0.9997634594176749, 'epsilon': 1.7652155689764878e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.06615259838412026, 'tol': 0.0016286019562210172, 'validation_fraction': 0.8056211070119536}
observation time 0.000005, current best -0.934066 at iter 44
saving meta data: {'args': {'--uuid': '16958f457a3351dfa8ff972778787674', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
