running: {'--uuid': 'e3be4ad8b45d53ff97e6ab74532cc4f0', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u e3be4ad8b45d53ff97e6ab74532cc4f0 -m nll -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast nll 45 1
with data root: None
suggestion time taken 0.014396 iter 0 next_points [{'alpha': 4.331160707619669, 'batch_size': 67, 'beta_1': 0.9209133128009197, 'beta_2': 0.9999904713637262, 'epsilon': 1.4975370315663666e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0009574142489070697, 'tol': 0.0004565562936052948, 'validation_fraction': 0.11658332178852622}]
function_evaluation time 0.508348 value 0.545705 suggestion {'alpha': 4.331160707619669, 'batch_size': 67, 'beta_1': 0.9209133128009197, 'beta_2': 0.9999904713637262, 'epsilon': 1.4975370315663666e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0009574142489070697, 'tol': 0.0004565562936052948, 'validation_fraction': 0.11658332178852622}
observation time 0.000004, current best 0.545705 at iter 0
suggestion time taken 0.010638 iter 1 next_points [{'alpha': 0.006977034355144937, 'batch_size': 123, 'beta_1': 0.8626244785742203, 'beta_2': 0.9999982687991468, 'epsilon': 6.600487769102175e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.03362973704678337, 'tol': 0.0017774001048179763, 'validation_fraction': 0.7990476613181517}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.647548 value 0.467771 suggestion {'alpha': 0.006977034355144937, 'batch_size': 123, 'beta_1': 0.8626244785742203, 'beta_2': 0.9999982687991468, 'epsilon': 6.600487769102175e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.03362973704678337, 'tol': 0.0017774001048179763, 'validation_fraction': 0.7990476613181517}
observation time 0.000005, current best 0.467771 at iter 1
suggestion time taken 0.011300 iter 2 next_points [{'alpha': 3.8600650704922015, 'batch_size': 105, 'beta_1': 0.9673552844045469, 'beta_2': 0.9999529527904469, 'epsilon': 1.6155187894981714e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0003570503611256605, 'tol': 0.07385804758223836, 'validation_fraction': 0.4361162756744545}]
function_evaluation time 0.466679 value 9.327932 suggestion {'alpha': 3.8600650704922015, 'batch_size': 105, 'beta_1': 0.9673552844045469, 'beta_2': 0.9999529527904469, 'epsilon': 1.6155187894981714e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0003570503611256605, 'tol': 0.07385804758223836, 'validation_fraction': 0.4361162756744545}
observation time 0.000003, current best 0.467771 at iter 2
suggestion time taken 0.010374 iter 3 next_points [{'alpha': 1.0492236014396912, 'batch_size': 215, 'beta_1': 0.6389708030814215, 'beta_2': 0.9999225164527547, 'epsilon': 8.21114189981923e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.00020862567148751583, 'tol': 0.05089570918907052, 'validation_fraction': 0.48719618800822523}]
function_evaluation time 0.395257 value 12.279443 suggestion {'alpha': 1.0492236014396912, 'batch_size': 215, 'beta_1': 0.6389708030814215, 'beta_2': 0.9999225164527547, 'epsilon': 8.21114189981923e-09, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.00020862567148751583, 'tol': 0.05089570918907052, 'validation_fraction': 0.48719618800822523}
observation time 0.000010, current best 0.467771 at iter 3
suggestion time taken 0.015843 iter 4 next_points [{'alpha': 1.7095174012684123e-05, 'batch_size': 82, 'beta_1': 0.9875488911216982, 'beta_2': 0.9907921969551468, 'epsilon': 4.361775737280486e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.00020088114265496247, 'tol': 0.001170390593510483, 'validation_fraction': 0.7856188402856642}]
function_evaluation time 0.357834 value 15.030531 suggestion {'alpha': 1.7095174012684123e-05, 'batch_size': 82, 'beta_1': 0.9875488911216982, 'beta_2': 0.9907921969551468, 'epsilon': 4.361775737280486e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.00020088114265496247, 'tol': 0.001170390593510483, 'validation_fraction': 0.7856188402856642}
observation time 0.000010, current best 0.467771 at iter 4
suggestion time taken 0.012319 iter 5 next_points [{'alpha': 0.0005490233937679949, 'batch_size': 82, 'beta_1': 0.5852710851321211, 'beta_2': 0.999997442029452, 'epsilon': 1.0221963644866688e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 2.5299836258368962e-05, 'tol': 0.00010047127280177484, 'validation_fraction': 0.520217464320891}]
function_evaluation time 0.385398 value 13.515632 suggestion {'alpha': 0.0005490233937679949, 'batch_size': 82, 'beta_1': 0.5852710851321211, 'beta_2': 0.999997442029452, 'epsilon': 1.0221963644866688e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 2.5299836258368962e-05, 'tol': 0.00010047127280177484, 'validation_fraction': 0.520217464320891}
observation time 0.000004, current best 0.467771 at iter 5
suggestion time taken 0.011189 iter 6 next_points [{'alpha': 0.2706369540756214, 'batch_size': 63, 'beta_1': 0.6107834151556139, 'beta_2': 0.9999871980392613, 'epsilon': 9.578884177777946e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.002165343113443523, 'tol': 0.01706480596588586, 'validation_fraction': 0.5385395095485117}]
function_evaluation time 0.680791 value 0.466461 suggestion {'alpha': 0.2706369540756214, 'batch_size': 63, 'beta_1': 0.6107834151556139, 'beta_2': 0.9999871980392613, 'epsilon': 9.578884177777946e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.002165343113443523, 'tol': 0.01706480596588586, 'validation_fraction': 0.5385395095485117}
observation time 0.000008, current best 0.466461 at iter 6
suggestion time taken 0.012131 iter 7 next_points [{'alpha': 0.003841982885487591, 'batch_size': 36, 'beta_1': 0.5062076689427453, 'beta_2': 0.9998533801939488, 'epsilon': 4.221940606775275e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.00233663037455477, 'tol': 0.09060641392164742, 'validation_fraction': 0.723784740661972}]
function_evaluation time 0.554323 value 0.496023 suggestion {'alpha': 0.003841982885487591, 'batch_size': 36, 'beta_1': 0.5062076689427453, 'beta_2': 0.9998533801939488, 'epsilon': 4.221940606775275e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.00233663037455477, 'tol': 0.09060641392164742, 'validation_fraction': 0.723784740661972}
observation time 0.000013, current best 0.466461 at iter 7
suggestion time taken 0.014478 iter 8 next_points [{'alpha': 0.002408631204767112, 'batch_size': 143, 'beta_1': 0.8456367825658039, 'beta_2': 0.9999974278770325, 'epsilon': 1.67351874340758e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 2.4096133190150865e-05, 'tol': 0.005118767872093693, 'validation_fraction': 0.4736006405723047}]
function_evaluation time 0.612129 value 11.729522 suggestion {'alpha': 0.002408631204767112, 'batch_size': 143, 'beta_1': 0.8456367825658039, 'beta_2': 0.9999974278770325, 'epsilon': 1.67351874340758e-08, 'hidden_layer_sizes': 156, 'learning_rate_init': 2.4096133190150865e-05, 'tol': 0.005118767872093693, 'validation_fraction': 0.4736006405723047}
observation time 0.000004, current best 0.466461 at iter 8
suggestion time taken 0.010199 iter 9 next_points [{'alpha': 1.0179020798607672e-05, 'batch_size': 157, 'beta_1': 0.9891006551093421, 'beta_2': 0.9985959734317793, 'epsilon': 4.4320432309634244e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0012854255926040728, 'tol': 9.783330643572629e-05, 'validation_fraction': 0.14086532036635596}]
function_evaluation time 0.782100 value 0.550313 suggestion {'alpha': 1.0179020798607672e-05, 'batch_size': 157, 'beta_1': 0.9891006551093421, 'beta_2': 0.9985959734317793, 'epsilon': 4.4320432309634244e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0012854255926040728, 'tol': 9.783330643572629e-05, 'validation_fraction': 0.14086532036635596}
observation time 0.000005, current best 0.466461 at iter 9
suggestion time taken 0.011188 iter 10 next_points [{'alpha': 0.0061164946592693215, 'batch_size': 196, 'beta_1': 0.8162119630576122, 'beta_2': 0.9999971690556324, 'epsilon': 3.182679628380203e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.00011634472545538468, 'tol': 1.0562523462171361e-05, 'validation_fraction': 0.6925119452456523}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.260070 value 12.773616 suggestion {'alpha': 0.0061164946592693215, 'batch_size': 196, 'beta_1': 0.8162119630576122, 'beta_2': 0.9999971690556324, 'epsilon': 3.182679628380203e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.00011634472545538468, 'tol': 1.0562523462171361e-05, 'validation_fraction': 0.6925119452456523}
observation time 0.000004, current best 0.466461 at iter 10
suggestion time taken 0.010509 iter 11 next_points [{'alpha': 0.008440594385248149, 'batch_size': 210, 'beta_1': 0.7099227448101423, 'beta_2': 0.9994271014229494, 'epsilon': 1.6226646559357626e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 2.4217848942765687e-05, 'tol': 0.0032217860739224857, 'validation_fraction': 0.28070126987799515}]
function_evaluation time 0.395536 value 18.364452 suggestion {'alpha': 0.008440594385248149, 'batch_size': 210, 'beta_1': 0.7099227448101423, 'beta_2': 0.9994271014229494, 'epsilon': 1.6226646559357626e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 2.4217848942765687e-05, 'tol': 0.0032217860739224857, 'validation_fraction': 0.28070126987799515}
observation time 0.000004, current best 0.466461 at iter 11
suggestion time taken 0.011464 iter 12 next_points [{'alpha': 0.27736767141110885, 'batch_size': 52, 'beta_1': 0.5735131466827766, 'beta_2': 0.999911855677747, 'epsilon': 1.4358982464708929e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.010018595773143162, 'tol': 0.00232967438486174, 'validation_fraction': 0.8111803237286046}]
function_evaluation time 0.680005 value 0.699494 suggestion {'alpha': 0.27736767141110885, 'batch_size': 52, 'beta_1': 0.5735131466827766, 'beta_2': 0.999911855677747, 'epsilon': 1.4358982464708929e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.010018595773143162, 'tol': 0.00232967438486174, 'validation_fraction': 0.8111803237286046}
observation time 0.000004, current best 0.466461 at iter 12
suggestion time taken 0.010081 iter 13 next_points [{'alpha': 2.424184422767791, 'batch_size': 226, 'beta_1': 0.620245959563858, 'beta_2': 0.9988892181642246, 'epsilon': 3.955299356044613e-07, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.029985226398872068, 'tol': 1.7915379006198594e-05, 'validation_fraction': 0.7796422390727082}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.693714 value 0.973881 suggestion {'alpha': 2.424184422767791, 'batch_size': 226, 'beta_1': 0.620245959563858, 'beta_2': 0.9988892181642246, 'epsilon': 3.955299356044613e-07, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.029985226398872068, 'tol': 1.7915379006198594e-05, 'validation_fraction': 0.7796422390727082}
observation time 0.000004, current best 0.466461 at iter 13
suggestion time taken 0.010869 iter 14 next_points [{'alpha': 2.146750136671925e-05, 'batch_size': 27, 'beta_1': 0.9447566649041694, 'beta_2': 0.9880946787799454, 'epsilon': 1.3319452981501813e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.0038166270935375596, 'tol': 0.0013715697689819747, 'validation_fraction': 0.7010831128094078}]
function_evaluation time 1.054812 value 0.929723 suggestion {'alpha': 2.146750136671925e-05, 'batch_size': 27, 'beta_1': 0.9447566649041694, 'beta_2': 0.9880946787799454, 'epsilon': 1.3319452981501813e-07, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.0038166270935375596, 'tol': 0.0013715697689819747, 'validation_fraction': 0.7010831128094078}
observation time 0.000005, current best 0.466461 at iter 14
suggestion time taken 0.010735 iter 15 next_points [{'alpha': 0.0019205259292041524, 'batch_size': 37, 'beta_1': 0.9156279406822784, 'beta_2': 0.9999984423993328, 'epsilon': 6.705345713790162e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.018250776574894014, 'tol': 0.023608613157750463, 'validation_fraction': 0.41774844050721166}]
function_evaluation time 0.772442 value 0.869505 suggestion {'alpha': 0.0019205259292041524, 'batch_size': 37, 'beta_1': 0.9156279406822784, 'beta_2': 0.9999984423993328, 'epsilon': 6.705345713790162e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.018250776574894014, 'tol': 0.023608613157750463, 'validation_fraction': 0.41774844050721166}
observation time 0.000008, current best 0.466461 at iter 15
suggestion time taken 0.014256 iter 16 next_points [{'alpha': 3.964184442640388e-05, 'batch_size': 62, 'beta_1': 0.5617081642317705, 'beta_2': 0.999991690600155, 'epsilon': 6.726468661470273e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0004152314114058718, 'tol': 0.008945346516606209, 'validation_fraction': 0.5625389133972881}]
function_evaluation time 1.323014 value 0.352272 suggestion {'alpha': 3.964184442640388e-05, 'batch_size': 62, 'beta_1': 0.5617081642317705, 'beta_2': 0.999991690600155, 'epsilon': 6.726468661470273e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.0004152314114058718, 'tol': 0.008945346516606209, 'validation_fraction': 0.5625389133972881}
observation time 0.000005, current best 0.352272 at iter 16
suggestion time taken 0.010904 iter 17 next_points [{'alpha': 0.0010069067927236416, 'batch_size': 226, 'beta_1': 0.5628751050926718, 'beta_2': 0.9512876616673208, 'epsilon': 1.3659708204621863e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.0008555522246893791, 'tol': 0.03961388105315629, 'validation_fraction': 0.794208020370153}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.367175 value 7.748971 suggestion {'alpha': 0.0010069067927236416, 'batch_size': 226, 'beta_1': 0.5628751050926718, 'beta_2': 0.9512876616673208, 'epsilon': 1.3659708204621863e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.0008555522246893791, 'tol': 0.03961388105315629, 'validation_fraction': 0.794208020370153}
observation time 0.000003, current best 0.352272 at iter 17
suggestion time taken 0.010388 iter 18 next_points [{'alpha': 5.036743885429522, 'batch_size': 143, 'beta_1': 0.9724202955623089, 'beta_2': 0.999896082131715, 'epsilon': 2.601232528888886e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.08200764991374689, 'tol': 0.0009901728153674965, 'validation_fraction': 0.18112061301067983}]
function_evaluation time 0.693175 value 2.905439 suggestion {'alpha': 5.036743885429522, 'batch_size': 143, 'beta_1': 0.9724202955623089, 'beta_2': 0.999896082131715, 'epsilon': 2.601232528888886e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.08200764991374689, 'tol': 0.0009901728153674965, 'validation_fraction': 0.18112061301067983}
observation time 0.000011, current best 0.352272 at iter 18
suggestion time taken 0.012723 iter 19 next_points [{'alpha': 0.06963492158791416, 'batch_size': 215, 'beta_1': 0.5855282081642941, 'beta_2': 0.9978195840892465, 'epsilon': 3.4123971133871417e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.0009088266695646603, 'tol': 0.0002425006323711042, 'validation_fraction': 0.6611172971635125}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.522991 value 9.568546 suggestion {'alpha': 0.06963492158791416, 'batch_size': 215, 'beta_1': 0.5855282081642941, 'beta_2': 0.9978195840892465, 'epsilon': 3.4123971133871417e-09, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.0009088266695646603, 'tol': 0.0002425006323711042, 'validation_fraction': 0.6611172971635125}
observation time 0.000003, current best 0.352272 at iter 19
suggestion time taken 0.009591 iter 20 next_points [{'alpha': 0.00030054702824319844, 'batch_size': 161, 'beta_1': 0.7204178505669548, 'beta_2': 0.9999171067713503, 'epsilon': 1.6639268397876289e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.025688309975241727, 'tol': 1.3961298450270913e-05, 'validation_fraction': 0.15053669011115348}]
function_evaluation time 0.837297 value 0.656593 suggestion {'alpha': 0.00030054702824319844, 'batch_size': 161, 'beta_1': 0.7204178505669548, 'beta_2': 0.9999171067713503, 'epsilon': 1.6639268397876289e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.025688309975241727, 'tol': 1.3961298450270913e-05, 'validation_fraction': 0.15053669011115348}
observation time 0.000010, current best 0.352272 at iter 20
suggestion time taken 0.012316 iter 21 next_points [{'alpha': 0.07718627801347788, 'batch_size': 56, 'beta_1': 0.9089896800074957, 'beta_2': 0.9999519848883324, 'epsilon': 9.731758597471724e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 3.91650491748855e-05, 'tol': 0.0002964285599533668, 'validation_fraction': 0.229725846051498}]
function_evaluation time 0.994796 value 10.015275 suggestion {'alpha': 0.07718627801347788, 'batch_size': 56, 'beta_1': 0.9089896800074957, 'beta_2': 0.9999519848883324, 'epsilon': 9.731758597471724e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 3.91650491748855e-05, 'tol': 0.0002964285599533668, 'validation_fraction': 0.229725846051498}
observation time 0.000006, current best 0.352272 at iter 21
suggestion time taken 0.011130 iter 22 next_points [{'alpha': 0.46232061334411984, 'batch_size': 248, 'beta_1': 0.9383686666104556, 'beta_2': 0.998388282006629, 'epsilon': 6.36266905780074e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.00300992681345594, 'tol': 0.06803739832196774, 'validation_fraction': 0.8855472262427566}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.363981 value 2.211387 suggestion {'alpha': 0.46232061334411984, 'batch_size': 248, 'beta_1': 0.9383686666104556, 'beta_2': 0.998388282006629, 'epsilon': 6.36266905780074e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.00300992681345594, 'tol': 0.06803739832196774, 'validation_fraction': 0.8855472262427566}
observation time 0.000003, current best 0.352272 at iter 22
suggestion time taken 0.010275 iter 23 next_points [{'alpha': 2.5754617936107036e-05, 'batch_size': 159, 'beta_1': 0.9891805851183721, 'beta_2': 0.9926227892327852, 'epsilon': 1.625899966968362e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.009833516132053738, 'tol': 0.07933963529488836, 'validation_fraction': 0.2052876832377119}]
function_evaluation time 0.604684 value 1.262676 suggestion {'alpha': 2.5754617936107036e-05, 'batch_size': 159, 'beta_1': 0.9891805851183721, 'beta_2': 0.9926227892327852, 'epsilon': 1.625899966968362e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.009833516132053738, 'tol': 0.07933963529488836, 'validation_fraction': 0.2052876832377119}
observation time 0.000005, current best 0.352272 at iter 23
suggestion time taken 0.011103 iter 24 next_points [{'alpha': 0.034234869580279916, 'batch_size': 74, 'beta_1': 0.9865976171448312, 'beta_2': 0.9970369973451821, 'epsilon': 7.663909899352462e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0009113379894230043, 'tol': 0.0007594085738498789, 'validation_fraction': 0.8828286662523289}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.506614 value 2.986878 suggestion {'alpha': 0.034234869580279916, 'batch_size': 74, 'beta_1': 0.9865976171448312, 'beta_2': 0.9970369973451821, 'epsilon': 7.663909899352462e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0009113379894230043, 'tol': 0.0007594085738498789, 'validation_fraction': 0.8828286662523289}
observation time 0.000005, current best 0.352272 at iter 24
suggestion time taken 0.011326 iter 25 next_points [{'alpha': 2.6894732916210975, 'batch_size': 83, 'beta_1': 0.5316967121318521, 'beta_2': 0.9997802351961281, 'epsilon': 8.980270119962943e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 3.548589268334972e-05, 'tol': 0.03600091179138948, 'validation_fraction': 0.7805018121771926}]
function_evaluation time 0.368458 value 20.105986 suggestion {'alpha': 2.6894732916210975, 'batch_size': 83, 'beta_1': 0.5316967121318521, 'beta_2': 0.9997802351961281, 'epsilon': 8.980270119962943e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 3.548589268334972e-05, 'tol': 0.03600091179138948, 'validation_fraction': 0.7805018121771926}
observation time 0.000007, current best 0.352272 at iter 25
suggestion time taken 0.013985 iter 26 next_points [{'alpha': 0.004458952706895321, 'batch_size': 52, 'beta_1': 0.7648427196202741, 'beta_2': 0.9967197369685027, 'epsilon': 2.998194255157288e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.024533764003067712, 'tol': 0.020462695066875345, 'validation_fraction': 0.8966388645731908}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.366423 value 0.868620 suggestion {'alpha': 0.004458952706895321, 'batch_size': 52, 'beta_1': 0.7648427196202741, 'beta_2': 0.9967197369685027, 'epsilon': 2.998194255157288e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.024533764003067712, 'tol': 0.020462695066875345, 'validation_fraction': 0.8966388645731908}
observation time 0.000003, current best 0.352272 at iter 26
suggestion time taken 0.010342 iter 27 next_points [{'alpha': 0.0004911711598089122, 'batch_size': 47, 'beta_1': 0.9653580525360185, 'beta_2': 0.9892485882938389, 'epsilon': 1.37913274147338e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 4.839745247543482e-05, 'tol': 0.04658470440241461, 'validation_fraction': 0.19492730540830944}]
function_evaluation time 0.998792 value 8.635874 suggestion {'alpha': 0.0004911711598089122, 'batch_size': 47, 'beta_1': 0.9653580525360185, 'beta_2': 0.9892485882938389, 'epsilon': 1.37913274147338e-09, 'hidden_layer_sizes': 147, 'learning_rate_init': 4.839745247543482e-05, 'tol': 0.04658470440241461, 'validation_fraction': 0.19492730540830944}
observation time 0.000004, current best 0.352272 at iter 27
suggestion time taken 0.010077 iter 28 next_points [{'alpha': 0.00021587696578605873, 'batch_size': 142, 'beta_1': 0.8520507907838303, 'beta_2': 0.9917902342692004, 'epsilon': 1.3433147923855304e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.009991054173305307, 'tol': 1.609255071353201e-05, 'validation_fraction': 0.3941901787488385}]
function_evaluation time 0.809511 value 0.815016 suggestion {'alpha': 0.00021587696578605873, 'batch_size': 142, 'beta_1': 0.8520507907838303, 'beta_2': 0.9917902342692004, 'epsilon': 1.3433147923855304e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.009991054173305307, 'tol': 1.609255071353201e-05, 'validation_fraction': 0.3941901787488385}
observation time 0.000005, current best 0.352272 at iter 28
suggestion time taken 0.010702 iter 29 next_points [{'alpha': 5.246776972775194, 'batch_size': 198, 'beta_1': 0.8563757151180378, 'beta_2': 0.9999836707407873, 'epsilon': 9.29959350206689e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.00018412088520453017, 'tol': 0.008994681394671643, 'validation_fraction': 0.8195794555624353}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.471055 value 7.549570 suggestion {'alpha': 5.246776972775194, 'batch_size': 198, 'beta_1': 0.8563757151180378, 'beta_2': 0.9999836707407873, 'epsilon': 9.29959350206689e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.00018412088520453017, 'tol': 0.008994681394671643, 'validation_fraction': 0.8195794555624353}
observation time 0.000004, current best 0.352272 at iter 29
suggestion time taken 0.011142 iter 30 next_points [{'alpha': 0.08740326318110125, 'batch_size': 247, 'beta_1': 0.9569800127394589, 'beta_2': 0.9999931445060936, 'epsilon': 2.419765176399208e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.005346326584787761, 'tol': 0.014381887254416853, 'validation_fraction': 0.867395906108752}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.458906 value 5.583144 suggestion {'alpha': 0.08740326318110125, 'batch_size': 247, 'beta_1': 0.9569800127394589, 'beta_2': 0.9999931445060936, 'epsilon': 2.419765176399208e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.005346326584787761, 'tol': 0.014381887254416853, 'validation_fraction': 0.867395906108752}
observation time 0.000004, current best 0.352272 at iter 30
suggestion time taken 0.010629 iter 31 next_points [{'alpha': 4.078167816803384, 'batch_size': 30, 'beta_1': 0.7611829919482812, 'beta_2': 0.9999982923644216, 'epsilon': 2.02089828821484e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.08528140964718377, 'tol': 0.0005603943908202152, 'validation_fraction': 0.11498530808864642}]
function_evaluation time 0.557978 value 0.338630 suggestion {'alpha': 4.078167816803384, 'batch_size': 30, 'beta_1': 0.7611829919482812, 'beta_2': 0.9999982923644216, 'epsilon': 2.02089828821484e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.08528140964718377, 'tol': 0.0005603943908202152, 'validation_fraction': 0.11498530808864642}
observation time 0.000004, current best 0.338630 at iter 31
suggestion time taken 0.010921 iter 32 next_points [{'alpha': 0.06485209157071717, 'batch_size': 137, 'beta_1': 0.8923342883555038, 'beta_2': 0.9996278028482254, 'epsilon': 1.5956448474126303e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.08834445811103417, 'tol': 0.0001659382957985552, 'validation_fraction': 0.6364154332636643}]
function_evaluation time 0.537452 value 5.323161 suggestion {'alpha': 0.06485209157071717, 'batch_size': 137, 'beta_1': 0.8923342883555038, 'beta_2': 0.9996278028482254, 'epsilon': 1.5956448474126303e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.08834445811103417, 'tol': 0.0001659382957985552, 'validation_fraction': 0.6364154332636643}
observation time 0.000004, current best 0.338630 at iter 32
suggestion time taken 0.010816 iter 33 next_points [{'alpha': 0.04828184444214476, 'batch_size': 101, 'beta_1': 0.6263480890786782, 'beta_2': 0.9766001899035277, 'epsilon': 6.396160045759006e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.00033668902260317626, 'tol': 0.09756825228615448, 'validation_fraction': 0.19047526439132378}]
function_evaluation time 0.412071 value 10.006461 suggestion {'alpha': 0.04828184444214476, 'batch_size': 101, 'beta_1': 0.6263480890786782, 'beta_2': 0.9766001899035277, 'epsilon': 6.396160045759006e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.00033668902260317626, 'tol': 0.09756825228615448, 'validation_fraction': 0.19047526439132378}
observation time 0.000003, current best 0.338630 at iter 33
suggestion time taken 0.010264 iter 34 next_points [{'alpha': 0.0002616073631692029, 'batch_size': 175, 'beta_1': 0.7963883847200214, 'beta_2': 0.9955532910948903, 'epsilon': 1.0553051467527285e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0004799837226230328, 'tol': 1.4991112597745127e-05, 'validation_fraction': 0.16998445941775278}]
function_evaluation time 1.194109 value 0.337091 suggestion {'alpha': 0.0002616073631692029, 'batch_size': 175, 'beta_1': 0.7963883847200214, 'beta_2': 0.9955532910948903, 'epsilon': 1.0553051467527285e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0004799837226230328, 'tol': 1.4991112597745127e-05, 'validation_fraction': 0.16998445941775278}
observation time 0.000006, current best 0.337091 at iter 34
suggestion time taken 0.011191 iter 35 next_points [{'alpha': 0.22322634736700606, 'batch_size': 48, 'beta_1': 0.9572263885120997, 'beta_2': 0.9982718941071784, 'epsilon': 5.1160134547834976e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.01460990859399833, 'tol': 0.0006710024452146813, 'validation_fraction': 0.19993992217307968}]
function_evaluation time 0.610555 value 1.245392 suggestion {'alpha': 0.22322634736700606, 'batch_size': 48, 'beta_1': 0.9572263885120997, 'beta_2': 0.9982718941071784, 'epsilon': 5.1160134547834976e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.01460990859399833, 'tol': 0.0006710024452146813, 'validation_fraction': 0.19993992217307968}
observation time 0.000004, current best 0.337091 at iter 35
suggestion time taken 0.010604 iter 36 next_points [{'alpha': 3.552259947430935, 'batch_size': 177, 'beta_1': 0.9700057833607496, 'beta_2': 0.9931092984894638, 'epsilon': 2.4415771593323656e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00014878395399942093, 'tol': 0.000538827857126507, 'validation_fraction': 0.11077413903369003}]
function_evaluation time 0.338645 value 18.218372 suggestion {'alpha': 3.552259947430935, 'batch_size': 177, 'beta_1': 0.9700057833607496, 'beta_2': 0.9931092984894638, 'epsilon': 2.4415771593323656e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.00014878395399942093, 'tol': 0.000538827857126507, 'validation_fraction': 0.11077413903369003}
observation time 0.000006, current best 0.337091 at iter 36
suggestion time taken 0.011405 iter 37 next_points [{'alpha': 8.008048896275136, 'batch_size': 222, 'beta_1': 0.7665023462486321, 'beta_2': 0.9943720174638931, 'epsilon': 8.394123673756266e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.002907652946022102, 'tol': 0.05461303077817164, 'validation_fraction': 0.47827018748081795}]
function_evaluation time 0.483797 value 1.147781 suggestion {'alpha': 8.008048896275136, 'batch_size': 222, 'beta_1': 0.7665023462486321, 'beta_2': 0.9943720174638931, 'epsilon': 8.394123673756266e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.002907652946022102, 'tol': 0.05461303077817164, 'validation_fraction': 0.47827018748081795}
observation time 0.000010, current best 0.337091 at iter 37
suggestion time taken 0.012012 iter 38 next_points [{'alpha': 0.009221731275166534, 'batch_size': 34, 'beta_1': 0.9463378252095422, 'beta_2': 0.99616143458002, 'epsilon': 2.1242104940791566e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.05212677468684041, 'tol': 0.00012155968111919716, 'validation_fraction': 0.6263387734369864}]
function_evaluation time 1.054491 value 0.448143 suggestion {'alpha': 0.009221731275166534, 'batch_size': 34, 'beta_1': 0.9463378252095422, 'beta_2': 0.99616143458002, 'epsilon': 2.1242104940791566e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.05212677468684041, 'tol': 0.00012155968111919716, 'validation_fraction': 0.6263387734369864}
observation time 0.000009, current best 0.337091 at iter 38
suggestion time taken 0.012170 iter 39 next_points [{'alpha': 4.9073209425698385, 'batch_size': 125, 'beta_1': 0.9686984232677749, 'beta_2': 0.9999754166703123, 'epsilon': 4.6466424048408744e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.001029039067651255, 'tol': 0.002500791042633955, 'validation_fraction': 0.4550260774880962}]
function_evaluation time 0.877079 value 0.697815 suggestion {'alpha': 4.9073209425698385, 'batch_size': 125, 'beta_1': 0.9686984232677749, 'beta_2': 0.9999754166703123, 'epsilon': 4.6466424048408744e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.001029039067651255, 'tol': 0.002500791042633955, 'validation_fraction': 0.4550260774880962}
observation time 0.000014, current best 0.337091 at iter 39
suggestion time taken 0.010607 iter 40 next_points [{'alpha': 3.510987378250663e-05, 'batch_size': 109, 'beta_1': 0.9409512336805079, 'beta_2': 0.9502134594400315, 'epsilon': 9.993162080789305e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0052488704256641455, 'tol': 0.00037021383159716547, 'validation_fraction': 0.45824058738049916}]
function_evaluation time 0.989347 value 0.646164 suggestion {'alpha': 3.510987378250663e-05, 'batch_size': 109, 'beta_1': 0.9409512336805079, 'beta_2': 0.9502134594400315, 'epsilon': 9.993162080789305e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0052488704256641455, 'tol': 0.00037021383159716547, 'validation_fraction': 0.45824058738049916}
observation time 0.000004, current best 0.337091 at iter 40
suggestion time taken 0.010652 iter 41 next_points [{'alpha': 1.4883268352320125, 'batch_size': 204, 'beta_1': 0.9847320834652031, 'beta_2': 0.999967662615289, 'epsilon': 7.365041053427751e-08, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.024512512844760685, 'tol': 0.00555299146926797, 'validation_fraction': 0.5320833071361528}]
function_evaluation time 0.529312 value 0.908825 suggestion {'alpha': 1.4883268352320125, 'batch_size': 204, 'beta_1': 0.9847320834652031, 'beta_2': 0.999967662615289, 'epsilon': 7.365041053427751e-08, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.024512512844760685, 'tol': 0.00555299146926797, 'validation_fraction': 0.5320833071361528}
observation time 0.000004, current best 0.337091 at iter 41
suggestion time taken 0.010846 iter 42 next_points [{'alpha': 0.3808123543958391, 'batch_size': 117, 'beta_1': 0.9783217159685068, 'beta_2': 0.9536278610131024, 'epsilon': 5.931940657818424e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0004831091453629354, 'tol': 0.0009249989864658378, 'validation_fraction': 0.5917320861140244}]
function_evaluation time 0.549816 value 6.039985 suggestion {'alpha': 0.3808123543958391, 'batch_size': 117, 'beta_1': 0.9783217159685068, 'beta_2': 0.9536278610131024, 'epsilon': 5.931940657818424e-07, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0004831091453629354, 'tol': 0.0009249989864658378, 'validation_fraction': 0.5917320861140244}
observation time 0.000005, current best 0.337091 at iter 42
suggestion time taken 0.010800 iter 43 next_points [{'alpha': 0.020190987090023645, 'batch_size': 108, 'beta_1': 0.9778880563769008, 'beta_2': 0.9794021962564242, 'epsilon': 3.229541462835959e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0010696153414261912, 'tol': 1.5740189682263716e-05, 'validation_fraction': 0.5839855504301836}]
function_evaluation time 0.852203 value 5.288705 suggestion {'alpha': 0.020190987090023645, 'batch_size': 108, 'beta_1': 0.9778880563769008, 'beta_2': 0.9794021962564242, 'epsilon': 3.229541462835959e-08, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0010696153414261912, 'tol': 1.5740189682263716e-05, 'validation_fraction': 0.5839855504301836}
observation time 0.000004, current best 0.337091 at iter 43
suggestion time taken 0.010844 iter 44 next_points [{'alpha': 3.653673620134992e-05, 'batch_size': 209, 'beta_1': 0.9899900807565104, 'beta_2': 0.9966687256443176, 'epsilon': 4.5271304705681723e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.054072771580593586, 'tol': 0.010308947569912864, 'validation_fraction': 0.11191031862883057}]
function_evaluation time 0.553127 value 2.889244 suggestion {'alpha': 3.653673620134992e-05, 'batch_size': 209, 'beta_1': 0.9899900807565104, 'beta_2': 0.9966687256443176, 'epsilon': 4.5271304705681723e-08, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.054072771580593586, 'tol': 0.010308947569912864, 'validation_fraction': 0.11191031862883057}
observation time 0.000006, current best 0.337091 at iter 44
saving meta data: {'args': {'--uuid': 'e3be4ad8b45d53ff97e6ab74532cc4f0', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])}
saving results
saving timing
saving suggest log
done
