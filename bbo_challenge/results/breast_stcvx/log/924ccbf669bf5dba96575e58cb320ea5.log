running: {'--uuid': '924ccbf669bf5dba96575e58cb320ea5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 924ccbf669bf5dba96575e58cb320ea5 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.010619 iter 0 next_points [{'alpha': 2.5300449725271294e-05, 'batch_size': 57, 'beta_1': 0.9158050799145202, 'beta_2': 0.9344009019450865, 'epsilon': 2.0075193301555563e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 3.4247854095077546e-05, 'tol': 0.0009576636440010276, 'validation_fraction': 0.44141579283633625}]
function_evaluation time 0.861493 value -0.567033 suggestion {'alpha': 2.5300449725271294e-05, 'batch_size': 57, 'beta_1': 0.9158050799145202, 'beta_2': 0.9344009019450865, 'epsilon': 2.0075193301555563e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 3.4247854095077546e-05, 'tol': 0.0009576636440010276, 'validation_fraction': 0.44141579283633625}
observation time 0.000004, current best -0.567033 at iter 0
suggestion time taken 0.010485 iter 1 next_points [{'alpha': 0.7309454449925874, 'batch_size': 89, 'beta_1': 0.8741925837446648, 'beta_2': 0.9999975093451278, 'epsilon': 3.7139417993227375e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0004782402309030952, 'tol': 0.09013882493349266, 'validation_fraction': 0.838042180006805}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.295251 value -0.723077 suggestion {'alpha': 0.7309454449925874, 'batch_size': 89, 'beta_1': 0.8741925837446648, 'beta_2': 0.9999975093451278, 'epsilon': 3.7139417993227375e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0004782402309030952, 'tol': 0.09013882493349266, 'validation_fraction': 0.838042180006805}
observation time 0.000003, current best -0.723077 at iter 1
suggestion time taken 0.010522 iter 2 next_points [{'alpha': 0.006684491707531704, 'batch_size': 194, 'beta_1': 0.8600083556071904, 'beta_2': 0.9806197049449975, 'epsilon': 1.0692103821066695e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 1.5942069927368824e-05, 'tol': 0.000439878131884367, 'validation_fraction': 0.6596741008662118}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.250772 value -0.472527 suggestion {'alpha': 0.006684491707531704, 'batch_size': 194, 'beta_1': 0.8600083556071904, 'beta_2': 0.9806197049449975, 'epsilon': 1.0692103821066695e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 1.5942069927368824e-05, 'tol': 0.000439878131884367, 'validation_fraction': 0.6596741008662118}
observation time 0.000003, current best -0.723077 at iter 2
suggestion time taken 0.010464 iter 3 next_points [{'alpha': 0.0012588041291311505, 'batch_size': 194, 'beta_1': 0.7939973735399116, 'beta_2': 0.9999968393947808, 'epsilon': 4.11859131357462e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.00024161796154877895, 'tol': 1.4094190504833926e-05, 'validation_fraction': 0.7540663155834272}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.315751 value -0.630769 suggestion {'alpha': 0.0012588041291311505, 'batch_size': 194, 'beta_1': 0.7939973735399116, 'beta_2': 0.9999968393947808, 'epsilon': 4.11859131357462e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.00024161796154877895, 'tol': 1.4094190504833926e-05, 'validation_fraction': 0.7540663155834272}
observation time 0.000003, current best -0.723077 at iter 3
suggestion time taken 0.010650 iter 4 next_points [{'alpha': 0.5329855910736471, 'batch_size': 226, 'beta_1': 0.9817459226194856, 'beta_2': 0.9999967217664819, 'epsilon': 7.200166790944535e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.000570043391380919, 'tol': 0.0027734599648115057, 'validation_fraction': 0.8559603563415323}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.307219 value -0.705495 suggestion {'alpha': 0.5329855910736471, 'batch_size': 226, 'beta_1': 0.9817459226194856, 'beta_2': 0.9999967217664819, 'epsilon': 7.200166790944535e-07, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.000570043391380919, 'tol': 0.0027734599648115057, 'validation_fraction': 0.8559603563415323}
observation time 0.000003, current best -0.723077 at iter 4
suggestion time taken 0.010560 iter 5 next_points [{'alpha': 1.6918134115629155, 'batch_size': 16, 'beta_1': 0.9895951633275676, 'beta_2': 0.9999842926297098, 'epsilon': 5.47983366168943e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.001981411426102885, 'tol': 0.00010530735699639199, 'validation_fraction': 0.6821875629062283}]
function_evaluation time 1.100616 value -0.912088 suggestion {'alpha': 1.6918134115629155, 'batch_size': 16, 'beta_1': 0.9895951633275676, 'beta_2': 0.9999842926297098, 'epsilon': 5.47983366168943e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.001981411426102885, 'tol': 0.00010530735699639199, 'validation_fraction': 0.6821875629062283}
observation time 0.000003, current best -0.912088 at iter 5
suggestion time taken 0.010594 iter 6 next_points [{'alpha': 2.287042735737282e-05, 'batch_size': 121, 'beta_1': 0.949376433838767, 'beta_2': 0.9999896497496494, 'epsilon': 5.204143981469523e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0005249150695933702, 'tol': 0.03238667637689461, 'validation_fraction': 0.24016044455670418}]
function_evaluation time 0.640065 value -0.793407 suggestion {'alpha': 2.287042735737282e-05, 'batch_size': 121, 'beta_1': 0.949376433838767, 'beta_2': 0.9999896497496494, 'epsilon': 5.204143981469523e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0005249150695933702, 'tol': 0.03238667637689461, 'validation_fraction': 0.24016044455670418}
observation time 0.000003, current best -0.912088 at iter 6
suggestion time taken 0.008812 iter 7 next_points [{'alpha': 0.00044886492071057846, 'batch_size': 69, 'beta_1': 0.8248112202574265, 'beta_2': 0.9999776135822507, 'epsilon': 3.7122432475242066e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0008196320224925581, 'tol': 0.0012420741656938702, 'validation_fraction': 0.10455305673919331}]
function_evaluation time 0.446743 value -0.865934 suggestion {'alpha': 0.00044886492071057846, 'batch_size': 69, 'beta_1': 0.8248112202574265, 'beta_2': 0.9999776135822507, 'epsilon': 3.7122432475242066e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0008196320224925581, 'tol': 0.0012420741656938702, 'validation_fraction': 0.10455305673919331}
observation time 0.000002, current best -0.912088 at iter 7
suggestion time taken 0.010592 iter 8 next_points [{'alpha': 1.293622359470029e-05, 'batch_size': 206, 'beta_1': 0.9694598331543187, 'beta_2': 0.9973752333061319, 'epsilon': 2.4364940125758652e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.005092815174906933, 'tol': 0.01830012132174478, 'validation_fraction': 0.2594777382713357}]
function_evaluation time 0.559330 value -0.839560 suggestion {'alpha': 1.293622359470029e-05, 'batch_size': 206, 'beta_1': 0.9694598331543187, 'beta_2': 0.9973752333061319, 'epsilon': 2.4364940125758652e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.005092815174906933, 'tol': 0.01830012132174478, 'validation_fraction': 0.2594777382713357}
observation time 0.000003, current best -0.912088 at iter 8
suggestion time taken 0.011068 iter 9 next_points [{'alpha': 0.9120187146038822, 'batch_size': 152, 'beta_1': 0.9696657397207797, 'beta_2': 0.9969012408829251, 'epsilon': 8.979135329461461e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.001524841694911477, 'tol': 1.994788294218454e-05, 'validation_fraction': 0.7777102445739393}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.387620 value -0.857143 suggestion {'alpha': 0.9120187146038822, 'batch_size': 152, 'beta_1': 0.9696657397207797, 'beta_2': 0.9969012408829251, 'epsilon': 8.979135329461461e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.001524841694911477, 'tol': 1.994788294218454e-05, 'validation_fraction': 0.7777102445739393}
observation time 0.000003, current best -0.912088 at iter 9
suggestion time taken 0.011413 iter 10 next_points [{'alpha': 2.85851097249942e-05, 'batch_size': 79, 'beta_1': 0.758810676183366, 'beta_2': 0.977934617098554, 'epsilon': 4.953801041180324e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0001519819469287755, 'tol': 0.02353702615017599, 'validation_fraction': 0.15276019007801403}]
function_evaluation time 0.867858 value -0.800000 suggestion {'alpha': 2.85851097249942e-05, 'batch_size': 79, 'beta_1': 0.758810676183366, 'beta_2': 0.977934617098554, 'epsilon': 4.953801041180324e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0001519819469287755, 'tol': 0.02353702615017599, 'validation_fraction': 0.15276019007801403}
observation time 0.000004, current best -0.912088 at iter 10
suggestion time taken 0.010739 iter 11 next_points [{'alpha': 0.13096513313436103, 'batch_size': 53, 'beta_1': 0.8853037220773322, 'beta_2': 0.9412817320349621, 'epsilon': 9.842134997089146e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0005518351938807614, 'tol': 0.088793307985783, 'validation_fraction': 0.3518132828461853}]
function_evaluation time 0.356688 value -0.850549 suggestion {'alpha': 0.13096513313436103, 'batch_size': 53, 'beta_1': 0.8853037220773322, 'beta_2': 0.9412817320349621, 'epsilon': 9.842134997089146e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0005518351938807614, 'tol': 0.088793307985783, 'validation_fraction': 0.3518132828461853}
observation time 0.000003, current best -0.912088 at iter 11
suggestion time taken 0.010668 iter 12 next_points [{'alpha': 3.0481163115521173e-05, 'batch_size': 26, 'beta_1': 0.9195349686069199, 'beta_2': 0.9987864019672077, 'epsilon': 5.423494430896412e-08, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0009468538561428476, 'tol': 0.07216017459454736, 'validation_fraction': 0.13828109598768407}]
function_evaluation time 0.913203 value -0.861538 suggestion {'alpha': 3.0481163115521173e-05, 'batch_size': 26, 'beta_1': 0.9195349686069199, 'beta_2': 0.9987864019672077, 'epsilon': 5.423494430896412e-08, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0009468538561428476, 'tol': 0.07216017459454736, 'validation_fraction': 0.13828109598768407}
observation time 0.000004, current best -0.912088 at iter 12
suggestion time taken 0.010695 iter 13 next_points [{'alpha': 7.228626987027356, 'batch_size': 124, 'beta_1': 0.884354508817559, 'beta_2': 0.9667351328737452, 'epsilon': 2.599179501640574e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.015243924846556291, 'tol': 0.0029587063321869014, 'validation_fraction': 0.6895334850007553}]
function_evaluation time 0.668226 value -0.894505 suggestion {'alpha': 7.228626987027356, 'batch_size': 124, 'beta_1': 0.884354508817559, 'beta_2': 0.9667351328737452, 'epsilon': 2.599179501640574e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.015243924846556291, 'tol': 0.0029587063321869014, 'validation_fraction': 0.6895334850007553}
observation time 0.000003, current best -0.912088 at iter 13
suggestion time taken 0.010636 iter 14 next_points [{'alpha': 1.0316361516652346, 'batch_size': 20, 'beta_1': 0.8605250943126475, 'beta_2': 0.9999265954923748, 'epsilon': 1.2556703412762483e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0001576297036985915, 'tol': 0.003396409518385115, 'validation_fraction': 0.7409605288009399}]
function_evaluation time 1.009546 value -0.738462 suggestion {'alpha': 1.0316361516652346, 'batch_size': 20, 'beta_1': 0.8605250943126475, 'beta_2': 0.9999265954923748, 'epsilon': 1.2556703412762483e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0001576297036985915, 'tol': 0.003396409518385115, 'validation_fraction': 0.7409605288009399}
observation time 0.000004, current best -0.912088 at iter 14
suggestion time taken 0.011048 iter 15 next_points [{'alpha': 0.0537312909920541, 'batch_size': 43, 'beta_1': 0.8195464150837407, 'beta_2': 0.9996887832008389, 'epsilon': 1.0294011598390108e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0003448091691878723, 'tol': 0.04468579604777317, 'validation_fraction': 0.611420448144248}]
function_evaluation time 0.510051 value -0.685714 suggestion {'alpha': 0.0537312909920541, 'batch_size': 43, 'beta_1': 0.8195464150837407, 'beta_2': 0.9996887832008389, 'epsilon': 1.0294011598390108e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 0.0003448091691878723, 'tol': 0.04468579604777317, 'validation_fraction': 0.611420448144248}
observation time 0.000003, current best -0.912088 at iter 15
suggestion time taken 0.013354 iter 16 next_points [{'alpha': 0.3406732245269264, 'batch_size': 203, 'beta_1': 0.9843149270296672, 'beta_2': 0.9999989520066951, 'epsilon': 1.7410390891196476e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.004621482529922043, 'tol': 0.0002881740448244086, 'validation_fraction': 0.8225923577836111}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.635083 value -0.850549 suggestion {'alpha': 0.3406732245269264, 'batch_size': 203, 'beta_1': 0.9843149270296672, 'beta_2': 0.9999989520066951, 'epsilon': 1.7410390891196476e-07, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.004621482529922043, 'tol': 0.0002881740448244086, 'validation_fraction': 0.8225923577836111}
observation time 0.000003, current best -0.912088 at iter 16
suggestion time taken 0.011567 iter 17 next_points [{'alpha': 0.00013936881143307824, 'batch_size': 106, 'beta_1': 0.929070638280517, 'beta_2': 0.9999963883388975, 'epsilon': 2.95454936962716e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.023608977239752638, 'tol': 0.0002336345608211811, 'validation_fraction': 0.847790018781682}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.568269 value -0.854945 suggestion {'alpha': 0.00013936881143307824, 'batch_size': 106, 'beta_1': 0.929070638280517, 'beta_2': 0.9999963883388975, 'epsilon': 2.95454936962716e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.023608977239752638, 'tol': 0.0002336345608211811, 'validation_fraction': 0.847790018781682}
observation time 0.000003, current best -0.912088 at iter 17
suggestion time taken 0.010739 iter 18 next_points [{'alpha': 0.04297968724534798, 'batch_size': 202, 'beta_1': 0.9694740517925687, 'beta_2': 0.9999971930883598, 'epsilon': 8.321428424983008e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.0024963504829681412, 'tol': 6.35015601838568e-05, 'validation_fraction': 0.47647882995610097}]
function_evaluation time 0.650813 value -0.795604 suggestion {'alpha': 0.04297968724534798, 'batch_size': 202, 'beta_1': 0.9694740517925687, 'beta_2': 0.9999971930883598, 'epsilon': 8.321428424983008e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.0024963504829681412, 'tol': 6.35015601838568e-05, 'validation_fraction': 0.47647882995610097}
observation time 0.000003, current best -0.912088 at iter 18
suggestion time taken 0.010527 iter 19 next_points [{'alpha': 8.326154165244268e-05, 'batch_size': 27, 'beta_1': 0.6418115940801524, 'beta_2': 0.9981704372411374, 'epsilon': 5.0647343504528325e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 1.797510425766726e-05, 'tol': 0.05563606358068278, 'validation_fraction': 0.7003888867368693}]
function_evaluation time 0.459731 value -0.527473 suggestion {'alpha': 8.326154165244268e-05, 'batch_size': 27, 'beta_1': 0.6418115940801524, 'beta_2': 0.9981704372411374, 'epsilon': 5.0647343504528325e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 1.797510425766726e-05, 'tol': 0.05563606358068278, 'validation_fraction': 0.7003888867368693}
observation time 0.000003, current best -0.912088 at iter 19
suggestion time taken 0.010545 iter 20 next_points [{'alpha': 3.0331900880223412, 'batch_size': 32, 'beta_1': 0.561568239103943, 'beta_2': 0.9997966445858476, 'epsilon': 2.8552476413266325e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 3.999052613005166e-05, 'tol': 0.0020759814524797518, 'validation_fraction': 0.5063051403726853}]
function_evaluation time 0.611623 value -0.536264 suggestion {'alpha': 3.0331900880223412, 'batch_size': 32, 'beta_1': 0.561568239103943, 'beta_2': 0.9997966445858476, 'epsilon': 2.8552476413266325e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 3.999052613005166e-05, 'tol': 0.0020759814524797518, 'validation_fraction': 0.5063051403726853}
observation time 0.000004, current best -0.912088 at iter 20
suggestion time taken 0.010637 iter 21 next_points [{'alpha': 4.725678599686466e-05, 'batch_size': 27, 'beta_1': 0.9366490707074754, 'beta_2': 0.9690391235600023, 'epsilon': 1.137152774047652e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.009909455055296144, 'tol': 0.0014506768549125244, 'validation_fraction': 0.14148006803162086}]
function_evaluation time 0.887107 value -0.901099 suggestion {'alpha': 4.725678599686466e-05, 'batch_size': 27, 'beta_1': 0.9366490707074754, 'beta_2': 0.9690391235600023, 'epsilon': 1.137152774047652e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.009909455055296144, 'tol': 0.0014506768549125244, 'validation_fraction': 0.14148006803162086}
observation time 0.000004, current best -0.912088 at iter 21
suggestion time taken 0.010521 iter 22 next_points [{'alpha': 0.025228801787862996, 'batch_size': 147, 'beta_1': 0.8271948732958048, 'beta_2': 0.9999983376500715, 'epsilon': 1.1795088051348079e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0008208692695464463, 'tol': 0.00502271908773074, 'validation_fraction': 0.8194125629307174}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.480812 value -0.738462 suggestion {'alpha': 0.025228801787862996, 'batch_size': 147, 'beta_1': 0.8271948732958048, 'beta_2': 0.9999983376500715, 'epsilon': 1.1795088051348079e-07, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0008208692695464463, 'tol': 0.00502271908773074, 'validation_fraction': 0.8194125629307174}
observation time 0.000003, current best -0.912088 at iter 22
suggestion time taken 0.010465 iter 23 next_points [{'alpha': 0.0001285302153544213, 'batch_size': 21, 'beta_1': 0.929804590890376, 'beta_2': 0.9999553802969259, 'epsilon': 1.3325726928444654e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.04461482900137724, 'tol': 0.00033469493708983245, 'validation_fraction': 0.5454776401949386}]
function_evaluation time 1.574960 value -0.909890 suggestion {'alpha': 0.0001285302153544213, 'batch_size': 21, 'beta_1': 0.929804590890376, 'beta_2': 0.9999553802969259, 'epsilon': 1.3325726928444654e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.04461482900137724, 'tol': 0.00033469493708983245, 'validation_fraction': 0.5454776401949386}
observation time 0.000004, current best -0.912088 at iter 23
suggestion time taken 0.010663 iter 24 next_points [{'alpha': 0.016658796798682245, 'batch_size': 56, 'beta_1': 0.8047653642842452, 'beta_2': 0.9872779007652147, 'epsilon': 3.2494124988350436e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.00014416577510641175, 'tol': 0.00027936700304888085, 'validation_fraction': 0.6200167050907547}]
function_evaluation time 0.562446 value -0.663736 suggestion {'alpha': 0.016658796798682245, 'batch_size': 56, 'beta_1': 0.8047653642842452, 'beta_2': 0.9872779007652147, 'epsilon': 3.2494124988350436e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.00014416577510641175, 'tol': 0.00027936700304888085, 'validation_fraction': 0.6200167050907547}
observation time 0.000003, current best -0.912088 at iter 24
suggestion time taken 0.010422 iter 25 next_points [{'alpha': 0.0003279747782114229, 'batch_size': 187, 'beta_1': 0.7030211921275322, 'beta_2': 0.9999949719720961, 'epsilon': 3.810577276108047e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 2.507840516362566e-05, 'tol': 1.595272806550054e-05, 'validation_fraction': 0.11907523360620907}]
function_evaluation time 0.418330 value -0.582418 suggestion {'alpha': 0.0003279747782114229, 'batch_size': 187, 'beta_1': 0.7030211921275322, 'beta_2': 0.9999949719720961, 'epsilon': 3.810577276108047e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 2.507840516362566e-05, 'tol': 1.595272806550054e-05, 'validation_fraction': 0.11907523360620907}
observation time 0.000003, current best -0.912088 at iter 25
suggestion time taken 0.010950 iter 26 next_points [{'alpha': 3.6308518269792827, 'batch_size': 194, 'beta_1': 0.9302071214173097, 'beta_2': 0.9998994015843933, 'epsilon': 1.8867071582253222e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 7.923926077158772e-05, 'tol': 0.08030195703158076, 'validation_fraction': 0.14477175091508607}]
function_evaluation time 0.319145 value -0.419780 suggestion {'alpha': 3.6308518269792827, 'batch_size': 194, 'beta_1': 0.9302071214173097, 'beta_2': 0.9998994015843933, 'epsilon': 1.8867071582253222e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 7.923926077158772e-05, 'tol': 0.08030195703158076, 'validation_fraction': 0.14477175091508607}
observation time 0.000003, current best -0.912088 at iter 26
suggestion time taken 0.010565 iter 27 next_points [{'alpha': 1.4018204145272315, 'batch_size': 99, 'beta_1': 0.9724546680520607, 'beta_2': 0.9997729447883827, 'epsilon': 1.7258354096694327e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.001012766733559819, 'tol': 0.0013151073659018815, 'validation_fraction': 0.10092114755795328}]
function_evaluation time 0.401910 value -0.907692 suggestion {'alpha': 1.4018204145272315, 'batch_size': 99, 'beta_1': 0.9724546680520607, 'beta_2': 0.9997729447883827, 'epsilon': 1.7258354096694327e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.001012766733559819, 'tol': 0.0013151073659018815, 'validation_fraction': 0.10092114755795328}
observation time 0.000002, current best -0.912088 at iter 27
suggestion time taken 0.003941 iter 28 next_points [{'alpha': 0.001366321848099979, 'batch_size': 23, 'beta_1': 0.9620697865615192, 'beta_2': 0.999998769429213, 'epsilon': 2.377015205706736e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.000464773918263415, 'tol': 0.00013363011784043878, 'validation_fraction': 0.7839483439252218}]
function_evaluation time 0.918862 value -0.784615 suggestion {'alpha': 0.001366321848099979, 'batch_size': 23, 'beta_1': 0.9620697865615192, 'beta_2': 0.999998769429213, 'epsilon': 2.377015205706736e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 0.000464773918263415, 'tol': 0.00013363011784043878, 'validation_fraction': 0.7839483439252218}
observation time 0.000004, current best -0.912088 at iter 28
suggestion time taken 0.010505 iter 29 next_points [{'alpha': 0.0008543500155824399, 'batch_size': 26, 'beta_1': 0.9271357531089339, 'beta_2': 0.9952915851290436, 'epsilon': 2.533762545672689e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 5.140611369696062e-05, 'tol': 1.4405711066927768e-05, 'validation_fraction': 0.8314166075391767}]
function_evaluation time 0.379781 value -0.446154 suggestion {'alpha': 0.0008543500155824399, 'batch_size': 26, 'beta_1': 0.9271357531089339, 'beta_2': 0.9952915851290436, 'epsilon': 2.533762545672689e-09, 'hidden_layer_sizes': 108, 'learning_rate_init': 5.140611369696062e-05, 'tol': 1.4405711066927768e-05, 'validation_fraction': 0.8314166075391767}
observation time 0.000003, current best -0.912088 at iter 29
suggestion time taken 0.010381 iter 30 next_points [{'alpha': 4.557847347397875, 'batch_size': 63, 'beta_1': 0.9832983388511163, 'beta_2': 0.9999871302716693, 'epsilon': 5.46832916609436e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.0023257266129644285, 'tol': 0.00013700497042814862, 'validation_fraction': 0.15197091364796125}]
function_evaluation time 1.187829 value -0.907692 suggestion {'alpha': 4.557847347397875, 'batch_size': 63, 'beta_1': 0.9832983388511163, 'beta_2': 0.9999871302716693, 'epsilon': 5.46832916609436e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.0023257266129644285, 'tol': 0.00013700497042814862, 'validation_fraction': 0.15197091364796125}
observation time 0.000003, current best -0.912088 at iter 30
suggestion time taken 0.010476 iter 31 next_points [{'alpha': 1.7740468401268386, 'batch_size': 97, 'beta_1': 0.9653173590546216, 'beta_2': 0.9999930384198834, 'epsilon': 1.9898153042595634e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 1.660707344913857e-05, 'tol': 1.551154438388882e-05, 'validation_fraction': 0.8482340320121519}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.395147 value -0.582418 suggestion {'alpha': 1.7740468401268386, 'batch_size': 97, 'beta_1': 0.9653173590546216, 'beta_2': 0.9999930384198834, 'epsilon': 1.9898153042595634e-07, 'hidden_layer_sizes': 140, 'learning_rate_init': 1.660707344913857e-05, 'tol': 1.551154438388882e-05, 'validation_fraction': 0.8482340320121519}
observation time 0.000003, current best -0.912088 at iter 31
suggestion time taken 0.010492 iter 32 next_points [{'alpha': 0.013390289370372153, 'batch_size': 24, 'beta_1': 0.8054188045301894, 'beta_2': 0.9991150312870776, 'epsilon': 1.4819621927574965e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.007599298885310034, 'tol': 3.733114637190219e-05, 'validation_fraction': 0.170804205299121}]
function_evaluation time 1.061211 value -0.914286 suggestion {'alpha': 0.013390289370372153, 'batch_size': 24, 'beta_1': 0.8054188045301894, 'beta_2': 0.9991150312870776, 'epsilon': 1.4819621927574965e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.007599298885310034, 'tol': 3.733114637190219e-05, 'validation_fraction': 0.170804205299121}
observation time 0.000003, current best -0.914286 at iter 32
suggestion time taken 0.010572 iter 33 next_points [{'alpha': 1.542467293974273e-05, 'batch_size': 187, 'beta_1': 0.9275346826496474, 'beta_2': 0.9999967676365419, 'epsilon': 1.6114560901982644e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0002462898200418615, 'tol': 3.149645909743261e-05, 'validation_fraction': 0.8228413100606786}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.239785 value -0.637363 suggestion {'alpha': 1.542467293974273e-05, 'batch_size': 187, 'beta_1': 0.9275346826496474, 'beta_2': 0.9999967676365419, 'epsilon': 1.6114560901982644e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0002462898200418615, 'tol': 3.149645909743261e-05, 'validation_fraction': 0.8228413100606786}
observation time 0.000003, current best -0.914286 at iter 33
suggestion time taken 0.010507 iter 34 next_points [{'alpha': 1.4678373906196598, 'batch_size': 20, 'beta_1': 0.6152094887882887, 'beta_2': 0.998864664249899, 'epsilon': 1.2635934925219761e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 2.092866661564416e-05, 'tol': 0.00014254251480330128, 'validation_fraction': 0.13606317794076353}]
function_evaluation time 1.386237 value -0.784615 suggestion {'alpha': 1.4678373906196598, 'batch_size': 20, 'beta_1': 0.6152094887882887, 'beta_2': 0.998864664249899, 'epsilon': 1.2635934925219761e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 2.092866661564416e-05, 'tol': 0.00014254251480330128, 'validation_fraction': 0.13606317794076353}
observation time 0.000003, current best -0.914286 at iter 34
suggestion time taken 0.010612 iter 35 next_points [{'alpha': 0.0010354600904962552, 'batch_size': 114, 'beta_1': 0.855331669156796, 'beta_2': 0.9996882159822917, 'epsilon': 1.4705362370198249e-08, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.005742389925455076, 'tol': 0.000113866629860017, 'validation_fraction': 0.3661586653884577}]
function_evaluation time 0.709292 value -0.901099 suggestion {'alpha': 0.0010354600904962552, 'batch_size': 114, 'beta_1': 0.855331669156796, 'beta_2': 0.9996882159822917, 'epsilon': 1.4705362370198249e-08, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.005742389925455076, 'tol': 0.000113866629860017, 'validation_fraction': 0.3661586653884577}
observation time 0.000003, current best -0.914286 at iter 35
suggestion time taken 0.010441 iter 36 next_points [{'alpha': 0.00019200595401799793, 'batch_size': 146, 'beta_1': 0.9565201300305923, 'beta_2': 0.9931618671029454, 'epsilon': 2.8705476094788626e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.00015574325131974682, 'tol': 0.00011523153937165366, 'validation_fraction': 0.26835681618822227}]
function_evaluation time 0.518797 value -0.703297 suggestion {'alpha': 0.00019200595401799793, 'batch_size': 146, 'beta_1': 0.9565201300305923, 'beta_2': 0.9931618671029454, 'epsilon': 2.8705476094788626e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.00015574325131974682, 'tol': 0.00011523153937165366, 'validation_fraction': 0.26835681618822227}
observation time 0.000003, current best -0.914286 at iter 36
suggestion time taken 0.010630 iter 37 next_points [{'alpha': 0.00020953860291546275, 'batch_size': 55, 'beta_1': 0.5382986945301622, 'beta_2': 0.9997872575765979, 'epsilon': 2.5695531975075636e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.00034458902408908724, 'tol': 0.00018643860716287874, 'validation_fraction': 0.30390914749609316}]
function_evaluation time 0.638098 value -0.887912 suggestion {'alpha': 0.00020953860291546275, 'batch_size': 55, 'beta_1': 0.5382986945301622, 'beta_2': 0.9997872575765979, 'epsilon': 2.5695531975075636e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.00034458902408908724, 'tol': 0.00018643860716287874, 'validation_fraction': 0.30390914749609316}
observation time 0.000003, current best -0.914286 at iter 37
suggestion time taken 0.010527 iter 38 next_points [{'alpha': 1.358202659951921, 'batch_size': 205, 'beta_1': 0.5020628351752459, 'beta_2': 0.999993280746342, 'epsilon': 2.178280194509701e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.049337911835102125, 'tol': 0.038452941116618816, 'validation_fraction': 0.8511185513740352}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.341188 value -0.881319 suggestion {'alpha': 1.358202659951921, 'batch_size': 205, 'beta_1': 0.5020628351752459, 'beta_2': 0.999993280746342, 'epsilon': 2.178280194509701e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.049337911835102125, 'tol': 0.038452941116618816, 'validation_fraction': 0.8511185513740352}
observation time 0.000003, current best -0.914286 at iter 38
suggestion time taken 0.010469 iter 39 next_points [{'alpha': 0.00022104613026912334, 'batch_size': 22, 'beta_1': 0.825567861264156, 'beta_2': 0.9999988104815044, 'epsilon': 8.967094051851437e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 1.1301719456546872e-05, 'tol': 0.0003827825431088917, 'validation_fraction': 0.8257950214752252}]
function_evaluation time 0.659877 value -0.509890 suggestion {'alpha': 0.00022104613026912334, 'batch_size': 22, 'beta_1': 0.825567861264156, 'beta_2': 0.9999988104815044, 'epsilon': 8.967094051851437e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 1.1301719456546872e-05, 'tol': 0.0003827825431088917, 'validation_fraction': 0.8257950214752252}
observation time 0.000002, current best -0.914286 at iter 39
suggestion time taken 0.010418 iter 40 next_points [{'alpha': 0.003196479943263537, 'batch_size': 146, 'beta_1': 0.5260227851095909, 'beta_2': 0.9995349477254916, 'epsilon': 1.1861053261469992e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.00337057781738085, 'tol': 0.026295275528707703, 'validation_fraction': 0.7796897026917472}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.398262 value -0.912088 suggestion {'alpha': 0.003196479943263537, 'batch_size': 146, 'beta_1': 0.5260227851095909, 'beta_2': 0.9995349477254916, 'epsilon': 1.1861053261469992e-07, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.00337057781738085, 'tol': 0.026295275528707703, 'validation_fraction': 0.7796897026917472}
observation time 0.000003, current best -0.914286 at iter 40
suggestion time taken 0.010436 iter 41 next_points [{'alpha': 0.01678716813916128, 'batch_size': 81, 'beta_1': 0.9419490564977381, 'beta_2': 0.9999989886271742, 'epsilon': 1.3581990234948367e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00029778973683400523, 'tol': 0.04066572085219477, 'validation_fraction': 0.29627059439178277}]
function_evaluation time 0.833271 value -0.839560 suggestion {'alpha': 0.01678716813916128, 'batch_size': 81, 'beta_1': 0.9419490564977381, 'beta_2': 0.9999989886271742, 'epsilon': 1.3581990234948367e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00029778973683400523, 'tol': 0.04066572085219477, 'validation_fraction': 0.29627059439178277}
observation time 0.000003, current best -0.914286 at iter 41
suggestion time taken 0.010498 iter 42 next_points [{'alpha': 4.4833227980451265e-05, 'batch_size': 141, 'beta_1': 0.943592011114892, 'beta_2': 0.9999980165355709, 'epsilon': 2.808181050725417e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.004149148394306148, 'tol': 0.0020585844117157726, 'validation_fraction': 0.8023220984538856}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.556570 value -0.894505 suggestion {'alpha': 4.4833227980451265e-05, 'batch_size': 141, 'beta_1': 0.943592011114892, 'beta_2': 0.9999980165355709, 'epsilon': 2.808181050725417e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.004149148394306148, 'tol': 0.0020585844117157726, 'validation_fraction': 0.8023220984538856}
observation time 0.000003, current best -0.914286 at iter 42
suggestion time taken 0.010575 iter 43 next_points [{'alpha': 0.0001269127303473613, 'batch_size': 206, 'beta_1': 0.9642561407043101, 'beta_2': 0.9050175407136163, 'epsilon': 6.633568322685779e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 2.111820790884369e-05, 'tol': 0.00723432060609611, 'validation_fraction': 0.49286696330904256}]
function_evaluation time 0.238373 value -0.430769 suggestion {'alpha': 0.0001269127303473613, 'batch_size': 206, 'beta_1': 0.9642561407043101, 'beta_2': 0.9050175407136163, 'epsilon': 6.633568322685779e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 2.111820790884369e-05, 'tol': 0.00723432060609611, 'validation_fraction': 0.49286696330904256}
observation time 0.000003, current best -0.914286 at iter 43
suggestion time taken 0.010398 iter 44 next_points [{'alpha': 0.8433661408589708, 'batch_size': 50, 'beta_1': 0.9484436566930597, 'beta_2': 0.9969614269576154, 'epsilon': 4.794120389165278e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.010163062731531534, 'tol': 0.003123498460873622, 'validation_fraction': 0.43895355773256917}]
function_evaluation time 0.991345 value -0.909890 suggestion {'alpha': 0.8433661408589708, 'batch_size': 50, 'beta_1': 0.9484436566930597, 'beta_2': 0.9969614269576154, 'epsilon': 4.794120389165278e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.010163062731531534, 'tol': 0.003123498460873622, 'validation_fraction': 0.43895355773256917}
observation time 0.000004, current best -0.914286 at iter 44
saving meta data: {'args': {'--uuid': '924ccbf669bf5dba96575e58cb320ea5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
