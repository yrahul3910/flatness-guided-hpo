running: {'--uuid': 'e416e6bed8ae57b88040d424e082ca40', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d breast -o strongcvx -u e416e6bed8ae57b88040d424e082ca40 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam breast acc 45 1
with data root: None
suggestion time taken 19.519032 iter 0 next_points [{'alpha': 6.018109209015657, 'batch_size': 226, 'beta_1': 0.6149172384682514, 'beta_2': 0.9999930557906042, 'epsilon': 1.3365798261324302e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 6.716289824836422e-05, 'tol': 2.8945016014529792e-05, 'validation_fraction': 0.45832625476766203}]
function_evaluation time 0.334620 value -0.518681 suggestion {'alpha': 6.018109209015657, 'batch_size': 226, 'beta_1': 0.6149172384682514, 'beta_2': 0.9999930557906042, 'epsilon': 1.3365798261324302e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 6.716289824836422e-05, 'tol': 2.8945016014529792e-05, 'validation_fraction': 0.45832625476766203}
observation time 0.000005, current best -0.518681 at iter 0
suggestion time taken 19.697529 iter 1 next_points [{'alpha': 0.004781353070859415, 'batch_size': 25, 'beta_1': 0.8646740764993992, 'beta_2': 0.9999942517994562, 'epsilon': 1.6013390416623988e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.00010080702050621508, 'tol': 0.010982043219978711, 'validation_fraction': 0.176436016901075}]
function_evaluation time 1.360598 value -0.780220 suggestion {'alpha': 0.004781353070859415, 'batch_size': 25, 'beta_1': 0.8646740764993992, 'beta_2': 0.9999942517994562, 'epsilon': 1.6013390416623988e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.00010080702050621508, 'tol': 0.010982043219978711, 'validation_fraction': 0.176436016901075}
observation time 0.000005, current best -0.780220 at iter 1
suggestion time taken 19.124131 iter 2 next_points [{'alpha': 4.89941601739439e-05, 'batch_size': 225, 'beta_1': 0.7586875282375037, 'beta_2': 0.9960417047801857, 'epsilon': 4.880399294005117e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 1.2828371241559834e-05, 'tol': 0.00025110558474591505, 'validation_fraction': 0.5738826963961162}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.246379 value -0.637363 suggestion {'alpha': 4.89941601739439e-05, 'batch_size': 225, 'beta_1': 0.7586875282375037, 'beta_2': 0.9960417047801857, 'epsilon': 4.880399294005117e-09, 'hidden_layer_sizes': 73, 'learning_rate_init': 1.2828371241559834e-05, 'tol': 0.00025110558474591505, 'validation_fraction': 0.5738826963961162}
observation time 0.000015, current best -0.780220 at iter 2
suggestion time taken 19.873655 iter 3 next_points [{'alpha': 1.7794051805179232e-05, 'batch_size': 151, 'beta_1': 0.8455408308165137, 'beta_2': 0.925729911418198, 'epsilon': 5.675767590565121e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.00013136432576997864, 'tol': 0.01542282509479408, 'validation_fraction': 0.8378378983748506}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.407205 value -0.745055 suggestion {'alpha': 1.7794051805179232e-05, 'batch_size': 151, 'beta_1': 0.8455408308165137, 'beta_2': 0.925729911418198, 'epsilon': 5.675767590565121e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.00013136432576997864, 'tol': 0.01542282509479408, 'validation_fraction': 0.8378378983748506}
observation time 0.000010, current best -0.780220 at iter 3
suggestion time taken 19.865967 iter 4 next_points [{'alpha': 1.1961903771446319e-05, 'batch_size': 112, 'beta_1': 0.7807172308582104, 'beta_2': 0.9999697357108164, 'epsilon': 2.417366062595663e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 3.535363428990838e-05, 'tol': 0.00024128256392544237, 'validation_fraction': 0.5307050388123915}]
function_evaluation time 0.338676 value -0.582418 suggestion {'alpha': 1.1961903771446319e-05, 'batch_size': 112, 'beta_1': 0.7807172308582104, 'beta_2': 0.9999697357108164, 'epsilon': 2.417366062595663e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 3.535363428990838e-05, 'tol': 0.00024128256392544237, 'validation_fraction': 0.5307050388123915}
observation time 0.000005, current best -0.780220 at iter 4
suggestion time taken 19.523982 iter 5 next_points [{'alpha': 0.4157305475412346, 'batch_size': 11, 'beta_1': 0.8845211310338698, 'beta_2': 0.9799843471369454, 'epsilon': 1.4238587302996753e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.0025810138233494932, 'tol': 1.0580503818321876e-05, 'validation_fraction': 0.883341755294299}]
function_evaluation time 0.972491 value -0.903297 suggestion {'alpha': 0.4157305475412346, 'batch_size': 11, 'beta_1': 0.8845211310338698, 'beta_2': 0.9799843471369454, 'epsilon': 1.4238587302996753e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.0025810138233494932, 'tol': 1.0580503818321876e-05, 'validation_fraction': 0.883341755294299}
observation time 0.000006, current best -0.903297 at iter 5
suggestion time taken 20.031101 iter 6 next_points [{'alpha': 0.049156664999465166, 'batch_size': 15, 'beta_1': 0.556998795968666, 'beta_2': 0.9931268994207556, 'epsilon': 2.73470511944388e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0001936752241550651, 'tol': 0.0016888605497821856, 'validation_fraction': 0.8620039914723303}]
function_evaluation time 1.613994 value -0.846154 suggestion {'alpha': 0.049156664999465166, 'batch_size': 15, 'beta_1': 0.556998795968666, 'beta_2': 0.9931268994207556, 'epsilon': 2.73470511944388e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0001936752241550651, 'tol': 0.0016888605497821856, 'validation_fraction': 0.8620039914723303}
observation time 0.000006, current best -0.903297 at iter 6
suggestion time taken 19.699553 iter 7 next_points [{'alpha': 0.00022800246435355256, 'batch_size': 150, 'beta_1': 0.9781873278843846, 'beta_2': 0.9815637430359035, 'epsilon': 1.0529448073746667e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.00010763999538459235, 'tol': 9.353415530058824e-05, 'validation_fraction': 0.5016986302073662}]
function_evaluation time 0.527852 value -0.580220 suggestion {'alpha': 0.00022800246435355256, 'batch_size': 150, 'beta_1': 0.9781873278843846, 'beta_2': 0.9815637430359035, 'epsilon': 1.0529448073746667e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.00010763999538459235, 'tol': 9.353415530058824e-05, 'validation_fraction': 0.5016986302073662}
observation time 0.000011, current best -0.903297 at iter 7
suggestion time taken 20.423763 iter 8 next_points [{'alpha': 1.5727849231407798, 'batch_size': 225, 'beta_1': 0.920457351291363, 'beta_2': 0.9952592259208374, 'epsilon': 4.559892928712157e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0019613822708393416, 'tol': 0.016970117274331856, 'validation_fraction': 0.7987644317318335}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.371537 value -0.784615 suggestion {'alpha': 1.5727849231407798, 'batch_size': 225, 'beta_1': 0.920457351291363, 'beta_2': 0.9952592259208374, 'epsilon': 4.559892928712157e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0019613822708393416, 'tol': 0.016970117274331856, 'validation_fraction': 0.7987644317318335}
observation time 0.000012, current best -0.903297 at iter 8
suggestion time taken 19.165452 iter 9 next_points [{'alpha': 0.1159992292290819, 'batch_size': 15, 'beta_1': 0.6815364752147154, 'beta_2': 0.9999935149364272, 'epsilon': 8.1232588460348e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.002562469096891124, 'tol': 0.004266665034903905, 'validation_fraction': 0.8994656152942031}]
function_evaluation time 0.759172 value -0.905495 suggestion {'alpha': 0.1159992292290819, 'batch_size': 15, 'beta_1': 0.6815364752147154, 'beta_2': 0.9999935149364272, 'epsilon': 8.1232588460348e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.002562469096891124, 'tol': 0.004266665034903905, 'validation_fraction': 0.8994656152942031}
observation time 0.000005, current best -0.905495 at iter 9
suggestion time taken 20.040632 iter 10 next_points [{'alpha': 0.00014371823185282024, 'batch_size': 227, 'beta_1': 0.7486039883487663, 'beta_2': 0.9997494743758165, 'epsilon': 1.624888574174494e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.07066806409270203, 'tol': 0.008738691063625233, 'validation_fraction': 0.1602598935934321}]
function_evaluation time 0.870287 value -0.885714 suggestion {'alpha': 0.00014371823185282024, 'batch_size': 227, 'beta_1': 0.7486039883487663, 'beta_2': 0.9997494743758165, 'epsilon': 1.624888574174494e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.07066806409270203, 'tol': 0.008738691063625233, 'validation_fraction': 0.1602598935934321}
observation time 0.000005, current best -0.905495 at iter 10
suggestion time taken 20.064507 iter 11 next_points [{'alpha': 0.012927704615004238, 'batch_size': 12, 'beta_1': 0.696425534580229, 'beta_2': 0.9999352443669743, 'epsilon': 1.3801703365970036e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 1.501128152046893e-05, 'tol': 0.001514429142907565, 'validation_fraction': 0.7136688387801774}]
function_evaluation time 0.889912 value -0.472527 suggestion {'alpha': 0.012927704615004238, 'batch_size': 12, 'beta_1': 0.696425534580229, 'beta_2': 0.9999352443669743, 'epsilon': 1.3801703365970036e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 1.501128152046893e-05, 'tol': 0.001514429142907565, 'validation_fraction': 0.7136688387801774}
observation time 0.000006, current best -0.905495 at iter 11
suggestion time taken 20.262305 iter 12 next_points [{'alpha': 0.15271336305447306, 'batch_size': 90, 'beta_1': 0.6840684804358097, 'beta_2': 0.9981919054051239, 'epsilon': 3.6412773266553784e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.019873279420492457, 'tol': 0.0012867752951811063, 'validation_fraction': 0.15928184329103948}]
function_evaluation time 0.871073 value -0.916484 suggestion {'alpha': 0.15271336305447306, 'batch_size': 90, 'beta_1': 0.6840684804358097, 'beta_2': 0.9981919054051239, 'epsilon': 3.6412773266553784e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.019873279420492457, 'tol': 0.0012867752951811063, 'validation_fraction': 0.15928184329103948}
observation time 0.000006, current best -0.916484 at iter 12
suggestion time taken 20.858086 iter 13 next_points [{'alpha': 0.44117715913272043, 'batch_size': 224, 'beta_1': 0.8368674477125534, 'beta_2': 0.9992538373459547, 'epsilon': 3.360764682065503e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.00028616472830265017, 'tol': 0.023556999832899606, 'validation_fraction': 0.43852175276495897}]
function_evaluation time 0.389379 value -0.639560 suggestion {'alpha': 0.44117715913272043, 'batch_size': 224, 'beta_1': 0.8368674477125534, 'beta_2': 0.9992538373459547, 'epsilon': 3.360764682065503e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.00028616472830265017, 'tol': 0.023556999832899606, 'validation_fraction': 0.43852175276495897}
observation time 0.000008, current best -0.916484 at iter 13
suggestion time taken 20.315877 iter 14 next_points [{'alpha': 0.0013623714918252546, 'batch_size': 227, 'beta_1': 0.8243273672419068, 'beta_2': 0.9999986236800877, 'epsilon': 1.651748644896412e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 1.978593831367434e-05, 'tol': 0.017795981049198134, 'validation_fraction': 0.467628462905403}]
function_evaluation time 0.314054 value -0.461538 suggestion {'alpha': 0.0013623714918252546, 'batch_size': 227, 'beta_1': 0.8243273672419068, 'beta_2': 0.9999986236800877, 'epsilon': 1.651748644896412e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 1.978593831367434e-05, 'tol': 0.017795981049198134, 'validation_fraction': 0.467628462905403}
observation time 0.000014, current best -0.916484 at iter 14
suggestion time taken 21.111920 iter 15 next_points [{'alpha': 0.0008166043132168781, 'batch_size': 227, 'beta_1': 0.5286275580274133, 'beta_2': 0.9994116863213676, 'epsilon': 1.0644746586347717e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.0026811547274454154, 'tol': 0.00018902042906572718, 'validation_fraction': 0.8552152417382287}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.744941 value -0.909890 suggestion {'alpha': 0.0008166043132168781, 'batch_size': 227, 'beta_1': 0.5286275580274133, 'beta_2': 0.9994116863213676, 'epsilon': 1.0644746586347717e-08, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.0026811547274454154, 'tol': 0.00018902042906572718, 'validation_fraction': 0.8552152417382287}
observation time 0.000005, current best -0.916484 at iter 15
suggestion time taken 21.845325 iter 16 next_points [{'alpha': 0.0013386883081668223, 'batch_size': 224, 'beta_1': 0.7973319189226302, 'beta_2': 0.9999984987830531, 'epsilon': 8.721564803327928e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.002128567574291608, 'tol': 5.789269032419794e-05, 'validation_fraction': 0.885301359518179}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.717355 value -0.907692 suggestion {'alpha': 0.0013386883081668223, 'batch_size': 224, 'beta_1': 0.7973319189226302, 'beta_2': 0.9999984987830531, 'epsilon': 8.721564803327928e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.002128567574291608, 'tol': 5.789269032419794e-05, 'validation_fraction': 0.885301359518179}
observation time 0.000006, current best -0.916484 at iter 16
suggestion time taken 23.820157 iter 17 next_points [{'alpha': 0.0002396248256573648, 'batch_size': 41, 'beta_1': 0.5557532517673592, 'beta_2': 0.9983608725617849, 'epsilon': 2.4095509061808756e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 4.181961895628342e-05, 'tol': 0.011274504128808756, 'validation_fraction': 0.7133368704634544}]
function_evaluation time 0.424977 value -0.527473 suggestion {'alpha': 0.0002396248256573648, 'batch_size': 41, 'beta_1': 0.5557532517673592, 'beta_2': 0.9983608725617849, 'epsilon': 2.4095509061808756e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 4.181961895628342e-05, 'tol': 0.011274504128808756, 'validation_fraction': 0.7133368704634544}
observation time 0.000014, current best -0.916484 at iter 17
suggestion time taken 24.103932 iter 18 next_points [{'alpha': 0.028205383119445357, 'batch_size': 226, 'beta_1': 0.8680929081733075, 'beta_2': 0.9803987975819292, 'epsilon': 1.4943346252969382e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.04638541506109493, 'tol': 3.911660384864843e-05, 'validation_fraction': 0.10649735895270859}]
function_evaluation time 0.818172 value -0.894505 suggestion {'alpha': 0.028205383119445357, 'batch_size': 226, 'beta_1': 0.8680929081733075, 'beta_2': 0.9803987975819292, 'epsilon': 1.4943346252969382e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.04638541506109493, 'tol': 3.911660384864843e-05, 'validation_fraction': 0.10649735895270859}
observation time 0.000007, current best -0.916484 at iter 18
suggestion time taken 20.780257 iter 19 next_points [{'alpha': 0.007151821812842697, 'batch_size': 17, 'beta_1': 0.5990100143044531, 'beta_2': 0.9960249569627512, 'epsilon': 1.2927520230915577e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.00061065648864134, 'tol': 0.08054493203156264, 'validation_fraction': 0.516744490040546}]
function_evaluation time 1.084539 value -0.920879 suggestion {'alpha': 0.007151821812842697, 'batch_size': 17, 'beta_1': 0.5990100143044531, 'beta_2': 0.9960249569627512, 'epsilon': 1.2927520230915577e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.00061065648864134, 'tol': 0.08054493203156264, 'validation_fraction': 0.516744490040546}
observation time 0.000006, current best -0.920879 at iter 19
suggestion time taken 21.950625 iter 20 next_points [{'alpha': 0.018725469264003085, 'batch_size': 15, 'beta_1': 0.7333043357558728, 'beta_2': 0.9988511155399508, 'epsilon': 8.719324416349289e-09, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0016910606218470741, 'tol': 0.0003365453608969099, 'validation_fraction': 0.8802585020427227}]
function_evaluation time 1.027230 value -0.909890 suggestion {'alpha': 0.018725469264003085, 'batch_size': 15, 'beta_1': 0.7333043357558728, 'beta_2': 0.9988511155399508, 'epsilon': 8.719324416349289e-09, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0016910606218470741, 'tol': 0.0003365453608969099, 'validation_fraction': 0.8802585020427227}
observation time 0.000013, current best -0.920879 at iter 20
suggestion time taken 21.841815 iter 21 next_points [{'alpha': 0.32446772737590346, 'batch_size': 224, 'beta_1': 0.8788934231762261, 'beta_2': 0.9999989359320376, 'epsilon': 2.902301718901101e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.0007204614767439197, 'tol': 1.838731166978521e-05, 'validation_fraction': 0.5793834569192214}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.879011 value -0.742857 suggestion {'alpha': 0.32446772737590346, 'batch_size': 224, 'beta_1': 0.8788934231762261, 'beta_2': 0.9999989359320376, 'epsilon': 2.902301718901101e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.0007204614767439197, 'tol': 1.838731166978521e-05, 'validation_fraction': 0.5793834569192214}
observation time 0.000005, current best -0.920879 at iter 21
suggestion time taken 22.292297 iter 22 next_points [{'alpha': 1.644162840345947, 'batch_size': 32, 'beta_1': 0.8796737163083058, 'beta_2': 0.999370235816743, 'epsilon': 3.4200466392031983e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.029032212264934413, 'tol': 1.6992818957023418e-05, 'validation_fraction': 0.24961144222299758}]
function_evaluation time 1.603235 value -0.903297 suggestion {'alpha': 1.644162840345947, 'batch_size': 32, 'beta_1': 0.8796737163083058, 'beta_2': 0.999370235816743, 'epsilon': 3.4200466392031983e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.029032212264934413, 'tol': 1.6992818957023418e-05, 'validation_fraction': 0.24961144222299758}
observation time 0.000006, current best -0.920879 at iter 22
suggestion time taken 20.403121 iter 23 next_points [{'alpha': 0.012265940991581075, 'batch_size': 151, 'beta_1': 0.7617440173520897, 'beta_2': 0.9950400468516921, 'epsilon': 7.72744484895992e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.0018522092647679826, 'tol': 0.03199604732546757, 'validation_fraction': 0.769241507335777}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.412181 value -0.839560 suggestion {'alpha': 0.012265940991581075, 'batch_size': 151, 'beta_1': 0.7617440173520897, 'beta_2': 0.9950400468516921, 'epsilon': 7.72744484895992e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.0018522092647679826, 'tol': 0.03199604732546757, 'validation_fraction': 0.769241507335777}
observation time 0.000005, current best -0.920879 at iter 23
suggestion time taken 20.150605 iter 24 next_points [{'alpha': 0.02867977748231863, 'batch_size': 227, 'beta_1': 0.9239331487892603, 'beta_2': 0.9999884655689426, 'epsilon': 1.0565524763245787e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.00392448015948591, 'tol': 7.926498215084231e-05, 'validation_fraction': 0.19031356009588443}]
function_evaluation time 0.714284 value -0.837363 suggestion {'alpha': 0.02867977748231863, 'batch_size': 227, 'beta_1': 0.9239331487892603, 'beta_2': 0.9999884655689426, 'epsilon': 1.0565524763245787e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.00392448015948591, 'tol': 7.926498215084231e-05, 'validation_fraction': 0.19031356009588443}
observation time 0.000008, current best -0.920879 at iter 24
suggestion time taken 20.010885 iter 25 next_points [{'alpha': 0.14935090442037166, 'batch_size': 45, 'beta_1': 0.6742427624112729, 'beta_2': 0.9999926594365354, 'epsilon': 4.959528469929489e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0012852654174616744, 'tol': 0.000301112495098088, 'validation_fraction': 0.36736911217023654}]
function_evaluation time 1.488670 value -0.909890 suggestion {'alpha': 0.14935090442037166, 'batch_size': 45, 'beta_1': 0.6742427624112729, 'beta_2': 0.9999926594365354, 'epsilon': 4.959528469929489e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0012852654174616744, 'tol': 0.000301112495098088, 'validation_fraction': 0.36736911217023654}
observation time 0.000005, current best -0.920879 at iter 25
suggestion time taken 20.371073 iter 26 next_points [{'alpha': 2.1770263999160897e-05, 'batch_size': 151, 'beta_1': 0.8607731215054303, 'beta_2': 0.9999912582390877, 'epsilon': 2.4749473175918854e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0006481396778156934, 'tol': 1.732668149870492e-05, 'validation_fraction': 0.5065296845978935}]
function_evaluation time 0.937790 value -0.916484 suggestion {'alpha': 2.1770263999160897e-05, 'batch_size': 151, 'beta_1': 0.8607731215054303, 'beta_2': 0.9999912582390877, 'epsilon': 2.4749473175918854e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0006481396778156934, 'tol': 1.732668149870492e-05, 'validation_fraction': 0.5065296845978935}
observation time 0.000007, current best -0.920879 at iter 26
suggestion time taken 20.061627 iter 27 next_points [{'alpha': 0.001679699247932309, 'batch_size': 25, 'beta_1': 0.6711452027498118, 'beta_2': 0.9967005786022394, 'epsilon': 8.553675726560353e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0008023411870873898, 'tol': 2.300867235114474e-05, 'validation_fraction': 0.11913978413107046}]
function_evaluation time 1.189344 value -0.894505 suggestion {'alpha': 0.001679699247932309, 'batch_size': 25, 'beta_1': 0.6711452027498118, 'beta_2': 0.9967005786022394, 'epsilon': 8.553675726560353e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.0008023411870873898, 'tol': 2.300867235114474e-05, 'validation_fraction': 0.11913978413107046}
observation time 0.000005, current best -0.920879 at iter 27
suggestion time taken 20.009226 iter 28 next_points [{'alpha': 4.236465506349856e-05, 'batch_size': 225, 'beta_1': 0.8914270013966603, 'beta_2': 0.9999944075247652, 'epsilon': 1.6126475830379176e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0032108897478283793, 'tol': 0.004914803191525211, 'validation_fraction': 0.8970705595451746}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.632346 value -0.905495 suggestion {'alpha': 4.236465506349856e-05, 'batch_size': 225, 'beta_1': 0.8914270013966603, 'beta_2': 0.9999944075247652, 'epsilon': 1.6126475830379176e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0032108897478283793, 'tol': 0.004914803191525211, 'validation_fraction': 0.8970705595451746}
observation time 0.000011, current best -0.920879 at iter 28
suggestion time taken 21.539930 iter 29 next_points [{'alpha': 0.00016567879642749418, 'batch_size': 227, 'beta_1': 0.8058864667098731, 'beta_2': 0.9998447579372719, 'epsilon': 8.007896625361154e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.0018184089476158097, 'tol': 0.0002461264759066016, 'validation_fraction': 0.2767466741273451}]
function_evaluation time 0.932581 value -0.903297 suggestion {'alpha': 0.00016567879642749418, 'batch_size': 227, 'beta_1': 0.8058864667098731, 'beta_2': 0.9998447579372719, 'epsilon': 8.007896625361154e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.0018184089476158097, 'tol': 0.0002461264759066016, 'validation_fraction': 0.2767466741273451}
observation time 0.000006, current best -0.920879 at iter 29
suggestion time taken 19.476093 iter 30 next_points [{'alpha': 3.46582528970913e-05, 'batch_size': 41, 'beta_1': 0.7017689271670218, 'beta_2': 0.9939162052248517, 'epsilon': 5.191180681072399e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.0007800488999863952, 'tol': 0.0006556776606055534, 'validation_fraction': 0.5367196557294756}]
function_evaluation time 1.427427 value -0.907692 suggestion {'alpha': 3.46582528970913e-05, 'batch_size': 41, 'beta_1': 0.7017689271670218, 'beta_2': 0.9939162052248517, 'epsilon': 5.191180681072399e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.0007800488999863952, 'tol': 0.0006556776606055534, 'validation_fraction': 0.5367196557294756}
observation time 0.000016, current best -0.920879 at iter 30
suggestion time taken 21.119594 iter 31 next_points [{'alpha': 5.011099294486339, 'batch_size': 41, 'beta_1': 0.9503548980448999, 'beta_2': 0.9999965798851617, 'epsilon': 3.496556413987611e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.029476687168747292, 'tol': 0.008437882248489698, 'validation_fraction': 0.889676033271161}]
function_evaluation time 0.509966 value -0.894505 suggestion {'alpha': 5.011099294486339, 'batch_size': 41, 'beta_1': 0.9503548980448999, 'beta_2': 0.9999965798851617, 'epsilon': 3.496556413987611e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.029476687168747292, 'tol': 0.008437882248489698, 'validation_fraction': 0.889676033271161}
observation time 0.000014, current best -0.920879 at iter 31
suggestion time taken 19.515908 iter 32 next_points [{'alpha': 3.8707294334706355e-05, 'batch_size': 226, 'beta_1': 0.5748203909052774, 'beta_2': 0.9999937383271115, 'epsilon': 2.706497124361855e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 3.837583351570214e-05, 'tol': 2.3297306022689886e-05, 'validation_fraction': 0.4633976851832361}]
function_evaluation time 0.489676 value -0.472527 suggestion {'alpha': 3.8707294334706355e-05, 'batch_size': 226, 'beta_1': 0.5748203909052774, 'beta_2': 0.9999937383271115, 'epsilon': 2.706497124361855e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 3.837583351570214e-05, 'tol': 2.3297306022689886e-05, 'validation_fraction': 0.4633976851832361}
observation time 0.000005, current best -0.920879 at iter 32
suggestion time taken 21.296977 iter 33 next_points [{'alpha': 0.0008601578123435278, 'batch_size': 112, 'beta_1': 0.9764712770536174, 'beta_2': 0.9999934311866202, 'epsilon': 2.40885499486242e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 4.7490243537249294e-05, 'tol': 2.683723486120063e-05, 'validation_fraction': 0.1112281501746081}]
function_evaluation time 0.677429 value -0.729670 suggestion {'alpha': 0.0008601578123435278, 'batch_size': 112, 'beta_1': 0.9764712770536174, 'beta_2': 0.9999934311866202, 'epsilon': 2.40885499486242e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 4.7490243537249294e-05, 'tol': 2.683723486120063e-05, 'validation_fraction': 0.1112281501746081}
observation time 0.000006, current best -0.920879 at iter 33
suggestion time taken 19.928963 iter 34 next_points [{'alpha': 0.28408084812097906, 'batch_size': 90, 'beta_1': 0.9734052549585176, 'beta_2': 0.9999776190437553, 'epsilon': 2.8587943530002254e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00024360676382156147, 'tol': 6.352556255564813e-05, 'validation_fraction': 0.2006597851260747}]
function_evaluation time 0.304639 value -0.701099 suggestion {'alpha': 0.28408084812097906, 'batch_size': 90, 'beta_1': 0.9734052549585176, 'beta_2': 0.9999776190437553, 'epsilon': 2.8587943530002254e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00024360676382156147, 'tol': 6.352556255564813e-05, 'validation_fraction': 0.2006597851260747}
observation time 0.000005, current best -0.920879 at iter 34
suggestion time taken 21.472548 iter 35 next_points [{'alpha': 3.452643161241976e-05, 'batch_size': 12, 'beta_1': 0.933494174453111, 'beta_2': 0.9998861915891384, 'epsilon': 6.786613692433507e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.0068744481884839646, 'tol': 0.00040479246729674384, 'validation_fraction': 0.6270695603427612}]
function_evaluation time 2.482922 value -0.907692 suggestion {'alpha': 3.452643161241976e-05, 'batch_size': 12, 'beta_1': 0.933494174453111, 'beta_2': 0.9998861915891384, 'epsilon': 6.786613692433507e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.0068744481884839646, 'tol': 0.00040479246729674384, 'validation_fraction': 0.6270695603427612}
observation time 0.000007, current best -0.920879 at iter 35
suggestion time taken 19.922479 iter 36 next_points [{'alpha': 0.04118503548187426, 'batch_size': 28, 'beta_1': 0.913332522840906, 'beta_2': 0.9999985705015002, 'epsilon': 2.7641202138767554e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.002142065739887976, 'tol': 0.0016704899328222175, 'validation_fraction': 0.11455453480882119}]
function_evaluation time 1.125379 value -0.903297 suggestion {'alpha': 0.04118503548187426, 'batch_size': 28, 'beta_1': 0.913332522840906, 'beta_2': 0.9999985705015002, 'epsilon': 2.7641202138767554e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.002142065739887976, 'tol': 0.0016704899328222175, 'validation_fraction': 0.11455453480882119}
observation time 0.000011, current best -0.920879 at iter 36
suggestion time taken 21.169524 iter 37 next_points [{'alpha': 0.0004307333711575669, 'batch_size': 225, 'beta_1': 0.9200733735304759, 'beta_2': 0.9920961164560538, 'epsilon': 1.5211736237150049e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 1.7036738615563362e-05, 'tol': 0.018299809074165535, 'validation_fraction': 0.7461340549836198}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.314934 value -0.527473 suggestion {'alpha': 0.0004307333711575669, 'batch_size': 225, 'beta_1': 0.9200733735304759, 'beta_2': 0.9920961164560538, 'epsilon': 1.5211736237150049e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 1.7036738615563362e-05, 'tol': 0.018299809074165535, 'validation_fraction': 0.7461340549836198}
observation time 0.000006, current best -0.920879 at iter 37
suggestion time taken 20.157560 iter 38 next_points [{'alpha': 0.4614491025234793, 'batch_size': 226, 'beta_1': 0.546418892444033, 'beta_2': 0.9938069096624761, 'epsilon': 1.3613333569185232e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.00015618047523147395, 'tol': 0.0006127142181615388, 'validation_fraction': 0.3427060582654487}]
function_evaluation time 0.593766 value -0.573626 suggestion {'alpha': 0.4614491025234793, 'batch_size': 226, 'beta_1': 0.546418892444033, 'beta_2': 0.9938069096624761, 'epsilon': 1.3613333569185232e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.00015618047523147395, 'tol': 0.0006127142181615388, 'validation_fraction': 0.3427060582654487}
observation time 0.000012, current best -0.920879 at iter 38
suggestion time taken 20.925313 iter 39 next_points [{'alpha': 0.002655055103650029, 'batch_size': 113, 'beta_1': 0.9444895901696756, 'beta_2': 0.9465526381602554, 'epsilon': 2.7802802884317145e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0001031372517779199, 'tol': 0.00040632537646470297, 'validation_fraction': 0.6775275638421193}]
function_evaluation time 0.405957 value -0.514286 suggestion {'alpha': 0.002655055103650029, 'batch_size': 113, 'beta_1': 0.9444895901696756, 'beta_2': 0.9465526381602554, 'epsilon': 2.7802802884317145e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0001031372517779199, 'tol': 0.00040632537646470297, 'validation_fraction': 0.6775275638421193}
observation time 0.000011, current best -0.920879 at iter 39
suggestion time taken 21.003057 iter 40 next_points [{'alpha': 7.5379245701301585, 'batch_size': 14, 'beta_1': 0.9878732796892574, 'beta_2': 0.9816455448628818, 'epsilon': 3.8294452916529457e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0893187794949348, 'tol': 0.00967761957309285, 'validation_fraction': 0.7739793872941805}]
function_evaluation time 1.238707 value -0.898901 suggestion {'alpha': 7.5379245701301585, 'batch_size': 14, 'beta_1': 0.9878732796892574, 'beta_2': 0.9816455448628818, 'epsilon': 3.8294452916529457e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.0893187794949348, 'tol': 0.00967761957309285, 'validation_fraction': 0.7739793872941805}
observation time 0.000012, current best -0.920879 at iter 40
suggestion time taken 19.589252 iter 41 next_points [{'alpha': 1.4919204201285594, 'batch_size': 41, 'beta_1': 0.969343501619258, 'beta_2': 0.9926254625152126, 'epsilon': 3.673772948713052e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 1.496220004150207e-05, 'tol': 0.0016373541790174755, 'validation_fraction': 0.3202436309725546}]
function_evaluation time 0.250257 value -0.443956 suggestion {'alpha': 1.4919204201285594, 'batch_size': 41, 'beta_1': 0.969343501619258, 'beta_2': 0.9926254625152126, 'epsilon': 3.673772948713052e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 1.496220004150207e-05, 'tol': 0.0016373541790174755, 'validation_fraction': 0.3202436309725546}
observation time 0.000011, current best -0.920879 at iter 41
suggestion time taken 21.203652 iter 42 next_points [{'alpha': 2.0751101673865994e-05, 'batch_size': 25, 'beta_1': 0.9809023509225467, 'beta_2': 0.9972663996536408, 'epsilon': 6.579227188732446e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 6.42631523634408e-05, 'tol': 0.0005799513063852346, 'validation_fraction': 0.1692549393627921}]
function_evaluation time 0.783225 value -0.628571 suggestion {'alpha': 2.0751101673865994e-05, 'batch_size': 25, 'beta_1': 0.9809023509225467, 'beta_2': 0.9972663996536408, 'epsilon': 6.579227188732446e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 6.42631523634408e-05, 'tol': 0.0005799513063852346, 'validation_fraction': 0.1692549393627921}
observation time 0.000006, current best -0.920879 at iter 42
suggestion time taken 16.955941 iter 43 next_points [{'alpha': 5.627341973793899, 'batch_size': 227, 'beta_1': 0.6413413107413882, 'beta_2': 0.9999293462073077, 'epsilon': 1.2614219725534136e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.00015456152803440898, 'tol': 6.84197581162971e-05, 'validation_fraction': 0.5405801838165674}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.281319 value -0.562637 suggestion {'alpha': 5.627341973793899, 'batch_size': 227, 'beta_1': 0.6413413107413882, 'beta_2': 0.9999293462073077, 'epsilon': 1.2614219725534136e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.00015456152803440898, 'tol': 6.84197581162971e-05, 'validation_fraction': 0.5405801838165674}
observation time 0.000005, current best -0.920879 at iter 43
suggestion time taken 15.174856 iter 44 next_points [{'alpha': 0.0005194263490902193, 'batch_size': 225, 'beta_1': 0.5193735328807618, 'beta_2': 0.9991449563967421, 'epsilon': 8.579331139691294e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 1.565560449065823e-05, 'tol': 0.0005341160576300873, 'validation_fraction': 0.19097181089408657}]
function_evaluation time 0.286513 value -0.527473 suggestion {'alpha': 0.0005194263490902193, 'batch_size': 225, 'beta_1': 0.5193735328807618, 'beta_2': 0.9991449563967421, 'epsilon': 8.579331139691294e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 1.565560449065823e-05, 'tol': 0.0005341160576300873, 'validation_fraction': 0.19097181089408657}
observation time 0.000005, current best -0.920879 at iter 44
saving meta data: {'args': {'--uuid': 'e416e6bed8ae57b88040d424e082ca40', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
