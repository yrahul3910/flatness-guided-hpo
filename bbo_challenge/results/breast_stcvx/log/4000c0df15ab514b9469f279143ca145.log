running: {'--uuid': '4000c0df15ab514b9469f279143ca145', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 4000c0df15ab514b9469f279143ca145 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.012310 iter 0 next_points [{'alpha': 0.009378244988806437, 'batch_size': 230, 'beta_1': 0.8829112824991879, 'beta_2': 0.9912672018769343, 'epsilon': 1.131316168888265e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.054747065747051515, 'tol': 2.208703130525617e-05, 'validation_fraction': 0.1692559788534661}]
function_evaluation time 0.924202 value -0.892308 suggestion {'alpha': 0.009378244988806437, 'batch_size': 230, 'beta_1': 0.8829112824991879, 'beta_2': 0.9912672018769343, 'epsilon': 1.131316168888265e-09, 'hidden_layer_sizes': 160, 'learning_rate_init': 0.054747065747051515, 'tol': 2.208703130525617e-05, 'validation_fraction': 0.1692559788534661}
observation time 0.000005, current best -0.892308 at iter 0
suggestion time taken 0.013942 iter 1 next_points [{'alpha': 0.011028196451582943, 'batch_size': 233, 'beta_1': 0.9589698190359625, 'beta_2': 0.9999917248025751, 'epsilon': 2.0844091298852048e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0001324784040308083, 'tol': 1.8895972169701245e-05, 'validation_fraction': 0.7291821973046897}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.577829 value -0.472527 suggestion {'alpha': 0.011028196451582943, 'batch_size': 233, 'beta_1': 0.9589698190359625, 'beta_2': 0.9999917248025751, 'epsilon': 2.0844091298852048e-08, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.0001324784040308083, 'tol': 1.8895972169701245e-05, 'validation_fraction': 0.7291821973046897}
observation time 0.000003, current best -0.892308 at iter 1
suggestion time taken 0.009907 iter 2 next_points [{'alpha': 0.0006639815251492255, 'batch_size': 43, 'beta_1': 0.7344004640777996, 'beta_2': 0.9962392415338858, 'epsilon': 5.812745055908998e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0021464132985735823, 'tol': 0.002133786689548714, 'validation_fraction': 0.8411175319494454}]
function_evaluation time 0.785458 value -0.848352 suggestion {'alpha': 0.0006639815251492255, 'batch_size': 43, 'beta_1': 0.7344004640777996, 'beta_2': 0.9962392415338858, 'epsilon': 5.812745055908998e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.0021464132985735823, 'tol': 0.002133786689548714, 'validation_fraction': 0.8411175319494454}
observation time 0.000008, current best -0.892308 at iter 2
suggestion time taken 0.012513 iter 3 next_points [{'alpha': 0.00010926892991866805, 'batch_size': 166, 'beta_1': 0.6818003346948918, 'beta_2': 0.9997786472925758, 'epsilon': 3.6818061260070135e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.05303431734066388, 'tol': 0.0002690942032166216, 'validation_fraction': 0.107608429772535}]
function_evaluation time 0.789186 value -0.907692 suggestion {'alpha': 0.00010926892991866805, 'batch_size': 166, 'beta_1': 0.6818003346948918, 'beta_2': 0.9997786472925758, 'epsilon': 3.6818061260070135e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.05303431734066388, 'tol': 0.0002690942032166216, 'validation_fraction': 0.107608429772535}
observation time 0.000007, current best -0.907692 at iter 3
suggestion time taken 0.011267 iter 4 next_points [{'alpha': 0.01855417337103852, 'batch_size': 48, 'beta_1': 0.9301833821544605, 'beta_2': 0.9988775109300285, 'epsilon': 1.6434241491329792e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.005201184983953586, 'tol': 6.582510720857915e-05, 'validation_fraction': 0.8110163259478153}]
function_evaluation time 0.720828 value -0.912088 suggestion {'alpha': 0.01855417337103852, 'batch_size': 48, 'beta_1': 0.9301833821544605, 'beta_2': 0.9988775109300285, 'epsilon': 1.6434241491329792e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.005201184983953586, 'tol': 6.582510720857915e-05, 'validation_fraction': 0.8110163259478153}
observation time 0.000007, current best -0.912088 at iter 4
suggestion time taken 0.011413 iter 5 next_points [{'alpha': 0.12017139106442079, 'batch_size': 132, 'beta_1': 0.7702668484106369, 'beta_2': 0.9998883856320804, 'epsilon': 1.850952420987212e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.0006755183761127263, 'tol': 0.0011552574711039666, 'validation_fraction': 0.5909236205291841}]
function_evaluation time 1.034268 value -0.901099 suggestion {'alpha': 0.12017139106442079, 'batch_size': 132, 'beta_1': 0.7702668484106369, 'beta_2': 0.9998883856320804, 'epsilon': 1.850952420987212e-08, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.0006755183761127263, 'tol': 0.0011552574711039666, 'validation_fraction': 0.5909236205291841}
observation time 0.000006, current best -0.912088 at iter 5
suggestion time taken 0.011194 iter 6 next_points [{'alpha': 1.640760129124152e-05, 'batch_size': 72, 'beta_1': 0.8591611633051954, 'beta_2': 0.999887507247571, 'epsilon': 9.220702562942748e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0010789825918290899, 'tol': 0.00011533238674816385, 'validation_fraction': 0.421301587674545}]
function_evaluation time 0.781762 value -0.841758 suggestion {'alpha': 1.640760129124152e-05, 'batch_size': 72, 'beta_1': 0.8591611633051954, 'beta_2': 0.999887507247571, 'epsilon': 9.220702562942748e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0010789825918290899, 'tol': 0.00011533238674816385, 'validation_fraction': 0.421301587674545}
observation time 0.000003, current best -0.912088 at iter 6
suggestion time taken 0.012352 iter 7 next_points [{'alpha': 2.474753830573638e-05, 'batch_size': 172, 'beta_1': 0.6575672428595192, 'beta_2': 0.9744501224421506, 'epsilon': 2.2230333772261782e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.008050873910144342, 'tol': 0.033420202984129135, 'validation_fraction': 0.44183216598575326}]
function_evaluation time 0.457101 value -0.920879 suggestion {'alpha': 2.474753830573638e-05, 'batch_size': 172, 'beta_1': 0.6575672428595192, 'beta_2': 0.9744501224421506, 'epsilon': 2.2230333772261782e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.008050873910144342, 'tol': 0.033420202984129135, 'validation_fraction': 0.44183216598575326}
observation time 0.000004, current best -0.920879 at iter 7
suggestion time taken 0.010879 iter 8 next_points [{'alpha': 0.2104032064146232, 'batch_size': 236, 'beta_1': 0.9601911511805603, 'beta_2': 0.999706744757198, 'epsilon': 5.1394140438730286e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.007857812370027374, 'tol': 0.002586409606275247, 'validation_fraction': 0.5074372353467105}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.685857 value -0.885714 suggestion {'alpha': 0.2104032064146232, 'batch_size': 236, 'beta_1': 0.9601911511805603, 'beta_2': 0.999706744757198, 'epsilon': 5.1394140438730286e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.007857812370027374, 'tol': 0.002586409606275247, 'validation_fraction': 0.5074372353467105}
observation time 0.000003, current best -0.920879 at iter 8
suggestion time taken 0.010067 iter 9 next_points [{'alpha': 0.0009257905811030085, 'batch_size': 42, 'beta_1': 0.9687493201850406, 'beta_2': 0.9964633163615607, 'epsilon': 5.907777133287407e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.0008710640615271182, 'tol': 0.006426064455163187, 'validation_fraction': 0.5270172286127891}]
function_evaluation time 1.218546 value -0.890110 suggestion {'alpha': 0.0009257905811030085, 'batch_size': 42, 'beta_1': 0.9687493201850406, 'beta_2': 0.9964633163615607, 'epsilon': 5.907777133287407e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.0008710640615271182, 'tol': 0.006426064455163187, 'validation_fraction': 0.5270172286127891}
observation time 0.000003, current best -0.920879 at iter 9
suggestion time taken 0.010202 iter 10 next_points [{'alpha': 1.5050834348667648e-05, 'batch_size': 200, 'beta_1': 0.7892820848851707, 'beta_2': 0.9995868360250197, 'epsilon': 7.110055685266171e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 9.00559199720642e-05, 'tol': 0.0008038168216683264, 'validation_fraction': 0.49140622477691537}]
function_evaluation time 0.528781 value -0.514286 suggestion {'alpha': 1.5050834348667648e-05, 'batch_size': 200, 'beta_1': 0.7892820848851707, 'beta_2': 0.9995868360250197, 'epsilon': 7.110055685266171e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 9.00559199720642e-05, 'tol': 0.0008038168216683264, 'validation_fraction': 0.49140622477691537}
observation time 0.000004, current best -0.920879 at iter 10
suggestion time taken 0.012273 iter 11 next_points [{'alpha': 0.0067359804575385035, 'batch_size': 53, 'beta_1': 0.727626463788028, 'beta_2': 0.9896427578845994, 'epsilon': 4.895072719597071e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 3.986114362207594e-05, 'tol': 0.008726176022148882, 'validation_fraction': 0.7742355787695087}]
function_evaluation time 0.327997 value -0.516484 suggestion {'alpha': 0.0067359804575385035, 'batch_size': 53, 'beta_1': 0.727626463788028, 'beta_2': 0.9896427578845994, 'epsilon': 4.895072719597071e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 3.986114362207594e-05, 'tol': 0.008726176022148882, 'validation_fraction': 0.7742355787695087}
observation time 0.000003, current best -0.920879 at iter 11
suggestion time taken 0.010233 iter 12 next_points [{'alpha': 0.00011255503195648143, 'batch_size': 45, 'beta_1': 0.6029139302542008, 'beta_2': 0.9971990132271074, 'epsilon': 6.135120396167113e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.021533853562855417, 'tol': 0.05964051769966384, 'validation_fraction': 0.2559474851644778}]
function_evaluation time 0.937345 value -0.896703 suggestion {'alpha': 0.00011255503195648143, 'batch_size': 45, 'beta_1': 0.6029139302542008, 'beta_2': 0.9971990132271074, 'epsilon': 6.135120396167113e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.021533853562855417, 'tol': 0.05964051769966384, 'validation_fraction': 0.2559474851644778}
observation time 0.000007, current best -0.920879 at iter 12
suggestion time taken 0.012509 iter 13 next_points [{'alpha': 0.41580544375240214, 'batch_size': 95, 'beta_1': 0.9008838313558285, 'beta_2': 0.9963195749110458, 'epsilon': 1.4927944331706806e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.06829485043162153, 'tol': 0.001805642696699741, 'validation_fraction': 0.7652551024352753}]
function_evaluation time 0.369329 value -0.727473 suggestion {'alpha': 0.41580544375240214, 'batch_size': 95, 'beta_1': 0.9008838313558285, 'beta_2': 0.9963195749110458, 'epsilon': 1.4927944331706806e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.06829485043162153, 'tol': 0.001805642696699741, 'validation_fraction': 0.7652551024352753}
observation time 0.000004, current best -0.920879 at iter 13
suggestion time taken 0.011817 iter 14 next_points [{'alpha': 0.3362504561367161, 'batch_size': 131, 'beta_1': 0.9889279111473561, 'beta_2': 0.9993972009355006, 'epsilon': 3.4465624420329405e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.01049954815563729, 'tol': 0.00042792382327887246, 'validation_fraction': 0.5717777042295573}]
function_evaluation time 0.809531 value -0.912088 suggestion {'alpha': 0.3362504561367161, 'batch_size': 131, 'beta_1': 0.9889279111473561, 'beta_2': 0.9993972009355006, 'epsilon': 3.4465624420329405e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.01049954815563729, 'tol': 0.00042792382327887246, 'validation_fraction': 0.5717777042295573}
observation time 0.000003, current best -0.920879 at iter 14
suggestion time taken 0.009779 iter 15 next_points [{'alpha': 4.266806735986631e-05, 'batch_size': 59, 'beta_1': 0.800870316972509, 'beta_2': 0.9981846764212542, 'epsilon': 4.0560980028549225e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.002481544130001486, 'tol': 0.0031506790029980844, 'validation_fraction': 0.42999650077879553}]
function_evaluation time 1.086000 value -0.918681 suggestion {'alpha': 4.266806735986631e-05, 'batch_size': 59, 'beta_1': 0.800870316972509, 'beta_2': 0.9981846764212542, 'epsilon': 4.0560980028549225e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.002481544130001486, 'tol': 0.0031506790029980844, 'validation_fraction': 0.42999650077879553}
observation time 0.000003, current best -0.920879 at iter 15
suggestion time taken 0.010262 iter 16 next_points [{'alpha': 0.0001018224373522195, 'batch_size': 11, 'beta_1': 0.7512180539978246, 'beta_2': 0.9998143560310024, 'epsilon': 1.0447161707761513e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 1.4369086815605173e-05, 'tol': 0.09164608178094923, 'validation_fraction': 0.6526471270762909}]
function_evaluation time 1.280643 value -0.591209 suggestion {'alpha': 0.0001018224373522195, 'batch_size': 11, 'beta_1': 0.7512180539978246, 'beta_2': 0.9998143560310024, 'epsilon': 1.0447161707761513e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 1.4369086815605173e-05, 'tol': 0.09164608178094923, 'validation_fraction': 0.6526471270762909}
observation time 0.000004, current best -0.920879 at iter 16
suggestion time taken 0.010859 iter 17 next_points [{'alpha': 0.42515106374877515, 'batch_size': 33, 'beta_1': 0.9772553838551111, 'beta_2': 0.9999942417276262, 'epsilon': 1.1099546375015947e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.01720875346459265, 'tol': 0.0011244303987786037, 'validation_fraction': 0.8497394260658542}]
function_evaluation time 0.688926 value -0.887912 suggestion {'alpha': 0.42515106374877515, 'batch_size': 33, 'beta_1': 0.9772553838551111, 'beta_2': 0.9999942417276262, 'epsilon': 1.1099546375015947e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.01720875346459265, 'tol': 0.0011244303987786037, 'validation_fraction': 0.8497394260658542}
observation time 0.000003, current best -0.920879 at iter 17
suggestion time taken 0.010652 iter 18 next_points [{'alpha': 0.0007449448720958798, 'batch_size': 100, 'beta_1': 0.9638354873528389, 'beta_2': 0.9974729021312401, 'epsilon': 2.6730961533366317e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 6.980039147857811e-05, 'tol': 0.07775105686753374, 'validation_fraction': 0.7737001757033493}]
function_evaluation time 0.232415 value -0.472527 suggestion {'alpha': 0.0007449448720958798, 'batch_size': 100, 'beta_1': 0.9638354873528389, 'beta_2': 0.9974729021312401, 'epsilon': 2.6730961533366317e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 6.980039147857811e-05, 'tol': 0.07775105686753374, 'validation_fraction': 0.7737001757033493}
observation time 0.000004, current best -0.920879 at iter 18
suggestion time taken 0.011200 iter 19 next_points [{'alpha': 0.059737515389785854, 'batch_size': 215, 'beta_1': 0.9598598748450236, 'beta_2': 0.9967438513582605, 'epsilon': 8.423030645461298e-08, 'hidden_layer_sizes': 143, 'learning_rate_init': 5.606053734332431e-05, 'tol': 0.00021205297962361726, 'validation_fraction': 0.859187641741694}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.351861 value -0.582418 suggestion {'alpha': 0.059737515389785854, 'batch_size': 215, 'beta_1': 0.9598598748450236, 'beta_2': 0.9967438513582605, 'epsilon': 8.423030645461298e-08, 'hidden_layer_sizes': 143, 'learning_rate_init': 5.606053734332431e-05, 'tol': 0.00021205297962361726, 'validation_fraction': 0.859187641741694}
observation time 0.000008, current best -0.920879 at iter 19
suggestion time taken 0.013512 iter 20 next_points [{'alpha': 0.007889238388161052, 'batch_size': 114, 'beta_1': 0.69774864737718, 'beta_2': 0.9999905108255769, 'epsilon': 5.526639971243365e-09, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0031579667698843853, 'tol': 2.0134651761648633e-05, 'validation_fraction': 0.6667858890699327}]
function_evaluation time 0.574622 value -0.914286 suggestion {'alpha': 0.007889238388161052, 'batch_size': 114, 'beta_1': 0.69774864737718, 'beta_2': 0.9999905108255769, 'epsilon': 5.526639971243365e-09, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.0031579667698843853, 'tol': 2.0134651761648633e-05, 'validation_fraction': 0.6667858890699327}
observation time 0.000003, current best -0.920879 at iter 20
suggestion time taken 0.010411 iter 21 next_points [{'alpha': 1.664098260143899e-05, 'batch_size': 139, 'beta_1': 0.9592172697944612, 'beta_2': 0.9898612723501161, 'epsilon': 1.282169354450728e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.006876061084043072, 'tol': 0.033570182930800385, 'validation_fraction': 0.35575840462386676}]
function_evaluation time 0.572088 value -0.907692 suggestion {'alpha': 1.664098260143899e-05, 'batch_size': 139, 'beta_1': 0.9592172697944612, 'beta_2': 0.9898612723501161, 'epsilon': 1.282169354450728e-08, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.006876061084043072, 'tol': 0.033570182930800385, 'validation_fraction': 0.35575840462386676}
observation time 0.000005, current best -0.920879 at iter 21
suggestion time taken 0.010572 iter 22 next_points [{'alpha': 0.8103720057535179, 'batch_size': 116, 'beta_1': 0.8998467599746424, 'beta_2': 0.9996736825761712, 'epsilon': 5.213973383058083e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 1.001941859588503e-05, 'tol': 0.00038674675569496883, 'validation_fraction': 0.8653414439960142}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.282872 value -0.419780 suggestion {'alpha': 0.8103720057535179, 'batch_size': 116, 'beta_1': 0.8998467599746424, 'beta_2': 0.9996736825761712, 'epsilon': 5.213973383058083e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 1.001941859588503e-05, 'tol': 0.00038674675569496883, 'validation_fraction': 0.8653414439960142}
observation time 0.000004, current best -0.920879 at iter 22
suggestion time taken 0.010385 iter 23 next_points [{'alpha': 3.426336427915471e-05, 'batch_size': 169, 'beta_1': 0.9061460404921429, 'beta_2': 0.9985577252435731, 'epsilon': 4.399670844703951e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.0011625819528543913, 'tol': 1.6504466810704146e-05, 'validation_fraction': 0.747939360284461}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.829463 value -0.843956 suggestion {'alpha': 3.426336427915471e-05, 'batch_size': 169, 'beta_1': 0.9061460404921429, 'beta_2': 0.9985577252435731, 'epsilon': 4.399670844703951e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.0011625819528543913, 'tol': 1.6504466810704146e-05, 'validation_fraction': 0.747939360284461}
observation time 0.000009, current best -0.920879 at iter 23
suggestion time taken 0.012067 iter 24 next_points [{'alpha': 0.0007904819653566138, 'batch_size': 49, 'beta_1': 0.7133257846549652, 'beta_2': 0.9280685096704748, 'epsilon': 4.555938842337557e-09, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.020571898329846173, 'tol': 2.9639934452666727e-05, 'validation_fraction': 0.6893762098001411}]
function_evaluation time 1.205487 value -0.903297 suggestion {'alpha': 0.0007904819653566138, 'batch_size': 49, 'beta_1': 0.7133257846549652, 'beta_2': 0.9280685096704748, 'epsilon': 4.555938842337557e-09, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.020571898329846173, 'tol': 2.9639934452666727e-05, 'validation_fraction': 0.6893762098001411}
observation time 0.000003, current best -0.920879 at iter 24
suggestion time taken 0.010834 iter 25 next_points [{'alpha': 0.001987406114470999, 'batch_size': 219, 'beta_1': 0.9512075140170655, 'beta_2': 0.9999984149537048, 'epsilon': 3.1053122316440435e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0660082783556585, 'tol': 0.0007724274568698446, 'validation_fraction': 0.8048785689476986}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.469745 value -0.901099 suggestion {'alpha': 0.001987406114470999, 'batch_size': 219, 'beta_1': 0.9512075140170655, 'beta_2': 0.9999984149537048, 'epsilon': 3.1053122316440435e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0660082783556585, 'tol': 0.0007724274568698446, 'validation_fraction': 0.8048785689476986}
observation time 0.000007, current best -0.920879 at iter 25
suggestion time taken 0.013762 iter 26 next_points [{'alpha': 0.0001283098241537353, 'batch_size': 41, 'beta_1': 0.9539109584490089, 'beta_2': 0.999973362941267, 'epsilon': 1.254797578273072e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.0002389784278169676, 'tol': 0.00013703740017055187, 'validation_fraction': 0.8562801697041658}]
function_evaluation time 0.702913 value -0.727473 suggestion {'alpha': 0.0001283098241537353, 'batch_size': 41, 'beta_1': 0.9539109584490089, 'beta_2': 0.999973362941267, 'epsilon': 1.254797578273072e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.0002389784278169676, 'tol': 0.00013703740017055187, 'validation_fraction': 0.8562801697041658}
observation time 0.000003, current best -0.920879 at iter 26
suggestion time taken 0.012015 iter 27 next_points [{'alpha': 1.5483178484073687, 'batch_size': 209, 'beta_1': 0.9414567103557641, 'beta_2': 0.9826144746565094, 'epsilon': 2.067129015187401e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.010309312862830468, 'tol': 9.428361162163113e-05, 'validation_fraction': 0.8995329623288482}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.717654 value -0.903297 suggestion {'alpha': 1.5483178484073687, 'batch_size': 209, 'beta_1': 0.9414567103557641, 'beta_2': 0.9826144746565094, 'epsilon': 2.067129015187401e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.010309312862830468, 'tol': 9.428361162163113e-05, 'validation_fraction': 0.8995329623288482}
observation time 0.000005, current best -0.920879 at iter 27
suggestion time taken 0.011647 iter 28 next_points [{'alpha': 0.018685544355359764, 'batch_size': 174, 'beta_1': 0.737877373242859, 'beta_2': 0.9995468654473819, 'epsilon': 3.295723706149301e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 4.0405826922453225e-05, 'tol': 1.5262930959868098e-05, 'validation_fraction': 0.10516678215195562}]
function_evaluation time 0.315695 value -0.527473 suggestion {'alpha': 0.018685544355359764, 'batch_size': 174, 'beta_1': 0.737877373242859, 'beta_2': 0.9995468654473819, 'epsilon': 3.295723706149301e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 4.0405826922453225e-05, 'tol': 1.5262930959868098e-05, 'validation_fraction': 0.10516678215195562}
observation time 0.000004, current best -0.920879 at iter 28
suggestion time taken 0.010888 iter 29 next_points [{'alpha': 0.0005290140739247417, 'batch_size': 66, 'beta_1': 0.9898418449079134, 'beta_2': 0.919744474377794, 'epsilon': 2.0536436049216484e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.031970816905479135, 'tol': 0.005138405165643207, 'validation_fraction': 0.46522739378083927}]
function_evaluation time 0.762863 value -0.890110 suggestion {'alpha': 0.0005290140739247417, 'batch_size': 66, 'beta_1': 0.9898418449079134, 'beta_2': 0.919744474377794, 'epsilon': 2.0536436049216484e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.031970816905479135, 'tol': 0.005138405165643207, 'validation_fraction': 0.46522739378083927}
observation time 0.000004, current best -0.920879 at iter 29
suggestion time taken 0.010508 iter 30 next_points [{'alpha': 0.03256001764175126, 'batch_size': 141, 'beta_1': 0.5186259744642422, 'beta_2': 0.9998182898495819, 'epsilon': 5.963911489923749e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.09055391289776833, 'tol': 0.0006371469628936217, 'validation_fraction': 0.6257907705747856}]
function_evaluation time 0.746877 value -0.894505 suggestion {'alpha': 0.03256001764175126, 'batch_size': 141, 'beta_1': 0.5186259744642422, 'beta_2': 0.9998182898495819, 'epsilon': 5.963911489923749e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.09055391289776833, 'tol': 0.0006371469628936217, 'validation_fraction': 0.6257907705747856}
observation time 0.000004, current best -0.920879 at iter 30
suggestion time taken 0.011049 iter 31 next_points [{'alpha': 0.0012343374824387231, 'batch_size': 224, 'beta_1': 0.9872587026078319, 'beta_2': 0.9996509610150981, 'epsilon': 8.132732610724803e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.076156602560245, 'tol': 0.00047274401467619975, 'validation_fraction': 0.15977977054338738}]
function_evaluation time 0.488153 value -0.764835 suggestion {'alpha': 0.0012343374824387231, 'batch_size': 224, 'beta_1': 0.9872587026078319, 'beta_2': 0.9996509610150981, 'epsilon': 8.132732610724803e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.076156602560245, 'tol': 0.00047274401467619975, 'validation_fraction': 0.15977977054338738}
observation time 0.000006, current best -0.920879 at iter 31
suggestion time taken 0.011201 iter 32 next_points [{'alpha': 0.00012445899610890638, 'batch_size': 140, 'beta_1': 0.9542436521874188, 'beta_2': 0.9999636294741708, 'epsilon': 1.655141793124266e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.08770328208923349, 'tol': 2.109441690101709e-05, 'validation_fraction': 0.40468043860000674}]
function_evaluation time 0.554692 value -0.727473 suggestion {'alpha': 0.00012445899610890638, 'batch_size': 140, 'beta_1': 0.9542436521874188, 'beta_2': 0.9999636294741708, 'epsilon': 1.655141793124266e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.08770328208923349, 'tol': 2.109441690101709e-05, 'validation_fraction': 0.40468043860000674}
observation time 0.000009, current best -0.920879 at iter 32
suggestion time taken 0.011533 iter 33 next_points [{'alpha': 0.001791621089425574, 'batch_size': 14, 'beta_1': 0.9207805447560048, 'beta_2': 0.9967294366111276, 'epsilon': 7.491467164436707e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.046260079323959376, 'tol': 2.0289864786542037e-05, 'validation_fraction': 0.10845912225222223}]
function_evaluation time 1.622329 value -0.791209 suggestion {'alpha': 0.001791621089425574, 'batch_size': 14, 'beta_1': 0.9207805447560048, 'beta_2': 0.9967294366111276, 'epsilon': 7.491467164436707e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.046260079323959376, 'tol': 2.0289864786542037e-05, 'validation_fraction': 0.10845912225222223}
observation time 0.000004, current best -0.920879 at iter 33
suggestion time taken 0.011756 iter 34 next_points [{'alpha': 0.006246078216729195, 'batch_size': 148, 'beta_1': 0.970822437532585, 'beta_2': 0.9997666215206032, 'epsilon': 8.322316822128912e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0004992649252263553, 'tol': 0.005821444136480678, 'validation_fraction': 0.5007608112415323}]
function_evaluation time 0.458666 value -0.628571 suggestion {'alpha': 0.006246078216729195, 'batch_size': 148, 'beta_1': 0.970822437532585, 'beta_2': 0.9997666215206032, 'epsilon': 8.322316822128912e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0004992649252263553, 'tol': 0.005821444136480678, 'validation_fraction': 0.5007608112415323}
observation time 0.000008, current best -0.920879 at iter 34
suggestion time taken 0.011817 iter 35 next_points [{'alpha': 3.318021171625421e-05, 'batch_size': 248, 'beta_1': 0.9613364113544222, 'beta_2': 0.9989680724952277, 'epsilon': 2.817197378352275e-09, 'hidden_layer_sizes': 175, 'learning_rate_init': 2.5111616294789345e-05, 'tol': 0.00012856840924024534, 'validation_fraction': 0.5555122838395475}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.304338 value -0.472527 suggestion {'alpha': 3.318021171625421e-05, 'batch_size': 248, 'beta_1': 0.9613364113544222, 'beta_2': 0.9989680724952277, 'epsilon': 2.817197378352275e-09, 'hidden_layer_sizes': 175, 'learning_rate_init': 2.5111616294789345e-05, 'tol': 0.00012856840924024534, 'validation_fraction': 0.5555122838395475}
observation time 0.000003, current best -0.920879 at iter 35
suggestion time taken 0.010255 iter 36 next_points [{'alpha': 0.00041206375260780605, 'batch_size': 32, 'beta_1': 0.7164129303559399, 'beta_2': 0.9998393087622055, 'epsilon': 2.9846332415387907e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0035254422956256903, 'tol': 1.3643799323176221e-05, 'validation_fraction': 0.1374658994934168}]
function_evaluation time 1.008026 value -0.901099 suggestion {'alpha': 0.00041206375260780605, 'batch_size': 32, 'beta_1': 0.7164129303559399, 'beta_2': 0.9998393087622055, 'epsilon': 2.9846332415387907e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0035254422956256903, 'tol': 1.3643799323176221e-05, 'validation_fraction': 0.1374658994934168}
observation time 0.000003, current best -0.920879 at iter 36
suggestion time taken 0.010526 iter 37 next_points [{'alpha': 3.0696882529597896e-05, 'batch_size': 54, 'beta_1': 0.9879622399823184, 'beta_2': 0.9999309566383152, 'epsilon': 2.2392148676802524e-09, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.0009839216423770279, 'tol': 7.211205509054635e-05, 'validation_fraction': 0.624102403178374}]
function_evaluation time 1.296128 value -0.912088 suggestion {'alpha': 3.0696882529597896e-05, 'batch_size': 54, 'beta_1': 0.9879622399823184, 'beta_2': 0.9999309566383152, 'epsilon': 2.2392148676802524e-09, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.0009839216423770279, 'tol': 7.211205509054635e-05, 'validation_fraction': 0.624102403178374}
observation time 0.000005, current best -0.920879 at iter 37
suggestion time taken 0.013448 iter 38 next_points [{'alpha': 0.06448245496326255, 'batch_size': 204, 'beta_1': 0.5826504640900898, 'beta_2': 0.9999011862950119, 'epsilon': 2.493939048757742e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.06597990568336351, 'tol': 3.878785769625987e-05, 'validation_fraction': 0.6712488881352536}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.658312 value -0.901099 suggestion {'alpha': 0.06448245496326255, 'batch_size': 204, 'beta_1': 0.5826504640900898, 'beta_2': 0.9999011862950119, 'epsilon': 2.493939048757742e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.06597990568336351, 'tol': 3.878785769625987e-05, 'validation_fraction': 0.6712488881352536}
observation time 0.000009, current best -0.920879 at iter 38
suggestion time taken 0.011125 iter 39 next_points [{'alpha': 0.16649365545702038, 'batch_size': 118, 'beta_1': 0.9073531997055129, 'beta_2': 0.9999724991260094, 'epsilon': 5.987395364586979e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 2.332748330865847e-05, 'tol': 0.06514217096502467, 'validation_fraction': 0.5599154526331446}]
function_evaluation time 0.292630 value -0.529670 suggestion {'alpha': 0.16649365545702038, 'batch_size': 118, 'beta_1': 0.9073531997055129, 'beta_2': 0.9999724991260094, 'epsilon': 5.987395364586979e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 2.332748330865847e-05, 'tol': 0.06514217096502467, 'validation_fraction': 0.5599154526331446}
observation time 0.000004, current best -0.920879 at iter 39
suggestion time taken 0.012367 iter 40 next_points [{'alpha': 0.07606622155791738, 'batch_size': 55, 'beta_1': 0.9358364341451116, 'beta_2': 0.9978873864234886, 'epsilon': 2.591397144709504e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0033935841144202413, 'tol': 3.44690777272484e-05, 'validation_fraction': 0.285701959785084}]
function_evaluation time 1.439399 value -0.903297 suggestion {'alpha': 0.07606622155791738, 'batch_size': 55, 'beta_1': 0.9358364341451116, 'beta_2': 0.9978873864234886, 'epsilon': 2.591397144709504e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0033935841144202413, 'tol': 3.44690777272484e-05, 'validation_fraction': 0.285701959785084}
observation time 0.000008, current best -0.920879 at iter 40
suggestion time taken 0.014074 iter 41 next_points [{'alpha': 7.221803028984518e-05, 'batch_size': 173, 'beta_1': 0.9872869937975628, 'beta_2': 0.9998092346849756, 'epsilon': 7.043864574950937e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 1.803516756070229e-05, 'tol': 0.08942632507311446, 'validation_fraction': 0.38997288665433266}]
function_evaluation time 0.351775 value -0.472527 suggestion {'alpha': 7.221803028984518e-05, 'batch_size': 173, 'beta_1': 0.9872869937975628, 'beta_2': 0.9998092346849756, 'epsilon': 7.043864574950937e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 1.803516756070229e-05, 'tol': 0.08942632507311446, 'validation_fraction': 0.38997288665433266}
observation time 0.000003, current best -0.920879 at iter 41
suggestion time taken 0.012336 iter 42 next_points [{'alpha': 1.1142804547563672, 'batch_size': 99, 'beta_1': 0.9756148766463891, 'beta_2': 0.9999703684207755, 'epsilon': 1.752120148172333e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0020263243718482158, 'tol': 0.003130129285661501, 'validation_fraction': 0.3724620957405559}]
function_evaluation time 1.219706 value -0.912088 suggestion {'alpha': 1.1142804547563672, 'batch_size': 99, 'beta_1': 0.9756148766463891, 'beta_2': 0.9999703684207755, 'epsilon': 1.752120148172333e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0020263243718482158, 'tol': 0.003130129285661501, 'validation_fraction': 0.3724620957405559}
observation time 0.000003, current best -0.920879 at iter 42
suggestion time taken 0.010115 iter 43 next_points [{'alpha': 0.007901703639184332, 'batch_size': 173, 'beta_1': 0.6887127054568764, 'beta_2': 0.9450760467005613, 'epsilon': 2.0932939711766504e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.021242093702050716, 'tol': 0.005282409490638681, 'validation_fraction': 0.25308270351247264}]
function_evaluation time 0.734177 value -0.901099 suggestion {'alpha': 0.007901703639184332, 'batch_size': 173, 'beta_1': 0.6887127054568764, 'beta_2': 0.9450760467005613, 'epsilon': 2.0932939711766504e-09, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.021242093702050716, 'tol': 0.005282409490638681, 'validation_fraction': 0.25308270351247264}
observation time 0.000004, current best -0.920879 at iter 43
suggestion time taken 0.010892 iter 44 next_points [{'alpha': 0.00608635389381562, 'batch_size': 52, 'beta_1': 0.8582618761336653, 'beta_2': 0.9778420336878145, 'epsilon': 3.4013676410278394e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.06992463010962717, 'tol': 0.006577459861906811, 'validation_fraction': 0.24820705485894956}]
function_evaluation time 1.641411 value -0.909890 suggestion {'alpha': 0.00608635389381562, 'batch_size': 52, 'beta_1': 0.8582618761336653, 'beta_2': 0.9778420336878145, 'epsilon': 3.4013676410278394e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.06992463010962717, 'tol': 0.006577459861906811, 'validation_fraction': 0.24820705485894956}
observation time 0.000004, current best -0.920879 at iter 44
saving meta data: {'args': {'--uuid': '4000c0df15ab514b9469f279143ca145', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
