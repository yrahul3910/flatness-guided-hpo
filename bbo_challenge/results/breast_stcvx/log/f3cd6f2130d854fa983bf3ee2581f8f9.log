running: {'--uuid': 'f3cd6f2130d854fa983bf3ee2581f8f9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u f3cd6f2130d854fa983bf3ee2581f8f9 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.013936 iter 0 next_points [{'alpha': 0.6926604016396675, 'batch_size': 13, 'beta_1': 0.9650000864147211, 'beta_2': 0.9996698527603456, 'epsilon': 3.585154439895083e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0005653248206550856, 'tol': 0.010893001279610801, 'validation_fraction': 0.8102697287012823}]
function_evaluation time 1.017833 value -0.824176 suggestion {'alpha': 0.6926604016396675, 'batch_size': 13, 'beta_1': 0.9650000864147211, 'beta_2': 0.9996698527603456, 'epsilon': 3.585154439895083e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0005653248206550856, 'tol': 0.010893001279610801, 'validation_fraction': 0.8102697287012823}
observation time 0.000009, current best -0.824176 at iter 0
suggestion time taken 0.014218 iter 1 next_points [{'alpha': 0.001595385197395856, 'batch_size': 29, 'beta_1': 0.8019288239773813, 'beta_2': 0.9998277409841099, 'epsilon': 7.372516351816523e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0011876640293446777, 'tol': 0.001811850311261278, 'validation_fraction': 0.20431988146286736}]
function_evaluation time 1.816107 value -0.907692 suggestion {'alpha': 0.001595385197395856, 'batch_size': 29, 'beta_1': 0.8019288239773813, 'beta_2': 0.9998277409841099, 'epsilon': 7.372516351816523e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0011876640293446777, 'tol': 0.001811850311261278, 'validation_fraction': 0.20431988146286736}
observation time 0.000003, current best -0.907692 at iter 1
suggestion time taken 0.009856 iter 2 next_points [{'alpha': 0.3745971299859985, 'batch_size': 192, 'beta_1': 0.6066725369261635, 'beta_2': 0.9918970837238446, 'epsilon': 2.799985220272791e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.06014554662012312, 'tol': 0.002378029809661451, 'validation_fraction': 0.23630711479684338}]
function_evaluation time 0.732427 value -0.890110 suggestion {'alpha': 0.3745971299859985, 'batch_size': 192, 'beta_1': 0.6066725369261635, 'beta_2': 0.9918970837238446, 'epsilon': 2.799985220272791e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.06014554662012312, 'tol': 0.002378029809661451, 'validation_fraction': 0.23630711479684338}
observation time 0.000010, current best -0.907692 at iter 2
suggestion time taken 0.012170 iter 3 next_points [{'alpha': 4.928394164079336e-05, 'batch_size': 169, 'beta_1': 0.9099646022926904, 'beta_2': 0.9999988669332838, 'epsilon': 7.197107861634608e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00019567771862331128, 'tol': 0.0004073939745815013, 'validation_fraction': 0.29572184371158416}]
function_evaluation time 0.483010 value -0.641758 suggestion {'alpha': 4.928394164079336e-05, 'batch_size': 169, 'beta_1': 0.9099646022926904, 'beta_2': 0.9999988669332838, 'epsilon': 7.197107861634608e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00019567771862331128, 'tol': 0.0004073939745815013, 'validation_fraction': 0.29572184371158416}
observation time 0.000005, current best -0.907692 at iter 3
suggestion time taken 0.011275 iter 4 next_points [{'alpha': 0.02155281914080137, 'batch_size': 66, 'beta_1': 0.933526677724097, 'beta_2': 0.9999686195123606, 'epsilon': 7.470670335265837e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.009788165550358906, 'tol': 6.586605456868178e-05, 'validation_fraction': 0.8949154598415462}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.657249 value -0.879121 suggestion {'alpha': 0.02155281914080137, 'batch_size': 66, 'beta_1': 0.933526677724097, 'beta_2': 0.9999686195123606, 'epsilon': 7.470670335265837e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.009788165550358906, 'tol': 6.586605456868178e-05, 'validation_fraction': 0.8949154598415462}
observation time 0.000009, current best -0.907692 at iter 4
suggestion time taken 0.011860 iter 5 next_points [{'alpha': 1.4095154781710213, 'batch_size': 195, 'beta_1': 0.9413335309021811, 'beta_2': 0.9991975602824386, 'epsilon': 4.97369411384752e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00025547760658414315, 'tol': 0.00015098572939157377, 'validation_fraction': 0.1381050044768071}]
function_evaluation time 1.219333 value -0.885714 suggestion {'alpha': 1.4095154781710213, 'batch_size': 195, 'beta_1': 0.9413335309021811, 'beta_2': 0.9991975602824386, 'epsilon': 4.97369411384752e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.00025547760658414315, 'tol': 0.00015098572939157377, 'validation_fraction': 0.1381050044768071}
observation time 0.000003, current best -0.907692 at iter 5
suggestion time taken 0.009450 iter 6 next_points [{'alpha': 0.000794340887919999, 'batch_size': 14, 'beta_1': 0.9841519147870664, 'beta_2': 0.9935739990350406, 'epsilon': 1.544063844296043e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.004439555689841613, 'tol': 0.0007772374589344718, 'validation_fraction': 0.10197860337355015}]
function_evaluation time 1.491491 value -0.905495 suggestion {'alpha': 0.000794340887919999, 'batch_size': 14, 'beta_1': 0.9841519147870664, 'beta_2': 0.9935739990350406, 'epsilon': 1.544063844296043e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.004439555689841613, 'tol': 0.0007772374589344718, 'validation_fraction': 0.10197860337355015}
observation time 0.000007, current best -0.907692 at iter 6
suggestion time taken 0.013608 iter 7 next_points [{'alpha': 0.001642147947999668, 'batch_size': 168, 'beta_1': 0.7399157615024289, 'beta_2': 0.9978512411764859, 'epsilon': 1.4755373923631806e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.003435578523588895, 'tol': 0.00015153810654172073, 'validation_fraction': 0.30116699746484493}]
function_evaluation time 0.720583 value -0.903297 suggestion {'alpha': 0.001642147947999668, 'batch_size': 168, 'beta_1': 0.7399157615024289, 'beta_2': 0.9978512411764859, 'epsilon': 1.4755373923631806e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.003435578523588895, 'tol': 0.00015153810654172073, 'validation_fraction': 0.30116699746484493}
observation time 0.000003, current best -0.907692 at iter 7
suggestion time taken 0.010491 iter 8 next_points [{'alpha': 5.182923056799751, 'batch_size': 33, 'beta_1': 0.866737594543831, 'beta_2': 0.936094797032253, 'epsilon': 1.5492397591336368e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.003216690911957818, 'tol': 0.0004113288322162973, 'validation_fraction': 0.8969017101067586}]
function_evaluation time 0.920435 value -0.848352 suggestion {'alpha': 5.182923056799751, 'batch_size': 33, 'beta_1': 0.866737594543831, 'beta_2': 0.936094797032253, 'epsilon': 1.5492397591336368e-07, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.003216690911957818, 'tol': 0.0004113288322162973, 'validation_fraction': 0.8969017101067586}
observation time 0.000004, current best -0.907692 at iter 8
suggestion time taken 0.009187 iter 9 next_points [{'alpha': 5.000660622847375, 'batch_size': 109, 'beta_1': 0.9885038376083782, 'beta_2': 0.9839848870256762, 'epsilon': 1.4125029497368405e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.005373786380797044, 'tol': 0.05290909828689223, 'validation_fraction': 0.8638008638106163}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.473290 value -0.885714 suggestion {'alpha': 5.000660622847375, 'batch_size': 109, 'beta_1': 0.9885038376083782, 'beta_2': 0.9839848870256762, 'epsilon': 1.4125029497368405e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.005373786380797044, 'tol': 0.05290909828689223, 'validation_fraction': 0.8638008638106163}
observation time 0.000005, current best -0.907692 at iter 9
suggestion time taken 0.013723 iter 10 next_points [{'alpha': 2.026528146190175, 'batch_size': 123, 'beta_1': 0.9876693632740149, 'beta_2': 0.9999274060266778, 'epsilon': 4.3860142374661375e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 1.3716164334130472e-05, 'tol': 0.0011860512555185857, 'validation_fraction': 0.10426921649348309}]
function_evaluation time 0.514859 value -0.641758 suggestion {'alpha': 2.026528146190175, 'batch_size': 123, 'beta_1': 0.9876693632740149, 'beta_2': 0.9999274060266778, 'epsilon': 4.3860142374661375e-07, 'hidden_layer_sizes': 179, 'learning_rate_init': 1.3716164334130472e-05, 'tol': 0.0011860512555185857, 'validation_fraction': 0.10426921649348309}
observation time 0.000003, current best -0.907692 at iter 10
suggestion time taken 0.012023 iter 11 next_points [{'alpha': 0.0014583854277261093, 'batch_size': 127, 'beta_1': 0.9792968845990827, 'beta_2': 0.9982626889226027, 'epsilon': 9.766200060952648e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.00015351129981313303, 'tol': 0.03230155416009306, 'validation_fraction': 0.7778309286193776}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.270903 value -0.527473 suggestion {'alpha': 0.0014583854277261093, 'batch_size': 127, 'beta_1': 0.9792968845990827, 'beta_2': 0.9982626889226027, 'epsilon': 9.766200060952648e-08, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.00015351129981313303, 'tol': 0.03230155416009306, 'validation_fraction': 0.7778309286193776}
observation time 0.000006, current best -0.907692 at iter 11
suggestion time taken 0.011262 iter 12 next_points [{'alpha': 0.0003507608026560657, 'batch_size': 228, 'beta_1': 0.7247870458092409, 'beta_2': 0.9999955942033547, 'epsilon': 1.829942933984964e-07, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.00033998933464284595, 'tol': 0.0009042205735166707, 'validation_fraction': 0.5301322525214498}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.482533 value -0.606593 suggestion {'alpha': 0.0003507608026560657, 'batch_size': 228, 'beta_1': 0.7247870458092409, 'beta_2': 0.9999955942033547, 'epsilon': 1.829942933984964e-07, 'hidden_layer_sizes': 74, 'learning_rate_init': 0.00033998933464284595, 'tol': 0.0009042205735166707, 'validation_fraction': 0.5301322525214498}
observation time 0.000008, current best -0.907692 at iter 12
suggestion time taken 0.011283 iter 13 next_points [{'alpha': 0.3179793307674257, 'batch_size': 152, 'beta_1': 0.9370245105765999, 'beta_2': 0.9999909258780916, 'epsilon': 1.6448193144426157e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.00023502995483888514, 'tol': 0.01927011532065409, 'validation_fraction': 0.19379289951202655}]
function_evaluation time 0.212769 value -0.459341 suggestion {'alpha': 0.3179793307674257, 'batch_size': 152, 'beta_1': 0.9370245105765999, 'beta_2': 0.9999909258780916, 'epsilon': 1.6448193144426157e-08, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.00023502995483888514, 'tol': 0.01927011532065409, 'validation_fraction': 0.19379289951202655}
observation time 0.000002, current best -0.907692 at iter 13
suggestion time taken 0.003271 iter 14 next_points [{'alpha': 1.2604263297186806e-05, 'batch_size': 146, 'beta_1': 0.5675220009195947, 'beta_2': 0.9999654189349729, 'epsilon': 6.361810291963465e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.02492611739671831, 'tol': 0.0006958271358694851, 'validation_fraction': 0.11833699533563537}]
function_evaluation time 0.771538 value -0.890110 suggestion {'alpha': 1.2604263297186806e-05, 'batch_size': 146, 'beta_1': 0.5675220009195947, 'beta_2': 0.9999654189349729, 'epsilon': 6.361810291963465e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.02492611739671831, 'tol': 0.0006958271358694851, 'validation_fraction': 0.11833699533563537}
observation time 0.000007, current best -0.907692 at iter 14
suggestion time taken 0.011080 iter 15 next_points [{'alpha': 0.00012078325486137979, 'batch_size': 72, 'beta_1': 0.8201243408141649, 'beta_2': 0.9738049700467881, 'epsilon': 3.430863822821217e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 4.838085105967484e-05, 'tol': 1.4189275962591299e-05, 'validation_fraction': 0.6399295050997095}]
function_evaluation time 0.308085 value -0.578022 suggestion {'alpha': 0.00012078325486137979, 'batch_size': 72, 'beta_1': 0.8201243408141649, 'beta_2': 0.9738049700467881, 'epsilon': 3.430863822821217e-09, 'hidden_layer_sizes': 100, 'learning_rate_init': 4.838085105967484e-05, 'tol': 1.4189275962591299e-05, 'validation_fraction': 0.6399295050997095}
observation time 0.000003, current best -0.907692 at iter 15
suggestion time taken 0.009013 iter 16 next_points [{'alpha': 1.0128908239683333e-05, 'batch_size': 119, 'beta_1': 0.7362891132701559, 'beta_2': 0.9999945208383246, 'epsilon': 4.956582860399477e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.015676094944133735, 'tol': 0.010300156524396455, 'validation_fraction': 0.33564280508357386}]
function_evaluation time 0.622798 value -0.892308 suggestion {'alpha': 1.0128908239683333e-05, 'batch_size': 119, 'beta_1': 0.7362891132701559, 'beta_2': 0.9999945208383246, 'epsilon': 4.956582860399477e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.015676094944133735, 'tol': 0.010300156524396455, 'validation_fraction': 0.33564280508357386}
observation time 0.000004, current best -0.907692 at iter 16
suggestion time taken 0.011282 iter 17 next_points [{'alpha': 8.535616463067787e-05, 'batch_size': 183, 'beta_1': 0.962690362811838, 'beta_2': 0.9118770744944898, 'epsilon': 2.923101830117903e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0020090104254333854, 'tol': 0.012253822378310339, 'validation_fraction': 0.5922234841657903}]
function_evaluation time 0.398543 value -0.762637 suggestion {'alpha': 8.535616463067787e-05, 'batch_size': 183, 'beta_1': 0.962690362811838, 'beta_2': 0.9118770744944898, 'epsilon': 2.923101830117903e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0020090104254333854, 'tol': 0.012253822378310339, 'validation_fraction': 0.5922234841657903}
observation time 0.000003, current best -0.907692 at iter 17
suggestion time taken 0.009239 iter 18 next_points [{'alpha': 0.006254119045669632, 'batch_size': 54, 'beta_1': 0.9791299496906996, 'beta_2': 0.9994804015316601, 'epsilon': 2.2092151774984337e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0007084545934080426, 'tol': 0.011280626773371256, 'validation_fraction': 0.12045964269380025}]
function_evaluation time 0.681068 value -0.896703 suggestion {'alpha': 0.006254119045669632, 'batch_size': 54, 'beta_1': 0.9791299496906996, 'beta_2': 0.9994804015316601, 'epsilon': 2.2092151774984337e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0007084545934080426, 'tol': 0.011280626773371256, 'validation_fraction': 0.12045964269380025}
observation time 0.000009, current best -0.907692 at iter 18
suggestion time taken 0.010855 iter 19 next_points [{'alpha': 0.0001515511685922664, 'batch_size': 107, 'beta_1': 0.9440210957539195, 'beta_2': 0.9999950882565254, 'epsilon': 2.7725257508518213e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 5.8019100067255915e-05, 'tol': 0.004201386958321583, 'validation_fraction': 0.15117774802850606}]
function_evaluation time 0.684520 value -0.624176 suggestion {'alpha': 0.0001515511685922664, 'batch_size': 107, 'beta_1': 0.9440210957539195, 'beta_2': 0.9999950882565254, 'epsilon': 2.7725257508518213e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 5.8019100067255915e-05, 'tol': 0.004201386958321583, 'validation_fraction': 0.15117774802850606}
observation time 0.000010, current best -0.907692 at iter 19
suggestion time taken 0.014145 iter 20 next_points [{'alpha': 0.008800551731963674, 'batch_size': 178, 'beta_1': 0.9867929954640765, 'beta_2': 0.999871791750134, 'epsilon': 1.5734615076647932e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.002231424740922264, 'tol': 4.5382183055146074e-05, 'validation_fraction': 0.4826154262858186}]
function_evaluation time 0.685261 value -0.850549 suggestion {'alpha': 0.008800551731963674, 'batch_size': 178, 'beta_1': 0.9867929954640765, 'beta_2': 0.999871791750134, 'epsilon': 1.5734615076647932e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.002231424740922264, 'tol': 4.5382183055146074e-05, 'validation_fraction': 0.4826154262858186}
observation time 0.000004, current best -0.907692 at iter 20
suggestion time taken 0.012149 iter 21 next_points [{'alpha': 9.701366382839886, 'batch_size': 84, 'beta_1': 0.941384017189549, 'beta_2': 0.9916510739347852, 'epsilon': 1.6633000836040608e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 1.2384870980142666e-05, 'tol': 0.07485899855542545, 'validation_fraction': 0.17439054616696298}]
function_evaluation time 0.632931 value -0.472527 suggestion {'alpha': 9.701366382839886, 'batch_size': 84, 'beta_1': 0.941384017189549, 'beta_2': 0.9916510739347852, 'epsilon': 1.6633000836040608e-08, 'hidden_layer_sizes': 152, 'learning_rate_init': 1.2384870980142666e-05, 'tol': 0.07485899855542545, 'validation_fraction': 0.17439054616696298}
observation time 0.000005, current best -0.907692 at iter 21
suggestion time taken 0.010707 iter 22 next_points [{'alpha': 0.01320481366248481, 'batch_size': 180, 'beta_1': 0.7227604115960655, 'beta_2': 0.9999976933965498, 'epsilon': 2.9271153454316796e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.0003008058177288728, 'tol': 0.007814773385157915, 'validation_fraction': 0.7949905333610306}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.351072 value -0.637363 suggestion {'alpha': 0.01320481366248481, 'batch_size': 180, 'beta_1': 0.7227604115960655, 'beta_2': 0.9999976933965498, 'epsilon': 2.9271153454316796e-07, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.0003008058177288728, 'tol': 0.007814773385157915, 'validation_fraction': 0.7949905333610306}
observation time 0.000003, current best -0.907692 at iter 22
suggestion time taken 0.010032 iter 23 next_points [{'alpha': 0.2122580252636732, 'batch_size': 244, 'beta_1': 0.7355775504392772, 'beta_2': 0.9291531083072636, 'epsilon': 8.906058970530369e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.06458730043313105, 'tol': 0.008858236806842949, 'validation_fraction': 0.5862207602070437}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.613903 value -0.839560 suggestion {'alpha': 0.2122580252636732, 'batch_size': 244, 'beta_1': 0.7355775504392772, 'beta_2': 0.9291531083072636, 'epsilon': 8.906058970530369e-08, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.06458730043313105, 'tol': 0.008858236806842949, 'validation_fraction': 0.5862207602070437}
observation time 0.000004, current best -0.907692 at iter 23
suggestion time taken 0.010436 iter 24 next_points [{'alpha': 0.06775471143940125, 'batch_size': 140, 'beta_1': 0.7496558849828502, 'beta_2': 0.9999899234654427, 'epsilon': 3.94142791285367e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.00321855795015508, 'tol': 0.00012054643414326715, 'validation_fraction': 0.14086249987126348}]
function_evaluation time 0.646738 value -0.890110 suggestion {'alpha': 0.06775471143940125, 'batch_size': 140, 'beta_1': 0.7496558849828502, 'beta_2': 0.9999899234654427, 'epsilon': 3.94142791285367e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.00321855795015508, 'tol': 0.00012054643414326715, 'validation_fraction': 0.14086249987126348}
observation time 0.000009, current best -0.907692 at iter 24
suggestion time taken 0.010843 iter 25 next_points [{'alpha': 0.0005849957156728861, 'batch_size': 145, 'beta_1': 0.6275275065543985, 'beta_2': 0.9995429994081814, 'epsilon': 5.64871553560151e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.001941629175980211, 'tol': 0.012707095321691604, 'validation_fraction': 0.337267079126386}]
function_evaluation time 0.716227 value -0.905495 suggestion {'alpha': 0.0005849957156728861, 'batch_size': 145, 'beta_1': 0.6275275065543985, 'beta_2': 0.9995429994081814, 'epsilon': 5.64871553560151e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.001941629175980211, 'tol': 0.012707095321691604, 'validation_fraction': 0.337267079126386}
observation time 0.000004, current best -0.907692 at iter 25
suggestion time taken 0.010379 iter 26 next_points [{'alpha': 0.0156552179470712, 'batch_size': 126, 'beta_1': 0.9771459952622815, 'beta_2': 0.9999985566668508, 'epsilon': 2.9502026895406056e-09, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.03431499632115175, 'tol': 1.0411886068573275e-05, 'validation_fraction': 0.666640122668183}]
function_evaluation time 0.658185 value -0.892308 suggestion {'alpha': 0.0156552179470712, 'batch_size': 126, 'beta_1': 0.9771459952622815, 'beta_2': 0.9999985566668508, 'epsilon': 2.9502026895406056e-09, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.03431499632115175, 'tol': 1.0411886068573275e-05, 'validation_fraction': 0.666640122668183}
observation time 0.000008, current best -0.907692 at iter 26
suggestion time taken 0.013723 iter 27 next_points [{'alpha': 0.07749132087654317, 'batch_size': 179, 'beta_1': 0.9821689225111612, 'beta_2': 0.9864207830537441, 'epsilon': 2.248646639589406e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.000220504411180595, 'tol': 0.0002145775907432191, 'validation_fraction': 0.698347060974916}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.416326 value -0.646154 suggestion {'alpha': 0.07749132087654317, 'batch_size': 179, 'beta_1': 0.9821689225111612, 'beta_2': 0.9864207830537441, 'epsilon': 2.248646639589406e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.000220504411180595, 'tol': 0.0002145775907432191, 'validation_fraction': 0.698347060974916}
observation time 0.000003, current best -0.907692 at iter 27
suggestion time taken 0.009718 iter 28 next_points [{'alpha': 0.0007337902840497866, 'batch_size': 209, 'beta_1': 0.6192109966137055, 'beta_2': 0.999997074060335, 'epsilon': 4.2256678516783684e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.014442242345148602, 'tol': 1.4308949151400875e-05, 'validation_fraction': 0.3986168217457471}]
function_evaluation time 0.687057 value -0.903297 suggestion {'alpha': 0.0007337902840497866, 'batch_size': 209, 'beta_1': 0.6192109966137055, 'beta_2': 0.999997074060335, 'epsilon': 4.2256678516783684e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.014442242345148602, 'tol': 1.4308949151400875e-05, 'validation_fraction': 0.3986168217457471}
observation time 0.000006, current best -0.907692 at iter 28
suggestion time taken 0.010982 iter 29 next_points [{'alpha': 0.0012204739907209687, 'batch_size': 235, 'beta_1': 0.9527670540202033, 'beta_2': 0.9971113199066444, 'epsilon': 9.41243726474624e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.356078799535508e-05, 'tol': 0.030959301821711777, 'validation_fraction': 0.4948821137298596}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.239530 value -0.529670 suggestion {'alpha': 0.0012204739907209687, 'batch_size': 235, 'beta_1': 0.9527670540202033, 'beta_2': 0.9971113199066444, 'epsilon': 9.41243726474624e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.356078799535508e-05, 'tol': 0.030959301821711777, 'validation_fraction': 0.4948821137298596}
observation time 0.000009, current best -0.907692 at iter 29
suggestion time taken 0.011727 iter 30 next_points [{'alpha': 6.675308090699546e-05, 'batch_size': 221, 'beta_1': 0.5137584291925287, 'beta_2': 0.9993499743185773, 'epsilon': 3.624174738742086e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0013948661077572417, 'tol': 0.003601452786947921, 'validation_fraction': 0.10196120511701832}]
function_evaluation time 0.599385 value -0.887912 suggestion {'alpha': 6.675308090699546e-05, 'batch_size': 221, 'beta_1': 0.5137584291925287, 'beta_2': 0.9993499743185773, 'epsilon': 3.624174738742086e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0013948661077572417, 'tol': 0.003601452786947921, 'validation_fraction': 0.10196120511701832}
observation time 0.000005, current best -0.907692 at iter 30
suggestion time taken 0.011128 iter 31 next_points [{'alpha': 7.455222645881776e-05, 'batch_size': 207, 'beta_1': 0.5595184259841914, 'beta_2': 0.9991425332621279, 'epsilon': 2.02926440700453e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.001024474130679066, 'tol': 1.0453983984326861e-05, 'validation_fraction': 0.15368017811625595}]
function_evaluation time 0.780934 value -0.903297 suggestion {'alpha': 7.455222645881776e-05, 'batch_size': 207, 'beta_1': 0.5595184259841914, 'beta_2': 0.9991425332621279, 'epsilon': 2.02926440700453e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.001024474130679066, 'tol': 1.0453983984326861e-05, 'validation_fraction': 0.15368017811625595}
observation time 0.000003, current best -0.907692 at iter 31
suggestion time taken 0.009715 iter 32 next_points [{'alpha': 0.005145119846439367, 'batch_size': 207, 'beta_1': 0.6524494104912595, 'beta_2': 0.9999113280644972, 'epsilon': 4.622470501357525e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.049923940576838105, 'tol': 0.004428397476046986, 'validation_fraction': 0.19054749008319488}]
function_evaluation time 0.640025 value -0.898901 suggestion {'alpha': 0.005145119846439367, 'batch_size': 207, 'beta_1': 0.6524494104912595, 'beta_2': 0.9999113280644972, 'epsilon': 4.622470501357525e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.049923940576838105, 'tol': 0.004428397476046986, 'validation_fraction': 0.19054749008319488}
observation time 0.000007, current best -0.907692 at iter 32
suggestion time taken 0.010695 iter 33 next_points [{'alpha': 0.7241765241415449, 'batch_size': 212, 'beta_1': 0.5411142526287952, 'beta_2': 0.9999536885459295, 'epsilon': 7.519595929480483e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0027481379815810446, 'tol': 0.0007897510824886884, 'validation_fraction': 0.7722572900884089}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.504695 value -0.907692 suggestion {'alpha': 0.7241765241415449, 'batch_size': 212, 'beta_1': 0.5411142526287952, 'beta_2': 0.9999536885459295, 'epsilon': 7.519595929480483e-07, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0027481379815810446, 'tol': 0.0007897510824886884, 'validation_fraction': 0.7722572900884089}
observation time 0.000003, current best -0.907692 at iter 33
suggestion time taken 0.009990 iter 34 next_points [{'alpha': 0.03427383270312889, 'batch_size': 128, 'beta_1': 0.7422549715396538, 'beta_2': 0.99888845859978, 'epsilon': 2.388238888808461e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0020767770095835134, 'tol': 0.004205950277226164, 'validation_fraction': 0.27213022466642284}]
function_evaluation time 0.979009 value -0.901099 suggestion {'alpha': 0.03427383270312889, 'batch_size': 128, 'beta_1': 0.7422549715396538, 'beta_2': 0.99888845859978, 'epsilon': 2.388238888808461e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0020767770095835134, 'tol': 0.004205950277226164, 'validation_fraction': 0.27213022466642284}
observation time 0.000004, current best -0.907692 at iter 34
suggestion time taken 0.010322 iter 35 next_points [{'alpha': 2.7576324123039197e-05, 'batch_size': 153, 'beta_1': 0.96352734629885, 'beta_2': 0.9999989719206848, 'epsilon': 2.039296534647263e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.0005100268193446523, 'tol': 0.013900071063119258, 'validation_fraction': 0.7807852401705035}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.399756 value -0.679121 suggestion {'alpha': 2.7576324123039197e-05, 'batch_size': 153, 'beta_1': 0.96352734629885, 'beta_2': 0.9999989719206848, 'epsilon': 2.039296534647263e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.0005100268193446523, 'tol': 0.013900071063119258, 'validation_fraction': 0.7807852401705035}
observation time 0.000008, current best -0.907692 at iter 35
suggestion time taken 0.010899 iter 36 next_points [{'alpha': 0.0001527467454205467, 'batch_size': 62, 'beta_1': 0.7590612827596046, 'beta_2': 0.9978033581312015, 'epsilon': 1.4342276753713426e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 1.0958841581850333e-05, 'tol': 6.10312413957709e-05, 'validation_fraction': 0.652381128474311}]
function_evaluation time 0.479769 value -0.272527 suggestion {'alpha': 0.0001527467454205467, 'batch_size': 62, 'beta_1': 0.7590612827596046, 'beta_2': 0.9978033581312015, 'epsilon': 1.4342276753713426e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 1.0958841581850333e-05, 'tol': 6.10312413957709e-05, 'validation_fraction': 0.652381128474311}
observation time 0.000004, current best -0.907692 at iter 36
suggestion time taken 0.010732 iter 37 next_points [{'alpha': 2.7423423532492626, 'batch_size': 235, 'beta_1': 0.8965141816415818, 'beta_2': 0.9999966813351872, 'epsilon': 1.0522803334967341e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0008726233757495698, 'tol': 8.883190660737861e-05, 'validation_fraction': 0.7058723473140461}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.437954 value -0.742857 suggestion {'alpha': 2.7423423532492626, 'batch_size': 235, 'beta_1': 0.8965141816415818, 'beta_2': 0.9999966813351872, 'epsilon': 1.0522803334967341e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0008726233757495698, 'tol': 8.883190660737861e-05, 'validation_fraction': 0.7058723473140461}
observation time 0.000003, current best -0.907692 at iter 37
suggestion time taken 0.009534 iter 38 next_points [{'alpha': 0.000438644908071728, 'batch_size': 125, 'beta_1': 0.988406789810994, 'beta_2': 0.9999796262242805, 'epsilon': 4.79432525623265e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 4.802424405237575e-05, 'tol': 0.0052225913317555635, 'validation_fraction': 0.24230944844352684}]
function_evaluation time 0.968132 value -0.470330 suggestion {'alpha': 0.000438644908071728, 'batch_size': 125, 'beta_1': 0.988406789810994, 'beta_2': 0.9999796262242805, 'epsilon': 4.79432525623265e-07, 'hidden_layer_sizes': 86, 'learning_rate_init': 4.802424405237575e-05, 'tol': 0.0052225913317555635, 'validation_fraction': 0.24230944844352684}
observation time 0.000003, current best -0.907692 at iter 38
suggestion time taken 0.010311 iter 39 next_points [{'alpha': 0.07545782894738425, 'batch_size': 15, 'beta_1': 0.844185202661261, 'beta_2': 0.9987473888933701, 'epsilon': 2.237626057609532e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.002913524150908262, 'tol': 0.005997481529830997, 'validation_fraction': 0.2814759281357195}]
function_evaluation time 2.535643 value -0.901099 suggestion {'alpha': 0.07545782894738425, 'batch_size': 15, 'beta_1': 0.844185202661261, 'beta_2': 0.9987473888933701, 'epsilon': 2.237626057609532e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.002913524150908262, 'tol': 0.005997481529830997, 'validation_fraction': 0.2814759281357195}
observation time 0.000003, current best -0.907692 at iter 39
suggestion time taken 0.010753 iter 40 next_points [{'alpha': 1.754196869452215e-05, 'batch_size': 78, 'beta_1': 0.9778340711333924, 'beta_2': 0.9993997889439452, 'epsilon': 9.949426841332199e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.0001610081147719785, 'tol': 0.02866338991341431, 'validation_fraction': 0.13088860632423238}]
function_evaluation time 0.997589 value -0.804396 suggestion {'alpha': 1.754196869452215e-05, 'batch_size': 78, 'beta_1': 0.9778340711333924, 'beta_2': 0.9993997889439452, 'epsilon': 9.949426841332199e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.0001610081147719785, 'tol': 0.02866338991341431, 'validation_fraction': 0.13088860632423238}
observation time 0.000007, current best -0.907692 at iter 40
suggestion time taken 0.011079 iter 41 next_points [{'alpha': 0.7510379356618797, 'batch_size': 149, 'beta_1': 0.8455769060218631, 'beta_2': 0.999457657644049, 'epsilon': 1.90420750802135e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.006962802423343433, 'tol': 0.026722900460539233, 'validation_fraction': 0.4655549487004681}]
function_evaluation time 0.507381 value -0.907692 suggestion {'alpha': 0.7510379356618797, 'batch_size': 149, 'beta_1': 0.8455769060218631, 'beta_2': 0.999457657644049, 'epsilon': 1.90420750802135e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.006962802423343433, 'tol': 0.026722900460539233, 'validation_fraction': 0.4655549487004681}
observation time 0.000004, current best -0.907692 at iter 41
suggestion time taken 0.010512 iter 42 next_points [{'alpha': 6.309119954385385e-05, 'batch_size': 232, 'beta_1': 0.7210548584420133, 'beta_2': 0.99997950044619, 'epsilon': 1.041767535555904e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 1.8971081982059913e-05, 'tol': 0.039227897519588786, 'validation_fraction': 0.1708240998873627}]
function_evaluation time 0.377503 value -0.472527 suggestion {'alpha': 6.309119954385385e-05, 'batch_size': 232, 'beta_1': 0.7210548584420133, 'beta_2': 0.99997950044619, 'epsilon': 1.041767535555904e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 1.8971081982059913e-05, 'tol': 0.039227897519588786, 'validation_fraction': 0.1708240998873627}
observation time 0.000003, current best -0.907692 at iter 42
suggestion time taken 0.009781 iter 43 next_points [{'alpha': 0.8371569633767132, 'batch_size': 142, 'beta_1': 0.9777824837688192, 'beta_2': 0.9665399092364491, 'epsilon': 1.4021635381244309e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.0009687335173236964, 'tol': 0.012948888993813336, 'validation_fraction': 0.6488476141585001}]
function_evaluation time 0.452950 value -0.782418 suggestion {'alpha': 0.8371569633767132, 'batch_size': 142, 'beta_1': 0.9777824837688192, 'beta_2': 0.9665399092364491, 'epsilon': 1.4021635381244309e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.0009687335173236964, 'tol': 0.012948888993813336, 'validation_fraction': 0.6488476141585001}
observation time 0.000009, current best -0.907692 at iter 43
suggestion time taken 0.012365 iter 44 next_points [{'alpha': 0.0006343669033193111, 'batch_size': 44, 'beta_1': 0.7534662893990384, 'beta_2': 0.9999986617669726, 'epsilon': 3.1887474048320375e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.010217158717089243, 'tol': 1.061130621829093e-05, 'validation_fraction': 0.4976219186385572}]
function_evaluation time 1.186176 value -0.905495 suggestion {'alpha': 0.0006343669033193111, 'batch_size': 44, 'beta_1': 0.7534662893990384, 'beta_2': 0.9999986617669726, 'epsilon': 3.1887474048320375e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.010217158717089243, 'tol': 1.061130621829093e-05, 'validation_fraction': 0.4976219186385572}
observation time 0.000010, current best -0.907692 at iter 44
saving meta data: {'args': {'--uuid': 'f3cd6f2130d854fa983bf3ee2581f8f9', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
