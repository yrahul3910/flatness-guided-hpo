running: {'--uuid': 'c90f7a2c2d125e8f8f09ffdb09d76cb5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d breast -o strongcvx -u c90f7a2c2d125e8f8f09ffdb09d76cb5 -m nll -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam breast nll 45 1
with data root: None
suggestion time taken 19.683122 iter 0 next_points [{'alpha': 2.616175132621998, 'batch_size': 227, 'beta_1': 0.5951949135065454, 'beta_2': 0.9970559115297504, 'epsilon': 4.7117492974666123e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 5.719383178210793e-05, 'tol': 3.4456757914916466e-05, 'validation_fraction': 0.8964516553280513}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.797023 value 9.605242 suggestion {'alpha': 2.616175132621998, 'batch_size': 227, 'beta_1': 0.5951949135065454, 'beta_2': 0.9970559115297504, 'epsilon': 4.7117492974666123e-07, 'hidden_layer_sizes': 192, 'learning_rate_init': 5.719383178210793e-05, 'tol': 3.4456757914916466e-05, 'validation_fraction': 0.8964516553280513}
observation time 0.000005, current best 9.605242 at iter 0
suggestion time taken 19.489639 iter 1 next_points [{'alpha': 0.001357258053730096, 'batch_size': 151, 'beta_1': 0.8309954279222288, 'beta_2': 0.9999930239062247, 'epsilon': 1.1831690282410617e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.0032337719051508847, 'tol': 0.013734709175155752, 'validation_fraction': 0.43038053958515654}]
function_evaluation time 0.780981 value 0.448321 suggestion {'alpha': 0.001357258053730096, 'batch_size': 151, 'beta_1': 0.8309954279222288, 'beta_2': 0.9999930239062247, 'epsilon': 1.1831690282410617e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.0032337719051508847, 'tol': 0.013734709175155752, 'validation_fraction': 0.43038053958515654}
observation time 0.000008, current best 0.448321 at iter 1
suggestion time taken 17.111636 iter 2 next_points [{'alpha': 0.00016760182565891585, 'batch_size': 25, 'beta_1': 0.9687912495848728, 'beta_2': 0.9999968898949375, 'epsilon': 2.2898576889029133e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0015913137586007302, 'tol': 1.3857481680131362e-05, 'validation_fraction': 0.7421998425113068}]
function_evaluation time 1.052450 value 0.663903 suggestion {'alpha': 0.00016760182565891585, 'batch_size': 25, 'beta_1': 0.9687912495848728, 'beta_2': 0.9999968898949375, 'epsilon': 2.2898576889029133e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0015913137586007302, 'tol': 1.3857481680131362e-05, 'validation_fraction': 0.7421998425113068}
observation time 0.000005, current best 0.448321 at iter 2
suggestion time taken 15.147657 iter 3 next_points [{'alpha': 0.0003751169695071829, 'batch_size': 30, 'beta_1': 0.5615182443028518, 'beta_2': 0.9994463326018319, 'epsilon': 5.38431958530803e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 4.3014540232952704e-05, 'tol': 2.1987244165489844e-05, 'validation_fraction': 0.12977942679584675}]
function_evaluation time 1.210520 value 9.601929 suggestion {'alpha': 0.0003751169695071829, 'batch_size': 30, 'beta_1': 0.5615182443028518, 'beta_2': 0.9994463326018319, 'epsilon': 5.38431958530803e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 4.3014540232952704e-05, 'tol': 2.1987244165489844e-05, 'validation_fraction': 0.12977942679584675}
observation time 0.000005, current best 0.448321 at iter 3
suggestion time taken 14.484375 iter 4 next_points [{'alpha': 0.22045051047341124, 'batch_size': 25, 'beta_1': 0.9894189066769434, 'beta_2': 0.9998944066833308, 'epsilon': 3.0576657507542165e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 1.1756579575466159e-05, 'tol': 0.0006469177114817673, 'validation_fraction': 0.43293226345386254}]
function_evaluation time 1.016603 value 7.408671 suggestion {'alpha': 0.22045051047341124, 'batch_size': 25, 'beta_1': 0.9894189066769434, 'beta_2': 0.9998944066833308, 'epsilon': 3.0576657507542165e-07, 'hidden_layer_sizes': 85, 'learning_rate_init': 1.1756579575466159e-05, 'tol': 0.0006469177114817673, 'validation_fraction': 0.43293226345386254}
observation time 0.000005, current best 0.448321 at iter 4
suggestion time taken 15.395911 iter 5 next_points [{'alpha': 0.0002350696986104152, 'batch_size': 150, 'beta_1': 0.9696613836761527, 'beta_2': 0.9938154174255429, 'epsilon': 1.3364151049264534e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.007995895798300751, 'tol': 0.0004985795691630744, 'validation_fraction': 0.7968484073177428}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.505408 value 1.021750 suggestion {'alpha': 0.0002350696986104152, 'batch_size': 150, 'beta_1': 0.9696613836761527, 'beta_2': 0.9938154174255429, 'epsilon': 1.3364151049264534e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.007995895798300751, 'tol': 0.0004985795691630744, 'validation_fraction': 0.7968484073177428}
observation time 0.000005, current best 0.448321 at iter 5
suggestion time taken 15.578083 iter 6 next_points [{'alpha': 0.0011468916268019644, 'batch_size': 151, 'beta_1': 0.5113297211586023, 'beta_2': 0.9999396000531132, 'epsilon': 3.593106108919009e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.008871834765146126, 'tol': 0.00031677215547720744, 'validation_fraction': 0.7056919625294872}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.426024 value 0.818560 suggestion {'alpha': 0.0011468916268019644, 'batch_size': 151, 'beta_1': 0.5113297211586023, 'beta_2': 0.9999396000531132, 'epsilon': 3.593106108919009e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.008871834765146126, 'tol': 0.00031677215547720744, 'validation_fraction': 0.7056919625294872}
observation time 0.000004, current best 0.448321 at iter 6
suggestion time taken 15.237154 iter 7 next_points [{'alpha': 7.063516656325293, 'batch_size': 12, 'beta_1': 0.987137056499198, 'beta_2': 0.9298564105012196, 'epsilon': 8.261219100782982e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0011011778760637973, 'tol': 9.003113190334631e-05, 'validation_fraction': 0.4756592131939935}]
function_evaluation time 2.436515 value 0.829609 suggestion {'alpha': 7.063516656325293, 'batch_size': 12, 'beta_1': 0.987137056499198, 'beta_2': 0.9298564105012196, 'epsilon': 8.261219100782982e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0011011778760637973, 'tol': 9.003113190334631e-05, 'validation_fraction': 0.4756592131939935}
observation time 0.000005, current best 0.448321 at iter 7
suggestion time taken 19.721876 iter 8 next_points [{'alpha': 0.01872586031648307, 'batch_size': 227, 'beta_1': 0.5318086670906761, 'beta_2': 0.999380398301344, 'epsilon': 7.66819559499141e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 5.825793753906095e-05, 'tol': 0.06583363937818144, 'validation_fraction': 0.7646212245422562}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.271159 value 16.394801 suggestion {'alpha': 0.01872586031648307, 'batch_size': 227, 'beta_1': 0.5318086670906761, 'beta_2': 0.999380398301344, 'epsilon': 7.66819559499141e-09, 'hidden_layer_sizes': 119, 'learning_rate_init': 5.825793753906095e-05, 'tol': 0.06583363937818144, 'validation_fraction': 0.7646212245422562}
observation time 0.000005, current best 0.448321 at iter 8
suggestion time taken 19.125939 iter 9 next_points [{'alpha': 0.058627993558957044, 'batch_size': 113, 'beta_1': 0.9473141442574095, 'beta_2': 0.9999854996435995, 'epsilon': 8.698740915138673e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 4.1680552988450835e-05, 'tol': 1.1598458112196704e-05, 'validation_fraction': 0.851232801777013}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.281311 value 13.394076 suggestion {'alpha': 0.058627993558957044, 'batch_size': 113, 'beta_1': 0.9473141442574095, 'beta_2': 0.9999854996435995, 'epsilon': 8.698740915138673e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 4.1680552988450835e-05, 'tol': 1.1598458112196704e-05, 'validation_fraction': 0.851232801777013}
observation time 0.000005, current best 0.448321 at iter 9
suggestion time taken 20.571805 iter 10 next_points [{'alpha': 3.41692581436938, 'batch_size': 151, 'beta_1': 0.853775926942745, 'beta_2': 0.9997608422916809, 'epsilon': 7.191079575749375e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 4.924573061486111e-05, 'tol': 0.013254234475400096, 'validation_fraction': 0.6677660369637278}]
function_evaluation time 0.308050 value 16.250397 suggestion {'alpha': 3.41692581436938, 'batch_size': 151, 'beta_1': 0.853775926942745, 'beta_2': 0.9997608422916809, 'epsilon': 7.191079575749375e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 4.924573061486111e-05, 'tol': 0.013254234475400096, 'validation_fraction': 0.6677660369637278}
observation time 0.000013, current best 0.448321 at iter 10
suggestion time taken 19.219133 iter 11 next_points [{'alpha': 0.011025155944088294, 'batch_size': 227, 'beta_1': 0.5428639365806031, 'beta_2': 0.9341458545933166, 'epsilon': 1.985840497170963e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 1.4206994654577907e-05, 'tol': 0.0009158331536772378, 'validation_fraction': 0.11183115045716548}]
function_evaluation time 0.405231 value 10.999674 suggestion {'alpha': 0.011025155944088294, 'batch_size': 227, 'beta_1': 0.5428639365806031, 'beta_2': 0.9341458545933166, 'epsilon': 1.985840497170963e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 1.4206994654577907e-05, 'tol': 0.0009158331536772378, 'validation_fraction': 0.11183115045716548}
observation time 0.000007, current best 0.448321 at iter 11
suggestion time taken 20.979093 iter 12 next_points [{'alpha': 5.141677455252363e-05, 'batch_size': 15, 'beta_1': 0.9111718820898647, 'beta_2': 0.950234012408876, 'epsilon': 2.1114831848772868e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.012263428343438144, 'tol': 0.002421916173786058, 'validation_fraction': 0.2827573669123101}]
function_evaluation time 1.951113 value 0.883315 suggestion {'alpha': 5.141677455252363e-05, 'batch_size': 15, 'beta_1': 0.9111718820898647, 'beta_2': 0.950234012408876, 'epsilon': 2.1114831848772868e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.012263428343438144, 'tol': 0.002421916173786058, 'validation_fraction': 0.2827573669123101}
observation time 0.000008, current best 0.448321 at iter 12
suggestion time taken 19.194731 iter 13 next_points [{'alpha': 0.012671293285908974, 'batch_size': 151, 'beta_1': 0.9851132606175527, 'beta_2': 0.9947309430789426, 'epsilon': 9.569513120042935e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.00411607035692565, 'tol': 0.0678891282056858, 'validation_fraction': 0.19725531594058815}]
function_evaluation time 0.540045 value 0.878172 suggestion {'alpha': 0.012671293285908974, 'batch_size': 151, 'beta_1': 0.9851132606175527, 'beta_2': 0.9947309430789426, 'epsilon': 9.569513120042935e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.00411607035692565, 'tol': 0.0678891282056858, 'validation_fraction': 0.19725531594058815}
observation time 0.000010, current best 0.448321 at iter 13
suggestion time taken 21.382805 iter 14 next_points [{'alpha': 1.2394969968199914, 'batch_size': 15, 'beta_1': 0.9264182740528183, 'beta_2': 0.9998582875253775, 'epsilon': 1.0829597533614928e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.03839521562808695, 'tol': 0.0019763683387474793, 'validation_fraction': 0.4417266063815354}]
function_evaluation time 2.685008 value 0.260207 suggestion {'alpha': 1.2394969968199914, 'batch_size': 15, 'beta_1': 0.9264182740528183, 'beta_2': 0.9998582875253775, 'epsilon': 1.0829597533614928e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.03839521562808695, 'tol': 0.0019763683387474793, 'validation_fraction': 0.4417266063815354}
observation time 0.000005, current best 0.260207 at iter 14
suggestion time taken 20.236012 iter 15 next_points [{'alpha': 0.001016967720896574, 'batch_size': 150, 'beta_1': 0.8783453882153059, 'beta_2': 0.9991040325960244, 'epsilon': 1.0236061008527268e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.004168728479976181, 'tol': 0.004279624084629962, 'validation_fraction': 0.2500696762844136}]
function_evaluation time 0.804129 value 0.527428 suggestion {'alpha': 0.001016967720896574, 'batch_size': 150, 'beta_1': 0.8783453882153059, 'beta_2': 0.9991040325960244, 'epsilon': 1.0236061008527268e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.004168728479976181, 'tol': 0.004279624084629962, 'validation_fraction': 0.2500696762844136}
observation time 0.000012, current best 0.260207 at iter 15
suggestion time taken 19.790190 iter 16 next_points [{'alpha': 0.005241752633232079, 'batch_size': 90, 'beta_1': 0.8106132707766197, 'beta_2': 0.9999605180681274, 'epsilon': 9.639704695727079e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.04981888369635789, 'tol': 0.06983404780071403, 'validation_fraction': 0.25507785814024775}]
function_evaluation time 0.299760 value 0.382497 suggestion {'alpha': 0.005241752633232079, 'batch_size': 90, 'beta_1': 0.8106132707766197, 'beta_2': 0.9999605180681274, 'epsilon': 9.639704695727079e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.04981888369635789, 'tol': 0.06983404780071403, 'validation_fraction': 0.25507785814024775}
observation time 0.000006, current best 0.260207 at iter 16
suggestion time taken 20.726586 iter 17 next_points [{'alpha': 1.0658121401351741, 'batch_size': 151, 'beta_1': 0.976877408794918, 'beta_2': 0.9994440789270062, 'epsilon': 4.321898606744641e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.0005437509531141292, 'tol': 0.00025747661649215184, 'validation_fraction': 0.8978734998218214}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.688894 value 0.377781 suggestion {'alpha': 1.0658121401351741, 'batch_size': 151, 'beta_1': 0.976877408794918, 'beta_2': 0.9994440789270062, 'epsilon': 4.321898606744641e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.0005437509531141292, 'tol': 0.00025747661649215184, 'validation_fraction': 0.8978734998218214}
observation time 0.000008, current best 0.260207 at iter 17
suggestion time taken 19.507326 iter 18 next_points [{'alpha': 3.978161908511222e-05, 'batch_size': 41, 'beta_1': 0.8609936587013676, 'beta_2': 0.9801681955067272, 'epsilon': 1.4945439061823926e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.01644182669038601, 'tol': 2.5003452296870673e-05, 'validation_fraction': 0.4664457212482614}]
function_evaluation time 1.494772 value 0.792890 suggestion {'alpha': 3.978161908511222e-05, 'batch_size': 41, 'beta_1': 0.8609936587013676, 'beta_2': 0.9801681955067272, 'epsilon': 1.4945439061823926e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.01644182669038601, 'tol': 2.5003452296870673e-05, 'validation_fraction': 0.4664457212482614}
observation time 0.000005, current best 0.260207 at iter 18
suggestion time taken 20.944559 iter 19 next_points [{'alpha': 6.24716796011183e-05, 'batch_size': 41, 'beta_1': 0.6147920274614302, 'beta_2': 0.9999956836230944, 'epsilon': 1.204144308852701e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.001864366350509501, 'tol': 0.00021119863886314292, 'validation_fraction': 0.8171963479175691}]
function_evaluation time 1.162214 value 0.412303 suggestion {'alpha': 6.24716796011183e-05, 'batch_size': 41, 'beta_1': 0.6147920274614302, 'beta_2': 0.9999956836230944, 'epsilon': 1.204144308852701e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.001864366350509501, 'tol': 0.00021119863886314292, 'validation_fraction': 0.8171963479175691}
observation time 0.000015, current best 0.260207 at iter 19
suggestion time taken 20.090404 iter 20 next_points [{'alpha': 0.12037820925151459, 'batch_size': 151, 'beta_1': 0.9576513169453796, 'beta_2': 0.9981252158365093, 'epsilon': 1.0013277466952205e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.02270882612628648, 'tol': 0.00012245221790968379, 'validation_fraction': 0.27742275990352394}]
function_evaluation time 0.837501 value 1.160135 suggestion {'alpha': 0.12037820925151459, 'batch_size': 151, 'beta_1': 0.9576513169453796, 'beta_2': 0.9981252158365093, 'epsilon': 1.0013277466952205e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.02270882612628648, 'tol': 0.00012245221790968379, 'validation_fraction': 0.27742275990352394}
observation time 0.000006, current best 0.260207 at iter 20
suggestion time taken 21.343616 iter 21 next_points [{'alpha': 0.15390496294273573, 'batch_size': 15, 'beta_1': 0.943729469884216, 'beta_2': 0.9609316205529957, 'epsilon': 1.4780076921499842e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.000128519408221734, 'tol': 0.04301927489232754, 'validation_fraction': 0.830122161183301}]
function_evaluation time 0.912411 value 6.566690 suggestion {'alpha': 0.15390496294273573, 'batch_size': 15, 'beta_1': 0.943729469884216, 'beta_2': 0.9609316205529957, 'epsilon': 1.4780076921499842e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.000128519408221734, 'tol': 0.04301927489232754, 'validation_fraction': 0.830122161183301}
observation time 0.000008, current best 0.260207 at iter 21
suggestion time taken 19.721165 iter 22 next_points [{'alpha': 0.06017093460439114, 'batch_size': 227, 'beta_1': 0.8277108905453942, 'beta_2': 0.9544211781174413, 'epsilon': 2.3207072551422838e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.0006858597009326556, 'tol': 0.058895616087626924, 'validation_fraction': 0.2529199686872339}]
function_evaluation time 0.360054 value 5.647654 suggestion {'alpha': 0.06017093460439114, 'batch_size': 227, 'beta_1': 0.8277108905453942, 'beta_2': 0.9544211781174413, 'epsilon': 2.3207072551422838e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.0006858597009326556, 'tol': 0.058895616087626924, 'validation_fraction': 0.2529199686872339}
observation time 0.000006, current best 0.260207 at iter 22
suggestion time taken 21.355448 iter 23 next_points [{'alpha': 3.169494954170623, 'batch_size': 11, 'beta_1': 0.9663637249978401, 'beta_2': 0.9425765126219092, 'epsilon': 3.4956008461982705e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.00016941671869068903, 'tol': 0.06700160371300116, 'validation_fraction': 0.7815682464424483}]
function_evaluation time 1.258223 value 3.366731 suggestion {'alpha': 3.169494954170623, 'batch_size': 11, 'beta_1': 0.9663637249978401, 'beta_2': 0.9425765126219092, 'epsilon': 3.4956008461982705e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.00016941671869068903, 'tol': 0.06700160371300116, 'validation_fraction': 0.7815682464424483}
observation time 0.000008, current best 0.260207 at iter 23
suggestion time taken 19.796281 iter 24 next_points [{'alpha': 8.078146335892086e-05, 'batch_size': 10, 'beta_1': 0.6756599932917216, 'beta_2': 0.9999830873540995, 'epsilon': 6.25993153433427e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.013673867925313717, 'tol': 1.907058150850679e-05, 'validation_fraction': 0.8879615732320371}]
function_evaluation time 0.828541 value 0.734934 suggestion {'alpha': 8.078146335892086e-05, 'batch_size': 10, 'beta_1': 0.6756599932917216, 'beta_2': 0.9999830873540995, 'epsilon': 6.25993153433427e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.013673867925313717, 'tol': 1.907058150850679e-05, 'validation_fraction': 0.8879615732320371}
observation time 0.000007, current best 0.260207 at iter 24
suggestion time taken 21.935107 iter 25 next_points [{'alpha': 1.0381738597976816e-05, 'batch_size': 41, 'beta_1': 0.520339731750115, 'beta_2': 0.9999941348709543, 'epsilon': 1.4473248943829283e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.02183037047883041, 'tol': 0.010805086893803419, 'validation_fraction': 0.44311418634884286}]
function_evaluation time 0.989757 value 1.032585 suggestion {'alpha': 1.0381738597976816e-05, 'batch_size': 41, 'beta_1': 0.520339731750115, 'beta_2': 0.9999941348709543, 'epsilon': 1.4473248943829283e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.02183037047883041, 'tol': 0.010805086893803419, 'validation_fraction': 0.44311418634884286}
observation time 0.000018, current best 0.260207 at iter 25
suggestion time taken 19.766337 iter 26 next_points [{'alpha': 0.004428455452183719, 'batch_size': 75, 'beta_1': 0.7395452061986643, 'beta_2': 0.9959830887300242, 'epsilon': 4.642685501299362e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 1.503052153487527e-05, 'tol': 1.2032647852330545e-05, 'validation_fraction': 0.8541521794449485}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.237128 value 18.016838 suggestion {'alpha': 0.004428455452183719, 'batch_size': 75, 'beta_1': 0.7395452061986643, 'beta_2': 0.9959830887300242, 'epsilon': 4.642685501299362e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 1.503052153487527e-05, 'tol': 1.2032647852330545e-05, 'validation_fraction': 0.8541521794449485}
observation time 0.000005, current best 0.260207 at iter 26
suggestion time taken 21.091283 iter 27 next_points [{'alpha': 1.0621310762654757e-05, 'batch_size': 90, 'beta_1': 0.5553621113932005, 'beta_2': 0.9989210942467814, 'epsilon': 7.2885970891622645e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.015197448671607645, 'tol': 0.011530851510826954, 'validation_fraction': 0.6920372694673426}]
function_evaluation time 0.506866 value 0.825281 suggestion {'alpha': 1.0621310762654757e-05, 'batch_size': 90, 'beta_1': 0.5553621113932005, 'beta_2': 0.9989210942467814, 'epsilon': 7.2885970891622645e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.015197448671607645, 'tol': 0.011530851510826954, 'validation_fraction': 0.6920372694673426}
observation time 0.000005, current best 0.260207 at iter 27
suggestion time taken 20.024685 iter 28 next_points [{'alpha': 0.020135569905412893, 'batch_size': 28, 'beta_1': 0.6448355252793077, 'beta_2': 0.9999650417090393, 'epsilon': 3.239669942579737e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 4.6576790436145556e-05, 'tol': 0.0062094090792727255, 'validation_fraction': 0.21849105093182083}]
function_evaluation time 3.292256 value 2.412683 suggestion {'alpha': 0.020135569905412893, 'batch_size': 28, 'beta_1': 0.6448355252793077, 'beta_2': 0.9999650417090393, 'epsilon': 3.239669942579737e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 4.6576790436145556e-05, 'tol': 0.0062094090792727255, 'validation_fraction': 0.21849105093182083}
observation time 0.000006, current best 0.260207 at iter 28
suggestion time taken 21.081654 iter 29 next_points [{'alpha': 0.00029163050698744657, 'batch_size': 13, 'beta_1': 0.9629277086040754, 'beta_2': 0.9994808721502041, 'epsilon': 6.107622865671856e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.011474219664943651, 'tol': 0.002538141626120222, 'validation_fraction': 0.8317699614467233}]
function_evaluation time 1.205991 value 1.198842 suggestion {'alpha': 0.00029163050698744657, 'batch_size': 13, 'beta_1': 0.9629277086040754, 'beta_2': 0.9994808721502041, 'epsilon': 6.107622865671856e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.011474219664943651, 'tol': 0.002538141626120222, 'validation_fraction': 0.8317699614467233}
observation time 0.000013, current best 0.260207 at iter 29
suggestion time taken 19.765383 iter 30 next_points [{'alpha': 1.3194260500093667e-05, 'batch_size': 150, 'beta_1': 0.5841613283670398, 'beta_2': 0.9971238599793487, 'epsilon': 1.4551624864888545e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 1.4404029499853885e-05, 'tol': 0.00044924546628082154, 'validation_fraction': 0.83511769161802}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.339545 value 14.129063 suggestion {'alpha': 1.3194260500093667e-05, 'batch_size': 150, 'beta_1': 0.5841613283670398, 'beta_2': 0.9971238599793487, 'epsilon': 1.4551624864888545e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 1.4404029499853885e-05, 'tol': 0.00044924546628082154, 'validation_fraction': 0.83511769161802}
observation time 0.000006, current best 0.260207 at iter 30
suggestion time taken 21.625250 iter 31 next_points [{'alpha': 0.1383314491930923, 'batch_size': 227, 'beta_1': 0.7244747452396066, 'beta_2': 0.9999853290737198, 'epsilon': 4.3601676498003775e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.08079835166320842, 'tol': 0.08734240944502977, 'validation_fraction': 0.3742122404079371}]
function_evaluation time 0.485816 value 3.199624 suggestion {'alpha': 0.1383314491930923, 'batch_size': 227, 'beta_1': 0.7244747452396066, 'beta_2': 0.9999853290737198, 'epsilon': 4.3601676498003775e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.08079835166320842, 'tol': 0.08734240944502977, 'validation_fraction': 0.3742122404079371}
observation time 0.000005, current best 0.260207 at iter 31
suggestion time taken 20.387689 iter 32 next_points [{'alpha': 0.0017575591926796608, 'batch_size': 12, 'beta_1': 0.9609513150763361, 'beta_2': 0.999711966207526, 'epsilon': 2.6662877464130775e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 9.610834802705156e-05, 'tol': 0.0003386956707405913, 'validation_fraction': 0.20289383590603594}]
function_evaluation time 1.480377 value 0.337425 suggestion {'alpha': 0.0017575591926796608, 'batch_size': 12, 'beta_1': 0.9609513150763361, 'beta_2': 0.999711966207526, 'epsilon': 2.6662877464130775e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 9.610834802705156e-05, 'tol': 0.0003386956707405913, 'validation_fraction': 0.20289383590603594}
observation time 0.000016, current best 0.260207 at iter 32
suggestion time taken 21.401747 iter 33 next_points [{'alpha': 2.7624221024346657e-05, 'batch_size': 11, 'beta_1': 0.9458308931433, 'beta_2': 0.9999975932725037, 'epsilon': 5.539151470634311e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0008287742329591254, 'tol': 0.014253032659877462, 'validation_fraction': 0.45091480832285974}]
function_evaluation time 0.915708 value 0.379438 suggestion {'alpha': 2.7624221024346657e-05, 'batch_size': 11, 'beta_1': 0.9458308931433, 'beta_2': 0.9999975932725037, 'epsilon': 5.539151470634311e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.0008287742329591254, 'tol': 0.014253032659877462, 'validation_fraction': 0.45091480832285974}
observation time 0.000005, current best 0.260207 at iter 33
suggestion time taken 20.351625 iter 34 next_points [{'alpha': 0.025188164640085824, 'batch_size': 226, 'beta_1': 0.7867524210933112, 'beta_2': 0.9999833449100078, 'epsilon': 1.3113183829297508e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.004868602854639257, 'tol': 0.00759563404677529, 'validation_fraction': 0.13217151160160487}]
function_evaluation time 0.627724 value 0.530748 suggestion {'alpha': 0.025188164640085824, 'batch_size': 226, 'beta_1': 0.7867524210933112, 'beta_2': 0.9999833449100078, 'epsilon': 1.3113183829297508e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.004868602854639257, 'tol': 0.00759563404677529, 'validation_fraction': 0.13217151160160487}
observation time 0.000006, current best 0.260207 at iter 34
suggestion time taken 19.882521 iter 35 next_points [{'alpha': 0.0025061029759012015, 'batch_size': 151, 'beta_1': 0.9320827939166424, 'beta_2': 0.9998006190676009, 'epsilon': 4.821768887640973e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 1.3567833731683634e-05, 'tol': 0.0010816001052979622, 'validation_fraction': 0.27542622717019033}]
function_evaluation time 0.601737 value 12.845489 suggestion {'alpha': 0.0025061029759012015, 'batch_size': 151, 'beta_1': 0.9320827939166424, 'beta_2': 0.9998006190676009, 'epsilon': 4.821768887640973e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 1.3567833731683634e-05, 'tol': 0.0010816001052979622, 'validation_fraction': 0.27542622717019033}
observation time 0.000014, current best 0.260207 at iter 35
suggestion time taken 21.796035 iter 36 next_points [{'alpha': 0.0021263441750257704, 'batch_size': 18, 'beta_1': 0.7884011530862041, 'beta_2': 0.999120691969447, 'epsilon': 4.446578810103992e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 3.836978603441172e-05, 'tol': 0.028613513365509647, 'validation_fraction': 0.8558653581829244}]
function_evaluation time 0.437204 value 7.599814 suggestion {'alpha': 0.0021263441750257704, 'batch_size': 18, 'beta_1': 0.7884011530862041, 'beta_2': 0.999120691969447, 'epsilon': 4.446578810103992e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 3.836978603441172e-05, 'tol': 0.028613513365509647, 'validation_fraction': 0.8558653581829244}
observation time 0.000008, current best 0.260207 at iter 36
suggestion time taken 20.296175 iter 37 next_points [{'alpha': 8.840908403919684, 'batch_size': 75, 'beta_1': 0.8453698062295544, 'beta_2': 0.999997461405341, 'epsilon': 3.2893639892167777e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.028908499594612117, 'tol': 0.0018728599955236441, 'validation_fraction': 0.5730432163083716}]
function_evaluation time 0.795298 value 0.657076 suggestion {'alpha': 8.840908403919684, 'batch_size': 75, 'beta_1': 0.8453698062295544, 'beta_2': 0.999997461405341, 'epsilon': 3.2893639892167777e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.028908499594612117, 'tol': 0.0018728599955236441, 'validation_fraction': 0.5730432163083716}
observation time 0.000007, current best 0.260207 at iter 37
suggestion time taken 21.600673 iter 38 next_points [{'alpha': 0.007061961615809885, 'batch_size': 151, 'beta_1': 0.7821310081291674, 'beta_2': 0.9995998216965662, 'epsilon': 3.681260184197529e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0001055681809441449, 'tol': 2.5447079599314233e-05, 'validation_fraction': 0.8814254621252218}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.333750 value 11.742225 suggestion {'alpha': 0.007061961615809885, 'batch_size': 151, 'beta_1': 0.7821310081291674, 'beta_2': 0.9995998216965662, 'epsilon': 3.681260184197529e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0001055681809441449, 'tol': 2.5447079599314233e-05, 'validation_fraction': 0.8814254621252218}
observation time 0.000005, current best 0.260207 at iter 38
suggestion time taken 19.956100 iter 39 next_points [{'alpha': 1.1922084947541452e-05, 'batch_size': 40, 'beta_1': 0.9017276817674507, 'beta_2': 0.9999726215374959, 'epsilon': 5.170870793434369e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.00016554472985634742, 'tol': 0.02672796382131872, 'validation_fraction': 0.3413945668880804}]
function_evaluation time 1.216317 value 0.513783 suggestion {'alpha': 1.1922084947541452e-05, 'batch_size': 40, 'beta_1': 0.9017276817674507, 'beta_2': 0.9999726215374959, 'epsilon': 5.170870793434369e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.00016554472985634742, 'tol': 0.02672796382131872, 'validation_fraction': 0.3413945668880804}
observation time 0.000008, current best 0.260207 at iter 39
suggestion time taken 21.029608 iter 40 next_points [{'alpha': 5.726023060743928, 'batch_size': 227, 'beta_1': 0.8398809895548824, 'beta_2': 0.9999969620670741, 'epsilon': 3.9731455157973194e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.00012905291272384523, 'tol': 0.0028719079732484713, 'validation_fraction': 0.1314125941357117}]
function_evaluation time 0.819224 value 9.545917 suggestion {'alpha': 5.726023060743928, 'batch_size': 227, 'beta_1': 0.8398809895548824, 'beta_2': 0.9999969620670741, 'epsilon': 3.9731455157973194e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.00012905291272384523, 'tol': 0.0028719079732484713, 'validation_fraction': 0.1314125941357117}
observation time 0.000005, current best 0.260207 at iter 40
suggestion time taken 20.878940 iter 41 next_points [{'alpha': 0.00024307522701891472, 'batch_size': 151, 'beta_1': 0.9109353692151665, 'beta_2': 0.9998950131706973, 'epsilon': 2.486507737962038e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.013939882790374761, 'tol': 0.07166115402825803, 'validation_fraction': 0.2163203114205856}]
function_evaluation time 0.630018 value 1.021404 suggestion {'alpha': 0.00024307522701891472, 'batch_size': 151, 'beta_1': 0.9109353692151665, 'beta_2': 0.9998950131706973, 'epsilon': 2.486507737962038e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.013939882790374761, 'tol': 0.07166115402825803, 'validation_fraction': 0.2163203114205856}
observation time 0.000005, current best 0.260207 at iter 41
suggestion time taken 20.229068 iter 42 next_points [{'alpha': 0.05370638493140458, 'batch_size': 41, 'beta_1': 0.7728614160420417, 'beta_2': 0.9585585939304638, 'epsilon': 7.864262847764955e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.025470455618344122, 'tol': 0.009884546235800143, 'validation_fraction': 0.8115450089066031}]
function_evaluation time 0.485646 value 1.132526 suggestion {'alpha': 0.05370638493140458, 'batch_size': 41, 'beta_1': 0.7728614160420417, 'beta_2': 0.9585585939304638, 'epsilon': 7.864262847764955e-07, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.025470455618344122, 'tol': 0.009884546235800143, 'validation_fraction': 0.8115450089066031}
observation time 0.000005, current best 0.260207 at iter 42
suggestion time taken 21.693506 iter 43 next_points [{'alpha': 0.0023850380616300413, 'batch_size': 151, 'beta_1': 0.6733099208164285, 'beta_2': 0.9999852512351086, 'epsilon': 4.509538261689615e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.022852537547582638, 'tol': 0.00010122144924804923, 'validation_fraction': 0.7872993499754557}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.624572 value 0.969909 suggestion {'alpha': 0.0023850380616300413, 'batch_size': 151, 'beta_1': 0.6733099208164285, 'beta_2': 0.9999852512351086, 'epsilon': 4.509538261689615e-08, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.022852537547582638, 'tol': 0.00010122144924804923, 'validation_fraction': 0.7872993499754557}
observation time 0.000006, current best 0.260207 at iter 43
suggestion time taken 20.419210 iter 44 next_points [{'alpha': 3.704542047419542e-05, 'batch_size': 15, 'beta_1': 0.5341381513444268, 'beta_2': 0.9462393024627811, 'epsilon': 1.2298323014490026e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.009318697678433631, 'tol': 0.023626985245811156, 'validation_fraction': 0.8846062211350811}]
function_evaluation time 0.682082 value 0.783644 suggestion {'alpha': 3.704542047419542e-05, 'batch_size': 15, 'beta_1': 0.5341381513444268, 'beta_2': 0.9462393024627811, 'epsilon': 1.2298323014490026e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.009318697678433631, 'tol': 0.023626985245811156, 'validation_fraction': 0.8846062211350811}
observation time 0.000006, current best 0.260207 at iter 44
saving meta data: {'args': {'--uuid': 'c90f7a2c2d125e8f8f09ffdb09d76cb5', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])}
saving results
saving timing
saving suggest log
done
