running: {'--uuid': '0d1c85c29be652ee80107c5ff74369d7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 0d1c85c29be652ee80107c5ff74369d7 -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.011658 iter 0 next_points [{'alpha': 0.08076840200573637, 'batch_size': 108, 'beta_1': 0.9340935538622075, 'beta_2': 0.9999988711041651, 'epsilon': 2.8716116493947188e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0665980819838069, 'tol': 2.0298556925536654e-05, 'validation_fraction': 0.14373459799609034}]
function_evaluation time 0.701290 value -0.795604 suggestion {'alpha': 0.08076840200573637, 'batch_size': 108, 'beta_1': 0.9340935538622075, 'beta_2': 0.9999988711041651, 'epsilon': 2.8716116493947188e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0665980819838069, 'tol': 2.0298556925536654e-05, 'validation_fraction': 0.14373459799609034}
observation time 0.000014, current best -0.795604 at iter 0
suggestion time taken 0.014774 iter 1 next_points [{'alpha': 0.00168757980713827, 'batch_size': 142, 'beta_1': 0.9057505180934622, 'beta_2': 0.9999769492586932, 'epsilon': 2.7518002095951984e-08, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0745643773803394, 'tol': 0.00120146284840567, 'validation_fraction': 0.8884991551756859}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.409056 value -0.789011 suggestion {'alpha': 0.00168757980713827, 'batch_size': 142, 'beta_1': 0.9057505180934622, 'beta_2': 0.9999769492586932, 'epsilon': 2.7518002095951984e-08, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0745643773803394, 'tol': 0.00120146284840567, 'validation_fraction': 0.8884991551756859}
observation time 0.000004, current best -0.795604 at iter 1
suggestion time taken 0.010302 iter 2 next_points [{'alpha': 0.07318989205184712, 'batch_size': 219, 'beta_1': 0.5974408946342447, 'beta_2': 0.9946451915387268, 'epsilon': 7.559556516941092e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 1.106940577992768e-05, 'tol': 0.001228152214140711, 'validation_fraction': 0.2773823605055325}]
function_evaluation time 0.877096 value -0.564835 suggestion {'alpha': 0.07318989205184712, 'batch_size': 219, 'beta_1': 0.5974408946342447, 'beta_2': 0.9946451915387268, 'epsilon': 7.559556516941092e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 1.106940577992768e-05, 'tol': 0.001228152214140711, 'validation_fraction': 0.2773823605055325}
observation time 0.000008, current best -0.795604 at iter 2
suggestion time taken 0.011682 iter 3 next_points [{'alpha': 5.650889250388581e-05, 'batch_size': 108, 'beta_1': 0.959318570975137, 'beta_2': 0.943570782903209, 'epsilon': 2.9333233774805287e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 2.8583376345229713e-05, 'tol': 1.2548442865244806e-05, 'validation_fraction': 0.3546115742296626}]
function_evaluation time 0.371013 value -0.459341 suggestion {'alpha': 5.650889250388581e-05, 'batch_size': 108, 'beta_1': 0.959318570975137, 'beta_2': 0.943570782903209, 'epsilon': 2.9333233774805287e-09, 'hidden_layer_sizes': 88, 'learning_rate_init': 2.8583376345229713e-05, 'tol': 1.2548442865244806e-05, 'validation_fraction': 0.3546115742296626}
observation time 0.000004, current best -0.795604 at iter 3
suggestion time taken 0.010922 iter 4 next_points [{'alpha': 1.4239056549992697, 'batch_size': 191, 'beta_1': 0.8096256313696574, 'beta_2': 0.9999989905001084, 'epsilon': 2.73470038358159e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.005780006842055667, 'tol': 0.0019197588844990098, 'validation_fraction': 0.8459836106334376}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.677624 value -0.896703 suggestion {'alpha': 1.4239056549992697, 'batch_size': 191, 'beta_1': 0.8096256313696574, 'beta_2': 0.9999989905001084, 'epsilon': 2.73470038358159e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.005780006842055667, 'tol': 0.0019197588844990098, 'validation_fraction': 0.8459836106334376}
observation time 0.000006, current best -0.896703 at iter 4
suggestion time taken 0.012364 iter 5 next_points [{'alpha': 0.02498011703916816, 'batch_size': 127, 'beta_1': 0.9897531438796816, 'beta_2': 0.9999698012626516, 'epsilon': 8.87448821801219e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.026639649738763514, 'tol': 1.1089052208453901e-05, 'validation_fraction': 0.6371108278571934}]
function_evaluation time 0.647300 value -0.901099 suggestion {'alpha': 0.02498011703916816, 'batch_size': 127, 'beta_1': 0.9897531438796816, 'beta_2': 0.9999698012626516, 'epsilon': 8.87448821801219e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.026639649738763514, 'tol': 1.1089052208453901e-05, 'validation_fraction': 0.6371108278571934}
observation time 0.000010, current best -0.901099 at iter 5
suggestion time taken 0.012954 iter 6 next_points [{'alpha': 5.907196771010499, 'batch_size': 27, 'beta_1': 0.9807896583866806, 'beta_2': 0.9989145982407003, 'epsilon': 2.98161700945617e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 3.6611524410870427e-05, 'tol': 0.008131759755546199, 'validation_fraction': 0.8196465264878776}]
function_evaluation time 0.485392 value -0.492308 suggestion {'alpha': 5.907196771010499, 'batch_size': 27, 'beta_1': 0.9807896583866806, 'beta_2': 0.9989145982407003, 'epsilon': 2.98161700945617e-08, 'hidden_layer_sizes': 146, 'learning_rate_init': 3.6611524410870427e-05, 'tol': 0.008131759755546199, 'validation_fraction': 0.8196465264878776}
observation time 0.000003, current best -0.901099 at iter 6
suggestion time taken 0.009956 iter 7 next_points [{'alpha': 1.2287767540579524, 'batch_size': 39, 'beta_1': 0.8645698753012707, 'beta_2': 0.9999904162033932, 'epsilon': 4.828365081989898e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 3.355665492348518e-05, 'tol': 0.00018878183375074757, 'validation_fraction': 0.21418445702350022}]
function_evaluation time 0.937204 value -0.696703 suggestion {'alpha': 1.2287767540579524, 'batch_size': 39, 'beta_1': 0.8645698753012707, 'beta_2': 0.9999904162033932, 'epsilon': 4.828365081989898e-07, 'hidden_layer_sizes': 125, 'learning_rate_init': 3.355665492348518e-05, 'tol': 0.00018878183375074757, 'validation_fraction': 0.21418445702350022}
observation time 0.000008, current best -0.901099 at iter 7
suggestion time taken 0.011394 iter 8 next_points [{'alpha': 0.10227960066219906, 'batch_size': 145, 'beta_1': 0.8779465239761266, 'beta_2': 0.9999983855219154, 'epsilon': 1.056267904619042e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0006363868473452338, 'tol': 0.08608203405967532, 'validation_fraction': 0.7557924633526784}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.313809 value -0.734066 suggestion {'alpha': 0.10227960066219906, 'batch_size': 145, 'beta_1': 0.8779465239761266, 'beta_2': 0.9999983855219154, 'epsilon': 1.056267904619042e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0006363868473452338, 'tol': 0.08608203405967532, 'validation_fraction': 0.7557924633526784}
observation time 0.000005, current best -0.901099 at iter 8
suggestion time taken 0.010917 iter 9 next_points [{'alpha': 1.8700643751191122, 'batch_size': 12, 'beta_1': 0.9500143479539127, 'beta_2': 0.9997814813429089, 'epsilon': 1.2889769997077976e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 8.416458698879418e-05, 'tol': 0.0130794957430236, 'validation_fraction': 0.881680755056324}]
function_evaluation time 0.547628 value -0.643956 suggestion {'alpha': 1.8700643751191122, 'batch_size': 12, 'beta_1': 0.9500143479539127, 'beta_2': 0.9997814813429089, 'epsilon': 1.2889769997077976e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 8.416458698879418e-05, 'tol': 0.0130794957430236, 'validation_fraction': 0.881680755056324}
observation time 0.000004, current best -0.901099 at iter 9
suggestion time taken 0.010814 iter 10 next_points [{'alpha': 0.3381616793871571, 'batch_size': 222, 'beta_1': 0.9876457950951605, 'beta_2': 0.9659866339100849, 'epsilon': 5.559392377001346e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.06108680759845949, 'tol': 0.0003153892552580182, 'validation_fraction': 0.5026275466503758}]
function_evaluation time 0.528371 value -0.832967 suggestion {'alpha': 0.3381616793871571, 'batch_size': 222, 'beta_1': 0.9876457950951605, 'beta_2': 0.9659866339100849, 'epsilon': 5.559392377001346e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.06108680759845949, 'tol': 0.0003153892552580182, 'validation_fraction': 0.5026275466503758}
observation time 0.000004, current best -0.901099 at iter 10
suggestion time taken 0.012682 iter 11 next_points [{'alpha': 0.03759899792614121, 'batch_size': 20, 'beta_1': 0.5563971920486604, 'beta_2': 0.9989938179731603, 'epsilon': 3.7876243315916434e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0004772131608612576, 'tol': 0.009642501598921055, 'validation_fraction': 0.8457071627643367}]
function_evaluation time 0.954456 value -0.793407 suggestion {'alpha': 0.03759899792614121, 'batch_size': 20, 'beta_1': 0.5563971920486604, 'beta_2': 0.9989938179731603, 'epsilon': 3.7876243315916434e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0004772131608612576, 'tol': 0.009642501598921055, 'validation_fraction': 0.8457071627643367}
observation time 0.000003, current best -0.901099 at iter 11
suggestion time taken 0.010734 iter 12 next_points [{'alpha': 0.02203004137751705, 'batch_size': 69, 'beta_1': 0.5454497435848684, 'beta_2': 0.9648265881846317, 'epsilon': 1.2038665732752774e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 8.125317704914707e-05, 'tol': 0.00017825123017092592, 'validation_fraction': 0.12746858493572347}]
function_evaluation time 0.580413 value -0.749451 suggestion {'alpha': 0.02203004137751705, 'batch_size': 69, 'beta_1': 0.5454497435848684, 'beta_2': 0.9648265881846317, 'epsilon': 1.2038665732752774e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 8.125317704914707e-05, 'tol': 0.00017825123017092592, 'validation_fraction': 0.12746858493572347}
observation time 0.000004, current best -0.901099 at iter 12
suggestion time taken 0.010773 iter 13 next_points [{'alpha': 0.3954583303343834, 'batch_size': 195, 'beta_1': 0.959607033571663, 'beta_2': 0.9994182268316741, 'epsilon': 1.2561252831078637e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.07622397337170549, 'tol': 0.00033669121909055057, 'validation_fraction': 0.631577633918089}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.415917 value -0.846154 suggestion {'alpha': 0.3954583303343834, 'batch_size': 195, 'beta_1': 0.959607033571663, 'beta_2': 0.9994182268316741, 'epsilon': 1.2561252831078637e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.07622397337170549, 'tol': 0.00033669121909055057, 'validation_fraction': 0.631577633918089}
observation time 0.000003, current best -0.901099 at iter 13
suggestion time taken 0.009687 iter 14 next_points [{'alpha': 0.00028241930418370563, 'batch_size': 77, 'beta_1': 0.8976470732215822, 'beta_2': 0.9519372998938236, 'epsilon': 1.2651512789737037e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.012161250726495345, 'tol': 0.00015133533610980215, 'validation_fraction': 0.49069717418407904}]
function_evaluation time 1.067849 value -0.916484 suggestion {'alpha': 0.00028241930418370563, 'batch_size': 77, 'beta_1': 0.8976470732215822, 'beta_2': 0.9519372998938236, 'epsilon': 1.2651512789737037e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.012161250726495345, 'tol': 0.00015133533610980215, 'validation_fraction': 0.49069717418407904}
observation time 0.000004, current best -0.916484 at iter 14
suggestion time taken 0.010422 iter 15 next_points [{'alpha': 0.02370605562822726, 'batch_size': 213, 'beta_1': 0.6457744901969671, 'beta_2': 0.9993304874362218, 'epsilon': 8.921260805012255e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 1.3716485480314463e-05, 'tol': 0.0001351233344437136, 'validation_fraction': 0.3218500809314535}]
function_evaluation time 0.423557 value -0.527473 suggestion {'alpha': 0.02370605562822726, 'batch_size': 213, 'beta_1': 0.6457744901969671, 'beta_2': 0.9993304874362218, 'epsilon': 8.921260805012255e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 1.3716485480314463e-05, 'tol': 0.0001351233344437136, 'validation_fraction': 0.3218500809314535}
observation time 0.000010, current best -0.916484 at iter 15
suggestion time taken 0.014869 iter 16 next_points [{'alpha': 0.0007869260926049227, 'batch_size': 173, 'beta_1': 0.8975291673398501, 'beta_2': 0.9813951736236376, 'epsilon': 6.735901739790547e-07, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.017456887433008297, 'tol': 0.0007271735063815604, 'validation_fraction': 0.7532525181906591}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.464400 value -0.874725 suggestion {'alpha': 0.0007869260926049227, 'batch_size': 173, 'beta_1': 0.8975291673398501, 'beta_2': 0.9813951736236376, 'epsilon': 6.735901739790547e-07, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.017456887433008297, 'tol': 0.0007271735063815604, 'validation_fraction': 0.7532525181906591}
observation time 0.000004, current best -0.916484 at iter 16
suggestion time taken 0.010010 iter 17 next_points [{'alpha': 0.0058576831751998275, 'batch_size': 155, 'beta_1': 0.9475374386403963, 'beta_2': 0.9960516905685926, 'epsilon': 1.2868705595378748e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.00036456305862474377, 'tol': 7.655287067718354e-05, 'validation_fraction': 0.8972622958342843}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.509030 value -0.556044 suggestion {'alpha': 0.0058576831751998275, 'batch_size': 155, 'beta_1': 0.9475374386403963, 'beta_2': 0.9960516905685926, 'epsilon': 1.2868705595378748e-07, 'hidden_layer_sizes': 189, 'learning_rate_init': 0.00036456305862474377, 'tol': 7.655287067718354e-05, 'validation_fraction': 0.8972622958342843}
observation time 0.000012, current best -0.916484 at iter 17
suggestion time taken 0.012843 iter 18 next_points [{'alpha': 0.0032932054758277136, 'batch_size': 139, 'beta_1': 0.7399184885491517, 'beta_2': 0.9995158467976925, 'epsilon': 1.3099766552767135e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 1.6808034637298745e-05, 'tol': 0.0013225341437075459, 'validation_fraction': 0.5804865292237698}]
function_evaluation time 0.441500 value -0.404396 suggestion {'alpha': 0.0032932054758277136, 'batch_size': 139, 'beta_1': 0.7399184885491517, 'beta_2': 0.9995158467976925, 'epsilon': 1.3099766552767135e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 1.6808034637298745e-05, 'tol': 0.0013225341437075459, 'validation_fraction': 0.5804865292237698}
observation time 0.000003, current best -0.916484 at iter 18
suggestion time taken 0.010012 iter 19 next_points [{'alpha': 1.5460099898376065, 'batch_size': 241, 'beta_1': 0.9132865960805936, 'beta_2': 0.999423356387799, 'epsilon': 1.7542045549870867e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.024090009992551332, 'tol': 1.1550297021494332e-05, 'validation_fraction': 0.4035189479140799}]
function_evaluation time 0.836395 value -0.896703 suggestion {'alpha': 1.5460099898376065, 'batch_size': 241, 'beta_1': 0.9132865960805936, 'beta_2': 0.999423356387799, 'epsilon': 1.7542045549870867e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.024090009992551332, 'tol': 1.1550297021494332e-05, 'validation_fraction': 0.4035189479140799}
observation time 0.000003, current best -0.916484 at iter 19
suggestion time taken 0.010462 iter 20 next_points [{'alpha': 3.0035570974689048, 'batch_size': 44, 'beta_1': 0.9061794176421331, 'beta_2': 0.9999778983050791, 'epsilon': 1.3322452426450258e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.03535925749360779, 'tol': 0.053463526928576505, 'validation_fraction': 0.238276729076178}]
function_evaluation time 0.946956 value -0.903297 suggestion {'alpha': 3.0035570974689048, 'batch_size': 44, 'beta_1': 0.9061794176421331, 'beta_2': 0.9999778983050791, 'epsilon': 1.3322452426450258e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.03535925749360779, 'tol': 0.053463526928576505, 'validation_fraction': 0.238276729076178}
observation time 0.000006, current best -0.916484 at iter 20
suggestion time taken 0.010677 iter 21 next_points [{'alpha': 0.00048502228224533864, 'batch_size': 220, 'beta_1': 0.9767320131074185, 'beta_2': 0.9978013248654461, 'epsilon': 8.057563571508793e-09, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0006286857761217926, 'tol': 0.008141955469870812, 'validation_fraction': 0.10287448651853001}]
function_evaluation time 1.093528 value -0.881319 suggestion {'alpha': 0.00048502228224533864, 'batch_size': 220, 'beta_1': 0.9767320131074185, 'beta_2': 0.9978013248654461, 'epsilon': 8.057563571508793e-09, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0006286857761217926, 'tol': 0.008141955469870812, 'validation_fraction': 0.10287448651853001}
observation time 0.000004, current best -0.916484 at iter 21
suggestion time taken 0.010774 iter 22 next_points [{'alpha': 0.011361247397908017, 'batch_size': 174, 'beta_1': 0.9626150481207995, 'beta_2': 0.9999953586002427, 'epsilon': 4.7400682613751785e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 2.238008944753523e-05, 'tol': 0.08877426452925291, 'validation_fraction': 0.2183133222264199}]
function_evaluation time 0.420302 value -0.362637 suggestion {'alpha': 0.011361247397908017, 'batch_size': 174, 'beta_1': 0.9626150481207995, 'beta_2': 0.9999953586002427, 'epsilon': 4.7400682613751785e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 2.238008944753523e-05, 'tol': 0.08877426452925291, 'validation_fraction': 0.2183133222264199}
observation time 0.000004, current best -0.916484 at iter 22
suggestion time taken 0.009296 iter 23 next_points [{'alpha': 0.23153433001790646, 'batch_size': 106, 'beta_1': 0.9681068826285485, 'beta_2': 0.9998456482989136, 'epsilon': 5.004086866339689e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 9.798464221516633e-05, 'tol': 9.202814029856245e-05, 'validation_fraction': 0.22595530639555467}]
function_evaluation time 0.783391 value -0.637363 suggestion {'alpha': 0.23153433001790646, 'batch_size': 106, 'beta_1': 0.9681068826285485, 'beta_2': 0.9998456482989136, 'epsilon': 5.004086866339689e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 9.798464221516633e-05, 'tol': 9.202814029856245e-05, 'validation_fraction': 0.22595530639555467}
observation time 0.000004, current best -0.916484 at iter 23
suggestion time taken 0.013395 iter 24 next_points [{'alpha': 0.020490994385298413, 'batch_size': 22, 'beta_1': 0.9699213194920053, 'beta_2': 0.9999871934193858, 'epsilon': 6.975557585636104e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.00017747786792759768, 'tol': 1.744095165248261e-05, 'validation_fraction': 0.7319343238708482}]
function_evaluation time 1.120751 value -0.749451 suggestion {'alpha': 0.020490994385298413, 'batch_size': 22, 'beta_1': 0.9699213194920053, 'beta_2': 0.9999871934193858, 'epsilon': 6.975557585636104e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.00017747786792759768, 'tol': 1.744095165248261e-05, 'validation_fraction': 0.7319343238708482}
observation time 0.000008, current best -0.916484 at iter 24
suggestion time taken 0.011303 iter 25 next_points [{'alpha': 0.736844155912026, 'batch_size': 146, 'beta_1': 0.9035720667094767, 'beta_2': 0.9998443864767588, 'epsilon': 4.75279561636645e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.00571809511859696, 'tol': 0.001741608788636747, 'validation_fraction': 0.7409673131176725}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.530249 value -0.909890 suggestion {'alpha': 0.736844155912026, 'batch_size': 146, 'beta_1': 0.9035720667094767, 'beta_2': 0.9998443864767588, 'epsilon': 4.75279561636645e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.00571809511859696, 'tol': 0.001741608788636747, 'validation_fraction': 0.7409673131176725}
observation time 0.000005, current best -0.916484 at iter 25
suggestion time taken 0.013076 iter 26 next_points [{'alpha': 1.0773362092387927e-05, 'batch_size': 234, 'beta_1': 0.9701626537564693, 'beta_2': 0.9999957771604382, 'epsilon': 4.965337071408234e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.00022643529613929406, 'tol': 0.00010221219651984577, 'validation_fraction': 0.17999030732989713}]
function_evaluation time 0.587672 value -0.674725 suggestion {'alpha': 1.0773362092387927e-05, 'batch_size': 234, 'beta_1': 0.9701626537564693, 'beta_2': 0.9999957771604382, 'epsilon': 4.965337071408234e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.00022643529613929406, 'tol': 0.00010221219651984577, 'validation_fraction': 0.17999030732989713}
observation time 0.000004, current best -0.916484 at iter 26
suggestion time taken 0.010110 iter 27 next_points [{'alpha': 7.255232604364105e-05, 'batch_size': 116, 'beta_1': 0.9232721955890251, 'beta_2': 0.924068959116953, 'epsilon': 2.5362747253749303e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.000519950566080242, 'tol': 0.00013935275346929596, 'validation_fraction': 0.2595484958005515}]
function_evaluation time 1.354528 value -0.914286 suggestion {'alpha': 7.255232604364105e-05, 'batch_size': 116, 'beta_1': 0.9232721955890251, 'beta_2': 0.924068959116953, 'epsilon': 2.5362747253749303e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.000519950566080242, 'tol': 0.00013935275346929596, 'validation_fraction': 0.2595484958005515}
observation time 0.000004, current best -0.916484 at iter 27
suggestion time taken 0.010897 iter 28 next_points [{'alpha': 0.0030835456444576054, 'batch_size': 102, 'beta_1': 0.9750680205603259, 'beta_2': 0.9970563828455079, 'epsilon': 3.869422177414824e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.07740790480999458, 'tol': 0.010620197833103423, 'validation_fraction': 0.47373883744382295}]
function_evaluation time 0.640474 value -0.854945 suggestion {'alpha': 0.0030835456444576054, 'batch_size': 102, 'beta_1': 0.9750680205603259, 'beta_2': 0.9970563828455079, 'epsilon': 3.869422177414824e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.07740790480999458, 'tol': 0.010620197833103423, 'validation_fraction': 0.47373883744382295}
observation time 0.000004, current best -0.916484 at iter 28
suggestion time taken 0.009889 iter 29 next_points [{'alpha': 0.5482959698160255, 'batch_size': 238, 'beta_1': 0.7901240609236987, 'beta_2': 0.9682744469070435, 'epsilon': 5.960589948180996e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0003163952016180209, 'tol': 0.005175134977208588, 'validation_fraction': 0.6047239351322321}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.296291 value -0.595604 suggestion {'alpha': 0.5482959698160255, 'batch_size': 238, 'beta_1': 0.7901240609236987, 'beta_2': 0.9682744469070435, 'epsilon': 5.960589948180996e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.0003163952016180209, 'tol': 0.005175134977208588, 'validation_fraction': 0.6047239351322321}
observation time 0.000004, current best -0.916484 at iter 29
suggestion time taken 0.011069 iter 30 next_points [{'alpha': 0.03594574212274736, 'batch_size': 192, 'beta_1': 0.9452913259394136, 'beta_2': 0.9865158640597997, 'epsilon': 2.7377965122811504e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00027352166021332486, 'tol': 4.347220097920536e-05, 'validation_fraction': 0.8889125834184985}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.449036 value -0.615385 suggestion {'alpha': 0.03594574212274736, 'batch_size': 192, 'beta_1': 0.9452913259394136, 'beta_2': 0.9865158640597997, 'epsilon': 2.7377965122811504e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00027352166021332486, 'tol': 4.347220097920536e-05, 'validation_fraction': 0.8889125834184985}
observation time 0.000007, current best -0.916484 at iter 30
suggestion time taken 0.010731 iter 31 next_points [{'alpha': 0.0025704409157150665, 'batch_size': 144, 'beta_1': 0.8150292939174607, 'beta_2': 0.9218995912675831, 'epsilon': 1.0607436221277215e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0001341037580570731, 'tol': 0.004183342580819887, 'validation_fraction': 0.3529779477650568}]
function_evaluation time 0.509810 value -0.525275 suggestion {'alpha': 0.0025704409157150665, 'batch_size': 144, 'beta_1': 0.8150292939174607, 'beta_2': 0.9218995912675831, 'epsilon': 1.0607436221277215e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 0.0001341037580570731, 'tol': 0.004183342580819887, 'validation_fraction': 0.3529779477650568}
observation time 0.000003, current best -0.916484 at iter 31
suggestion time taken 0.010022 iter 32 next_points [{'alpha': 1.8036464956841754e-05, 'batch_size': 86, 'beta_1': 0.8835941318140247, 'beta_2': 0.9734750159119966, 'epsilon': 2.4933148808844365e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.05854546849500947, 'tol': 0.023761335625978833, 'validation_fraction': 0.47214478580453123}]
function_evaluation time 0.628221 value -0.850549 suggestion {'alpha': 1.8036464956841754e-05, 'batch_size': 86, 'beta_1': 0.8835941318140247, 'beta_2': 0.9734750159119966, 'epsilon': 2.4933148808844365e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.05854546849500947, 'tol': 0.023761335625978833, 'validation_fraction': 0.47214478580453123}
observation time 0.000003, current best -0.916484 at iter 32
suggestion time taken 0.010498 iter 33 next_points [{'alpha': 0.0008042434287598196, 'batch_size': 57, 'beta_1': 0.980983927867843, 'beta_2': 0.9999885026017518, 'epsilon': 1.5310382018212458e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0013294702113558368, 'tol': 0.042808758366351216, 'validation_fraction': 0.8580039873824742}]
function_evaluation time 0.484731 value -0.806593 suggestion {'alpha': 0.0008042434287598196, 'batch_size': 57, 'beta_1': 0.980983927867843, 'beta_2': 0.9999885026017518, 'epsilon': 1.5310382018212458e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.0013294702113558368, 'tol': 0.042808758366351216, 'validation_fraction': 0.8580039873824742}
observation time 0.000003, current best -0.916484 at iter 33
suggestion time taken 0.010232 iter 34 next_points [{'alpha': 3.763320539754651e-05, 'batch_size': 179, 'beta_1': 0.9486818750924896, 'beta_2': 0.9903157982336872, 'epsilon': 3.9627598016449234e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.012346706548160316, 'tol': 0.0009223571549161689, 'validation_fraction': 0.8678905383083574}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.759059 value -0.907692 suggestion {'alpha': 3.763320539754651e-05, 'batch_size': 179, 'beta_1': 0.9486818750924896, 'beta_2': 0.9903157982336872, 'epsilon': 3.9627598016449234e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.012346706548160316, 'tol': 0.0009223571549161689, 'validation_fraction': 0.8678905383083574}
observation time 0.000009, current best -0.916484 at iter 34
suggestion time taken 0.011793 iter 35 next_points [{'alpha': 0.5175370042577643, 'batch_size': 66, 'beta_1': 0.8321741133197199, 'beta_2': 0.9999985657122742, 'epsilon': 3.362729685783771e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.09313687218861882, 'tol': 0.008793492965858782, 'validation_fraction': 0.8100791646108964}]
function_evaluation time 0.550158 value -0.832967 suggestion {'alpha': 0.5175370042577643, 'batch_size': 66, 'beta_1': 0.8321741133197199, 'beta_2': 0.9999985657122742, 'epsilon': 3.362729685783771e-09, 'hidden_layer_sizes': 197, 'learning_rate_init': 0.09313687218861882, 'tol': 0.008793492965858782, 'validation_fraction': 0.8100791646108964}
observation time 0.000010, current best -0.916484 at iter 35
suggestion time taken 0.013887 iter 36 next_points [{'alpha': 4.700320745471764e-05, 'batch_size': 179, 'beta_1': 0.9303448630626305, 'beta_2': 0.9983930793662301, 'epsilon': 2.1840472925015e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 6.631114439666996e-05, 'tol': 0.04899993787346009, 'validation_fraction': 0.4156424336071523}]
function_evaluation time 0.466785 value -0.419780 suggestion {'alpha': 4.700320745471764e-05, 'batch_size': 179, 'beta_1': 0.9303448630626305, 'beta_2': 0.9983930793662301, 'epsilon': 2.1840472925015e-07, 'hidden_layer_sizes': 191, 'learning_rate_init': 6.631114439666996e-05, 'tol': 0.04899993787346009, 'validation_fraction': 0.4156424336071523}
observation time 0.000005, current best -0.916484 at iter 36
suggestion time taken 0.010717 iter 37 next_points [{'alpha': 1.909049638952193e-05, 'batch_size': 190, 'beta_1': 0.9454466153794066, 'beta_2': 0.9998806936062093, 'epsilon': 1.6748636339210557e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 1.5602393811495815e-05, 'tol': 0.0017620921515604671, 'validation_fraction': 0.17175829764517467}]
function_evaluation time 0.588446 value -0.529670 suggestion {'alpha': 1.909049638952193e-05, 'batch_size': 190, 'beta_1': 0.9454466153794066, 'beta_2': 0.9998806936062093, 'epsilon': 1.6748636339210557e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 1.5602393811495815e-05, 'tol': 0.0017620921515604671, 'validation_fraction': 0.17175829764517467}
observation time 0.000008, current best -0.916484 at iter 37
suggestion time taken 0.010698 iter 38 next_points [{'alpha': 0.8170003028953937, 'batch_size': 52, 'beta_1': 0.9308293903553115, 'beta_2': 0.999998233597444, 'epsilon': 3.4488654557547256e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.040607429139284605, 'tol': 0.011670242628463598, 'validation_fraction': 0.24706255310645933}]
function_evaluation time 1.061543 value -0.905495 suggestion {'alpha': 0.8170003028953937, 'batch_size': 52, 'beta_1': 0.9308293903553115, 'beta_2': 0.999998233597444, 'epsilon': 3.4488654557547256e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.040607429139284605, 'tol': 0.011670242628463598, 'validation_fraction': 0.24706255310645933}
observation time 0.000006, current best -0.916484 at iter 38
suggestion time taken 0.011342 iter 39 next_points [{'alpha': 8.246822815623767e-05, 'batch_size': 210, 'beta_1': 0.9596251343104439, 'beta_2': 0.9990071855110367, 'epsilon': 2.548464687977476e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.01382620961201808, 'tol': 0.08383444239228303, 'validation_fraction': 0.2764917726164865}]
function_evaluation time 0.574128 value -0.852747 suggestion {'alpha': 8.246822815623767e-05, 'batch_size': 210, 'beta_1': 0.9596251343104439, 'beta_2': 0.9990071855110367, 'epsilon': 2.548464687977476e-07, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.01382620961201808, 'tol': 0.08383444239228303, 'validation_fraction': 0.2764917726164865}
observation time 0.000004, current best -0.916484 at iter 39
suggestion time taken 0.010281 iter 40 next_points [{'alpha': 0.009536424530042843, 'batch_size': 161, 'beta_1': 0.6198310995237467, 'beta_2': 0.9999930115046256, 'epsilon': 1.6796055587589752e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0030916709979732547, 'tol': 4.6702727569381046e-05, 'validation_fraction': 0.41373977796673633}]
function_evaluation time 0.715696 value -0.892308 suggestion {'alpha': 0.009536424530042843, 'batch_size': 161, 'beta_1': 0.6198310995237467, 'beta_2': 0.9999930115046256, 'epsilon': 1.6796055587589752e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.0030916709979732547, 'tol': 4.6702727569381046e-05, 'validation_fraction': 0.41373977796673633}
observation time 0.000009, current best -0.916484 at iter 40
suggestion time taken 0.012825 iter 41 next_points [{'alpha': 0.0002741038928374, 'batch_size': 208, 'beta_1': 0.9244343501326305, 'beta_2': 0.9999978804231016, 'epsilon': 2.3888752251866993e-07, 'hidden_layer_sizes': 119, 'learning_rate_init': 1.0858724642791215e-05, 'tol': 0.0017165896108850896, 'validation_fraction': 0.32065498631527534}]
function_evaluation time 0.367181 value -0.472527 suggestion {'alpha': 0.0002741038928374, 'batch_size': 208, 'beta_1': 0.9244343501326305, 'beta_2': 0.9999978804231016, 'epsilon': 2.3888752251866993e-07, 'hidden_layer_sizes': 119, 'learning_rate_init': 1.0858724642791215e-05, 'tol': 0.0017165896108850896, 'validation_fraction': 0.32065498631527534}
observation time 0.000003, current best -0.916484 at iter 41
suggestion time taken 0.009512 iter 42 next_points [{'alpha': 1.1682958609245775, 'batch_size': 123, 'beta_1': 0.8628815416766463, 'beta_2': 0.9999959325747473, 'epsilon': 1.2531293858367384e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 8.644800216770362e-05, 'tol': 6.27277818832855e-05, 'validation_fraction': 0.8553404321506243}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.223674 value -0.527473 suggestion {'alpha': 1.1682958609245775, 'batch_size': 123, 'beta_1': 0.8628815416766463, 'beta_2': 0.9999959325747473, 'epsilon': 1.2531293858367384e-08, 'hidden_layer_sizes': 115, 'learning_rate_init': 8.644800216770362e-05, 'tol': 6.27277818832855e-05, 'validation_fraction': 0.8553404321506243}
observation time 0.000004, current best -0.916484 at iter 42
suggestion time taken 0.009923 iter 43 next_points [{'alpha': 0.4451198914424174, 'batch_size': 22, 'beta_1': 0.7454631512511896, 'beta_2': 0.999988121731973, 'epsilon': 5.602932243208248e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 8.525982748155973e-05, 'tol': 0.049885898478673, 'validation_fraction': 0.6293709654110735}]
function_evaluation time 0.932449 value -0.564835 suggestion {'alpha': 0.4451198914424174, 'batch_size': 22, 'beta_1': 0.7454631512511896, 'beta_2': 0.999988121731973, 'epsilon': 5.602932243208248e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 8.525982748155973e-05, 'tol': 0.049885898478673, 'validation_fraction': 0.6293709654110735}
observation time 0.000003, current best -0.916484 at iter 43
suggestion time taken 0.009631 iter 44 next_points [{'alpha': 0.017348687625175798, 'batch_size': 164, 'beta_1': 0.9574638456488456, 'beta_2': 0.999865860182474, 'epsilon': 8.508774345667457e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 1.2164738866577734e-05, 'tol': 0.0465604350886811, 'validation_fraction': 0.4021447364643259}]
function_evaluation time 0.395369 value -0.560440 suggestion {'alpha': 0.017348687625175798, 'batch_size': 164, 'beta_1': 0.9574638456488456, 'beta_2': 0.999865860182474, 'epsilon': 8.508774345667457e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 1.2164738866577734e-05, 'tol': 0.0465604350886811, 'validation_fraction': 0.4021447364643259}
observation time 0.000039, current best -0.916484 at iter 44
saving meta data: {'args': {'--uuid': '0d1c85c29be652ee80107c5ff74369d7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
