running: {'--uuid': '075efa4de21257bf87c701e8c6127bbe', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 075efa4de21257bf87c701e8c6127bbe -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.013541 iter 0 next_points [{'alpha': 0.004819833789902688, 'batch_size': 34, 'beta_1': 0.8532477961280406, 'beta_2': 0.9999676679149796, 'epsilon': 6.142738880113384e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.004565357736170413, 'tol': 0.09084491816230225, 'validation_fraction': 0.8213038331608697}]
function_evaluation time 0.628120 value -0.905495 suggestion {'alpha': 0.004819833789902688, 'batch_size': 34, 'beta_1': 0.8532477961280406, 'beta_2': 0.9999676679149796, 'epsilon': 6.142738880113384e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.004565357736170413, 'tol': 0.09084491816230225, 'validation_fraction': 0.8213038331608697}
observation time 0.000005, current best -0.905495 at iter 0
suggestion time taken 0.011852 iter 1 next_points [{'alpha': 0.1866201779723669, 'batch_size': 245, 'beta_1': 0.7375934210608871, 'beta_2': 0.9996757545696444, 'epsilon': 1.133591439722207e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 2.4915539918216097e-05, 'tol': 0.02512384275294835, 'validation_fraction': 0.3381253425457602}]
function_evaluation time 0.304051 value -0.527473 suggestion {'alpha': 0.1866201779723669, 'batch_size': 245, 'beta_1': 0.7375934210608871, 'beta_2': 0.9996757545696444, 'epsilon': 1.133591439722207e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 2.4915539918216097e-05, 'tol': 0.02512384275294835, 'validation_fraction': 0.3381253425457602}
observation time 0.000006, current best -0.905495 at iter 1
suggestion time taken 0.011299 iter 2 next_points [{'alpha': 6.075741561825569e-05, 'batch_size': 34, 'beta_1': 0.5952304592918304, 'beta_2': 0.9999974432916743, 'epsilon': 6.701067534750167e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 5.6078951537909204e-05, 'tol': 0.00012793190122758853, 'validation_fraction': 0.36571852044038256}]
function_evaluation time 1.500029 value -0.679121 suggestion {'alpha': 6.075741561825569e-05, 'batch_size': 34, 'beta_1': 0.5952304592918304, 'beta_2': 0.9999974432916743, 'epsilon': 6.701067534750167e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 5.6078951537909204e-05, 'tol': 0.00012793190122758853, 'validation_fraction': 0.36571852044038256}
observation time 0.000008, current best -0.905495 at iter 2
suggestion time taken 0.011754 iter 3 next_points [{'alpha': 0.0005200110836006066, 'batch_size': 127, 'beta_1': 0.9672894967565167, 'beta_2': 0.9999068247381105, 'epsilon': 8.282692273236213e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.003500488048173032, 'tol': 0.0006664296205496785, 'validation_fraction': 0.35829332031320665}]
function_evaluation time 0.842148 value -0.907692 suggestion {'alpha': 0.0005200110836006066, 'batch_size': 127, 'beta_1': 0.9672894967565167, 'beta_2': 0.9999068247381105, 'epsilon': 8.282692273236213e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 0.003500488048173032, 'tol': 0.0006664296205496785, 'validation_fraction': 0.35829332031320665}
observation time 0.000005, current best -0.907692 at iter 3
suggestion time taken 0.010746 iter 4 next_points [{'alpha': 0.0003271737403365235, 'batch_size': 47, 'beta_1': 0.9280080009230234, 'beta_2': 0.9971524712213139, 'epsilon': 2.7145033207325633e-07, 'hidden_layer_sizes': 144, 'learning_rate_init': 1.122935069977108e-05, 'tol': 0.004085092711469391, 'validation_fraction': 0.12123658990417606}]
function_evaluation time 0.684197 value -0.461538 suggestion {'alpha': 0.0003271737403365235, 'batch_size': 47, 'beta_1': 0.9280080009230234, 'beta_2': 0.9971524712213139, 'epsilon': 2.7145033207325633e-07, 'hidden_layer_sizes': 144, 'learning_rate_init': 1.122935069977108e-05, 'tol': 0.004085092711469391, 'validation_fraction': 0.12123658990417606}
observation time 0.000004, current best -0.907692 at iter 4
suggestion time taken 0.010792 iter 5 next_points [{'alpha': 0.006392322769204401, 'batch_size': 238, 'beta_1': 0.8122825130463177, 'beta_2': 0.9712535935170981, 'epsilon': 4.007646470065977e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 1.016490495494247e-05, 'tol': 0.02422496737276898, 'validation_fraction': 0.8764617373418543}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.344420 value -0.472527 suggestion {'alpha': 0.006392322769204401, 'batch_size': 238, 'beta_1': 0.8122825130463177, 'beta_2': 0.9712535935170981, 'epsilon': 4.007646470065977e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 1.016490495494247e-05, 'tol': 0.02422496737276898, 'validation_fraction': 0.8764617373418543}
observation time 0.000007, current best -0.907692 at iter 5
suggestion time taken 0.011452 iter 6 next_points [{'alpha': 1.7463441407282092, 'batch_size': 223, 'beta_1': 0.9583951053547483, 'beta_2': 0.9856304497622083, 'epsilon': 8.051169530186875e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.005190183252941966, 'tol': 0.008096757992611758, 'validation_fraction': 0.5065838608783004}]
function_evaluation time 0.617200 value -0.907692 suggestion {'alpha': 1.7463441407282092, 'batch_size': 223, 'beta_1': 0.9583951053547483, 'beta_2': 0.9856304497622083, 'epsilon': 8.051169530186875e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.005190183252941966, 'tol': 0.008096757992611758, 'validation_fraction': 0.5065838608783004}
observation time 0.000004, current best -0.907692 at iter 6
suggestion time taken 0.010998 iter 7 next_points [{'alpha': 0.0360153992198473, 'batch_size': 23, 'beta_1': 0.9756510884628157, 'beta_2': 0.9977279344658058, 'epsilon': 2.5990103645971155e-08, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.01632173701543121, 'tol': 3.513517714031415e-05, 'validation_fraction': 0.35530363930259073}]
function_evaluation time 2.729066 value -0.903297 suggestion {'alpha': 0.0360153992198473, 'batch_size': 23, 'beta_1': 0.9756510884628157, 'beta_2': 0.9977279344658058, 'epsilon': 2.5990103645971155e-08, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.01632173701543121, 'tol': 3.513517714031415e-05, 'validation_fraction': 0.35530363930259073}
observation time 0.000010, current best -0.907692 at iter 7
suggestion time taken 0.012166 iter 8 next_points [{'alpha': 3.428424315076323, 'batch_size': 47, 'beta_1': 0.8190038234165774, 'beta_2': 0.9995251571401882, 'epsilon': 7.342519889436126e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.015002163084259858, 'tol': 5.350111927204731e-05, 'validation_fraction': 0.8226367296452827}]
function_evaluation time 0.641131 value -0.909890 suggestion {'alpha': 3.428424315076323, 'batch_size': 47, 'beta_1': 0.8190038234165774, 'beta_2': 0.9995251571401882, 'epsilon': 7.342519889436126e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.015002163084259858, 'tol': 5.350111927204731e-05, 'validation_fraction': 0.8226367296452827}
observation time 0.000009, current best -0.909890 at iter 8
suggestion time taken 0.014408 iter 9 next_points [{'alpha': 0.00025907799072522855, 'batch_size': 141, 'beta_1': 0.6055684952474707, 'beta_2': 0.9999232663578068, 'epsilon': 5.812295913395301e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00011008955505646589, 'tol': 0.007255395659450584, 'validation_fraction': 0.4717563576529118}]
function_evaluation time 0.660552 value -0.685714 suggestion {'alpha': 0.00025907799072522855, 'batch_size': 141, 'beta_1': 0.6055684952474707, 'beta_2': 0.9999232663578068, 'epsilon': 5.812295913395301e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.00011008955505646589, 'tol': 0.007255395659450584, 'validation_fraction': 0.4717563576529118}
observation time 0.000003, current best -0.909890 at iter 9
suggestion time taken 0.010335 iter 10 next_points [{'alpha': 0.23789213258541553, 'batch_size': 232, 'beta_1': 0.9436045553888434, 'beta_2': 0.9996867824477844, 'epsilon': 5.117058990833811e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.03723761827014275, 'tol': 0.009257403859071402, 'validation_fraction': 0.8234869442313429}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.586590 value -0.795604 suggestion {'alpha': 0.23789213258541553, 'batch_size': 232, 'beta_1': 0.9436045553888434, 'beta_2': 0.9996867824477844, 'epsilon': 5.117058990833811e-08, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.03723761827014275, 'tol': 0.009257403859071402, 'validation_fraction': 0.8234869442313429}
observation time 0.000004, current best -0.909890 at iter 10
suggestion time taken 0.011036 iter 11 next_points [{'alpha': 0.015382305716685106, 'batch_size': 140, 'beta_1': 0.8046945337366824, 'beta_2': 0.98519376196232, 'epsilon': 7.0719675138635785e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.005694726141998913, 'tol': 9.864518678527807e-05, 'validation_fraction': 0.6539572954796041}]
function_evaluation time 0.600949 value -0.905495 suggestion {'alpha': 0.015382305716685106, 'batch_size': 140, 'beta_1': 0.8046945337366824, 'beta_2': 0.98519376196232, 'epsilon': 7.0719675138635785e-09, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.005694726141998913, 'tol': 9.864518678527807e-05, 'validation_fraction': 0.6539572954796041}
observation time 0.000008, current best -0.909890 at iter 11
suggestion time taken 0.011440 iter 12 next_points [{'alpha': 0.11055696501117247, 'batch_size': 178, 'beta_1': 0.5781138863914415, 'beta_2': 0.9999074011319631, 'epsilon': 2.4157007469265724e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 1.1266262819287907e-05, 'tol': 0.00469854609874068, 'validation_fraction': 0.3076586774409677}]
function_evaluation time 0.467260 value -0.527473 suggestion {'alpha': 0.11055696501117247, 'batch_size': 178, 'beta_1': 0.5781138863914415, 'beta_2': 0.9999074011319631, 'epsilon': 2.4157007469265724e-07, 'hidden_layer_sizes': 164, 'learning_rate_init': 1.1266262819287907e-05, 'tol': 0.00469854609874068, 'validation_fraction': 0.3076586774409677}
observation time 0.000033, current best -0.909890 at iter 12
suggestion time taken 0.010677 iter 13 next_points [{'alpha': 0.14821958590812448, 'batch_size': 31, 'beta_1': 0.6978567290408156, 'beta_2': 0.9999985950131236, 'epsilon': 5.139426787912887e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.021304208293450602, 'tol': 9.11348947610454e-05, 'validation_fraction': 0.17138124702228189}]
function_evaluation time 0.888486 value -0.890110 suggestion {'alpha': 0.14821958590812448, 'batch_size': 31, 'beta_1': 0.6978567290408156, 'beta_2': 0.9999985950131236, 'epsilon': 5.139426787912887e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.021304208293450602, 'tol': 9.11348947610454e-05, 'validation_fraction': 0.17138124702228189}
observation time 0.000005, current best -0.909890 at iter 13
suggestion time taken 0.010499 iter 14 next_points [{'alpha': 0.6896491095811368, 'batch_size': 105, 'beta_1': 0.9824320920261534, 'beta_2': 0.9128199987931902, 'epsilon': 1.6620832646102666e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00023094690044582036, 'tol': 8.793931650771507e-05, 'validation_fraction': 0.42312886041002923}]
function_evaluation time 0.392541 value -0.582418 suggestion {'alpha': 0.6896491095811368, 'batch_size': 105, 'beta_1': 0.9824320920261534, 'beta_2': 0.9128199987931902, 'epsilon': 1.6620832646102666e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.00023094690044582036, 'tol': 8.793931650771507e-05, 'validation_fraction': 0.42312886041002923}
observation time 0.000003, current best -0.909890 at iter 14
suggestion time taken 0.010088 iter 15 next_points [{'alpha': 1.2757641578686225e-05, 'batch_size': 158, 'beta_1': 0.7537842472173947, 'beta_2': 0.9999924839927086, 'epsilon': 2.6856906417226983e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.04928781537842319, 'tol': 0.07831391253611274, 'validation_fraction': 0.7280629765384032}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.486246 value -0.903297 suggestion {'alpha': 1.2757641578686225e-05, 'batch_size': 158, 'beta_1': 0.7537842472173947, 'beta_2': 0.9999924839927086, 'epsilon': 2.6856906417226983e-08, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.04928781537842319, 'tol': 0.07831391253611274, 'validation_fraction': 0.7280629765384032}
observation time 0.000009, current best -0.909890 at iter 15
suggestion time taken 0.013574 iter 16 next_points [{'alpha': 0.0017445438013593754, 'batch_size': 160, 'beta_1': 0.9784964733046525, 'beta_2': 0.9371892936758617, 'epsilon': 2.1865980018595244e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 1.0181300321424203e-05, 'tol': 0.004316562753211636, 'validation_fraction': 0.7158392543846913}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.279126 value -0.472527 suggestion {'alpha': 0.0017445438013593754, 'batch_size': 160, 'beta_1': 0.9784964733046525, 'beta_2': 0.9371892936758617, 'epsilon': 2.1865980018595244e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 1.0181300321424203e-05, 'tol': 0.004316562753211636, 'validation_fraction': 0.7158392543846913}
observation time 0.000007, current best -0.909890 at iter 16
suggestion time taken 0.012209 iter 17 next_points [{'alpha': 1.6131732148019802, 'batch_size': 235, 'beta_1': 0.9829863212931024, 'beta_2': 0.9978611892454383, 'epsilon': 7.82477052895417e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 8.011827938220416e-05, 'tol': 8.214237886335474e-05, 'validation_fraction': 0.7735031807584992}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.259257 value -0.446154 suggestion {'alpha': 1.6131732148019802, 'batch_size': 235, 'beta_1': 0.9829863212931024, 'beta_2': 0.9978611892454383, 'epsilon': 7.82477052895417e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 8.011827938220416e-05, 'tol': 8.214237886335474e-05, 'validation_fraction': 0.7735031807584992}
observation time 0.000003, current best -0.909890 at iter 17
suggestion time taken 0.009284 iter 18 next_points [{'alpha': 9.078974204461332e-05, 'batch_size': 50, 'beta_1': 0.9119997736783219, 'beta_2': 0.9217099313402585, 'epsilon': 3.110970492177314e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0003360501316182714, 'tol': 0.054946398944883595, 'validation_fraction': 0.7940154764359728}]
function_evaluation time 0.459646 value -0.621978 suggestion {'alpha': 9.078974204461332e-05, 'batch_size': 50, 'beta_1': 0.9119997736783219, 'beta_2': 0.9217099313402585, 'epsilon': 3.110970492177314e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0003360501316182714, 'tol': 0.054946398944883595, 'validation_fraction': 0.7940154764359728}
observation time 0.000010, current best -0.909890 at iter 18
suggestion time taken 0.012773 iter 19 next_points [{'alpha': 0.9600970989976289, 'batch_size': 73, 'beta_1': 0.962523593208172, 'beta_2': 0.9991383489342387, 'epsilon': 1.538326262370995e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0038503719561660326, 'tol': 2.6548050720941624e-05, 'validation_fraction': 0.8683074201242597}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.529538 value -0.848352 suggestion {'alpha': 0.9600970989976289, 'batch_size': 73, 'beta_1': 0.962523593208172, 'beta_2': 0.9991383489342387, 'epsilon': 1.538326262370995e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0038503719561660326, 'tol': 2.6548050720941624e-05, 'validation_fraction': 0.8683074201242597}
observation time 0.000003, current best -0.909890 at iter 19
suggestion time taken 0.009649 iter 20 next_points [{'alpha': 0.0018821002178870856, 'batch_size': 58, 'beta_1': 0.9702111064149868, 'beta_2': 0.9999976310765667, 'epsilon': 1.6940644396042656e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 1.3725779566645715e-05, 'tol': 0.0021557180017000165, 'validation_fraction': 0.5713343848951}]
function_evaluation time 0.475434 value -0.393407 suggestion {'alpha': 0.0018821002178870856, 'batch_size': 58, 'beta_1': 0.9702111064149868, 'beta_2': 0.9999976310765667, 'epsilon': 1.6940644396042656e-09, 'hidden_layer_sizes': 141, 'learning_rate_init': 1.3725779566645715e-05, 'tol': 0.0021557180017000165, 'validation_fraction': 0.5713343848951}
observation time 0.000004, current best -0.909890 at iter 20
suggestion time taken 0.010746 iter 21 next_points [{'alpha': 8.892263099696719e-05, 'batch_size': 114, 'beta_1': 0.9400888756125824, 'beta_2': 0.9868267674083967, 'epsilon': 6.495958468262744e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.00089685957850229, 'tol': 0.00012270654041469692, 'validation_fraction': 0.17933210534647145}]
function_evaluation time 1.038085 value -0.898901 suggestion {'alpha': 8.892263099696719e-05, 'batch_size': 114, 'beta_1': 0.9400888756125824, 'beta_2': 0.9868267674083967, 'epsilon': 6.495958468262744e-09, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.00089685957850229, 'tol': 0.00012270654041469692, 'validation_fraction': 0.17933210534647145}
observation time 0.000005, current best -0.909890 at iter 21
suggestion time taken 0.012932 iter 22 next_points [{'alpha': 0.0213363999714801, 'batch_size': 111, 'beta_1': 0.8998185039418773, 'beta_2': 0.9683517544287267, 'epsilon': 1.1129641828699934e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 2.9407937860248987e-05, 'tol': 0.0006861936492196324, 'validation_fraction': 0.8942348038132981}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.314393 value -0.582418 suggestion {'alpha': 0.0213363999714801, 'batch_size': 111, 'beta_1': 0.8998185039418773, 'beta_2': 0.9683517544287267, 'epsilon': 1.1129641828699934e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 2.9407937860248987e-05, 'tol': 0.0006861936492196324, 'validation_fraction': 0.8942348038132981}
observation time 0.000009, current best -0.909890 at iter 22
suggestion time taken 0.013577 iter 23 next_points [{'alpha': 0.6838438695743424, 'batch_size': 182, 'beta_1': 0.916054080880421, 'beta_2': 0.9472725555330648, 'epsilon': 1.0946477302457727e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.0397496621785325, 'tol': 0.00031945330918805177, 'validation_fraction': 0.38601504284564125}]
function_evaluation time 0.775205 value -0.898901 suggestion {'alpha': 0.6838438695743424, 'batch_size': 182, 'beta_1': 0.916054080880421, 'beta_2': 0.9472725555330648, 'epsilon': 1.0946477302457727e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.0397496621785325, 'tol': 0.00031945330918805177, 'validation_fraction': 0.38601504284564125}
observation time 0.000009, current best -0.909890 at iter 23
suggestion time taken 0.010880 iter 24 next_points [{'alpha': 1.1806604274484019e-05, 'batch_size': 128, 'beta_1': 0.6629623122943883, 'beta_2': 0.9969339570702437, 'epsilon': 4.785964079429655e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.09603934942349811, 'tol': 0.016387150179599054, 'validation_fraction': 0.11476079898690071}]
function_evaluation time 0.706448 value -0.846154 suggestion {'alpha': 1.1806604274484019e-05, 'batch_size': 128, 'beta_1': 0.6629623122943883, 'beta_2': 0.9969339570702437, 'epsilon': 4.785964079429655e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.09603934942349811, 'tol': 0.016387150179599054, 'validation_fraction': 0.11476079898690071}
observation time 0.000003, current best -0.909890 at iter 24
suggestion time taken 0.013165 iter 25 next_points [{'alpha': 0.0002160031348228465, 'batch_size': 52, 'beta_1': 0.9258123189445123, 'beta_2': 0.9936151928851821, 'epsilon': 2.1425563340899764e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.00012044829466368169, 'tol': 0.012685305090669301, 'validation_fraction': 0.6183545328478787}]
function_evaluation time 0.591421 value -0.736264 suggestion {'alpha': 0.0002160031348228465, 'batch_size': 52, 'beta_1': 0.9258123189445123, 'beta_2': 0.9936151928851821, 'epsilon': 2.1425563340899764e-09, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.00012044829466368169, 'tol': 0.012685305090669301, 'validation_fraction': 0.6183545328478787}
observation time 0.000005, current best -0.909890 at iter 25
suggestion time taken 0.009758 iter 26 next_points [{'alpha': 8.294901194405835e-05, 'batch_size': 200, 'beta_1': 0.9816806169757015, 'beta_2': 0.9999829932487801, 'epsilon': 3.7921217364797634e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0006940500369143075, 'tol': 0.06936770121457546, 'validation_fraction': 0.2080922636079298}]
function_evaluation time 0.582502 value -0.760440 suggestion {'alpha': 8.294901194405835e-05, 'batch_size': 200, 'beta_1': 0.9816806169757015, 'beta_2': 0.9999829932487801, 'epsilon': 3.7921217364797634e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0006940500369143075, 'tol': 0.06936770121457546, 'validation_fraction': 0.2080922636079298}
observation time 0.000005, current best -0.909890 at iter 26
suggestion time taken 0.013301 iter 27 next_points [{'alpha': 0.008432422605712307, 'batch_size': 23, 'beta_1': 0.7920182436990207, 'beta_2': 0.999882683843157, 'epsilon': 2.217527409733618e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.013265922583254425, 'tol': 0.07770827187588139, 'validation_fraction': 0.1343424933741627}]
function_evaluation time 0.867884 value -0.909890 suggestion {'alpha': 0.008432422605712307, 'batch_size': 23, 'beta_1': 0.7920182436990207, 'beta_2': 0.999882683843157, 'epsilon': 2.217527409733618e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.013265922583254425, 'tol': 0.07770827187588139, 'validation_fraction': 0.1343424933741627}
observation time 0.000004, current best -0.909890 at iter 27
suggestion time taken 0.013368 iter 28 next_points [{'alpha': 0.48826479323446065, 'batch_size': 218, 'beta_1': 0.9891862006355147, 'beta_2': 0.9999983047257723, 'epsilon': 1.4563494512573767e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 2.254529444407011e-05, 'tol': 0.01102397862837932, 'validation_fraction': 0.5894113724691562}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.377430 value -0.470330 suggestion {'alpha': 0.48826479323446065, 'batch_size': 218, 'beta_1': 0.9891862006355147, 'beta_2': 0.9999983047257723, 'epsilon': 1.4563494512573767e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 2.254529444407011e-05, 'tol': 0.01102397862837932, 'validation_fraction': 0.5894113724691562}
observation time 0.000004, current best -0.909890 at iter 28
suggestion time taken 0.010568 iter 29 next_points [{'alpha': 0.0011929993469168682, 'batch_size': 54, 'beta_1': 0.9458696225281777, 'beta_2': 0.9624936176507881, 'epsilon': 3.075450761998276e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0001444206238119989, 'tol': 0.007093872049031381, 'validation_fraction': 0.5952469466371211}]
function_evaluation time 0.918412 value -0.635165 suggestion {'alpha': 0.0011929993469168682, 'batch_size': 54, 'beta_1': 0.9458696225281777, 'beta_2': 0.9624936176507881, 'epsilon': 3.075450761998276e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0001444206238119989, 'tol': 0.007093872049031381, 'validation_fraction': 0.5952469466371211}
observation time 0.000004, current best -0.909890 at iter 29
suggestion time taken 0.010697 iter 30 next_points [{'alpha': 0.000890412918002487, 'batch_size': 21, 'beta_1': 0.9427515155186784, 'beta_2': 0.9985964567314463, 'epsilon': 1.2352768573741877e-09, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.0034151707501564707, 'tol': 0.0006096714964763032, 'validation_fraction': 0.8025639710602395}]
function_evaluation time 1.025148 value -0.905495 suggestion {'alpha': 0.000890412918002487, 'batch_size': 21, 'beta_1': 0.9427515155186784, 'beta_2': 0.9985964567314463, 'epsilon': 1.2352768573741877e-09, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.0034151707501564707, 'tol': 0.0006096714964763032, 'validation_fraction': 0.8025639710602395}
observation time 0.000005, current best -0.909890 at iter 30
suggestion time taken 0.010780 iter 31 next_points [{'alpha': 7.004453132423254, 'batch_size': 164, 'beta_1': 0.8358209586950202, 'beta_2': 0.9999767738776885, 'epsilon': 8.065393843344428e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0006227908818118669, 'tol': 0.0013733180175919488, 'validation_fraction': 0.7048432122143047}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.663262 value -0.736264 suggestion {'alpha': 7.004453132423254, 'batch_size': 164, 'beta_1': 0.8358209586950202, 'beta_2': 0.9999767738776885, 'epsilon': 8.065393843344428e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.0006227908818118669, 'tol': 0.0013733180175919488, 'validation_fraction': 0.7048432122143047}
observation time 0.000004, current best -0.909890 at iter 31
suggestion time taken 0.010977 iter 32 next_points [{'alpha': 0.27195211093483523, 'batch_size': 51, 'beta_1': 0.9787074334772261, 'beta_2': 0.9999854670943711, 'epsilon': 9.056970655448062e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.01648098261690605, 'tol': 3.287497127700212e-05, 'validation_fraction': 0.20129741823894293}]
function_evaluation time 1.219341 value -0.905495 suggestion {'alpha': 0.27195211093483523, 'batch_size': 51, 'beta_1': 0.9787074334772261, 'beta_2': 0.9999854670943711, 'epsilon': 9.056970655448062e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.01648098261690605, 'tol': 3.287497127700212e-05, 'validation_fraction': 0.20129741823894293}
observation time 0.000012, current best -0.909890 at iter 32
suggestion time taken 0.013835 iter 33 next_points [{'alpha': 0.1471982306729847, 'batch_size': 84, 'beta_1': 0.848382230435311, 'beta_2': 0.9988846478199106, 'epsilon': 4.012232139712344e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 1.429057273530165e-05, 'tol': 0.007488684553592763, 'validation_fraction': 0.40328472883910366}]
function_evaluation time 0.613987 value -0.531868 suggestion {'alpha': 0.1471982306729847, 'batch_size': 84, 'beta_1': 0.848382230435311, 'beta_2': 0.9988846478199106, 'epsilon': 4.012232139712344e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 1.429057273530165e-05, 'tol': 0.007488684553592763, 'validation_fraction': 0.40328472883910366}
observation time 0.000003, current best -0.909890 at iter 33
suggestion time taken 0.009690 iter 34 next_points [{'alpha': 0.20720994815252744, 'batch_size': 70, 'beta_1': 0.6327354125483848, 'beta_2': 0.9991253893789996, 'epsilon': 8.270141473242775e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.020606821596105593, 'tol': 0.0011540844555963045, 'validation_fraction': 0.3872803682364931}]
function_evaluation time 0.842994 value -0.914286 suggestion {'alpha': 0.20720994815252744, 'batch_size': 70, 'beta_1': 0.6327354125483848, 'beta_2': 0.9991253893789996, 'epsilon': 8.270141473242775e-08, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.020606821596105593, 'tol': 0.0011540844555963045, 'validation_fraction': 0.3872803682364931}
observation time 0.000004, current best -0.914286 at iter 34
suggestion time taken 0.010381 iter 35 next_points [{'alpha': 5.423692708350828e-05, 'batch_size': 246, 'beta_1': 0.9475427407166058, 'beta_2': 0.9998502658511761, 'epsilon': 1.1921926199378348e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.003507696480353141, 'tol': 0.0048545824605300235, 'validation_fraction': 0.8621837897644277}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.385192 value -0.802198 suggestion {'alpha': 5.423692708350828e-05, 'batch_size': 246, 'beta_1': 0.9475427407166058, 'beta_2': 0.9998502658511761, 'epsilon': 1.1921926199378348e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.003507696480353141, 'tol': 0.0048545824605300235, 'validation_fraction': 0.8621837897644277}
observation time 0.000004, current best -0.914286 at iter 35
suggestion time taken 0.011379 iter 36 next_points [{'alpha': 0.0022153727214883926, 'batch_size': 73, 'beta_1': 0.581378605643158, 'beta_2': 0.927495206442648, 'epsilon': 2.6184406786804635e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.020175110778956805, 'tol': 7.125311224551216e-05, 'validation_fraction': 0.6139050973251348}]
function_evaluation time 0.694671 value -0.909890 suggestion {'alpha': 0.0022153727214883926, 'batch_size': 73, 'beta_1': 0.581378605643158, 'beta_2': 0.927495206442648, 'epsilon': 2.6184406786804635e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.020175110778956805, 'tol': 7.125311224551216e-05, 'validation_fraction': 0.6139050973251348}
observation time 0.000003, current best -0.914286 at iter 36
suggestion time taken 0.009597 iter 37 next_points [{'alpha': 0.07671274207828113, 'batch_size': 33, 'beta_1': 0.8430113216380462, 'beta_2': 0.9995290910889358, 'epsilon': 3.1502926315229e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0010889082752728832, 'tol': 0.0007880019823565341, 'validation_fraction': 0.7187722110306793}]
function_evaluation time 1.099916 value -0.912088 suggestion {'alpha': 0.07671274207828113, 'batch_size': 33, 'beta_1': 0.8430113216380462, 'beta_2': 0.9995290910889358, 'epsilon': 3.1502926315229e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.0010889082752728832, 'tol': 0.0007880019823565341, 'validation_fraction': 0.7187722110306793}
observation time 0.000003, current best -0.914286 at iter 37
suggestion time taken 0.009898 iter 38 next_points [{'alpha': 0.0021892939802867144, 'batch_size': 241, 'beta_1': 0.9387150803603269, 'beta_2': 0.9893853523398214, 'epsilon': 4.171050485858713e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.0011301956003799136, 'tol': 3.1803659013158016e-05, 'validation_fraction': 0.10746471359158627}]
function_evaluation time 1.143064 value -0.907692 suggestion {'alpha': 0.0021892939802867144, 'batch_size': 241, 'beta_1': 0.9387150803603269, 'beta_2': 0.9893853523398214, 'epsilon': 4.171050485858713e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.0011301956003799136, 'tol': 3.1803659013158016e-05, 'validation_fraction': 0.10746471359158627}
observation time 0.000004, current best -0.914286 at iter 38
suggestion time taken 0.010151 iter 39 next_points [{'alpha': 2.7480033783181013e-05, 'batch_size': 197, 'beta_1': 0.9624004402951253, 'beta_2': 0.9999926246275412, 'epsilon': 6.636928472326581e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0030678122976519544, 'tol': 0.013892424877046986, 'validation_fraction': 0.7969908781153986}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.588638 value -0.912088 suggestion {'alpha': 2.7480033783181013e-05, 'batch_size': 197, 'beta_1': 0.9624004402951253, 'beta_2': 0.9999926246275412, 'epsilon': 6.636928472326581e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0030678122976519544, 'tol': 0.013892424877046986, 'validation_fraction': 0.7969908781153986}
observation time 0.000004, current best -0.914286 at iter 39
suggestion time taken 0.011171 iter 40 next_points [{'alpha': 9.039351459276157, 'batch_size': 21, 'beta_1': 0.7659355299868833, 'beta_2': 0.9941949675125987, 'epsilon': 2.0954501503569168e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.03185352045611508, 'tol': 4.045478480180401e-05, 'validation_fraction': 0.8071510058402406}]
function_evaluation time 0.971392 value -0.898901 suggestion {'alpha': 9.039351459276157, 'batch_size': 21, 'beta_1': 0.7659355299868833, 'beta_2': 0.9941949675125987, 'epsilon': 2.0954501503569168e-08, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.03185352045611508, 'tol': 4.045478480180401e-05, 'validation_fraction': 0.8071510058402406}
observation time 0.000009, current best -0.914286 at iter 40
suggestion time taken 0.013527 iter 41 next_points [{'alpha': 0.02283884807387392, 'batch_size': 90, 'beta_1': 0.9267696341165078, 'beta_2': 0.9999989117866526, 'epsilon': 4.4161324326906534e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.00014276784554887074, 'tol': 1.2308829971511262e-05, 'validation_fraction': 0.8845844880817239}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.325091 value -0.637363 suggestion {'alpha': 0.02283884807387392, 'batch_size': 90, 'beta_1': 0.9267696341165078, 'beta_2': 0.9999989117866526, 'epsilon': 4.4161324326906534e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.00014276784554887074, 'tol': 1.2308829971511262e-05, 'validation_fraction': 0.8845844880817239}
observation time 0.000006, current best -0.914286 at iter 41
suggestion time taken 0.011007 iter 42 next_points [{'alpha': 0.07436368403235515, 'batch_size': 36, 'beta_1': 0.8474451738140545, 'beta_2': 0.99945504384624, 'epsilon': 6.405432412190076e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.00021510791904456154, 'tol': 0.005843015496156847, 'validation_fraction': 0.8891142523153819}]
function_evaluation time 0.374136 value -0.679121 suggestion {'alpha': 0.07436368403235515, 'batch_size': 36, 'beta_1': 0.8474451738140545, 'beta_2': 0.99945504384624, 'epsilon': 6.405432412190076e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.00021510791904456154, 'tol': 0.005843015496156847, 'validation_fraction': 0.8891142523153819}
observation time 0.000004, current best -0.914286 at iter 42
suggestion time taken 0.011206 iter 43 next_points [{'alpha': 5.900139599766731, 'batch_size': 27, 'beta_1': 0.8141168463358655, 'beta_2': 0.9975904097218962, 'epsilon': 4.999063280286878e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.0019324737157594345, 'tol': 6.6128444915493e-05, 'validation_fraction': 0.7685263746872636}]
function_evaluation time 0.918713 value -0.898901 suggestion {'alpha': 5.900139599766731, 'batch_size': 27, 'beta_1': 0.8141168463358655, 'beta_2': 0.9975904097218962, 'epsilon': 4.999063280286878e-08, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.0019324737157594345, 'tol': 6.6128444915493e-05, 'validation_fraction': 0.7685263746872636}
observation time 0.000004, current best -0.914286 at iter 43
suggestion time taken 0.011656 iter 44 next_points [{'alpha': 0.005231313841488189, 'batch_size': 53, 'beta_1': 0.9745248090079268, 'beta_2': 0.9879935451018094, 'epsilon': 3.253396456424443e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.0406865829484705, 'tol': 7.9820716320691e-05, 'validation_fraction': 0.18447639356895126}]
function_evaluation time 0.620838 value -0.907692 suggestion {'alpha': 0.005231313841488189, 'batch_size': 53, 'beta_1': 0.9745248090079268, 'beta_2': 0.9879935451018094, 'epsilon': 3.253396456424443e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.0406865829484705, 'tol': 7.9820716320691e-05, 'validation_fraction': 0.18447639356895126}
observation time 0.000004, current best -0.914286 at iter 44
saving meta data: {'args': {'--uuid': '075efa4de21257bf87c701e8c6127bbe', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
