running: {'--uuid': '7c6d82cc4e195cd493b9564b3dc6880f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python strongcvx/optimizer.py -c MLP-adam -d breast -o strongcvx -u 7c6d82cc4e195cd493b9564b3dc6880f -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study strongcvx MLP-adam breast acc 45 1
with data root: None
suggestion time taken 19.615486 iter 0 next_points [{'alpha': 0.00012760647963215598, 'batch_size': 150, 'beta_1': 0.98965129515872, 'beta_2': 0.9999940898455945, 'epsilon': 2.1720304115399293e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0009852983402088363, 'tol': 0.00015821987259642488, 'validation_fraction': 0.3906384988305472}]
function_evaluation time 0.496891 value -0.800000 suggestion {'alpha': 0.00012760647963215598, 'batch_size': 150, 'beta_1': 0.98965129515872, 'beta_2': 0.9999940898455945, 'epsilon': 2.1720304115399293e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.0009852983402088363, 'tol': 0.00015821987259642488, 'validation_fraction': 0.3906384988305472}
observation time 0.000006, current best -0.800000 at iter 0
suggestion time taken 19.275244 iter 1 next_points [{'alpha': 0.365727033600218, 'batch_size': 25, 'beta_1': 0.845080005416389, 'beta_2': 0.9992303384215511, 'epsilon': 1.6008268592689774e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.05424421820639943, 'tol': 4.697685700083762e-05, 'validation_fraction': 0.37261476508076646}]
function_evaluation time 2.092885 value -0.912088 suggestion {'alpha': 0.365727033600218, 'batch_size': 25, 'beta_1': 0.845080005416389, 'beta_2': 0.9992303384215511, 'epsilon': 1.6008268592689774e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.05424421820639943, 'tol': 4.697685700083762e-05, 'validation_fraction': 0.37261476508076646}
observation time 0.000005, current best -0.912088 at iter 1
suggestion time taken 18.737872 iter 2 next_points [{'alpha': 9.772040515378912e-05, 'batch_size': 150, 'beta_1': 0.9591694759374128, 'beta_2': 0.9685941480911124, 'epsilon': 2.5207179184809173e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.001605952903061822, 'tol': 2.0307427955184023e-05, 'validation_fraction': 0.19111377203231433}]
function_evaluation time 1.070959 value -0.852747 suggestion {'alpha': 9.772040515378912e-05, 'batch_size': 150, 'beta_1': 0.9591694759374128, 'beta_2': 0.9685941480911124, 'epsilon': 2.5207179184809173e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.001605952903061822, 'tol': 2.0307427955184023e-05, 'validation_fraction': 0.19111377203231433}
observation time 0.000006, current best -0.912088 at iter 2
suggestion time taken 19.581155 iter 3 next_points [{'alpha': 0.1032589358588636, 'batch_size': 15, 'beta_1': 0.6609549643119111, 'beta_2': 0.9964463929819988, 'epsilon': 9.1522290152668e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.012210492560054487, 'tol': 0.0951792738223097, 'validation_fraction': 0.1467542540544886}]
function_evaluation time 0.731809 value -0.901099 suggestion {'alpha': 0.1032589358588636, 'batch_size': 15, 'beta_1': 0.6609549643119111, 'beta_2': 0.9964463929819988, 'epsilon': 9.1522290152668e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.012210492560054487, 'tol': 0.0951792738223097, 'validation_fraction': 0.1467542540544886}
observation time 0.000004, current best -0.912088 at iter 3
suggestion time taken 19.602556 iter 4 next_points [{'alpha': 0.025676381147264952, 'batch_size': 227, 'beta_1': 0.9602019071667754, 'beta_2': 0.9513731102419899, 'epsilon': 2.1984807383878237e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.00014824479666214813, 'tol': 3.304871599938807e-05, 'validation_fraction': 0.30735413405746276}]
function_evaluation time 0.619102 value -0.672527 suggestion {'alpha': 0.025676381147264952, 'batch_size': 227, 'beta_1': 0.9602019071667754, 'beta_2': 0.9513731102419899, 'epsilon': 2.1984807383878237e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.00014824479666214813, 'tol': 3.304871599938807e-05, 'validation_fraction': 0.30735413405746276}
observation time 0.000005, current best -0.912088 at iter 4
suggestion time taken 19.723112 iter 5 next_points [{'alpha': 0.0001312082137594818, 'batch_size': 11, 'beta_1': 0.6705458959638252, 'beta_2': 0.9999973777889621, 'epsilon': 1.191189514052635e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.0004990100595053056, 'tol': 0.006388328014147432, 'validation_fraction': 0.8163342723179787}]
function_evaluation time 1.611790 value -0.903297 suggestion {'alpha': 0.0001312082137594818, 'batch_size': 11, 'beta_1': 0.6705458959638252, 'beta_2': 0.9999973777889621, 'epsilon': 1.191189514052635e-09, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.0004990100595053056, 'tol': 0.006388328014147432, 'validation_fraction': 0.8163342723179787}
observation time 0.000006, current best -0.912088 at iter 5
suggestion time taken 20.179989 iter 6 next_points [{'alpha': 0.13779092557246242, 'batch_size': 113, 'beta_1': 0.9264746286627545, 'beta_2': 0.999997423266892, 'epsilon': 2.665623846270141e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.00021329266237326641, 'tol': 3.3953338528358786e-05, 'validation_fraction': 0.2513235094702417}]
function_evaluation time 0.745632 value -0.685714 suggestion {'alpha': 0.13779092557246242, 'batch_size': 113, 'beta_1': 0.9264746286627545, 'beta_2': 0.999997423266892, 'epsilon': 2.665623846270141e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.00021329266237326641, 'tol': 3.3953338528358786e-05, 'validation_fraction': 0.2513235094702417}
observation time 0.000005, current best -0.912088 at iter 6
suggestion time taken 18.619078 iter 7 next_points [{'alpha': 0.02043232530986044, 'batch_size': 151, 'beta_1': 0.9843965308684159, 'beta_2': 0.9999949117774352, 'epsilon': 8.833715980634875e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 1.3204093115614616e-05, 'tol': 7.642240340881855e-05, 'validation_fraction': 0.49371624820095283}]
function_evaluation time 0.409984 value -0.527473 suggestion {'alpha': 0.02043232530986044, 'batch_size': 151, 'beta_1': 0.9843965308684159, 'beta_2': 0.9999949117774352, 'epsilon': 8.833715980634875e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 1.3204093115614616e-05, 'tol': 7.642240340881855e-05, 'validation_fraction': 0.49371624820095283}
observation time 0.000007, current best -0.912088 at iter 7
suggestion time taken 20.243271 iter 8 next_points [{'alpha': 0.03056631662215319, 'batch_size': 30, 'beta_1': 0.9710739242937814, 'beta_2': 0.9999921649642056, 'epsilon': 2.6610428871262575e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 3.624924892315277e-05, 'tol': 0.07985811898730978, 'validation_fraction': 0.5282445955686317}]
function_evaluation time 0.763470 value -0.551648 suggestion {'alpha': 0.03056631662215319, 'batch_size': 30, 'beta_1': 0.9710739242937814, 'beta_2': 0.9999921649642056, 'epsilon': 2.6610428871262575e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 3.624924892315277e-05, 'tol': 0.07985811898730978, 'validation_fraction': 0.5282445955686317}
observation time 0.000006, current best -0.912088 at iter 8
suggestion time taken 20.443774 iter 9 next_points [{'alpha': 0.0014092571802549003, 'batch_size': 18, 'beta_1': 0.7930405870995663, 'beta_2': 0.9858815606549595, 'epsilon': 3.2069466948056645e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 1.4284888220352328e-05, 'tol': 9.12767337580803e-05, 'validation_fraction': 0.45024880388728306}]
function_evaluation time 2.737964 value -0.558242 suggestion {'alpha': 0.0014092571802549003, 'batch_size': 18, 'beta_1': 0.7930405870995663, 'beta_2': 0.9858815606549595, 'epsilon': 3.2069466948056645e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 1.4284888220352328e-05, 'tol': 9.12767337580803e-05, 'validation_fraction': 0.45024880388728306}
observation time 0.000004, current best -0.912088 at iter 9
suggestion time taken 19.688691 iter 10 next_points [{'alpha': 5.4099714751799574e-05, 'batch_size': 25, 'beta_1': 0.9489130444321558, 'beta_2': 0.9999385315095831, 'epsilon': 3.449576381504797e-08, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0017788618235042297, 'tol': 0.00034154415640906576, 'validation_fraction': 0.12190595119855198}]
function_evaluation time 1.297590 value -0.918681 suggestion {'alpha': 5.4099714751799574e-05, 'batch_size': 25, 'beta_1': 0.9489130444321558, 'beta_2': 0.9999385315095831, 'epsilon': 3.449576381504797e-08, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.0017788618235042297, 'tol': 0.00034154415640906576, 'validation_fraction': 0.12190595119855198}
observation time 0.000006, current best -0.918681 at iter 10
suggestion time taken 20.603953 iter 11 next_points [{'alpha': 0.4099845958598141, 'batch_size': 10, 'beta_1': 0.8285536331720311, 'beta_2': 0.999996518437594, 'epsilon': 4.500091600771894e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.09298578755562222, 'tol': 0.023085320869617357, 'validation_fraction': 0.16334076053659036}]
function_evaluation time 3.223888 value -0.916484 suggestion {'alpha': 0.4099845958598141, 'batch_size': 10, 'beta_1': 0.8285536331720311, 'beta_2': 0.999996518437594, 'epsilon': 4.500091600771894e-09, 'hidden_layer_sizes': 146, 'learning_rate_init': 0.09298578755562222, 'tol': 0.023085320869617357, 'validation_fraction': 0.16334076053659036}
observation time 0.000016, current best -0.918681 at iter 11
suggestion time taken 19.462480 iter 12 next_points [{'alpha': 7.973388623126631e-05, 'batch_size': 113, 'beta_1': 0.8713556758473786, 'beta_2': 0.9999984024042051, 'epsilon': 4.920299273831429e-08, 'hidden_layer_sizes': 195, 'learning_rate_init': 6.905899314265965e-05, 'tol': 0.026210652271596375, 'validation_fraction': 0.5859860047523712}]
function_evaluation time 0.433721 value -0.507692 suggestion {'alpha': 7.973388623126631e-05, 'batch_size': 113, 'beta_1': 0.8713556758473786, 'beta_2': 0.9999984024042051, 'epsilon': 4.920299273831429e-08, 'hidden_layer_sizes': 195, 'learning_rate_init': 6.905899314265965e-05, 'tol': 0.026210652271596375, 'validation_fraction': 0.5859860047523712}
observation time 0.000014, current best -0.918681 at iter 12
suggestion time taken 19.775240 iter 13 next_points [{'alpha': 0.0009383610494924781, 'batch_size': 227, 'beta_1': 0.5136502313856418, 'beta_2': 0.9999483496324985, 'epsilon': 1.4517732552171152e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 4.368554111704815e-05, 'tol': 0.030089085415589724, 'validation_fraction': 0.8516126371555147}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.261529 value -0.472527 suggestion {'alpha': 0.0009383610494924781, 'batch_size': 227, 'beta_1': 0.5136502313856418, 'beta_2': 0.9999483496324985, 'epsilon': 1.4517732552171152e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 4.368554111704815e-05, 'tol': 0.030089085415589724, 'validation_fraction': 0.8516126371555147}
observation time 0.000006, current best -0.918681 at iter 13
suggestion time taken 19.213263 iter 14 next_points [{'alpha': 2.7101845836948693e-05, 'batch_size': 227, 'beta_1': 0.6774318685963745, 'beta_2': 0.9999980058159272, 'epsilon': 3.873267348317267e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.00027775820281235417, 'tol': 0.0725682721934714, 'validation_fraction': 0.2839391952616059}]
function_evaluation time 0.478764 value -0.773626 suggestion {'alpha': 2.7101845836948693e-05, 'batch_size': 227, 'beta_1': 0.6774318685963745, 'beta_2': 0.9999980058159272, 'epsilon': 3.873267348317267e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.00027775820281235417, 'tol': 0.0725682721934714, 'validation_fraction': 0.2839391952616059}
observation time 0.000005, current best -0.918681 at iter 14
suggestion time taken 20.493129 iter 15 next_points [{'alpha': 0.0036285196196060828, 'batch_size': 227, 'beta_1': 0.9806716201603329, 'beta_2': 0.9988669786222446, 'epsilon': 2.3784267312475085e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0830210738517566, 'tol': 0.0022695174716451244, 'validation_fraction': 0.6926678028882514}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.576583 value -0.802198 suggestion {'alpha': 0.0036285196196060828, 'batch_size': 227, 'beta_1': 0.9806716201603329, 'beta_2': 0.9988669786222446, 'epsilon': 2.3784267312475085e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0830210738517566, 'tol': 0.0022695174716451244, 'validation_fraction': 0.6926678028882514}
observation time 0.000007, current best -0.918681 at iter 15
suggestion time taken 20.047906 iter 16 next_points [{'alpha': 0.00025661572999994154, 'batch_size': 18, 'beta_1': 0.7697454343642745, 'beta_2': 0.9825341976622858, 'epsilon': 4.35594395013628e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 2.962555652432438e-05, 'tol': 2.2245652349196947e-05, 'validation_fraction': 0.4095656301259159}]
function_evaluation time 1.532598 value -0.450549 suggestion {'alpha': 0.00025661572999994154, 'batch_size': 18, 'beta_1': 0.7697454343642745, 'beta_2': 0.9825341976622858, 'epsilon': 4.35594395013628e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 2.962555652432438e-05, 'tol': 2.2245652349196947e-05, 'validation_fraction': 0.4095656301259159}
observation time 0.000005, current best -0.918681 at iter 16
suggestion time taken 19.299898 iter 17 next_points [{'alpha': 0.05516230016640678, 'batch_size': 227, 'beta_1': 0.9752065130421094, 'beta_2': 0.9638696957251583, 'epsilon': 3.381637072584411e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.018366460620721045, 'tol': 0.0005358428016152693, 'validation_fraction': 0.887054851473546}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.364669 value -0.819780 suggestion {'alpha': 0.05516230016640678, 'batch_size': 227, 'beta_1': 0.9752065130421094, 'beta_2': 0.9638696957251583, 'epsilon': 3.381637072584411e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.018366460620721045, 'tol': 0.0005358428016152693, 'validation_fraction': 0.887054851473546}
observation time 0.000005, current best -0.918681 at iter 17
suggestion time taken 20.215389 iter 18 next_points [{'alpha': 0.01446044128062957, 'batch_size': 113, 'beta_1': 0.5314680214837665, 'beta_2': 0.9952899965775976, 'epsilon': 1.0123791086388784e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0032487022977519767, 'tol': 0.00041716659838304717, 'validation_fraction': 0.38442223900684924}]
function_evaluation time 0.741468 value -0.885714 suggestion {'alpha': 0.01446044128062957, 'batch_size': 113, 'beta_1': 0.5314680214837665, 'beta_2': 0.9952899965775976, 'epsilon': 1.0123791086388784e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0032487022977519767, 'tol': 0.00041716659838304717, 'validation_fraction': 0.38442223900684924}
observation time 0.000010, current best -0.918681 at iter 18
suggestion time taken 19.384146 iter 19 next_points [{'alpha': 0.020699662065351638, 'batch_size': 225, 'beta_1': 0.9177462467022687, 'beta_2': 0.9999504112831906, 'epsilon': 4.506340896013118e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 1.1788695390646683e-05, 'tol': 0.008912950300465045, 'validation_fraction': 0.7866264600211608}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.386037 value -0.525275 suggestion {'alpha': 0.020699662065351638, 'batch_size': 225, 'beta_1': 0.9177462467022687, 'beta_2': 0.9999504112831906, 'epsilon': 4.506340896013118e-09, 'hidden_layer_sizes': 67, 'learning_rate_init': 1.1788695390646683e-05, 'tol': 0.008912950300465045, 'validation_fraction': 0.7866264600211608}
observation time 0.000005, current best -0.918681 at iter 19
suggestion time taken 21.018489 iter 20 next_points [{'alpha': 0.047005808410818396, 'batch_size': 223, 'beta_1': 0.9373529375142574, 'beta_2': 0.9999787417944672, 'epsilon': 2.309439252079835e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.003468827471994763, 'tol': 1.9323640335979856e-05, 'validation_fraction': 0.6087622914335915}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.545624 value -0.837363 suggestion {'alpha': 0.047005808410818396, 'batch_size': 223, 'beta_1': 0.9373529375142574, 'beta_2': 0.9999787417944672, 'epsilon': 2.309439252079835e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.003468827471994763, 'tol': 1.9323640335979856e-05, 'validation_fraction': 0.6087622914335915}
observation time 0.000006, current best -0.918681 at iter 20
suggestion time taken 19.431097 iter 21 next_points [{'alpha': 0.0067946366615577415, 'batch_size': 14, 'beta_1': 0.6224162536717581, 'beta_2': 0.9998212075055125, 'epsilon': 3.1206729698246367e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.0019887874575628016, 'tol': 0.0017973518692250333, 'validation_fraction': 0.10603188366924599}]
function_evaluation time 1.582243 value -0.918681 suggestion {'alpha': 0.0067946366615577415, 'batch_size': 14, 'beta_1': 0.6224162536717581, 'beta_2': 0.9998212075055125, 'epsilon': 3.1206729698246367e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.0019887874575628016, 'tol': 0.0017973518692250333, 'validation_fraction': 0.10603188366924599}
observation time 0.000006, current best -0.918681 at iter 21
suggestion time taken 20.521817 iter 22 next_points [{'alpha': 2.5965562042247097, 'batch_size': 75, 'beta_1': 0.7163882299076608, 'beta_2': 0.9999629716393572, 'epsilon': 9.333618397349947e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.005330771142410099, 'tol': 0.018961586954086052, 'validation_fraction': 0.13337338189705847}]
function_evaluation time 0.362429 value -0.927473 suggestion {'alpha': 2.5965562042247097, 'batch_size': 75, 'beta_1': 0.7163882299076608, 'beta_2': 0.9999629716393572, 'epsilon': 9.333618397349947e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.005330771142410099, 'tol': 0.018961586954086052, 'validation_fraction': 0.13337338189705847}
observation time 0.000005, current best -0.927473 at iter 22
suggestion time taken 19.815052 iter 23 next_points [{'alpha': 0.0026583296064699477, 'batch_size': 227, 'beta_1': 0.7913773222393808, 'beta_2': 0.9008868178943263, 'epsilon': 4.001793148608643e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.029424684139630383, 'tol': 3.2075780275303517e-05, 'validation_fraction': 0.895777679384809}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.656066 value -0.901099 suggestion {'alpha': 0.0026583296064699477, 'batch_size': 227, 'beta_1': 0.7913773222393808, 'beta_2': 0.9008868178943263, 'epsilon': 4.001793148608643e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.029424684139630383, 'tol': 3.2075780275303517e-05, 'validation_fraction': 0.895777679384809}
observation time 0.000016, current best -0.927473 at iter 23
suggestion time taken 20.661950 iter 24 next_points [{'alpha': 0.01130033038587175, 'batch_size': 90, 'beta_1': 0.9523077147855674, 'beta_2': 0.9971008901406214, 'epsilon': 5.251023575864888e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 2.3440268356912358e-05, 'tol': 2.0985078491724337e-05, 'validation_fraction': 0.7341117237019155}]
function_evaluation time 0.295545 value -0.474725 suggestion {'alpha': 0.01130033038587175, 'batch_size': 90, 'beta_1': 0.9523077147855674, 'beta_2': 0.9971008901406214, 'epsilon': 5.251023575864888e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 2.3440268356912358e-05, 'tol': 2.0985078491724337e-05, 'validation_fraction': 0.7341117237019155}
observation time 0.000005, current best -0.927473 at iter 24
suggestion time taken 19.799021 iter 25 next_points [{'alpha': 0.017712720834590162, 'batch_size': 45, 'beta_1': 0.9481420261032036, 'beta_2': 0.9839679136242862, 'epsilon': 1.497103013470943e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 2.799105720335669e-05, 'tol': 0.06548336922978333, 'validation_fraction': 0.6636282195328107}]
function_evaluation time 0.499371 value -0.472527 suggestion {'alpha': 0.017712720834590162, 'batch_size': 45, 'beta_1': 0.9481420261032036, 'beta_2': 0.9839679136242862, 'epsilon': 1.497103013470943e-09, 'hidden_layer_sizes': 166, 'learning_rate_init': 2.799105720335669e-05, 'tol': 0.06548336922978333, 'validation_fraction': 0.6636282195328107}
observation time 0.000015, current best -0.927473 at iter 25
suggestion time taken 20.638225 iter 26 next_points [{'alpha': 5.69976919537995, 'batch_size': 151, 'beta_1': 0.9834662294680305, 'beta_2': 0.9966649034697238, 'epsilon': 1.2906132307506034e-09, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.020742964496488003, 'tol': 8.44115313256365e-05, 'validation_fraction': 0.5943525188668511}]
function_evaluation time 0.828289 value -0.905495 suggestion {'alpha': 5.69976919537995, 'batch_size': 151, 'beta_1': 0.9834662294680305, 'beta_2': 0.9966649034697238, 'epsilon': 1.2906132307506034e-09, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.020742964496488003, 'tol': 8.44115313256365e-05, 'validation_fraction': 0.5943525188668511}
observation time 0.000006, current best -0.927473 at iter 26
suggestion time taken 19.686573 iter 27 next_points [{'alpha': 0.0962268051164451, 'batch_size': 149, 'beta_1': 0.911498176535427, 'beta_2': 0.9952223079607685, 'epsilon': 4.2668748246879123e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.014989216536097886, 'tol': 0.0004883394454625378, 'validation_fraction': 0.8452184869929737}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.634338 value -0.901099 suggestion {'alpha': 0.0962268051164451, 'batch_size': 149, 'beta_1': 0.911498176535427, 'beta_2': 0.9952223079607685, 'epsilon': 4.2668748246879123e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.014989216536097886, 'tol': 0.0004883394454625378, 'validation_fraction': 0.8452184869929737}
observation time 0.000017, current best -0.927473 at iter 27
suggestion time taken 20.703578 iter 28 next_points [{'alpha': 0.002367095530689654, 'batch_size': 14, 'beta_1': 0.8380118008018704, 'beta_2': 0.9995470585625242, 'epsilon': 4.520133522090375e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0018613715562067895, 'tol': 3.3370108492296975e-05, 'validation_fraction': 0.24211869047071802}]
function_evaluation time 1.294143 value -0.918681 suggestion {'alpha': 0.002367095530689654, 'batch_size': 14, 'beta_1': 0.8380118008018704, 'beta_2': 0.9995470585625242, 'epsilon': 4.520133522090375e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.0018613715562067895, 'tol': 3.3370108492296975e-05, 'validation_fraction': 0.24211869047071802}
observation time 0.000006, current best -0.927473 at iter 28
suggestion time taken 19.968432 iter 29 next_points [{'alpha': 0.005228715667121392, 'batch_size': 227, 'beta_1': 0.8157826376679873, 'beta_2': 0.9999413330417276, 'epsilon': 1.6542097678161697e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 2.0210824551636297e-05, 'tol': 0.0224639224661559, 'validation_fraction': 0.856270101625516}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.264692 value -0.479121 suggestion {'alpha': 0.005228715667121392, 'batch_size': 227, 'beta_1': 0.8157826376679873, 'beta_2': 0.9999413330417276, 'epsilon': 1.6542097678161697e-08, 'hidden_layer_sizes': 148, 'learning_rate_init': 2.0210824551636297e-05, 'tol': 0.0224639224661559, 'validation_fraction': 0.856270101625516}
observation time 0.000006, current best -0.927473 at iter 29
suggestion time taken 20.749442 iter 30 next_points [{'alpha': 0.8714514251763854, 'batch_size': 89, 'beta_1': 0.972990832053451, 'beta_2': 0.9936962365932441, 'epsilon': 1.479713924472775e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 1.5462518445385345e-05, 'tol': 0.0007781070805012906, 'validation_fraction': 0.20908084470433286}]
function_evaluation time 0.847374 value -0.619780 suggestion {'alpha': 0.8714514251763854, 'batch_size': 89, 'beta_1': 0.972990832053451, 'beta_2': 0.9936962365932441, 'epsilon': 1.479713924472775e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 1.5462518445385345e-05, 'tol': 0.0007781070805012906, 'validation_fraction': 0.20908084470433286}
observation time 0.000013, current best -0.927473 at iter 30
suggestion time taken 20.143249 iter 31 next_points [{'alpha': 0.0031715965208497393, 'batch_size': 64, 'beta_1': 0.8801298240055749, 'beta_2': 0.9999540328211266, 'epsilon': 2.7566698796817106e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.005591900093228195, 'tol': 0.006288940781682443, 'validation_fraction': 0.37513248829300255}]
function_evaluation time 0.857894 value -0.901099 suggestion {'alpha': 0.0031715965208497393, 'batch_size': 64, 'beta_1': 0.8801298240055749, 'beta_2': 0.9999540328211266, 'epsilon': 2.7566698796817106e-08, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.005591900093228195, 'tol': 0.006288940781682443, 'validation_fraction': 0.37513248829300255}
observation time 0.000012, current best -0.927473 at iter 31
suggestion time taken 20.579008 iter 32 next_points [{'alpha': 3.3372069035473233, 'batch_size': 75, 'beta_1': 0.8569669162391613, 'beta_2': 0.9991005761291392, 'epsilon': 2.7941144795002986e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 8.100667543551355e-05, 'tol': 0.0032552873156011398, 'validation_fraction': 0.13203200825553518}]
function_evaluation time 0.719454 value -0.747253 suggestion {'alpha': 3.3372069035473233, 'batch_size': 75, 'beta_1': 0.8569669162391613, 'beta_2': 0.9991005761291392, 'epsilon': 2.7941144795002986e-09, 'hidden_layer_sizes': 96, 'learning_rate_init': 8.100667543551355e-05, 'tol': 0.0032552873156011398, 'validation_fraction': 0.13203200825553518}
observation time 0.000006, current best -0.927473 at iter 32
suggestion time taken 20.040154 iter 33 next_points [{'alpha': 0.0009001801032014878, 'batch_size': 16, 'beta_1': 0.9544327706898087, 'beta_2': 0.9999988543557101, 'epsilon': 5.488262240605301e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.00802837993848856, 'tol': 0.00017210169690240178, 'validation_fraction': 0.6150448969521077}]
function_evaluation time 1.401255 value -0.914286 suggestion {'alpha': 0.0009001801032014878, 'batch_size': 16, 'beta_1': 0.9544327706898087, 'beta_2': 0.9999988543557101, 'epsilon': 5.488262240605301e-07, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.00802837993848856, 'tol': 0.00017210169690240178, 'validation_fraction': 0.6150448969521077}
observation time 0.000012, current best -0.927473 at iter 33
suggestion time taken 20.272207 iter 34 next_points [{'alpha': 0.029356941978234134, 'batch_size': 151, 'beta_1': 0.8943280387723063, 'beta_2': 0.9999838914281055, 'epsilon': 6.853487587413657e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.0004726474302551098, 'tol': 0.04840845446687964, 'validation_fraction': 0.6449626907986219}]
function_evaluation time 0.527493 value -0.784615 suggestion {'alpha': 0.029356941978234134, 'batch_size': 151, 'beta_1': 0.8943280387723063, 'beta_2': 0.9999838914281055, 'epsilon': 6.853487587413657e-07, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.0004726474302551098, 'tol': 0.04840845446687964, 'validation_fraction': 0.6449626907986219}
observation time 0.000016, current best -0.927473 at iter 34
suggestion time taken 20.526352 iter 35 next_points [{'alpha': 0.00684547571397342, 'batch_size': 225, 'beta_1': 0.6998668154675121, 'beta_2': 0.9999892917473926, 'epsilon': 1.351365638206371e-07, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.00051203283517048, 'tol': 0.0025258594506030706, 'validation_fraction': 0.2985341833669781}]
function_evaluation time 1.041619 value -0.892308 suggestion {'alpha': 0.00684547571397342, 'batch_size': 225, 'beta_1': 0.6998668154675121, 'beta_2': 0.9999892917473926, 'epsilon': 1.351365638206371e-07, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.00051203283517048, 'tol': 0.0025258594506030706, 'validation_fraction': 0.2985341833669781}
observation time 0.000004, current best -0.927473 at iter 35
suggestion time taken 19.801653 iter 36 next_points [{'alpha': 0.0009350908927863356, 'batch_size': 225, 'beta_1': 0.9580649931600735, 'beta_2': 0.9999943321282592, 'epsilon': 2.4318096519951055e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.07859613389483837, 'tol': 0.05512290101764089, 'validation_fraction': 0.14332441754974667}]
function_evaluation time 0.417933 value -0.709890 suggestion {'alpha': 0.0009350908927863356, 'batch_size': 225, 'beta_1': 0.9580649931600735, 'beta_2': 0.9999943321282592, 'epsilon': 2.4318096519951055e-07, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.07859613389483837, 'tol': 0.05512290101764089, 'validation_fraction': 0.14332441754974667}
observation time 0.000004, current best -0.927473 at iter 36
suggestion time taken 21.695437 iter 37 next_points [{'alpha': 9.249803787922223, 'batch_size': 227, 'beta_1': 0.9408442888502561, 'beta_2': 0.9813162908572537, 'epsilon': 1.3718310000416757e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.02464219649254259, 'tol': 1.278896673525031e-05, 'validation_fraction': 0.8446202427235169}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.739848 value -0.850549 suggestion {'alpha': 9.249803787922223, 'batch_size': 227, 'beta_1': 0.9408442888502561, 'beta_2': 0.9813162908572537, 'epsilon': 1.3718310000416757e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.02464219649254259, 'tol': 1.278896673525031e-05, 'validation_fraction': 0.8446202427235169}
observation time 0.000014, current best -0.927473 at iter 37
suggestion time taken 19.972087 iter 38 next_points [{'alpha': 5.931922356261655, 'batch_size': 151, 'beta_1': 0.678660917335222, 'beta_2': 0.9994365130757202, 'epsilon': 2.9929079696091494e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.00030358449856783835, 'tol': 0.003334450126446131, 'validation_fraction': 0.23149969732158787}]
function_evaluation time 0.182605 value -0.527473 suggestion {'alpha': 5.931922356261655, 'batch_size': 151, 'beta_1': 0.678660917335222, 'beta_2': 0.9994365130757202, 'epsilon': 2.9929079696091494e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.00030358449856783835, 'tol': 0.003334450126446131, 'validation_fraction': 0.23149969732158787}
observation time 0.000009, current best -0.927473 at iter 38
suggestion time taken 20.683193 iter 39 next_points [{'alpha': 6.19102869458854e-05, 'batch_size': 32, 'beta_1': 0.8416961437910929, 'beta_2': 0.9999984284340648, 'epsilon': 2.592871179636487e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.008989668711524177, 'tol': 0.020176246837763152, 'validation_fraction': 0.2125640671448412}]
function_evaluation time 0.384395 value -0.896703 suggestion {'alpha': 6.19102869458854e-05, 'batch_size': 32, 'beta_1': 0.8416961437910929, 'beta_2': 0.9999984284340648, 'epsilon': 2.592871179636487e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.008989668711524177, 'tol': 0.020176246837763152, 'validation_fraction': 0.2125640671448412}
observation time 0.000003, current best -0.927473 at iter 39
suggestion time taken 15.072137 iter 40 next_points [{'alpha': 0.0004899551226484746, 'batch_size': 18, 'beta_1': 0.982499128997747, 'beta_2': 0.9161559133090378, 'epsilon': 1.1472286763889489e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0026191054791280984, 'tol': 0.0014700130855876275, 'validation_fraction': 0.6827986124913509}]
function_evaluation time 0.950611 value -0.894505 suggestion {'alpha': 0.0004899551226484746, 'batch_size': 18, 'beta_1': 0.982499128997747, 'beta_2': 0.9161559133090378, 'epsilon': 1.1472286763889489e-08, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0026191054791280984, 'tol': 0.0014700130855876275, 'validation_fraction': 0.6827986124913509}
observation time 0.000005, current best -0.927473 at iter 40
suggestion time taken 14.902181 iter 41 next_points [{'alpha': 0.006897196918118665, 'batch_size': 50, 'beta_1': 0.9235903230364286, 'beta_2': 0.9998839837348937, 'epsilon': 1.5095379027392257e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0042613048814351935, 'tol': 0.010311061714912544, 'validation_fraction': 0.47095292463266253}]
function_evaluation time 0.648691 value -0.898901 suggestion {'alpha': 0.006897196918118665, 'batch_size': 50, 'beta_1': 0.9235903230364286, 'beta_2': 0.9998839837348937, 'epsilon': 1.5095379027392257e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0042613048814351935, 'tol': 0.010311061714912544, 'validation_fraction': 0.47095292463266253}
observation time 0.000004, current best -0.927473 at iter 41
suggestion time taken 15.555862 iter 42 next_points [{'alpha': 0.002061464246916442, 'batch_size': 11, 'beta_1': 0.9233597186457394, 'beta_2': 0.9996626840053722, 'epsilon': 2.405987647316677e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.00035905665399158616, 'tol': 0.055073853500958184, 'validation_fraction': 0.3186968131086035}]
function_evaluation time 1.848494 value -0.916484 suggestion {'alpha': 0.002061464246916442, 'batch_size': 11, 'beta_1': 0.9233597186457394, 'beta_2': 0.9996626840053722, 'epsilon': 2.405987647316677e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.00035905665399158616, 'tol': 0.055073853500958184, 'validation_fraction': 0.3186968131086035}
observation time 0.000005, current best -0.927473 at iter 42
suggestion time taken 14.775248 iter 43 next_points [{'alpha': 8.689558170024465e-05, 'batch_size': 41, 'beta_1': 0.9883726106152714, 'beta_2': 0.980130684742402, 'epsilon': 9.633537874983231e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0001320570015032237, 'tol': 0.0004224657207778613, 'validation_fraction': 0.22319622175480844}]
function_evaluation time 1.287318 value -0.789011 suggestion {'alpha': 8.689558170024465e-05, 'batch_size': 41, 'beta_1': 0.9883726106152714, 'beta_2': 0.980130684742402, 'epsilon': 9.633537874983231e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0001320570015032237, 'tol': 0.0004224657207778613, 'validation_fraction': 0.22319622175480844}
observation time 0.000005, current best -0.927473 at iter 43
suggestion time taken 15.742375 iter 44 next_points [{'alpha': 2.3463880930681248e-05, 'batch_size': 113, 'beta_1': 0.9492076372238827, 'beta_2': 0.9809364383198607, 'epsilon': 2.685470150460265e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0015246600688725446, 'tol': 0.009587710992217462, 'validation_fraction': 0.16783560093462296}]
function_evaluation time 0.875931 value -0.901099 suggestion {'alpha': 2.3463880930681248e-05, 'batch_size': 113, 'beta_1': 0.9492076372238827, 'beta_2': 0.9809364383198607, 'epsilon': 2.685470150460265e-09, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0015246600688725446, 'tol': 0.009587710992217462, 'validation_fraction': 0.16783560093462296}
observation time 0.000005, current best -0.927473 at iter 44
saving meta data: {'args': {'--uuid': '7c6d82cc4e195cd493b9564b3dc6880f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'strongcvx', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
