running: {'--uuid': 'ef2d79d868105e13a60fe9c48eb9b174', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u ef2d79d868105e13a60fe9c48eb9b174 -m nll -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast nll 45 1
with data root: None
suggestion time taken 0.009317 iter 0 next_points [{'alpha': 0.022264154672016707, 'batch_size': 165, 'beta_1': 0.5177461888477825, 'beta_2': 0.9693855373477536, 'epsilon': 2.056361776157337e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 4.547711985464446e-05, 'tol': 2.8547266326910215e-05, 'validation_fraction': 0.16056491496891573}]
function_evaluation time 0.323209 value 15.792164 suggestion {'alpha': 0.022264154672016707, 'batch_size': 165, 'beta_1': 0.5177461888477825, 'beta_2': 0.9693855373477536, 'epsilon': 2.056361776157337e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 4.547711985464446e-05, 'tol': 2.8547266326910215e-05, 'validation_fraction': 0.16056491496891573}
observation time 0.000007, current best 15.792164 at iter 0
suggestion time taken 0.011024 iter 1 next_points [{'alpha': 0.0024247650123730372, 'batch_size': 228, 'beta_1': 0.612513941276746, 'beta_2': 0.9999975158017362, 'epsilon': 1.2632717721303834e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.008397032662373006, 'tol': 0.00019304829902950276, 'validation_fraction': 0.3085515871237542}]
function_evaluation time 0.812304 value 0.641437 suggestion {'alpha': 0.0024247650123730372, 'batch_size': 228, 'beta_1': 0.612513941276746, 'beta_2': 0.9999975158017362, 'epsilon': 1.2632717721303834e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.008397032662373006, 'tol': 0.00019304829902950276, 'validation_fraction': 0.3085515871237542}
observation time 0.000003, current best 0.641437 at iter 1
suggestion time taken 0.009922 iter 2 next_points [{'alpha': 1.799754564882413e-05, 'batch_size': 243, 'beta_1': 0.8890105162857461, 'beta_2': 0.9990969988223138, 'epsilon': 1.0091971090370494e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.007300562298170674, 'tol': 0.0019250199866352377, 'validation_fraction': 0.6165536823479879}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.588305 value 3.220117 suggestion {'alpha': 1.799754564882413e-05, 'batch_size': 243, 'beta_1': 0.8890105162857461, 'beta_2': 0.9990969988223138, 'epsilon': 1.0091971090370494e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.007300562298170674, 'tol': 0.0019250199866352377, 'validation_fraction': 0.6165536823479879}
observation time 0.000003, current best 0.641437 at iter 2
suggestion time taken 0.010633 iter 3 next_points [{'alpha': 8.745424256057388, 'batch_size': 236, 'beta_1': 0.8313964994142145, 'beta_2': 0.99982851323458, 'epsilon': 8.424449446561927e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0010197098459143127, 'tol': 0.007545861600605631, 'validation_fraction': 0.7459308607326757}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.572644 value 2.801439 suggestion {'alpha': 8.745424256057388, 'batch_size': 236, 'beta_1': 0.8313964994142145, 'beta_2': 0.99982851323458, 'epsilon': 8.424449446561927e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0010197098459143127, 'tol': 0.007545861600605631, 'validation_fraction': 0.7459308607326757}
observation time 0.000004, current best 0.641437 at iter 3
suggestion time taken 0.010879 iter 4 next_points [{'alpha': 2.1160092221461966, 'batch_size': 120, 'beta_1': 0.8745386145629809, 'beta_2': 0.9999901266012557, 'epsilon': 5.715395605289875e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0018452942645334066, 'tol': 0.00019319608037242014, 'validation_fraction': 0.20232230100957324}]
function_evaluation time 0.407977 value 0.553979 suggestion {'alpha': 2.1160092221461966, 'batch_size': 120, 'beta_1': 0.8745386145629809, 'beta_2': 0.9999901266012557, 'epsilon': 5.715395605289875e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.0018452942645334066, 'tol': 0.00019319608037242014, 'validation_fraction': 0.20232230100957324}
observation time 0.000004, current best 0.553979 at iter 4
suggestion time taken 0.004114 iter 5 next_points [{'alpha': 0.0009052465301296887, 'batch_size': 239, 'beta_1': 0.8997976311127783, 'beta_2': 0.9998019335057784, 'epsilon': 1.595021170237604e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0085104885214742, 'tol': 0.001018040894941076, 'validation_fraction': 0.1341150566636094}]
function_evaluation time 0.778908 value 1.041293 suggestion {'alpha': 0.0009052465301296887, 'batch_size': 239, 'beta_1': 0.8997976311127783, 'beta_2': 0.9998019335057784, 'epsilon': 1.595021170237604e-07, 'hidden_layer_sizes': 152, 'learning_rate_init': 0.0085104885214742, 'tol': 0.001018040894941076, 'validation_fraction': 0.1341150566636094}
observation time 0.000004, current best 0.553979 at iter 5
suggestion time taken 0.010645 iter 6 next_points [{'alpha': 0.0003930931472627311, 'batch_size': 159, 'beta_1': 0.931007158240955, 'beta_2': 0.9977328798270276, 'epsilon': 7.388566941193778e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.004480067834378625, 'tol': 0.0035908342856377545, 'validation_fraction': 0.5151481686739127}]
function_evaluation time 0.801772 value 0.640444 suggestion {'alpha': 0.0003930931472627311, 'batch_size': 159, 'beta_1': 0.931007158240955, 'beta_2': 0.9977328798270276, 'epsilon': 7.388566941193778e-07, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.004480067834378625, 'tol': 0.0035908342856377545, 'validation_fraction': 0.5151481686739127}
observation time 0.000004, current best 0.553979 at iter 6
suggestion time taken 0.010114 iter 7 next_points [{'alpha': 1.2676497109011787e-05, 'batch_size': 236, 'beta_1': 0.7179069095867183, 'beta_2': 0.9999561436000272, 'epsilon': 2.6131584226930617e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.00045540471259523864, 'tol': 0.009998092258356385, 'validation_fraction': 0.8012519076053157}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.502629 value 9.552501 suggestion {'alpha': 1.2676497109011787e-05, 'batch_size': 236, 'beta_1': 0.7179069095867183, 'beta_2': 0.9999561436000272, 'epsilon': 2.6131584226930617e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.00045540471259523864, 'tol': 0.009998092258356385, 'validation_fraction': 0.8012519076053157}
observation time 0.000004, current best 0.553979 at iter 7
suggestion time taken 0.010745 iter 8 next_points [{'alpha': 1.6921704400609313e-05, 'batch_size': 49, 'beta_1': 0.9689492004956493, 'beta_2': 0.9999965702397022, 'epsilon': 2.0930976461023982e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 1.829746898978467e-05, 'tol': 0.00737481852192274, 'validation_fraction': 0.6471343335497791}]
function_evaluation time 0.508164 value 10.811226 suggestion {'alpha': 1.6921704400609313e-05, 'batch_size': 49, 'beta_1': 0.9689492004956493, 'beta_2': 0.9999965702397022, 'epsilon': 2.0930976461023982e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 1.829746898978467e-05, 'tol': 0.00737481852192274, 'validation_fraction': 0.6471343335497791}
observation time 0.000003, current best 0.553979 at iter 8
suggestion time taken 0.010125 iter 9 next_points [{'alpha': 1.938297829947549e-05, 'batch_size': 37, 'beta_1': 0.6420858016777146, 'beta_2': 0.9996686415210263, 'epsilon': 1.2084341598575761e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 1.619252035879066e-05, 'tol': 0.01774486771775251, 'validation_fraction': 0.7091579341733998}]
function_evaluation time 0.595910 value 6.348722 suggestion {'alpha': 1.938297829947549e-05, 'batch_size': 37, 'beta_1': 0.6420858016777146, 'beta_2': 0.9996686415210263, 'epsilon': 1.2084341598575761e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 1.619252035879066e-05, 'tol': 0.01774486771775251, 'validation_fraction': 0.7091579341733998}
observation time 0.000004, current best 0.553979 at iter 9
suggestion time taken 0.010788 iter 10 next_points [{'alpha': 0.004859484225215135, 'batch_size': 157, 'beta_1': 0.9308935906194785, 'beta_2': 0.9999906787436393, 'epsilon': 1.6962344296810143e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 7.921531080164803e-05, 'tol': 0.022966387540466062, 'validation_fraction': 0.36929794061554555}]
function_evaluation time 0.369925 value 15.477571 suggestion {'alpha': 0.004859484225215135, 'batch_size': 157, 'beta_1': 0.9308935906194785, 'beta_2': 0.9999906787436393, 'epsilon': 1.6962344296810143e-09, 'hidden_layer_sizes': 143, 'learning_rate_init': 7.921531080164803e-05, 'tol': 0.022966387540466062, 'validation_fraction': 0.36929794061554555}
observation time 0.000003, current best 0.553979 at iter 10
suggestion time taken 0.009290 iter 11 next_points [{'alpha': 0.0025555858497055407, 'batch_size': 78, 'beta_1': 0.7136112915513005, 'beta_2': 0.9999751891064362, 'epsilon': 3.883898696351856e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 1.212351023479174e-05, 'tol': 0.00015777037436438425, 'validation_fraction': 0.3442447220488097}]
function_evaluation time 0.616693 value 16.024189 suggestion {'alpha': 0.0025555858497055407, 'batch_size': 78, 'beta_1': 0.7136112915513005, 'beta_2': 0.9999751891064362, 'epsilon': 3.883898696351856e-09, 'hidden_layer_sizes': 170, 'learning_rate_init': 1.212351023479174e-05, 'tol': 0.00015777037436438425, 'validation_fraction': 0.3442447220488097}
observation time 0.000004, current best 0.553979 at iter 11
suggestion time taken 0.010707 iter 12 next_points [{'alpha': 0.16683021752898483, 'batch_size': 49, 'beta_1': 0.955285581939958, 'beta_2': 0.9999517962907319, 'epsilon': 1.9052524310755814e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.04583538826971183, 'tol': 5.363907111491284e-05, 'validation_fraction': 0.8207885562189624}]
function_evaluation time 0.551713 value 0.636573 suggestion {'alpha': 0.16683021752898483, 'batch_size': 49, 'beta_1': 0.955285581939958, 'beta_2': 0.9999517962907319, 'epsilon': 1.9052524310755814e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.04583538826971183, 'tol': 5.363907111491284e-05, 'validation_fraction': 0.8207885562189624}
observation time 0.000005, current best 0.553979 at iter 12
suggestion time taken 0.010914 iter 13 next_points [{'alpha': 8.687746589322396, 'batch_size': 145, 'beta_1': 0.691848607105209, 'beta_2': 0.9884602309687767, 'epsilon': 1.9513169456606226e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 1.4715709578805995e-05, 'tol': 9.996352902543785e-05, 'validation_fraction': 0.8901208567260007}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.313369 value 16.147150 suggestion {'alpha': 8.687746589322396, 'batch_size': 145, 'beta_1': 0.691848607105209, 'beta_2': 0.9884602309687767, 'epsilon': 1.9513169456606226e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 1.4715709578805995e-05, 'tol': 9.996352902543785e-05, 'validation_fraction': 0.8901208567260007}
observation time 0.000007, current best 0.553979 at iter 13
suggestion time taken 0.013714 iter 14 next_points [{'alpha': 8.035225391670562e-05, 'batch_size': 122, 'beta_1': 0.9816085117255112, 'beta_2': 0.9999919454739732, 'epsilon': 5.901337722772167e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.09744399743884383, 'tol': 0.0649843912373579, 'validation_fraction': 0.3158412326735467}]
function_evaluation time 0.256141 value 6.980763 suggestion {'alpha': 8.035225391670562e-05, 'batch_size': 122, 'beta_1': 0.9816085117255112, 'beta_2': 0.9999919454739732, 'epsilon': 5.901337722772167e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.09744399743884383, 'tol': 0.0649843912373579, 'validation_fraction': 0.3158412326735467}
observation time 0.000009, current best 0.553979 at iter 14
suggestion time taken 0.011505 iter 15 next_points [{'alpha': 0.001299426461041035, 'batch_size': 97, 'beta_1': 0.9796865618807387, 'beta_2': 0.9183180156422205, 'epsilon': 1.4805021946744993e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.0002035649585547581, 'tol': 0.0009126898660326133, 'validation_fraction': 0.4032356822382174}]
function_evaluation time 0.522011 value 11.798403 suggestion {'alpha': 0.001299426461041035, 'batch_size': 97, 'beta_1': 0.9796865618807387, 'beta_2': 0.9183180156422205, 'epsilon': 1.4805021946744993e-07, 'hidden_layer_sizes': 92, 'learning_rate_init': 0.0002035649585547581, 'tol': 0.0009126898660326133, 'validation_fraction': 0.4032356822382174}
observation time 0.000003, current best 0.553979 at iter 15
suggestion time taken 0.010899 iter 16 next_points [{'alpha': 0.011345685928984512, 'batch_size': 197, 'beta_1': 0.9260879682410411, 'beta_2': 0.9935264722685723, 'epsilon': 1.4954911801387995e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.02718547162039255, 'tol': 0.018112406782739808, 'validation_fraction': 0.8360383087758153}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.442048 value 3.244789 suggestion {'alpha': 0.011345685928984512, 'batch_size': 197, 'beta_1': 0.9260879682410411, 'beta_2': 0.9935264722685723, 'epsilon': 1.4954911801387995e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.02718547162039255, 'tol': 0.018112406782739808, 'validation_fraction': 0.8360383087758153}
observation time 0.000004, current best 0.553979 at iter 16
suggestion time taken 0.012015 iter 17 next_points [{'alpha': 0.29453003844881626, 'batch_size': 247, 'beta_1': 0.8189532809704726, 'beta_2': 0.9999926711174557, 'epsilon': 5.638462780243877e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.08030438441329849, 'tol': 0.0016121741328662521, 'validation_fraction': 0.3032609546820646}]
function_evaluation time 0.683932 value 5.308210 suggestion {'alpha': 0.29453003844881626, 'batch_size': 247, 'beta_1': 0.8189532809704726, 'beta_2': 0.9999926711174557, 'epsilon': 5.638462780243877e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.08030438441329849, 'tol': 0.0016121741328662521, 'validation_fraction': 0.3032609546820646}
observation time 0.000007, current best 0.553979 at iter 17
suggestion time taken 0.011450 iter 18 next_points [{'alpha': 0.007626046898888322, 'batch_size': 218, 'beta_1': 0.9816402626689735, 'beta_2': 0.9988585390312272, 'epsilon': 8.804094334448558e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.0006674271806851498, 'tol': 1.163254351607025e-05, 'validation_fraction': 0.5910800345902121}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.591861 value 8.123453 suggestion {'alpha': 0.007626046898888322, 'batch_size': 218, 'beta_1': 0.9816402626689735, 'beta_2': 0.9988585390312272, 'epsilon': 8.804094334448558e-08, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.0006674271806851498, 'tol': 1.163254351607025e-05, 'validation_fraction': 0.5910800345902121}
observation time 0.000003, current best 0.553979 at iter 18
suggestion time taken 0.011677 iter 19 next_points [{'alpha': 0.0023425578250664027, 'batch_size': 41, 'beta_1': 0.8850274317977275, 'beta_2': 0.9988111338023724, 'epsilon': 3.057533851130866e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.004460636549375034, 'tol': 3.0911633216343003e-05, 'validation_fraction': 0.2266186409879436}]
function_evaluation time 1.997092 value 0.498481 suggestion {'alpha': 0.0023425578250664027, 'batch_size': 41, 'beta_1': 0.8850274317977275, 'beta_2': 0.9988111338023724, 'epsilon': 3.057533851130866e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.004460636549375034, 'tol': 3.0911633216343003e-05, 'validation_fraction': 0.2266186409879436}
observation time 0.000010, current best 0.498481 at iter 19
suggestion time taken 0.012176 iter 20 next_points [{'alpha': 1.048898894656952, 'batch_size': 73, 'beta_1': 0.6773580236318006, 'beta_2': 0.9999934443926255, 'epsilon': 6.255773300153422e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.000598522430752688, 'tol': 0.01974061021706546, 'validation_fraction': 0.7876376873305699}]
function_evaluation time 0.588729 value 2.714722 suggestion {'alpha': 1.048898894656952, 'batch_size': 73, 'beta_1': 0.6773580236318006, 'beta_2': 0.9999934443926255, 'epsilon': 6.255773300153422e-07, 'hidden_layer_sizes': 180, 'learning_rate_init': 0.000598522430752688, 'tol': 0.01974061021706546, 'validation_fraction': 0.7876376873305699}
observation time 0.000004, current best 0.498481 at iter 20
suggestion time taken 0.010613 iter 21 next_points [{'alpha': 0.0005323608227177026, 'batch_size': 53, 'beta_1': 0.9847498257277075, 'beta_2': 0.9999975384398933, 'epsilon': 7.665403725588276e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 3.806836480497115e-05, 'tol': 0.00010768895805329568, 'validation_fraction': 0.10663909640375664}]
function_evaluation time 0.686692 value 16.230861 suggestion {'alpha': 0.0005323608227177026, 'batch_size': 53, 'beta_1': 0.9847498257277075, 'beta_2': 0.9999975384398933, 'epsilon': 7.665403725588276e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 3.806836480497115e-05, 'tol': 0.00010768895805329568, 'validation_fraction': 0.10663909640375664}
observation time 0.000003, current best 0.498481 at iter 21
suggestion time taken 0.009088 iter 22 next_points [{'alpha': 0.00024614857666864856, 'batch_size': 74, 'beta_1': 0.6945484410243777, 'beta_2': 0.9987012324444917, 'epsilon': 1.1213396631827586e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.00030458665894743576, 'tol': 0.08803895801894088, 'validation_fraction': 0.653807205789334}]
function_evaluation time 0.517363 value 5.108670 suggestion {'alpha': 0.00024614857666864856, 'batch_size': 74, 'beta_1': 0.6945484410243777, 'beta_2': 0.9987012324444917, 'epsilon': 1.1213396631827586e-07, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.00030458665894743576, 'tol': 0.08803895801894088, 'validation_fraction': 0.653807205789334}
observation time 0.000009, current best 0.498481 at iter 22
suggestion time taken 0.013287 iter 23 next_points [{'alpha': 0.00042765693936326437, 'batch_size': 200, 'beta_1': 0.9675212688879409, 'beta_2': 0.9999867783118274, 'epsilon': 1.1167460503363311e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0002930364222700127, 'tol': 1.4175050479206455e-05, 'validation_fraction': 0.22859601394532486}]
function_evaluation time 0.515231 value 11.608001 suggestion {'alpha': 0.00042765693936326437, 'batch_size': 200, 'beta_1': 0.9675212688879409, 'beta_2': 0.9999867783118274, 'epsilon': 1.1167460503363311e-08, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0002930364222700127, 'tol': 1.4175050479206455e-05, 'validation_fraction': 0.22859601394532486}
observation time 0.000003, current best 0.498481 at iter 23
suggestion time taken 0.011596 iter 24 next_points [{'alpha': 0.059241401687848895, 'batch_size': 203, 'beta_1': 0.8944890468947819, 'beta_2': 0.9501499877808243, 'epsilon': 3.540291510783117e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.000565637065058154, 'tol': 0.01645234549321876, 'validation_fraction': 0.8754484919118307}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.320661 value 11.756159 suggestion {'alpha': 0.059241401687848895, 'batch_size': 203, 'beta_1': 0.8944890468947819, 'beta_2': 0.9501499877808243, 'epsilon': 3.540291510783117e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.000565637065058154, 'tol': 0.01645234549321876, 'validation_fraction': 0.8754484919118307}
observation time 0.000006, current best 0.498481 at iter 24
suggestion time taken 0.012498 iter 25 next_points [{'alpha': 0.00015471428988627443, 'batch_size': 32, 'beta_1': 0.9762615099317566, 'beta_2': 0.9980772382347076, 'epsilon': 7.681412295406817e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.00032699708418155673, 'tol': 1.9790649904295367e-05, 'validation_fraction': 0.2096006850413949}]
function_evaluation time 0.828615 value 0.583180 suggestion {'alpha': 0.00015471428988627443, 'batch_size': 32, 'beta_1': 0.9762615099317566, 'beta_2': 0.9980772382347076, 'epsilon': 7.681412295406817e-09, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.00032699708418155673, 'tol': 1.9790649904295367e-05, 'validation_fraction': 0.2096006850413949}
observation time 0.000002, current best 0.498481 at iter 25
suggestion time taken 0.003281 iter 26 next_points [{'alpha': 0.058890071822348324, 'batch_size': 223, 'beta_1': 0.9747181563067076, 'beta_2': 0.9768267434102273, 'epsilon': 1.1495369367903096e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 8.598789254667722e-05, 'tol': 4.403337515081551e-05, 'validation_fraction': 0.415939391393198}]
function_evaluation time 0.363311 value 16.015177 suggestion {'alpha': 0.058890071822348324, 'batch_size': 223, 'beta_1': 0.9747181563067076, 'beta_2': 0.9768267434102273, 'epsilon': 1.1495369367903096e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 8.598789254667722e-05, 'tol': 4.403337515081551e-05, 'validation_fraction': 0.415939391393198}
observation time 0.000012, current best 0.498481 at iter 26
suggestion time taken 0.013641 iter 27 next_points [{'alpha': 0.0002712486087531579, 'batch_size': 65, 'beta_1': 0.9832224795787957, 'beta_2': 0.9999932046661546, 'epsilon': 1.6124937935491308e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0018828657908305344, 'tol': 0.06572691277799214, 'validation_fraction': 0.18379368218001765}]
function_evaluation time 0.408257 value 0.850941 suggestion {'alpha': 0.0002712486087531579, 'batch_size': 65, 'beta_1': 0.9832224795787957, 'beta_2': 0.9999932046661546, 'epsilon': 1.6124937935491308e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.0018828657908305344, 'tol': 0.06572691277799214, 'validation_fraction': 0.18379368218001765}
observation time 0.000005, current best 0.498481 at iter 27
suggestion time taken 0.004193 iter 28 next_points [{'alpha': 1.0478312960311502, 'batch_size': 98, 'beta_1': 0.8576308919506616, 'beta_2': 0.9842460492287282, 'epsilon': 3.363527099183782e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 6.78219823791267e-05, 'tol': 0.002374412928618661, 'validation_fraction': 0.6482255392751054}]
function_evaluation time 1.011200 value 13.526889 suggestion {'alpha': 1.0478312960311502, 'batch_size': 98, 'beta_1': 0.8576308919506616, 'beta_2': 0.9842460492287282, 'epsilon': 3.363527099183782e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 6.78219823791267e-05, 'tol': 0.002374412928618661, 'validation_fraction': 0.6482255392751054}
observation time 0.000007, current best 0.498481 at iter 28
suggestion time taken 0.012187 iter 29 next_points [{'alpha': 0.00031537377001172894, 'batch_size': 157, 'beta_1': 0.9789964873567983, 'beta_2': 0.9520595371794616, 'epsilon': 1.7921576462021305e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.026355778814334305, 'tol': 0.0013986059492207383, 'validation_fraction': 0.12156496671893895}]
function_evaluation time 0.681387 value 0.710261 suggestion {'alpha': 0.00031537377001172894, 'batch_size': 157, 'beta_1': 0.9789964873567983, 'beta_2': 0.9520595371794616, 'epsilon': 1.7921576462021305e-08, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.026355778814334305, 'tol': 0.0013986059492207383, 'validation_fraction': 0.12156496671893895}
observation time 0.000010, current best 0.498481 at iter 29
suggestion time taken 0.013785 iter 30 next_points [{'alpha': 0.02451435456204434, 'batch_size': 133, 'beta_1': 0.5748581711285102, 'beta_2': 0.9998076594234673, 'epsilon': 4.461135883098758e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.008282355967949495, 'tol': 0.000443302638680875, 'validation_fraction': 0.34257546611675566}]
function_evaluation time 0.697343 value 0.608892 suggestion {'alpha': 0.02451435456204434, 'batch_size': 133, 'beta_1': 0.5748581711285102, 'beta_2': 0.9998076594234673, 'epsilon': 4.461135883098758e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.008282355967949495, 'tol': 0.000443302638680875, 'validation_fraction': 0.34257546611675566}
observation time 0.000003, current best 0.498481 at iter 30
suggestion time taken 0.010846 iter 31 next_points [{'alpha': 0.00013548393280944467, 'batch_size': 195, 'beta_1': 0.9739795221364135, 'beta_2': 0.9995212191946103, 'epsilon': 1.523118676040076e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.003421469781965341, 'tol': 0.01661233667973954, 'validation_fraction': 0.5225298057175747}]
function_evaluation time 0.709021 value 0.769628 suggestion {'alpha': 0.00013548393280944467, 'batch_size': 195, 'beta_1': 0.9739795221364135, 'beta_2': 0.9995212191946103, 'epsilon': 1.523118676040076e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 0.003421469781965341, 'tol': 0.01661233667973954, 'validation_fraction': 0.5225298057175747}
observation time 0.000012, current best 0.498481 at iter 31
suggestion time taken 0.012408 iter 32 next_points [{'alpha': 0.09014772932396511, 'batch_size': 215, 'beta_1': 0.9559134358360687, 'beta_2': 0.999997337926554, 'epsilon': 1.2056312921234141e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.09202466017873304, 'tol': 0.000715016890656166, 'validation_fraction': 0.5553285286523434}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.480209 value 3.407547 suggestion {'alpha': 0.09014772932396511, 'batch_size': 215, 'beta_1': 0.9559134358360687, 'beta_2': 0.999997337926554, 'epsilon': 1.2056312921234141e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.09202466017873304, 'tol': 0.000715016890656166, 'validation_fraction': 0.5553285286523434}
observation time 0.000004, current best 0.498481 at iter 32
suggestion time taken 0.010960 iter 33 next_points [{'alpha': 1.4105773214267823e-05, 'batch_size': 60, 'beta_1': 0.9134265648417423, 'beta_2': 0.9999268323653852, 'epsilon': 6.891429446491871e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 1.3307409213268256e-05, 'tol': 0.021621160887251818, 'validation_fraction': 0.891464745755294}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.314948 value 18.212754 suggestion {'alpha': 1.4105773214267823e-05, 'batch_size': 60, 'beta_1': 0.9134265648417423, 'beta_2': 0.9999268323653852, 'epsilon': 6.891429446491871e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 1.3307409213268256e-05, 'tol': 0.021621160887251818, 'validation_fraction': 0.891464745755294}
observation time 0.000010, current best 0.498481 at iter 33
suggestion time taken 0.012444 iter 34 next_points [{'alpha': 0.03625823797300567, 'batch_size': 62, 'beta_1': 0.7078772511685348, 'beta_2': 0.9904784756947012, 'epsilon': 4.511358318791284e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.0004179254955309736, 'tol': 1.4551380735839674e-05, 'validation_fraction': 0.25271094708247344}]
function_evaluation time 1.293095 value 0.301082 suggestion {'alpha': 0.03625823797300567, 'batch_size': 62, 'beta_1': 0.7078772511685348, 'beta_2': 0.9904784756947012, 'epsilon': 4.511358318791284e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.0004179254955309736, 'tol': 1.4551380735839674e-05, 'validation_fraction': 0.25271094708247344}
observation time 0.000005, current best 0.301082 at iter 34
suggestion time taken 0.011287 iter 35 next_points [{'alpha': 4.597335861482528, 'batch_size': 132, 'beta_1': 0.634812269664893, 'beta_2': 0.9504368271398566, 'epsilon': 1.912903962803192e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.000367909225383228, 'tol': 0.00011632482713222707, 'validation_fraction': 0.21831970787726995}]
function_evaluation time 1.381318 value 2.829648 suggestion {'alpha': 4.597335861482528, 'batch_size': 132, 'beta_1': 0.634812269664893, 'beta_2': 0.9504368271398566, 'epsilon': 1.912903962803192e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.000367909225383228, 'tol': 0.00011632482713222707, 'validation_fraction': 0.21831970787726995}
observation time 0.000003, current best 0.301082 at iter 35
suggestion time taken 0.009485 iter 36 next_points [{'alpha': 1.1730875474553744e-05, 'batch_size': 161, 'beta_1': 0.8909504430657055, 'beta_2': 0.9999679352663539, 'epsilon': 5.9387100162618335e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.00016187673073126923, 'tol': 0.05079905095771173, 'validation_fraction': 0.28581609760292737}]
function_evaluation time 0.565607 value 11.061492 suggestion {'alpha': 1.1730875474553744e-05, 'batch_size': 161, 'beta_1': 0.8909504430657055, 'beta_2': 0.9999679352663539, 'epsilon': 5.9387100162618335e-08, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.00016187673073126923, 'tol': 0.05079905095771173, 'validation_fraction': 0.28581609760292737}
observation time 0.000004, current best 0.301082 at iter 36
suggestion time taken 0.010659 iter 37 next_points [{'alpha': 2.253366885035795, 'batch_size': 184, 'beta_1': 0.8598614119399483, 'beta_2': 0.9977169156867158, 'epsilon': 3.252376927786819e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 9.490933097223373e-05, 'tol': 0.00021344580235619308, 'validation_fraction': 0.8944247336016575}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.442177 value 11.179751 suggestion {'alpha': 2.253366885035795, 'batch_size': 184, 'beta_1': 0.8598614119399483, 'beta_2': 0.9977169156867158, 'epsilon': 3.252376927786819e-07, 'hidden_layer_sizes': 157, 'learning_rate_init': 9.490933097223373e-05, 'tol': 0.00021344580235619308, 'validation_fraction': 0.8944247336016575}
observation time 0.000003, current best 0.301082 at iter 37
suggestion time taken 0.009769 iter 38 next_points [{'alpha': 0.04121707335478963, 'batch_size': 66, 'beta_1': 0.9717275785487274, 'beta_2': 0.9968265408466357, 'epsilon': 7.033528071587555e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.07536247457495024, 'tol': 0.015611705534770952, 'validation_fraction': 0.492608919708281}]
function_evaluation time 0.637973 value 2.976248 suggestion {'alpha': 0.04121707335478963, 'batch_size': 66, 'beta_1': 0.9717275785487274, 'beta_2': 0.9968265408466357, 'epsilon': 7.033528071587555e-09, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.07536247457495024, 'tol': 0.015611705534770952, 'validation_fraction': 0.492608919708281}
observation time 0.000010, current best 0.301082 at iter 38
suggestion time taken 0.010959 iter 39 next_points [{'alpha': 0.018990799089121064, 'batch_size': 58, 'beta_1': 0.5477093923038971, 'beta_2': 0.9999982658545788, 'epsilon': 1.3678693616944494e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.006262516696268388, 'tol': 0.00027188540699357196, 'validation_fraction': 0.8451971190364738}]
function_evaluation time 0.432281 value 0.496819 suggestion {'alpha': 0.018990799089121064, 'batch_size': 58, 'beta_1': 0.5477093923038971, 'beta_2': 0.9999982658545788, 'epsilon': 1.3678693616944494e-07, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.006262516696268388, 'tol': 0.00027188540699357196, 'validation_fraction': 0.8451971190364738}
observation time 0.000004, current best 0.301082 at iter 39
suggestion time taken 0.009778 iter 40 next_points [{'alpha': 0.00010068807104623915, 'batch_size': 33, 'beta_1': 0.8810523789145214, 'beta_2': 0.9943645166679627, 'epsilon': 5.054338651975745e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 3.188929977053166e-05, 'tol': 0.000472224051190554, 'validation_fraction': 0.8711523623059778}]
function_evaluation time 0.285432 value 16.365809 suggestion {'alpha': 0.00010068807104623915, 'batch_size': 33, 'beta_1': 0.8810523789145214, 'beta_2': 0.9943645166679627, 'epsilon': 5.054338651975745e-07, 'hidden_layer_sizes': 51, 'learning_rate_init': 3.188929977053166e-05, 'tol': 0.000472224051190554, 'validation_fraction': 0.8711523623059778}
observation time 0.000002, current best 0.301082 at iter 40
suggestion time taken 0.010908 iter 41 next_points [{'alpha': 0.00010996712923051282, 'batch_size': 129, 'beta_1': 0.9099397684222306, 'beta_2': 0.9999984110943474, 'epsilon': 3.019988410386135e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 2.1030737844465187e-05, 'tol': 0.001013381260434306, 'validation_fraction': 0.10991728573579185}]
function_evaluation time 0.668413 value 10.198110 suggestion {'alpha': 0.00010996712923051282, 'batch_size': 129, 'beta_1': 0.9099397684222306, 'beta_2': 0.9999984110943474, 'epsilon': 3.019988410386135e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 2.1030737844465187e-05, 'tol': 0.001013381260434306, 'validation_fraction': 0.10991728573579185}
observation time 0.000003, current best 0.301082 at iter 41
suggestion time taken 0.009788 iter 42 next_points [{'alpha': 0.028360038848153534, 'batch_size': 29, 'beta_1': 0.5434858166444165, 'beta_2': 0.9999962941107878, 'epsilon': 1.0850440285018379e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.013106178870110344, 'tol': 0.0003842043666865808, 'validation_fraction': 0.30865672906431935}]
function_evaluation time 1.416026 value 1.291195 suggestion {'alpha': 0.028360038848153534, 'batch_size': 29, 'beta_1': 0.5434858166444165, 'beta_2': 0.9999962941107878, 'epsilon': 1.0850440285018379e-08, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.013106178870110344, 'tol': 0.0003842043666865808, 'validation_fraction': 0.30865672906431935}
observation time 0.000005, current best 0.301082 at iter 42
suggestion time taken 0.011113 iter 43 next_points [{'alpha': 1.4313879664783622, 'batch_size': 51, 'beta_1': 0.9837793080458053, 'beta_2': 0.9934727642268779, 'epsilon': 4.5354840428670786e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0004169693672747124, 'tol': 0.00407490008832179, 'validation_fraction': 0.20549521944243607}]
function_evaluation time 1.802562 value 0.705980 suggestion {'alpha': 1.4313879664783622, 'batch_size': 51, 'beta_1': 0.9837793080458053, 'beta_2': 0.9934727642268779, 'epsilon': 4.5354840428670786e-07, 'hidden_layer_sizes': 151, 'learning_rate_init': 0.0004169693672747124, 'tol': 0.00407490008832179, 'validation_fraction': 0.20549521944243607}
observation time 0.000003, current best 0.301082 at iter 43
suggestion time taken 0.009903 iter 44 next_points [{'alpha': 0.00012818255002000723, 'batch_size': 234, 'beta_1': 0.9809777300334652, 'beta_2': 0.9999941010067656, 'epsilon': 2.468947294501922e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.025963140773491766, 'tol': 2.8223843027239533e-05, 'validation_fraction': 0.6201294509585908}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.407115 value 3.197515 suggestion {'alpha': 0.00012818255002000723, 'batch_size': 234, 'beta_1': 0.9809777300334652, 'beta_2': 0.9999941010067656, 'epsilon': 2.468947294501922e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.025963140773491766, 'tol': 2.8223843027239533e-05, 'validation_fraction': 0.6201294509585908}
observation time 0.000004, current best 0.301082 at iter 44
saving meta data: {'args': {'--uuid': 'ef2d79d868105e13a60fe9c48eb9b174', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])}
saving results
saving timing
saving suggest log
done
