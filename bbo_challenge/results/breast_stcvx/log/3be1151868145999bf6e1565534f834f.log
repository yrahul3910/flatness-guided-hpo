running: {'--uuid': '3be1151868145999bf6e1565534f834f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 3be1151868145999bf6e1565534f834f -m acc -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 45 1
with data root: None
suggestion time taken 0.011055 iter 0 next_points [{'alpha': 0.00019724583274319436, 'batch_size': 150, 'beta_1': 0.9675524470528133, 'beta_2': 0.9986744433103822, 'epsilon': 4.211615829786806e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00016347707923752603, 'tol': 0.00023671724752913478, 'validation_fraction': 0.8122070614083219}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.383955 value -0.509890 suggestion {'alpha': 0.00019724583274319436, 'batch_size': 150, 'beta_1': 0.9675524470528133, 'beta_2': 0.9986744433103822, 'epsilon': 4.211615829786806e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00016347707923752603, 'tol': 0.00023671724752913478, 'validation_fraction': 0.8122070614083219}
observation time 0.000005, current best -0.509890 at iter 0
suggestion time taken 0.010668 iter 1 next_points [{'alpha': 0.0002250026934888566, 'batch_size': 89, 'beta_1': 0.9772356840675583, 'beta_2': 0.9998578087979294, 'epsilon': 1.0896729652447564e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 6.23153836362335e-05, 'tol': 0.0193583725080597, 'validation_fraction': 0.7701698266915468}]
function_evaluation time 0.273486 value -0.580220 suggestion {'alpha': 0.0002250026934888566, 'batch_size': 89, 'beta_1': 0.9772356840675583, 'beta_2': 0.9998578087979294, 'epsilon': 1.0896729652447564e-07, 'hidden_layer_sizes': 131, 'learning_rate_init': 6.23153836362335e-05, 'tol': 0.0193583725080597, 'validation_fraction': 0.7701698266915468}
observation time 0.000005, current best -0.580220 at iter 1
suggestion time taken 0.010094 iter 2 next_points [{'alpha': 0.8998820823780036, 'batch_size': 112, 'beta_1': 0.6686515031073778, 'beta_2': 0.9999962069551359, 'epsilon': 1.0494552175580185e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.001177376583023175, 'tol': 2.7909442170136223e-05, 'validation_fraction': 0.2648422838233457}]
function_evaluation time 1.022021 value -0.887912 suggestion {'alpha': 0.8998820823780036, 'batch_size': 112, 'beta_1': 0.6686515031073778, 'beta_2': 0.9999962069551359, 'epsilon': 1.0494552175580185e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.001177376583023175, 'tol': 2.7909442170136223e-05, 'validation_fraction': 0.2648422838233457}
observation time 0.000004, current best -0.887912 at iter 2
suggestion time taken 0.011255 iter 3 next_points [{'alpha': 0.0008880352161659559, 'batch_size': 153, 'beta_1': 0.9259588731910073, 'beta_2': 0.9999934380890462, 'epsilon': 9.344005392243312e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.029142611172963954, 'tol': 0.0002670051860937521, 'validation_fraction': 0.17255583404840813}]
function_evaluation time 0.827551 value -0.898901 suggestion {'alpha': 0.0008880352161659559, 'batch_size': 153, 'beta_1': 0.9259588731910073, 'beta_2': 0.9999934380890462, 'epsilon': 9.344005392243312e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.029142611172963954, 'tol': 0.0002670051860937521, 'validation_fraction': 0.17255583404840813}
observation time 0.000005, current best -0.898901 at iter 3
suggestion time taken 0.011398 iter 4 next_points [{'alpha': 0.003113069550898653, 'batch_size': 235, 'beta_1': 0.9318875069358443, 'beta_2': 0.9999347289443978, 'epsilon': 5.6244036678509266e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.010091567434475847, 'tol': 0.0033998452518568855, 'validation_fraction': 0.6362490191302699}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.512814 value -0.905495 suggestion {'alpha': 0.003113069550898653, 'batch_size': 235, 'beta_1': 0.9318875069358443, 'beta_2': 0.9999347289443978, 'epsilon': 5.6244036678509266e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.010091567434475847, 'tol': 0.0033998452518568855, 'validation_fraction': 0.6362490191302699}
observation time 0.000005, current best -0.905495 at iter 4
suggestion time taken 0.012475 iter 5 next_points [{'alpha': 1.9233967279041915e-05, 'batch_size': 193, 'beta_1': 0.982246275000996, 'beta_2': 0.9999909973338161, 'epsilon': 4.6927458953964405e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.0002714751097833313, 'tol': 0.07515218206249322, 'validation_fraction': 0.1210773136990537}]
function_evaluation time 0.501641 value -0.690110 suggestion {'alpha': 1.9233967279041915e-05, 'batch_size': 193, 'beta_1': 0.982246275000996, 'beta_2': 0.9999909973338161, 'epsilon': 4.6927458953964405e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.0002714751097833313, 'tol': 0.07515218206249322, 'validation_fraction': 0.1210773136990537}
observation time 0.000011, current best -0.905495 at iter 5
suggestion time taken 0.011653 iter 6 next_points [{'alpha': 0.24919703171789379, 'batch_size': 130, 'beta_1': 0.988760395302382, 'beta_2': 0.9999542534019772, 'epsilon': 4.736534355309563e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.07691690098116298, 'tol': 0.0013118044661421509, 'validation_fraction': 0.39216324960729343}]
function_evaluation time 0.453157 value -0.723077 suggestion {'alpha': 0.24919703171789379, 'batch_size': 130, 'beta_1': 0.988760395302382, 'beta_2': 0.9999542534019772, 'epsilon': 4.736534355309563e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.07691690098116298, 'tol': 0.0013118044661421509, 'validation_fraction': 0.39216324960729343}
observation time 0.000009, current best -0.905495 at iter 6
suggestion time taken 0.010946 iter 7 next_points [{'alpha': 0.20311791209975857, 'batch_size': 234, 'beta_1': 0.578165173664757, 'beta_2': 0.9999686839113768, 'epsilon': 1.8467876230411766e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.004152728367882149, 'tol': 0.0016811163149018033, 'validation_fraction': 0.3966033531823243}]
function_evaluation time 0.672963 value -0.901099 suggestion {'alpha': 0.20311791209975857, 'batch_size': 234, 'beta_1': 0.578165173664757, 'beta_2': 0.9999686839113768, 'epsilon': 1.8467876230411766e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.004152728367882149, 'tol': 0.0016811163149018033, 'validation_fraction': 0.3966033531823243}
observation time 0.000004, current best -0.905495 at iter 7
suggestion time taken 0.010093 iter 8 next_points [{'alpha': 0.4718454570167743, 'batch_size': 202, 'beta_1': 0.8857595008854853, 'beta_2': 0.9961811504833374, 'epsilon': 2.790595311421448e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.08357883190250917, 'tol': 0.0001001994577638141, 'validation_fraction': 0.7020402606365475}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.386588 value -0.771429 suggestion {'alpha': 0.4718454570167743, 'batch_size': 202, 'beta_1': 0.8857595008854853, 'beta_2': 0.9961811504833374, 'epsilon': 2.790595311421448e-07, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.08357883190250917, 'tol': 0.0001001994577638141, 'validation_fraction': 0.7020402606365475}
observation time 0.000004, current best -0.905495 at iter 8
suggestion time taken 0.010821 iter 9 next_points [{'alpha': 0.012951240292497456, 'batch_size': 155, 'beta_1': 0.8061360519908671, 'beta_2': 0.9955292486918372, 'epsilon': 5.456849076188313e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.06174371468730096, 'tol': 0.003945797588808343, 'validation_fraction': 0.7716835487306899}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.452036 value -0.745055 suggestion {'alpha': 0.012951240292497456, 'batch_size': 155, 'beta_1': 0.8061360519908671, 'beta_2': 0.9955292486918372, 'epsilon': 5.456849076188313e-07, 'hidden_layer_sizes': 65, 'learning_rate_init': 0.06174371468730096, 'tol': 0.003945797588808343, 'validation_fraction': 0.7716835487306899}
observation time 0.000009, current best -0.905495 at iter 9
suggestion time taken 0.011429 iter 10 next_points [{'alpha': 1.544775322077398, 'batch_size': 153, 'beta_1': 0.9655050353528564, 'beta_2': 0.9993893326305404, 'epsilon': 5.664202923665353e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0008728066616418184, 'tol': 0.0036938732298790297, 'validation_fraction': 0.7253138838377023}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.308318 value -0.696703 suggestion {'alpha': 1.544775322077398, 'batch_size': 153, 'beta_1': 0.9655050353528564, 'beta_2': 0.9993893326305404, 'epsilon': 5.664202923665353e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0008728066616418184, 'tol': 0.0036938732298790297, 'validation_fraction': 0.7253138838377023}
observation time 0.000004, current best -0.905495 at iter 10
suggestion time taken 0.009566 iter 11 next_points [{'alpha': 0.23644115600543708, 'batch_size': 151, 'beta_1': 0.7968652684339412, 'beta_2': 0.999996909214165, 'epsilon': 3.364520925672614e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.022197136085019525, 'tol': 0.004152008941753016, 'validation_fraction': 0.4830030875618355}]
function_evaluation time 0.753163 value -0.894505 suggestion {'alpha': 0.23644115600543708, 'batch_size': 151, 'beta_1': 0.7968652684339412, 'beta_2': 0.999996909214165, 'epsilon': 3.364520925672614e-07, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.022197136085019525, 'tol': 0.004152008941753016, 'validation_fraction': 0.4830030875618355}
observation time 0.000005, current best -0.905495 at iter 11
suggestion time taken 0.011403 iter 12 next_points [{'alpha': 2.3322445338443365, 'batch_size': 165, 'beta_1': 0.7479318088747423, 'beta_2': 0.9863720946750599, 'epsilon': 4.64726828083793e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 2.276948587148744e-05, 'tol': 0.0006976920412525991, 'validation_fraction': 0.7124098083710313}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.234503 value -0.580220 suggestion {'alpha': 2.3322445338443365, 'batch_size': 165, 'beta_1': 0.7479318088747423, 'beta_2': 0.9863720946750599, 'epsilon': 4.64726828083793e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 2.276948587148744e-05, 'tol': 0.0006976920412525991, 'validation_fraction': 0.7124098083710313}
observation time 0.000005, current best -0.905495 at iter 12
suggestion time taken 0.010939 iter 13 next_points [{'alpha': 1.192336987831231, 'batch_size': 245, 'beta_1': 0.7621599472136635, 'beta_2': 0.9540457368456082, 'epsilon': 1.087129783809001e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.009442840233184965, 'tol': 0.0009143696005619769, 'validation_fraction': 0.6699585501711223}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.637281 value -0.918681 suggestion {'alpha': 1.192336987831231, 'batch_size': 245, 'beta_1': 0.7621599472136635, 'beta_2': 0.9540457368456082, 'epsilon': 1.087129783809001e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.009442840233184965, 'tol': 0.0009143696005619769, 'validation_fraction': 0.6699585501711223}
observation time 0.000012, current best -0.918681 at iter 13
suggestion time taken 0.011717 iter 14 next_points [{'alpha': 0.24116581186142963, 'batch_size': 98, 'beta_1': 0.9846371655835715, 'beta_2': 0.9999779874514968, 'epsilon': 7.159026442976198e-07, 'hidden_layer_sizes': 124, 'learning_rate_init': 2.109770217579721e-05, 'tol': 2.581226529502876e-05, 'validation_fraction': 0.8919541409938108}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.219076 value -0.582418 suggestion {'alpha': 0.24116581186142963, 'batch_size': 98, 'beta_1': 0.9846371655835715, 'beta_2': 0.9999779874514968, 'epsilon': 7.159026442976198e-07, 'hidden_layer_sizes': 124, 'learning_rate_init': 2.109770217579721e-05, 'tol': 2.581226529502876e-05, 'validation_fraction': 0.8919541409938108}
observation time 0.000004, current best -0.918681 at iter 14
suggestion time taken 0.009804 iter 15 next_points [{'alpha': 0.5190160946057912, 'batch_size': 108, 'beta_1': 0.9662511437963498, 'beta_2': 0.9921748948906474, 'epsilon': 3.2923835894700885e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 3.793499872305861e-05, 'tol': 0.010422156568703305, 'validation_fraction': 0.7175142194813006}]
function_evaluation time 0.425966 value -0.580220 suggestion {'alpha': 0.5190160946057912, 'batch_size': 108, 'beta_1': 0.9662511437963498, 'beta_2': 0.9921748948906474, 'epsilon': 3.2923835894700885e-09, 'hidden_layer_sizes': 115, 'learning_rate_init': 3.793499872305861e-05, 'tol': 0.010422156568703305, 'validation_fraction': 0.7175142194813006}
observation time 0.000006, current best -0.918681 at iter 15
suggestion time taken 0.013074 iter 16 next_points [{'alpha': 0.00039876452226829515, 'batch_size': 26, 'beta_1': 0.9845703444203278, 'beta_2': 0.9938650430302566, 'epsilon': 1.4380698445059969e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.02504803830422777, 'tol': 0.027743514945697757, 'validation_fraction': 0.8913710816595835}]
function_evaluation time 0.454184 value -0.901099 suggestion {'alpha': 0.00039876452226829515, 'batch_size': 26, 'beta_1': 0.9845703444203278, 'beta_2': 0.9938650430302566, 'epsilon': 1.4380698445059969e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.02504803830422777, 'tol': 0.027743514945697757, 'validation_fraction': 0.8913710816595835}
observation time 0.000004, current best -0.918681 at iter 16
suggestion time taken 0.009373 iter 17 next_points [{'alpha': 0.0018211495434287423, 'batch_size': 18, 'beta_1': 0.7428705005752415, 'beta_2': 0.9999939846728663, 'epsilon': 1.601838105948041e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0010235110401729483, 'tol': 0.00042348381631156, 'validation_fraction': 0.8490051061623449}]
function_evaluation time 0.698556 value -0.749451 suggestion {'alpha': 0.0018211495434287423, 'batch_size': 18, 'beta_1': 0.7428705005752415, 'beta_2': 0.9999939846728663, 'epsilon': 1.601838105948041e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.0010235110401729483, 'tol': 0.00042348381631156, 'validation_fraction': 0.8490051061623449}
observation time 0.000006, current best -0.918681 at iter 17
suggestion time taken 0.010501 iter 18 next_points [{'alpha': 3.7820708156663168, 'batch_size': 41, 'beta_1': 0.835350246070351, 'beta_2': 0.9991506389868302, 'epsilon': 1.34562269069569e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.07596978848394463, 'tol': 0.015955066005815165, 'validation_fraction': 0.2968886935201385}]
function_evaluation time 1.091589 value -0.912088 suggestion {'alpha': 3.7820708156663168, 'batch_size': 41, 'beta_1': 0.835350246070351, 'beta_2': 0.9991506389868302, 'epsilon': 1.34562269069569e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.07596978848394463, 'tol': 0.015955066005815165, 'validation_fraction': 0.2968886935201385}
observation time 0.000011, current best -0.918681 at iter 18
suggestion time taken 0.011968 iter 19 next_points [{'alpha': 0.0579297655504306, 'batch_size': 50, 'beta_1': 0.8396965688967413, 'beta_2': 0.9999986660914232, 'epsilon': 7.932391872491965e-09, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.00018422189005515375, 'tol': 3.801243317281915e-05, 'validation_fraction': 0.5714416410917406}]
function_evaluation time 1.255946 value -0.848352 suggestion {'alpha': 0.0579297655504306, 'batch_size': 50, 'beta_1': 0.8396965688967413, 'beta_2': 0.9999986660914232, 'epsilon': 7.932391872491965e-09, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.00018422189005515375, 'tol': 3.801243317281915e-05, 'validation_fraction': 0.5714416410917406}
observation time 0.000004, current best -0.918681 at iter 19
suggestion time taken 0.010200 iter 20 next_points [{'alpha': 0.5544166973213088, 'batch_size': 236, 'beta_1': 0.9165192186234786, 'beta_2': 0.9979123303563046, 'epsilon': 2.4292983468389588e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 6.857562078849206e-05, 'tol': 4.855298117234539e-05, 'validation_fraction': 0.6999514853965976}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.260756 value -0.527473 suggestion {'alpha': 0.5544166973213088, 'batch_size': 236, 'beta_1': 0.9165192186234786, 'beta_2': 0.9979123303563046, 'epsilon': 2.4292983468389588e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 6.857562078849206e-05, 'tol': 4.855298117234539e-05, 'validation_fraction': 0.6999514853965976}
observation time 0.000004, current best -0.918681 at iter 20
suggestion time taken 0.010637 iter 21 next_points [{'alpha': 0.5320152829052323, 'batch_size': 227, 'beta_1': 0.9459297146128444, 'beta_2': 0.9994991455580601, 'epsilon': 2.0211059232935967e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 1.8599591575145288e-05, 'tol': 0.0009290919430443032, 'validation_fraction': 0.3703105739330784}]
function_evaluation time 0.413817 value -0.417582 suggestion {'alpha': 0.5320152829052323, 'batch_size': 227, 'beta_1': 0.9459297146128444, 'beta_2': 0.9994991455580601, 'epsilon': 2.0211059232935967e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 1.8599591575145288e-05, 'tol': 0.0009290919430443032, 'validation_fraction': 0.3703105739330784}
observation time 0.000010, current best -0.918681 at iter 21
suggestion time taken 0.011255 iter 22 next_points [{'alpha': 5.341014235870508, 'batch_size': 57, 'beta_1': 0.7579360812457063, 'beta_2': 0.9997657714500615, 'epsilon': 1.3696710978325437e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.011158223113202703, 'tol': 0.00705476728202027, 'validation_fraction': 0.23739729235937423}]
function_evaluation time 1.071307 value -0.912088 suggestion {'alpha': 5.341014235870508, 'batch_size': 57, 'beta_1': 0.7579360812457063, 'beta_2': 0.9997657714500615, 'epsilon': 1.3696710978325437e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.011158223113202703, 'tol': 0.00705476728202027, 'validation_fraction': 0.23739729235937423}
observation time 0.000006, current best -0.918681 at iter 22
suggestion time taken 0.011919 iter 23 next_points [{'alpha': 0.9388006907217962, 'batch_size': 89, 'beta_1': 0.7162346804818622, 'beta_2': 0.9954169896578389, 'epsilon': 1.491446892085083e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 1.873165260826662e-05, 'tol': 5.370558846081376e-05, 'validation_fraction': 0.7438141126734835}]
function_evaluation time 0.311682 value -0.417582 suggestion {'alpha': 0.9388006907217962, 'batch_size': 89, 'beta_1': 0.7162346804818622, 'beta_2': 0.9954169896578389, 'epsilon': 1.491446892085083e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 1.873165260826662e-05, 'tol': 5.370558846081376e-05, 'validation_fraction': 0.7438141126734835}
observation time 0.000005, current best -0.918681 at iter 23
suggestion time taken 0.010784 iter 24 next_points [{'alpha': 3.097715584058047, 'batch_size': 245, 'beta_1': 0.9867485023626343, 'beta_2': 0.9995985443169317, 'epsilon': 8.565857771848044e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 6.410418361574953e-05, 'tol': 0.02805889370109697, 'validation_fraction': 0.18580332010011172}]
function_evaluation time 0.501943 value -0.597802 suggestion {'alpha': 3.097715584058047, 'batch_size': 245, 'beta_1': 0.9867485023626343, 'beta_2': 0.9995985443169317, 'epsilon': 8.565857771848044e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 6.410418361574953e-05, 'tol': 0.02805889370109697, 'validation_fraction': 0.18580332010011172}
observation time 0.000005, current best -0.918681 at iter 24
suggestion time taken 0.010539 iter 25 next_points [{'alpha': 1.570302830262373e-05, 'batch_size': 86, 'beta_1': 0.9780572373357648, 'beta_2': 0.9993909436034001, 'epsilon': 3.307206359924273e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 3.1374825258530046e-05, 'tol': 5.7236401224051235e-05, 'validation_fraction': 0.42434543132275604}]
function_evaluation time 0.470673 value -0.637363 suggestion {'alpha': 1.570302830262373e-05, 'batch_size': 86, 'beta_1': 0.9780572373357648, 'beta_2': 0.9993909436034001, 'epsilon': 3.307206359924273e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 3.1374825258530046e-05, 'tol': 5.7236401224051235e-05, 'validation_fraction': 0.42434543132275604}
observation time 0.000010, current best -0.918681 at iter 25
suggestion time taken 0.011101 iter 26 next_points [{'alpha': 0.4973727045486264, 'batch_size': 127, 'beta_1': 0.9602126568044019, 'beta_2': 0.9997322729261137, 'epsilon': 2.6118056924411893e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 1.2570002335091362e-05, 'tol': 0.0035523578972491174, 'validation_fraction': 0.19098269705556026}]
function_evaluation time 0.463347 value -0.527473 suggestion {'alpha': 0.4973727045486264, 'batch_size': 127, 'beta_1': 0.9602126568044019, 'beta_2': 0.9997322729261137, 'epsilon': 2.6118056924411893e-07, 'hidden_layer_sizes': 83, 'learning_rate_init': 1.2570002335091362e-05, 'tol': 0.0035523578972491174, 'validation_fraction': 0.19098269705556026}
observation time 0.000006, current best -0.918681 at iter 26
suggestion time taken 0.010719 iter 27 next_points [{'alpha': 8.838247531971119, 'batch_size': 82, 'beta_1': 0.9469643157515255, 'beta_2': 0.999998757343303, 'epsilon': 3.122941188001402e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 1.3349997475954128e-05, 'tol': 2.4761761795701254e-05, 'validation_fraction': 0.7898186073040763}]
function_evaluation time 0.278108 value -0.362637 suggestion {'alpha': 8.838247531971119, 'batch_size': 82, 'beta_1': 0.9469643157515255, 'beta_2': 0.999998757343303, 'epsilon': 3.122941188001402e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 1.3349997475954128e-05, 'tol': 2.4761761795701254e-05, 'validation_fraction': 0.7898186073040763}
observation time 0.000004, current best -0.918681 at iter 27
suggestion time taken 0.010383 iter 28 next_points [{'alpha': 2.88987975516136, 'batch_size': 184, 'beta_1': 0.6429426413116431, 'beta_2': 0.9999982885623742, 'epsilon': 1.4348725947896739e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.009509193376048677, 'tol': 2.475074534357996e-05, 'validation_fraction': 0.4356979782600075}]
function_evaluation time 0.577948 value -0.903297 suggestion {'alpha': 2.88987975516136, 'batch_size': 184, 'beta_1': 0.6429426413116431, 'beta_2': 0.9999982885623742, 'epsilon': 1.4348725947896739e-07, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.009509193376048677, 'tol': 2.475074534357996e-05, 'validation_fraction': 0.4356979782600075}
observation time 0.000010, current best -0.918681 at iter 28
suggestion time taken 0.012047 iter 29 next_points [{'alpha': 0.05060709132706406, 'batch_size': 195, 'beta_1': 0.9623184809031098, 'beta_2': 0.9841725570047282, 'epsilon': 6.497096904621215e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 4.484785771723106e-05, 'tol': 0.0003285809164239683, 'validation_fraction': 0.12006168458350512}]
function_evaluation time 0.499040 value -0.551648 suggestion {'alpha': 0.05060709132706406, 'batch_size': 195, 'beta_1': 0.9623184809031098, 'beta_2': 0.9841725570047282, 'epsilon': 6.497096904621215e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 4.484785771723106e-05, 'tol': 0.0003285809164239683, 'validation_fraction': 0.12006168458350512}
observation time 0.000004, current best -0.918681 at iter 29
suggestion time taken 0.009695 iter 30 next_points [{'alpha': 0.008937758635524174, 'batch_size': 75, 'beta_1': 0.9229112712632052, 'beta_2': 0.9999860304953742, 'epsilon': 5.187512574454357e-08, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.0002076750054016788, 'tol': 0.00010806633962069449, 'validation_fraction': 0.4758645835049253}]
function_evaluation time 0.633267 value -0.560440 suggestion {'alpha': 0.008937758635524174, 'batch_size': 75, 'beta_1': 0.9229112712632052, 'beta_2': 0.9999860304953742, 'epsilon': 5.187512574454357e-08, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.0002076750054016788, 'tol': 0.00010806633962069449, 'validation_fraction': 0.4758645835049253}
observation time 0.000004, current best -0.918681 at iter 30
suggestion time taken 0.010391 iter 31 next_points [{'alpha': 5.401645607054979, 'batch_size': 205, 'beta_1': 0.7502860351242396, 'beta_2': 0.999994674948618, 'epsilon': 8.914852441989415e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 1.629872056591035e-05, 'tol': 0.02537127506786934, 'validation_fraction': 0.7251298923377976}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.267210 value -0.617582 suggestion {'alpha': 5.401645607054979, 'batch_size': 205, 'beta_1': 0.7502860351242396, 'beta_2': 0.999994674948618, 'epsilon': 8.914852441989415e-09, 'hidden_layer_sizes': 135, 'learning_rate_init': 1.629872056591035e-05, 'tol': 0.02537127506786934, 'validation_fraction': 0.7251298923377976}
observation time 0.000018, current best -0.918681 at iter 31
suggestion time taken 0.009493 iter 32 next_points [{'alpha': 0.023478569760862458, 'batch_size': 39, 'beta_1': 0.9259075407331244, 'beta_2': 0.9998705943681706, 'epsilon': 1.4157566790673571e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.052609306906156734, 'tol': 4.7942137923712066e-05, 'validation_fraction': 0.47097789827324277}]
function_evaluation time 0.986660 value -0.901099 suggestion {'alpha': 0.023478569760862458, 'batch_size': 39, 'beta_1': 0.9259075407331244, 'beta_2': 0.9998705943681706, 'epsilon': 1.4157566790673571e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.052609306906156734, 'tol': 4.7942137923712066e-05, 'validation_fraction': 0.47097789827324277}
observation time 0.000005, current best -0.918681 at iter 32
suggestion time taken 0.010016 iter 33 next_points [{'alpha': 1.9962279289789124e-05, 'batch_size': 244, 'beta_1': 0.957062816809154, 'beta_2': 0.9999941472065256, 'epsilon': 2.614894882628053e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 2.2060927616154793e-05, 'tol': 7.544965992987963e-05, 'validation_fraction': 0.11797444293448976}]
function_evaluation time 0.361857 value -0.474725 suggestion {'alpha': 1.9962279289789124e-05, 'batch_size': 244, 'beta_1': 0.957062816809154, 'beta_2': 0.9999941472065256, 'epsilon': 2.614894882628053e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 2.2060927616154793e-05, 'tol': 7.544965992987963e-05, 'validation_fraction': 0.11797444293448976}
observation time 0.000005, current best -0.918681 at iter 33
suggestion time taken 0.010814 iter 34 next_points [{'alpha': 1.535398706582318e-05, 'batch_size': 77, 'beta_1': 0.586693343935343, 'beta_2': 0.9764796508481065, 'epsilon': 1.011340072576187e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.08758099233863309, 'tol': 0.011348683495548911, 'validation_fraction': 0.2787336417917044}]
function_evaluation time 0.773507 value -0.901099 suggestion {'alpha': 1.535398706582318e-05, 'batch_size': 77, 'beta_1': 0.586693343935343, 'beta_2': 0.9764796508481065, 'epsilon': 1.011340072576187e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.08758099233863309, 'tol': 0.011348683495548911, 'validation_fraction': 0.2787336417917044}
observation time 0.000004, current best -0.918681 at iter 34
suggestion time taken 0.009947 iter 35 next_points [{'alpha': 1.4311524018347415, 'batch_size': 98, 'beta_1': 0.6695410680876815, 'beta_2': 0.9998626206882039, 'epsilon': 1.0326921482025667e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.01102824754814316, 'tol': 0.00015897381181365146, 'validation_fraction': 0.6563644488436927}]
function_evaluation time 0.890189 value -0.916484 suggestion {'alpha': 1.4311524018347415, 'batch_size': 98, 'beta_1': 0.6695410680876815, 'beta_2': 0.9998626206882039, 'epsilon': 1.0326921482025667e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.01102824754814316, 'tol': 0.00015897381181365146, 'validation_fraction': 0.6563644488436927}
observation time 0.000005, current best -0.918681 at iter 35
suggestion time taken 0.010067 iter 36 next_points [{'alpha': 0.4643404547110678, 'batch_size': 94, 'beta_1': 0.8367952920297209, 'beta_2': 0.9997393346110193, 'epsilon': 2.8868030335658154e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.029581870381632156, 'tol': 0.042290984862056534, 'validation_fraction': 0.899752690278078}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.337982 value -0.912088 suggestion {'alpha': 0.4643404547110678, 'batch_size': 94, 'beta_1': 0.8367952920297209, 'beta_2': 0.9997393346110193, 'epsilon': 2.8868030335658154e-08, 'hidden_layer_sizes': 82, 'learning_rate_init': 0.029581870381632156, 'tol': 0.042290984862056534, 'validation_fraction': 0.899752690278078}
observation time 0.000006, current best -0.918681 at iter 36
suggestion time taken 0.011082 iter 37 next_points [{'alpha': 0.024890122167318503, 'batch_size': 134, 'beta_1': 0.9627030811464334, 'beta_2': 0.9999965222050472, 'epsilon': 2.8644028955143553e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.08548588094313447, 'tol': 4.84326425901552e-05, 'validation_fraction': 0.8166502192251893}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.402226 value -0.734066 suggestion {'alpha': 0.024890122167318503, 'batch_size': 134, 'beta_1': 0.9627030811464334, 'beta_2': 0.9999965222050472, 'epsilon': 2.8644028955143553e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.08548588094313447, 'tol': 4.84326425901552e-05, 'validation_fraction': 0.8166502192251893}
observation time 0.000008, current best -0.918681 at iter 37
suggestion time taken 0.010674 iter 38 next_points [{'alpha': 0.00013943081495618537, 'batch_size': 172, 'beta_1': 0.9741761560381856, 'beta_2': 0.9999773663983924, 'epsilon': 2.8758541771466384e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.03323218782459434, 'tol': 0.0004598424438680366, 'validation_fraction': 0.729684442240441}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.441147 value -0.808791 suggestion {'alpha': 0.00013943081495618537, 'batch_size': 172, 'beta_1': 0.9741761560381856, 'beta_2': 0.9999773663983924, 'epsilon': 2.8758541771466384e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.03323218782459434, 'tol': 0.0004598424438680366, 'validation_fraction': 0.729684442240441}
observation time 0.000004, current best -0.918681 at iter 38
suggestion time taken 0.009717 iter 39 next_points [{'alpha': 0.0003247027414890454, 'batch_size': 126, 'beta_1': 0.9725013109998731, 'beta_2': 0.9123845344417578, 'epsilon': 1.2209143232363535e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.05811722716411783, 'tol': 0.0005819176010977166, 'validation_fraction': 0.6033042461641087}]
function_evaluation time 0.706039 value -0.839560 suggestion {'alpha': 0.0003247027414890454, 'batch_size': 126, 'beta_1': 0.9725013109998731, 'beta_2': 0.9123845344417578, 'epsilon': 1.2209143232363535e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.05811722716411783, 'tol': 0.0005819176010977166, 'validation_fraction': 0.6033042461641087}
observation time 0.000005, current best -0.918681 at iter 39
suggestion time taken 0.010426 iter 40 next_points [{'alpha': 1.1105707123260244, 'batch_size': 177, 'beta_1': 0.7355444925993234, 'beta_2': 0.9998865672576254, 'epsilon': 7.225878771008202e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.010754138234771083, 'tol': 0.013474341140262447, 'validation_fraction': 0.33520643801057537}]
function_evaluation time 0.525849 value -0.887912 suggestion {'alpha': 1.1105707123260244, 'batch_size': 177, 'beta_1': 0.7355444925993234, 'beta_2': 0.9998865672576254, 'epsilon': 7.225878771008202e-09, 'hidden_layer_sizes': 79, 'learning_rate_init': 0.010754138234771083, 'tol': 0.013474341140262447, 'validation_fraction': 0.33520643801057537}
observation time 0.000007, current best -0.918681 at iter 40
suggestion time taken 0.011024 iter 41 next_points [{'alpha': 0.3804262993970757, 'batch_size': 17, 'beta_1': 0.9834918363945783, 'beta_2': 0.9996013254741614, 'epsilon': 4.5695498526367935e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.00018048362482349782, 'tol': 0.033842188673521616, 'validation_fraction': 0.35914860342552873}]
function_evaluation time 1.899596 value -0.901099 suggestion {'alpha': 0.3804262993970757, 'batch_size': 17, 'beta_1': 0.9834918363945783, 'beta_2': 0.9996013254741614, 'epsilon': 4.5695498526367935e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.00018048362482349782, 'tol': 0.033842188673521616, 'validation_fraction': 0.35914860342552873}
observation time 0.000004, current best -0.918681 at iter 41
suggestion time taken 0.010452 iter 42 next_points [{'alpha': 1.8105401264763133e-05, 'batch_size': 104, 'beta_1': 0.9846857549596347, 'beta_2': 0.999998877923376, 'epsilon': 5.571995436406667e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.004029036520465399, 'tol': 0.008189239404201023, 'validation_fraction': 0.557372691915198}]
function_evaluation time 0.725530 value -0.854945 suggestion {'alpha': 1.8105401264763133e-05, 'batch_size': 104, 'beta_1': 0.9846857549596347, 'beta_2': 0.999998877923376, 'epsilon': 5.571995436406667e-09, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.004029036520465399, 'tol': 0.008189239404201023, 'validation_fraction': 0.557372691915198}
observation time 0.000012, current best -0.918681 at iter 42
suggestion time taken 0.011753 iter 43 next_points [{'alpha': 0.019191494169771294, 'batch_size': 90, 'beta_1': 0.8520468855979173, 'beta_2': 0.9972454676697248, 'epsilon': 6.031532035925819e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.00034267751957905323, 'tol': 0.00014180540386561535, 'validation_fraction': 0.8885933330563655}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.209943 value -0.472527 suggestion {'alpha': 0.019191494169771294, 'batch_size': 90, 'beta_1': 0.8520468855979173, 'beta_2': 0.9972454676697248, 'epsilon': 6.031532035925819e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.00034267751957905323, 'tol': 0.00014180540386561535, 'validation_fraction': 0.8885933330563655}
observation time 0.000004, current best -0.918681 at iter 43
suggestion time taken 0.009945 iter 44 next_points [{'alpha': 2.2531675719681457e-05, 'batch_size': 141, 'beta_1': 0.7460062826636596, 'beta_2': 0.9869656072673929, 'epsilon': 5.104531769413259e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 6.65648897676345e-05, 'tol': 0.022926190228894985, 'validation_fraction': 0.6323676896971696}]
function_evaluation time 0.282085 value -0.531868 suggestion {'alpha': 2.2531675719681457e-05, 'batch_size': 141, 'beta_1': 0.7460062826636596, 'beta_2': 0.9869656072673929, 'epsilon': 5.104531769413259e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 6.65648897676345e-05, 'tol': 0.022926190228894985, 'validation_fraction': 0.6323676896971696}
observation time 0.000008, current best -0.918681 at iter 44
saving meta data: {'args': {'--uuid': '3be1151868145999bf6e1565534f834f', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
