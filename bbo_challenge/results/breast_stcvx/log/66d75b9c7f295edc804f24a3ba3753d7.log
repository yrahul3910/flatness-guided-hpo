running: {'--uuid': '66d75b9c7f295edc804f24a3ba3753d7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 66d75b9c7f295edc804f24a3ba3753d7 -m nll -n 45 -p 1 -dir /home/ryedida/bbo_challenge_starter_kit/output -b run_20231013_070336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:470: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast nll 45 1
with data root: None
suggestion time taken 0.010879 iter 0 next_points [{'alpha': 1.2269585125614084e-05, 'batch_size': 83, 'beta_1': 0.8531938406758902, 'beta_2': 0.9999822134996911, 'epsilon': 1.2925197115778598e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 7.110188127208846e-05, 'tol': 0.017690282127924742, 'validation_fraction': 0.14206249087329917}]
function_evaluation time 1.105762 value 8.222460 suggestion {'alpha': 1.2269585125614084e-05, 'batch_size': 83, 'beta_1': 0.8531938406758902, 'beta_2': 0.9999822134996911, 'epsilon': 1.2925197115778598e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 7.110188127208846e-05, 'tol': 0.017690282127924742, 'validation_fraction': 0.14206249087329917}
observation time 0.000004, current best 8.222460 at iter 0
suggestion time taken 0.010224 iter 1 next_points [{'alpha': 1.0286071888133554, 'batch_size': 52, 'beta_1': 0.7360751077563465, 'beta_2': 0.9999977407475588, 'epsilon': 5.421505419934078e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 2.7550167786353888e-05, 'tol': 0.005246701099179202, 'validation_fraction': 0.7064742612503258}]
function_evaluation time 0.394858 value 14.421976 suggestion {'alpha': 1.0286071888133554, 'batch_size': 52, 'beta_1': 0.7360751077563465, 'beta_2': 0.9999977407475588, 'epsilon': 5.421505419934078e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 2.7550167786353888e-05, 'tol': 0.005246701099179202, 'validation_fraction': 0.7064742612503258}
observation time 0.000009, current best 8.222460 at iter 1
suggestion time taken 0.011625 iter 2 next_points [{'alpha': 4.678634019620621, 'batch_size': 110, 'beta_1': 0.8820483783178743, 'beta_2': 0.9661347908342798, 'epsilon': 5.758105133285465e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.001503100662106303, 'tol': 0.026636116611103655, 'validation_fraction': 0.24868200864518386}]
function_evaluation time 0.697740 value 1.669170 suggestion {'alpha': 4.678634019620621, 'batch_size': 110, 'beta_1': 0.8820483783178743, 'beta_2': 0.9661347908342798, 'epsilon': 5.758105133285465e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.001503100662106303, 'tol': 0.026636116611103655, 'validation_fraction': 0.24868200864518386}
observation time 0.000004, current best 1.669170 at iter 2
suggestion time taken 0.010584 iter 3 next_points [{'alpha': 1.6056861304181578e-05, 'batch_size': 160, 'beta_1': 0.984931364669851, 'beta_2': 0.9970401408691407, 'epsilon': 2.2567437076354594e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0317114885115151, 'tol': 2.675799815156972e-05, 'validation_fraction': 0.5171470739524523}]
function_evaluation time 0.958261 value 0.572833 suggestion {'alpha': 1.6056861304181578e-05, 'batch_size': 160, 'beta_1': 0.984931364669851, 'beta_2': 0.9970401408691407, 'epsilon': 2.2567437076354594e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0317114885115151, 'tol': 2.675799815156972e-05, 'validation_fraction': 0.5171470739524523}
observation time 0.000004, current best 0.572833 at iter 3
suggestion time taken 0.010459 iter 4 next_points [{'alpha': 0.07322293554085724, 'batch_size': 235, 'beta_1': 0.5121034011307979, 'beta_2': 0.9998064378221819, 'epsilon': 7.44887601015647e-09, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.003943806014576507, 'tol': 0.00011607048904369728, 'validation_fraction': 0.7298847997471406}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.693823 value 0.494269 suggestion {'alpha': 0.07322293554085724, 'batch_size': 235, 'beta_1': 0.5121034011307979, 'beta_2': 0.9998064378221819, 'epsilon': 7.44887601015647e-09, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.003943806014576507, 'tol': 0.00011607048904369728, 'validation_fraction': 0.7298847997471406}
observation time 0.000009, current best 0.494269 at iter 4
suggestion time taken 0.016145 iter 5 next_points [{'alpha': 0.6821429682912025, 'batch_size': 148, 'beta_1': 0.9233303955655908, 'beta_2': 0.9999617943928288, 'epsilon': 5.205465920025443e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.004544964372032294, 'tol': 4.338577154599201e-05, 'validation_fraction': 0.6688594141189614}]
function_evaluation time 0.608523 value 0.528083 suggestion {'alpha': 0.6821429682912025, 'batch_size': 148, 'beta_1': 0.9233303955655908, 'beta_2': 0.9999617943928288, 'epsilon': 5.205465920025443e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.004544964372032294, 'tol': 4.338577154599201e-05, 'validation_fraction': 0.6688594141189614}
observation time 0.000004, current best 0.494269 at iter 5
suggestion time taken 0.010171 iter 6 next_points [{'alpha': 6.789385157038358e-05, 'batch_size': 30, 'beta_1': 0.8377449240312407, 'beta_2': 0.9999985636840474, 'epsilon': 9.112067543554491e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.00019768315250664795, 'tol': 2.8567723961769964e-05, 'validation_fraction': 0.43555498099671414}]
function_evaluation time 1.418047 value 6.265421 suggestion {'alpha': 6.789385157038358e-05, 'batch_size': 30, 'beta_1': 0.8377449240312407, 'beta_2': 0.9999985636840474, 'epsilon': 9.112067543554491e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.00019768315250664795, 'tol': 2.8567723961769964e-05, 'validation_fraction': 0.43555498099671414}
observation time 0.000013, current best 0.494269 at iter 6
suggestion time taken 0.014008 iter 7 next_points [{'alpha': 0.00018497370105150963, 'batch_size': 78, 'beta_1': 0.8750010117699583, 'beta_2': 0.9999621898125749, 'epsilon': 2.1433585906981763e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 2.5658375179233384e-05, 'tol': 0.00024240069214795975, 'validation_fraction': 0.14881144636295018}]
function_evaluation time 0.611564 value 15.416261 suggestion {'alpha': 0.00018497370105150963, 'batch_size': 78, 'beta_1': 0.8750010117699583, 'beta_2': 0.9999621898125749, 'epsilon': 2.1433585906981763e-07, 'hidden_layer_sizes': 160, 'learning_rate_init': 2.5658375179233384e-05, 'tol': 0.00024240069214795975, 'validation_fraction': 0.14881144636295018}
observation time 0.000004, current best 0.494269 at iter 7
suggestion time taken 0.009763 iter 8 next_points [{'alpha': 0.00024153353551426078, 'batch_size': 168, 'beta_1': 0.8899988612276654, 'beta_2': 0.9999890217122668, 'epsilon': 5.23988473407491e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.09814917372485774, 'tol': 0.00015416936865269188, 'validation_fraction': 0.3362508862103612}]
function_evaluation time 0.427628 value 7.683650 suggestion {'alpha': 0.00024153353551426078, 'batch_size': 168, 'beta_1': 0.8899988612276654, 'beta_2': 0.9999890217122668, 'epsilon': 5.23988473407491e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.09814917372485774, 'tol': 0.00015416936865269188, 'validation_fraction': 0.3362508862103612}
observation time 0.000005, current best 0.494269 at iter 8
suggestion time taken 0.014746 iter 9 next_points [{'alpha': 0.0026996283387158474, 'batch_size': 42, 'beta_1': 0.7306297282924349, 'beta_2': 0.9897403091188988, 'epsilon': 4.40514873623914e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.007614260669631017, 'tol': 8.775606077050513e-05, 'validation_fraction': 0.5625111656368981}]
function_evaluation time 0.890839 value 0.784469 suggestion {'alpha': 0.0026996283387158474, 'batch_size': 42, 'beta_1': 0.7306297282924349, 'beta_2': 0.9897403091188988, 'epsilon': 4.40514873623914e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.007614260669631017, 'tol': 8.775606077050513e-05, 'validation_fraction': 0.5625111656368981}
observation time 0.000011, current best 0.494269 at iter 9
suggestion time taken 0.011307 iter 10 next_points [{'alpha': 0.01719817143154736, 'batch_size': 124, 'beta_1': 0.8081045768475538, 'beta_2': 0.9964353789770427, 'epsilon': 1.54914797319047e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.001106053569264, 'tol': 0.0003019048590521487, 'validation_fraction': 0.27490210909222096}]
function_evaluation time 0.861520 value 2.808758 suggestion {'alpha': 0.01719817143154736, 'batch_size': 124, 'beta_1': 0.8081045768475538, 'beta_2': 0.9964353789770427, 'epsilon': 1.54914797319047e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.001106053569264, 'tol': 0.0003019048590521487, 'validation_fraction': 0.27490210909222096}
observation time 0.000006, current best 0.494269 at iter 10
suggestion time taken 0.012373 iter 11 next_points [{'alpha': 5.944097396063569, 'batch_size': 110, 'beta_1': 0.6815737951920281, 'beta_2': 0.9968869307706929, 'epsilon': 3.767977700781568e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.01359671856368955, 'tol': 0.03205167775151549, 'validation_fraction': 0.894967304939901}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.428055 value 0.758586 suggestion {'alpha': 5.944097396063569, 'batch_size': 110, 'beta_1': 0.6815737951920281, 'beta_2': 0.9968869307706929, 'epsilon': 3.767977700781568e-08, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.01359671856368955, 'tol': 0.03205167775151549, 'validation_fraction': 0.894967304939901}
observation time 0.000005, current best 0.494269 at iter 11
suggestion time taken 0.011696 iter 12 next_points [{'alpha': 0.0003082855071001799, 'batch_size': 148, 'beta_1': 0.9797901801687613, 'beta_2': 0.9896580537039499, 'epsilon': 8.633786160382328e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.028289569459885, 'tol': 0.002269135860576273, 'validation_fraction': 0.34316719129331624}]
function_evaluation time 0.775349 value 0.494175 suggestion {'alpha': 0.0003082855071001799, 'batch_size': 148, 'beta_1': 0.9797901801687613, 'beta_2': 0.9896580537039499, 'epsilon': 8.633786160382328e-07, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.028289569459885, 'tol': 0.002269135860576273, 'validation_fraction': 0.34316719129331624}
observation time 0.000012, current best 0.494175 at iter 12
suggestion time taken 0.013609 iter 13 next_points [{'alpha': 0.008571425383430467, 'batch_size': 17, 'beta_1': 0.8736699487447109, 'beta_2': 0.9999959658440328, 'epsilon': 1.521323696221348e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.005395328592186198, 'tol': 0.008605684859063864, 'validation_fraction': 0.11034079558639048}]
function_evaluation time 1.724497 value 0.529193 suggestion {'alpha': 0.008571425383430467, 'batch_size': 17, 'beta_1': 0.8736699487447109, 'beta_2': 0.9999959658440328, 'epsilon': 1.521323696221348e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.005395328592186198, 'tol': 0.008605684859063864, 'validation_fraction': 0.11034079558639048}
observation time 0.000003, current best 0.494175 at iter 13
suggestion time taken 0.009875 iter 14 next_points [{'alpha': 5.376945578003376e-05, 'batch_size': 138, 'beta_1': 0.9473992980675073, 'beta_2': 0.9999914884242834, 'epsilon': 7.83381361293686e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0045905427733879175, 'tol': 0.0009884946414354227, 'validation_fraction': 0.6801385637732277}]
function_evaluation time 0.542560 value 5.506536 suggestion {'alpha': 5.376945578003376e-05, 'batch_size': 138, 'beta_1': 0.9473992980675073, 'beta_2': 0.9999914884242834, 'epsilon': 7.83381361293686e-09, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.0045905427733879175, 'tol': 0.0009884946414354227, 'validation_fraction': 0.6801385637732277}
observation time 0.000005, current best 0.494175 at iter 14
suggestion time taken 0.011100 iter 15 next_points [{'alpha': 2.3918623666563113e-05, 'batch_size': 191, 'beta_1': 0.9269005698450943, 'beta_2': 0.9999980411176917, 'epsilon': 2.5673520968722355e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.03782443401751768, 'tol': 0.00018101201863429756, 'validation_fraction': 0.8755644125365007}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.463059 value 7.705752 suggestion {'alpha': 2.3918623666563113e-05, 'batch_size': 191, 'beta_1': 0.9269005698450943, 'beta_2': 0.9999980411176917, 'epsilon': 2.5673520968722355e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.03782443401751768, 'tol': 0.00018101201863429756, 'validation_fraction': 0.8755644125365007}
observation time 0.000005, current best 0.494175 at iter 15
suggestion time taken 0.009465 iter 16 next_points [{'alpha': 2.7951292347962915, 'batch_size': 65, 'beta_1': 0.6027065631705365, 'beta_2': 0.9999989443202704, 'epsilon': 8.987672214737558e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 3.860822057604166e-05, 'tol': 0.014488105218924713, 'validation_fraction': 0.5057800316303114}]
function_evaluation time 0.864453 value 10.086883 suggestion {'alpha': 2.7951292347962915, 'batch_size': 65, 'beta_1': 0.6027065631705365, 'beta_2': 0.9999989443202704, 'epsilon': 8.987672214737558e-07, 'hidden_layer_sizes': 188, 'learning_rate_init': 3.860822057604166e-05, 'tol': 0.014488105218924713, 'validation_fraction': 0.5057800316303114}
observation time 0.000004, current best 0.494175 at iter 16
suggestion time taken 0.010458 iter 17 next_points [{'alpha': 0.11408897906692711, 'batch_size': 46, 'beta_1': 0.5714285218518723, 'beta_2': 0.9942054930668243, 'epsilon': 1.592456300548729e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 3.8383262398497904e-05, 'tol': 0.004675395038724231, 'validation_fraction': 0.8868546146730505}]
function_evaluation time 0.343819 value 11.509882 suggestion {'alpha': 0.11408897906692711, 'batch_size': 46, 'beta_1': 0.5714285218518723, 'beta_2': 0.9942054930668243, 'epsilon': 1.592456300548729e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 3.8383262398497904e-05, 'tol': 0.004675395038724231, 'validation_fraction': 0.8868546146730505}
observation time 0.000005, current best 0.494175 at iter 17
suggestion time taken 0.011066 iter 18 next_points [{'alpha': 0.33234796138613404, 'batch_size': 102, 'beta_1': 0.9866426206041276, 'beta_2': 0.999998999441914, 'epsilon': 7.705312023689827e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.01096011376252885, 'tol': 0.0001019243590156019, 'validation_fraction': 0.46453335032174675}]
function_evaluation time 0.636534 value 1.124813 suggestion {'alpha': 0.33234796138613404, 'batch_size': 102, 'beta_1': 0.9866426206041276, 'beta_2': 0.999998999441914, 'epsilon': 7.705312023689827e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.01096011376252885, 'tol': 0.0001019243590156019, 'validation_fraction': 0.46453335032174675}
observation time 0.000004, current best 0.494175 at iter 18
suggestion time taken 0.009923 iter 19 next_points [{'alpha': 3.305839953319074, 'batch_size': 118, 'beta_1': 0.9829601448950773, 'beta_2': 0.9985584261559939, 'epsilon': 9.543745095793435e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0015062046060403426, 'tol': 0.0518698482403523, 'validation_fraction': 0.8018465301215275}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.294956 value 4.680322 suggestion {'alpha': 3.305839953319074, 'batch_size': 118, 'beta_1': 0.9829601448950773, 'beta_2': 0.9985584261559939, 'epsilon': 9.543745095793435e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0015062046060403426, 'tol': 0.0518698482403523, 'validation_fraction': 0.8018465301215275}
observation time 0.000005, current best 0.494175 at iter 19
suggestion time taken 0.011003 iter 20 next_points [{'alpha': 0.22283894327907394, 'batch_size': 47, 'beta_1': 0.8268632520893836, 'beta_2': 0.999996901690069, 'epsilon': 3.4672540353432256e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0016712695357255535, 'tol': 0.071339807061132, 'validation_fraction': 0.10694865522088194}]
function_evaluation time 0.820512 value 0.509644 suggestion {'alpha': 0.22283894327907394, 'batch_size': 47, 'beta_1': 0.8268632520893836, 'beta_2': 0.999996901690069, 'epsilon': 3.4672540353432256e-09, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.0016712695357255535, 'tol': 0.071339807061132, 'validation_fraction': 0.10694865522088194}
observation time 0.000002, current best 0.494175 at iter 20
suggestion time taken 0.010064 iter 21 next_points [{'alpha': 5.824340294558846e-05, 'batch_size': 231, 'beta_1': 0.697178488686666, 'beta_2': 0.9967586650112968, 'epsilon': 1.0189356414318432e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 2.655026556988395e-05, 'tol': 0.002404627005284313, 'validation_fraction': 0.6522335542127846}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.328393 value 15.240583 suggestion {'alpha': 5.824340294558846e-05, 'batch_size': 231, 'beta_1': 0.697178488686666, 'beta_2': 0.9967586650112968, 'epsilon': 1.0189356414318432e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 2.655026556988395e-05, 'tol': 0.002404627005284313, 'validation_fraction': 0.6522335542127846}
observation time 0.000006, current best 0.494175 at iter 21
suggestion time taken 0.011333 iter 22 next_points [{'alpha': 7.172029365720664e-05, 'batch_size': 157, 'beta_1': 0.9612003441060726, 'beta_2': 0.9996868249196452, 'epsilon': 2.4069179091565415e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0011502012917807807, 'tol': 0.062093055801823546, 'validation_fraction': 0.652407920187364}]
function_evaluation time 0.365260 value 8.553866 suggestion {'alpha': 7.172029365720664e-05, 'batch_size': 157, 'beta_1': 0.9612003441060726, 'beta_2': 0.9996868249196452, 'epsilon': 2.4069179091565415e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0011502012917807807, 'tol': 0.062093055801823546, 'validation_fraction': 0.652407920187364}
observation time 0.000005, current best 0.494175 at iter 22
suggestion time taken 0.010689 iter 23 next_points [{'alpha': 0.004689475741910082, 'batch_size': 214, 'beta_1': 0.9314634419754383, 'beta_2': 0.9928748903893762, 'epsilon': 9.110864498210603e-09, 'hidden_layer_sizes': 151, 'learning_rate_init': 2.959213941364495e-05, 'tol': 0.000769133293001976, 'validation_fraction': 0.13300779341447008}]
function_evaluation time 0.405669 value 16.320695 suggestion {'alpha': 0.004689475741910082, 'batch_size': 214, 'beta_1': 0.9314634419754383, 'beta_2': 0.9928748903893762, 'epsilon': 9.110864498210603e-09, 'hidden_layer_sizes': 151, 'learning_rate_init': 2.959213941364495e-05, 'tol': 0.000769133293001976, 'validation_fraction': 0.13300779341447008}
observation time 0.000004, current best 0.494175 at iter 23
suggestion time taken 0.010203 iter 24 next_points [{'alpha': 0.6464829503332747, 'batch_size': 14, 'beta_1': 0.5830058349097815, 'beta_2': 0.999979782800367, 'epsilon': 1.8386820592842512e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 1.530912098870918e-05, 'tol': 0.0034906648459738844, 'validation_fraction': 0.24386830346469246}]
function_evaluation time 3.444135 value 15.885941 suggestion {'alpha': 0.6464829503332747, 'batch_size': 14, 'beta_1': 0.5830058349097815, 'beta_2': 0.999979782800367, 'epsilon': 1.8386820592842512e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 1.530912098870918e-05, 'tol': 0.0034906648459738844, 'validation_fraction': 0.24386830346469246}
observation time 0.000010, current best 0.494175 at iter 24
suggestion time taken 0.013901 iter 25 next_points [{'alpha': 0.014394713302156725, 'batch_size': 199, 'beta_1': 0.6113871859891907, 'beta_2': 0.9999975473932597, 'epsilon': 1.0134639127690371e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 4.148716357053764e-05, 'tol': 6.39158490255634e-05, 'validation_fraction': 0.2671471027190696}]
function_evaluation time 0.482710 value 13.814861 suggestion {'alpha': 0.014394713302156725, 'batch_size': 199, 'beta_1': 0.6113871859891907, 'beta_2': 0.9999975473932597, 'epsilon': 1.0134639127690371e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 4.148716357053764e-05, 'tol': 6.39158490255634e-05, 'validation_fraction': 0.2671471027190696}
observation time 0.000004, current best 0.494175 at iter 25
suggestion time taken 0.011787 iter 26 next_points [{'alpha': 0.0015689093866699823, 'batch_size': 160, 'beta_1': 0.9368848152441686, 'beta_2': 0.9953417283862369, 'epsilon': 4.639504550398458e-09, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.000919535505076085, 'tol': 0.006708264189213101, 'validation_fraction': 0.7327972329025471}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.517911 value 3.069190 suggestion {'alpha': 0.0015689093866699823, 'batch_size': 160, 'beta_1': 0.9368848152441686, 'beta_2': 0.9953417283862369, 'epsilon': 4.639504550398458e-09, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.000919535505076085, 'tol': 0.006708264189213101, 'validation_fraction': 0.7327972329025471}
observation time 0.000009, current best 0.494175 at iter 26
suggestion time taken 0.013644 iter 27 next_points [{'alpha': 0.33924246981929485, 'batch_size': 53, 'beta_1': 0.9258531446220954, 'beta_2': 0.9085416739934115, 'epsilon': 5.16227678977948e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.0012726197789913025, 'tol': 4.268618526667974e-05, 'validation_fraction': 0.8048036351110135}]
function_evaluation time 0.821856 value 0.371874 suggestion {'alpha': 0.33924246981929485, 'batch_size': 53, 'beta_1': 0.9258531446220954, 'beta_2': 0.9085416739934115, 'epsilon': 5.16227678977948e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.0012726197789913025, 'tol': 4.268618526667974e-05, 'validation_fraction': 0.8048036351110135}
observation time 0.000004, current best 0.371874 at iter 27
suggestion time taken 0.011115 iter 28 next_points [{'alpha': 0.001744393047750458, 'batch_size': 45, 'beta_1': 0.6406381311419014, 'beta_2': 0.9951467094071007, 'epsilon': 1.956919175150768e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 6.127624242339752e-05, 'tol': 0.00045620293462600995, 'validation_fraction': 0.24776980423410097}]
function_evaluation time 2.450153 value 7.235926 suggestion {'alpha': 0.001744393047750458, 'batch_size': 45, 'beta_1': 0.6406381311419014, 'beta_2': 0.9951467094071007, 'epsilon': 1.956919175150768e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 6.127624242339752e-05, 'tol': 0.00045620293462600995, 'validation_fraction': 0.24776980423410097}
observation time 0.000010, current best 0.371874 at iter 28
suggestion time taken 0.014275 iter 29 next_points [{'alpha': 0.00011213777858561239, 'batch_size': 44, 'beta_1': 0.9661508351790636, 'beta_2': 0.9963178572113424, 'epsilon': 3.092995071032889e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.05203723743079704, 'tol': 0.0501942797357442, 'validation_fraction': 0.38460011456333737}]
function_evaluation time 0.426558 value 0.450080 suggestion {'alpha': 0.00011213777858561239, 'batch_size': 44, 'beta_1': 0.9661508351790636, 'beta_2': 0.9963178572113424, 'epsilon': 3.092995071032889e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.05203723743079704, 'tol': 0.0501942797357442, 'validation_fraction': 0.38460011456333737}
observation time 0.000004, current best 0.371874 at iter 29
suggestion time taken 0.009667 iter 30 next_points [{'alpha': 0.0042924117686573915, 'batch_size': 216, 'beta_1': 0.8912438513913666, 'beta_2': 0.99970068628558, 'epsilon': 1.9395155504758357e-07, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0011961226589388245, 'tol': 0.0331723873339137, 'validation_fraction': 0.8354635467747769}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.514688 value 0.447097 suggestion {'alpha': 0.0042924117686573915, 'batch_size': 216, 'beta_1': 0.8912438513913666, 'beta_2': 0.99970068628558, 'epsilon': 1.9395155504758357e-07, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0011961226589388245, 'tol': 0.0331723873339137, 'validation_fraction': 0.8354635467747769}
observation time 0.000013, current best 0.371874 at iter 30
suggestion time taken 0.014345 iter 31 next_points [{'alpha': 7.624300287749247e-05, 'batch_size': 101, 'beta_1': 0.7742918606600827, 'beta_2': 0.999129844515726, 'epsilon': 1.396438746076597e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0003595527942245531, 'tol': 0.00035446054605326534, 'validation_fraction': 0.6634072122489201}]
function_evaluation time 0.583195 value 8.883536 suggestion {'alpha': 7.624300287749247e-05, 'batch_size': 101, 'beta_1': 0.7742918606600827, 'beta_2': 0.999129844515726, 'epsilon': 1.396438746076597e-09, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.0003595527942245531, 'tol': 0.00035446054605326534, 'validation_fraction': 0.6634072122489201}
observation time 0.000003, current best 0.371874 at iter 31
suggestion time taken 0.009673 iter 32 next_points [{'alpha': 5.957196548946296, 'batch_size': 240, 'beta_1': 0.9748081454142496, 'beta_2': 0.9999850035581547, 'epsilon': 1.057300108241893e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.09055000203596274, 'tol': 0.0858487976976016, 'validation_fraction': 0.15372792154570386}]
function_evaluation time 0.662931 value 5.598395 suggestion {'alpha': 5.957196548946296, 'batch_size': 240, 'beta_1': 0.9748081454142496, 'beta_2': 0.9999850035581547, 'epsilon': 1.057300108241893e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.09055000203596274, 'tol': 0.0858487976976016, 'validation_fraction': 0.15372792154570386}
observation time 0.000005, current best 0.371874 at iter 32
suggestion time taken 0.010934 iter 33 next_points [{'alpha': 0.00034348143594361945, 'batch_size': 14, 'beta_1': 0.8806902489105514, 'beta_2': 0.999997336942194, 'epsilon': 1.6294759028324947e-09, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0009586163998759842, 'tol': 0.0039945113979554005, 'validation_fraction': 0.8485005253263558}]
function_evaluation time 0.776556 value 0.424852 suggestion {'alpha': 0.00034348143594361945, 'batch_size': 14, 'beta_1': 0.8806902489105514, 'beta_2': 0.999997336942194, 'epsilon': 1.6294759028324947e-09, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.0009586163998759842, 'tol': 0.0039945113979554005, 'validation_fraction': 0.8485005253263558}
observation time 0.000004, current best 0.371874 at iter 33
suggestion time taken 0.012670 iter 34 next_points [{'alpha': 0.005356453662835468, 'batch_size': 96, 'beta_1': 0.8119777864899642, 'beta_2': 0.9999913200777215, 'epsilon': 8.838883857754381e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.007000796407343358, 'tol': 0.011545182322389793, 'validation_fraction': 0.19178739775564277}]
function_evaluation time 1.083207 value 0.761314 suggestion {'alpha': 0.005356453662835468, 'batch_size': 96, 'beta_1': 0.8119777864899642, 'beta_2': 0.9999913200777215, 'epsilon': 8.838883857754381e-08, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.007000796407343358, 'tol': 0.011545182322389793, 'validation_fraction': 0.19178739775564277}
observation time 0.000010, current best 0.371874 at iter 34
suggestion time taken 0.014652 iter 35 next_points [{'alpha': 0.03667507488939044, 'batch_size': 122, 'beta_1': 0.7804935836912579, 'beta_2': 0.997586073883102, 'epsilon': 6.755883432074301e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.001976374611453637, 'tol': 0.0011893209907801257, 'validation_fraction': 0.8559765233728389}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.741358 value 2.800036 suggestion {'alpha': 0.03667507488939044, 'batch_size': 122, 'beta_1': 0.7804935836912579, 'beta_2': 0.997586073883102, 'epsilon': 6.755883432074301e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.001976374611453637, 'tol': 0.0011893209907801257, 'validation_fraction': 0.8559765233728389}
observation time 0.000003, current best 0.371874 at iter 35
suggestion time taken 0.010476 iter 36 next_points [{'alpha': 2.7486720520824066e-05, 'batch_size': 242, 'beta_1': 0.9005759593624005, 'beta_2': 0.9919227962591706, 'epsilon': 3.803098520613337e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.00880855824445375, 'tol': 0.009222372367158265, 'validation_fraction': 0.15339991780908313}]
function_evaluation time 0.887049 value 0.764008 suggestion {'alpha': 2.7486720520824066e-05, 'batch_size': 242, 'beta_1': 0.9005759593624005, 'beta_2': 0.9919227962591706, 'epsilon': 3.803098520613337e-09, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.00880855824445375, 'tol': 0.009222372367158265, 'validation_fraction': 0.15339991780908313}
observation time 0.000003, current best 0.371874 at iter 36
suggestion time taken 0.010467 iter 37 next_points [{'alpha': 0.0025457443755427162, 'batch_size': 48, 'beta_1': 0.9684985151284577, 'beta_2': 0.9999962776164574, 'epsilon': 4.1311816260443593e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0006114701961733094, 'tol': 0.00042687434992986134, 'validation_fraction': 0.7289377879771304}]
function_evaluation time 1.453975 value 0.350466 suggestion {'alpha': 0.0025457443755427162, 'batch_size': 48, 'beta_1': 0.9684985151284577, 'beta_2': 0.9999962776164574, 'epsilon': 4.1311816260443593e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0006114701961733094, 'tol': 0.00042687434992986134, 'validation_fraction': 0.7289377879771304}
observation time 0.000005, current best 0.350466 at iter 37
suggestion time taken 0.013892 iter 38 next_points [{'alpha': 4.1261016472815425e-05, 'batch_size': 36, 'beta_1': 0.9673750932415168, 'beta_2': 0.9999593306957546, 'epsilon': 8.220960149299364e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.018834950805383003, 'tol': 0.0008541625914465222, 'validation_fraction': 0.23816382162447267}]
function_evaluation time 1.911373 value 0.626565 suggestion {'alpha': 4.1261016472815425e-05, 'batch_size': 36, 'beta_1': 0.9673750932415168, 'beta_2': 0.9999593306957546, 'epsilon': 8.220960149299364e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.018834950805383003, 'tol': 0.0008541625914465222, 'validation_fraction': 0.23816382162447267}
observation time 0.000004, current best 0.350466 at iter 38
suggestion time taken 0.010386 iter 39 next_points [{'alpha': 0.008479504593665118, 'batch_size': 167, 'beta_1': 0.9870165602411226, 'beta_2': 0.9937096391311406, 'epsilon': 5.67030789969779e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0003300560115068974, 'tol': 0.001029314890505263, 'validation_fraction': 0.2513420424373687}]
function_evaluation time 0.592904 value 6.028483 suggestion {'alpha': 0.008479504593665118, 'batch_size': 167, 'beta_1': 0.9870165602411226, 'beta_2': 0.9937096391311406, 'epsilon': 5.67030789969779e-07, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0003300560115068974, 'tol': 0.001029314890505263, 'validation_fraction': 0.2513420424373687}
observation time 0.000006, current best 0.350466 at iter 39
suggestion time taken 0.011932 iter 40 next_points [{'alpha': 5.2508880755481574e-05, 'batch_size': 202, 'beta_1': 0.7382054791772679, 'beta_2': 0.9996962650110872, 'epsilon': 9.787433032605318e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.001335821861535619, 'tol': 1.8160165789260747e-05, 'validation_fraction': 0.8051166250002798}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.612160 value 5.315234 suggestion {'alpha': 5.2508880755481574e-05, 'batch_size': 202, 'beta_1': 0.7382054791772679, 'beta_2': 0.9996962650110872, 'epsilon': 9.787433032605318e-09, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.001335821861535619, 'tol': 1.8160165789260747e-05, 'validation_fraction': 0.8051166250002798}
observation time 0.000005, current best 0.350466 at iter 40
suggestion time taken 0.012392 iter 41 next_points [{'alpha': 0.00020280009123014786, 'batch_size': 197, 'beta_1': 0.9494741263937376, 'beta_2': 0.9606537326329334, 'epsilon': 9.212598140116827e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 5.9996497337362475e-05, 'tol': 0.010756594543463638, 'validation_fraction': 0.28287937700952215}]
function_evaluation time 0.707554 value 6.085804 suggestion {'alpha': 0.00020280009123014786, 'batch_size': 197, 'beta_1': 0.9494741263937376, 'beta_2': 0.9606537326329334, 'epsilon': 9.212598140116827e-08, 'hidden_layer_sizes': 187, 'learning_rate_init': 5.9996497337362475e-05, 'tol': 0.010756594543463638, 'validation_fraction': 0.28287937700952215}
observation time 0.000009, current best 0.350466 at iter 41
suggestion time taken 0.012573 iter 42 next_points [{'alpha': 2.3588718254982637, 'batch_size': 208, 'beta_1': 0.6460964336779562, 'beta_2': 0.9998593341322652, 'epsilon': 9.012270271784437e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 6.774703236786459e-05, 'tol': 0.05386372918194413, 'validation_fraction': 0.48974518960784813}]
function_evaluation time 0.319177 value 17.683361 suggestion {'alpha': 2.3588718254982637, 'batch_size': 208, 'beta_1': 0.6460964336779562, 'beta_2': 0.9998593341322652, 'epsilon': 9.012270271784437e-07, 'hidden_layer_sizes': 155, 'learning_rate_init': 6.774703236786459e-05, 'tol': 0.05386372918194413, 'validation_fraction': 0.48974518960784813}
observation time 0.000005, current best 0.350466 at iter 42
suggestion time taken 0.014920 iter 43 next_points [{'alpha': 0.00019841037301233344, 'batch_size': 40, 'beta_1': 0.960034130557419, 'beta_2': 0.9997212725432305, 'epsilon': 4.3614816172998395e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0008826085403205196, 'tol': 0.01533040830369177, 'validation_fraction': 0.6478045230766873}]
function_evaluation time 0.827139 value 2.835872 suggestion {'alpha': 0.00019841037301233344, 'batch_size': 40, 'beta_1': 0.960034130557419, 'beta_2': 0.9997212725432305, 'epsilon': 4.3614816172998395e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.0008826085403205196, 'tol': 0.01533040830369177, 'validation_fraction': 0.6478045230766873}
observation time 0.000005, current best 0.350466 at iter 43
suggestion time taken 0.011755 iter 44 next_points [{'alpha': 0.0012851173538829784, 'batch_size': 110, 'beta_1': 0.9846477797678773, 'beta_2': 0.9782867912889854, 'epsilon': 3.799674822724633e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.001105088198313462, 'tol': 3.548298439427965e-05, 'validation_fraction': 0.7718188579859138}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:621: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.514326 value 3.328556 suggestion {'alpha': 0.0012851173538829784, 'batch_size': 110, 'beta_1': 0.9846477797678773, 'beta_2': 0.9782867912889854, 'epsilon': 3.799674822724633e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.001105088198313462, 'tol': 3.548298439427965e-05, 'validation_fraction': 0.7718188579859138}
observation time 0.000005, current best 0.350466 at iter 44
saving meta data: {'args': {'--uuid': '66d75b9c7f295edc804f24a3ba3753d7', '-db-root': '/home/ryedida/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20231013_070336', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 45, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [7.80364911041716, 14.04577697134529, 11.882715334689305, 5.083775239316363, 3.3813441495654772])}
saving results
saving timing
saving suggest log
done
