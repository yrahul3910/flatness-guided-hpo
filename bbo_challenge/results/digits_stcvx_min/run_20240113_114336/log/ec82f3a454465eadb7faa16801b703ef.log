running: {'--uuid': 'ec82f3a454465eadb7faa16801b703ef', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d digits -o random -u ec82f3a454465eadb7faa16801b703ef -m nll -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_114336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.25190216699945595])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.005055 iter 0 next_points [{'alpha': 3.3356379531622564e-05, 'batch_size': 141, 'beta_1': 0.9580048628444262, 'beta_2': 0.9997964652791849, 'epsilon': 1.2464772625986851e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.033564132023279084, 'tol': 0.0002929750143662339, 'validation_fraction': 0.5409015155031524}]
function_evaluation time 2.174489 value 0.332995 suggestion {'alpha': 3.3356379531622564e-05, 'batch_size': 141, 'beta_1': 0.9580048628444262, 'beta_2': 0.9997964652791849, 'epsilon': 1.2464772625986851e-08, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.033564132023279084, 'tol': 0.0002929750143662339, 'validation_fraction': 0.5409015155031524}
observation time 0.000002, current best 0.332995 at iter 0
suggestion time taken 0.004517 iter 1 next_points [{'alpha': 0.0013778364325431455, 'batch_size': 99, 'beta_1': 0.9466035325504013, 'beta_2': 0.9999858249698161, 'epsilon': 2.382687587252304e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 1.6619423894475068e-05, 'tol': 0.02104563765759066, 'validation_fraction': 0.8077648152438638}]
function_evaluation time 0.393139 value 9.545735 suggestion {'alpha': 0.0013778364325431455, 'batch_size': 99, 'beta_1': 0.9466035325504013, 'beta_2': 0.9999858249698161, 'epsilon': 2.382687587252304e-07, 'hidden_layer_sizes': 117, 'learning_rate_init': 1.6619423894475068e-05, 'tol': 0.02104563765759066, 'validation_fraction': 0.8077648152438638}
observation time 0.000001, current best 0.332995 at iter 1
suggestion time taken 0.004477 iter 2 next_points [{'alpha': 1.6157782077430223, 'batch_size': 101, 'beta_1': 0.9047877372143742, 'beta_2': 0.9892983653952733, 'epsilon': 2.528599706486407e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 1.6988912641901055e-05, 'tol': 0.003755991538510542, 'validation_fraction': 0.7365029575133712}]
function_evaluation time 0.361398 value 12.236182 suggestion {'alpha': 1.6157782077430223, 'batch_size': 101, 'beta_1': 0.9047877372143742, 'beta_2': 0.9892983653952733, 'epsilon': 2.528599706486407e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 1.6988912641901055e-05, 'tol': 0.003755991538510542, 'validation_fraction': 0.7365029575133712}
observation time 0.000001, current best 0.332995 at iter 2
suggestion time taken 0.004498 iter 3 next_points [{'alpha': 0.00030532109262686695, 'batch_size': 185, 'beta_1': 0.5668299992945787, 'beta_2': 0.9188693253589351, 'epsilon': 9.124629227866616e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.0010256664869074089, 'tol': 0.010417857823722544, 'validation_fraction': 0.8037454725676166}]
function_evaluation time 1.017401 value 0.398974 suggestion {'alpha': 0.00030532109262686695, 'batch_size': 185, 'beta_1': 0.5668299992945787, 'beta_2': 0.9188693253589351, 'epsilon': 9.124629227866616e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 0.0010256664869074089, 'tol': 0.010417857823722544, 'validation_fraction': 0.8037454725676166}
observation time 0.000001, current best 0.332995 at iter 3
suggestion time taken 0.004472 iter 4 next_points [{'alpha': 0.0018882200124110907, 'batch_size': 211, 'beta_1': 0.9661574073421549, 'beta_2': 0.99994308113097, 'epsilon': 1.2719744750472341e-08, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.036918925277650366, 'tol': 0.0012309489885054979, 'validation_fraction': 0.8472565456940442}]
function_evaluation time 1.494538 value 1.089905 suggestion {'alpha': 0.0018882200124110907, 'batch_size': 211, 'beta_1': 0.9661574073421549, 'beta_2': 0.99994308113097, 'epsilon': 1.2719744750472341e-08, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.036918925277650366, 'tol': 0.0012309489885054979, 'validation_fraction': 0.8472565456940442}
observation time 0.000001, current best 0.332995 at iter 4
suggestion time taken 0.004458 iter 5 next_points [{'alpha': 1.533470586500164e-05, 'batch_size': 20, 'beta_1': 0.6057882304772988, 'beta_2': 0.9810796782257517, 'epsilon': 1.285829730402583e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.017007087265133173, 'tol': 0.055206354815705225, 'validation_fraction': 0.126237807552427}]
function_evaluation time 2.276074 value 0.232831 suggestion {'alpha': 1.533470586500164e-05, 'batch_size': 20, 'beta_1': 0.6057882304772988, 'beta_2': 0.9810796782257517, 'epsilon': 1.285829730402583e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.017007087265133173, 'tol': 0.055206354815705225, 'validation_fraction': 0.126237807552427}
observation time 0.000001, current best 0.232831 at iter 5
suggestion time taken 0.004448 iter 6 next_points [{'alpha': 7.346203821024359, 'batch_size': 171, 'beta_1': 0.987965993277545, 'beta_2': 0.903008604359846, 'epsilon': 3.6715445948532926e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.06533648168670403, 'tol': 0.02377758266304496, 'validation_fraction': 0.5397543949808126}]
function_evaluation time 0.921069 value 0.944155 suggestion {'alpha': 7.346203821024359, 'batch_size': 171, 'beta_1': 0.987965993277545, 'beta_2': 0.903008604359846, 'epsilon': 3.6715445948532926e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.06533648168670403, 'tol': 0.02377758266304496, 'validation_fraction': 0.5397543949808126}
observation time 0.000001, current best 0.232831 at iter 6
suggestion time taken 0.004466 iter 7 next_points [{'alpha': 0.0030294217343765787, 'batch_size': 95, 'beta_1': 0.961565533375674, 'beta_2': 0.9188845831672743, 'epsilon': 1.315511978501775e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.0037391885495954777, 'tol': 0.0016217685531264296, 'validation_fraction': 0.30373771164381713}]
function_evaluation time 2.104635 value 0.182461 suggestion {'alpha': 0.0030294217343765787, 'batch_size': 95, 'beta_1': 0.961565533375674, 'beta_2': 0.9188845831672743, 'epsilon': 1.315511978501775e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.0037391885495954777, 'tol': 0.0016217685531264296, 'validation_fraction': 0.30373771164381713}
observation time 0.000002, current best 0.182461 at iter 7
suggestion time taken 0.004499 iter 8 next_points [{'alpha': 0.024657576517688795, 'batch_size': 237, 'beta_1': 0.9573570392450889, 'beta_2': 0.9997854466377526, 'epsilon': 2.4124277737995875e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 6.516812739238607e-05, 'tol': 1.5068508317290815e-05, 'validation_fraction': 0.11360759131111563}]
function_evaluation time 8.129011 value 0.512831 suggestion {'alpha': 0.024657576517688795, 'batch_size': 237, 'beta_1': 0.9573570392450889, 'beta_2': 0.9997854466377526, 'epsilon': 2.4124277737995875e-08, 'hidden_layer_sizes': 125, 'learning_rate_init': 6.516812739238607e-05, 'tol': 1.5068508317290815e-05, 'validation_fraction': 0.11360759131111563}
observation time 0.000006, current best 0.182461 at iter 8
suggestion time taken 0.004763 iter 9 next_points [{'alpha': 0.00017354147334484667, 'batch_size': 25, 'beta_1': 0.7531693671911361, 'beta_2': 0.9998450087273244, 'epsilon': 2.13978465048494e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.006339622309358958, 'tol': 0.004895773571871995, 'validation_fraction': 0.21332263666818999}]
function_evaluation time 3.484745 value 0.108266 suggestion {'alpha': 0.00017354147334484667, 'batch_size': 25, 'beta_1': 0.7531693671911361, 'beta_2': 0.9998450087273244, 'epsilon': 2.13978465048494e-08, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.006339622309358958, 'tol': 0.004895773571871995, 'validation_fraction': 0.21332263666818999}
observation time 0.000002, current best 0.108266 at iter 9
suggestion time taken 0.004480 iter 10 next_points [{'alpha': 3.006889845644325e-05, 'batch_size': 193, 'beta_1': 0.6583462758443426, 'beta_2': 0.9751095541447876, 'epsilon': 1.0220744470405007e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 4.723790388883279e-05, 'tol': 0.07894966327815588, 'validation_fraction': 0.29684011552709555}]
function_evaluation time 0.490352 value 9.240551 suggestion {'alpha': 3.006889845644325e-05, 'batch_size': 193, 'beta_1': 0.6583462758443426, 'beta_2': 0.9751095541447876, 'epsilon': 1.0220744470405007e-07, 'hidden_layer_sizes': 56, 'learning_rate_init': 4.723790388883279e-05, 'tol': 0.07894966327815588, 'validation_fraction': 0.29684011552709555}
observation time 0.000001, current best 0.108266 at iter 10
suggestion time taken 0.004456 iter 11 next_points [{'alpha': 0.0006438935043013375, 'batch_size': 190, 'beta_1': 0.5562623663101307, 'beta_2': 0.9999434763833218, 'epsilon': 2.373907177283709e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 5.013637273396725e-05, 'tol': 0.00010433695803680371, 'validation_fraction': 0.8473106270193995}]
function_evaluation time 0.660911 value 7.653676 suggestion {'alpha': 0.0006438935043013375, 'batch_size': 190, 'beta_1': 0.5562623663101307, 'beta_2': 0.9999434763833218, 'epsilon': 2.373907177283709e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 5.013637273396725e-05, 'tol': 0.00010433695803680371, 'validation_fraction': 0.8473106270193995}
observation time 0.000001, current best 0.108266 at iter 11
suggestion time taken 0.004478 iter 12 next_points [{'alpha': 0.1499708833731073, 'batch_size': 117, 'beta_1': 0.9891620150017563, 'beta_2': 0.999421510272389, 'epsilon': 1.4210760373769233e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00020319016136864716, 'tol': 0.006601618659691034, 'validation_fraction': 0.4541706480277483}]
function_evaluation time 2.939613 value 0.302607 suggestion {'alpha': 0.1499708833731073, 'batch_size': 117, 'beta_1': 0.9891620150017563, 'beta_2': 0.999421510272389, 'epsilon': 1.4210760373769233e-07, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.00020319016136864716, 'tol': 0.006601618659691034, 'validation_fraction': 0.4541706480277483}
observation time 0.000001, current best 0.108266 at iter 12
suggestion time taken 0.004736 iter 13 next_points [{'alpha': 0.0001533018156402421, 'batch_size': 76, 'beta_1': 0.9438816556705919, 'beta_2': 0.957331976949502, 'epsilon': 9.46741488218207e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.011557940006303618, 'tol': 2.444735395337236e-05, 'validation_fraction': 0.2563379432799636}]
function_evaluation time 1.903581 value 0.174645 suggestion {'alpha': 0.0001533018156402421, 'batch_size': 76, 'beta_1': 0.9438816556705919, 'beta_2': 0.957331976949502, 'epsilon': 9.46741488218207e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.011557940006303618, 'tol': 2.444735395337236e-05, 'validation_fraction': 0.2563379432799636}
observation time 0.000001, current best 0.108266 at iter 13
suggestion time taken 0.004445 iter 14 next_points [{'alpha': 1.0418246854419375, 'batch_size': 88, 'beta_1': 0.9637268541965793, 'beta_2': 0.9999960108564115, 'epsilon': 1.2247516509075894e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 4.320409589401691e-05, 'tol': 0.026270764153634538, 'validation_fraction': 0.24945346671465413}]
function_evaluation time 2.826535 value 1.864067 suggestion {'alpha': 1.0418246854419375, 'batch_size': 88, 'beta_1': 0.9637268541965793, 'beta_2': 0.9999960108564115, 'epsilon': 1.2247516509075894e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 4.320409589401691e-05, 'tol': 0.026270764153634538, 'validation_fraction': 0.24945346671465413}
observation time 0.000001, current best 0.108266 at iter 14
saving meta data: {'args': {'--uuid': 'ec82f3a454465eadb7faa16801b703ef', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.25190216699945595])}
saving results
saving timing
saving suggest log
done
