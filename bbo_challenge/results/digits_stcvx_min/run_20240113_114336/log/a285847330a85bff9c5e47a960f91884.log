running: {'--uuid': 'a285847330a85bff9c5e47a960f91884', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d digits -o random -u a285847330a85bff9c5e47a960f91884 -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_114336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.004665 iter 0 next_points [{'alpha': 6.30176380841045, 'batch_size': 213, 'beta_1': 0.9167056408937357, 'beta_2': 0.9999831199095175, 'epsilon': 1.0878862052441122e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0003149669426202954, 'tol': 3.404140758410446e-05, 'validation_fraction': 0.71199142776633}]
function_evaluation time 4.874808 value -0.893549 suggestion {'alpha': 6.30176380841045, 'batch_size': 213, 'beta_1': 0.9167056408937357, 'beta_2': 0.9999831199095175, 'epsilon': 1.0878862052441122e-08, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0003149669426202954, 'tol': 3.404140758410446e-05, 'validation_fraction': 0.71199142776633}
observation time 0.000011, current best -0.893549 at iter 0
suggestion time taken 0.005545 iter 1 next_points [{'alpha': 1.4985336167104354e-05, 'batch_size': 136, 'beta_1': 0.9732991712584773, 'beta_2': 0.9756029123177293, 'epsilon': 2.1062277439569255e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.028283062206880767, 'tol': 1.1515783919698651e-05, 'validation_fraction': 0.4842676449413405}]
function_evaluation time 2.228887 value -0.930396 suggestion {'alpha': 1.4985336167104354e-05, 'batch_size': 136, 'beta_1': 0.9732991712584773, 'beta_2': 0.9756029123177293, 'epsilon': 2.1062277439569255e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.028283062206880767, 'tol': 1.1515783919698651e-05, 'validation_fraction': 0.4842676449413405}
observation time 0.000002, current best -0.930396 at iter 1
suggestion time taken 0.004556 iter 2 next_points [{'alpha': 1.184999717530723e-05, 'batch_size': 118, 'beta_1': 0.9766747154141773, 'beta_2': 0.9999745474828428, 'epsilon': 1.4674045240309914e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.00468955296534214, 'tol': 0.001821585137219602, 'validation_fraction': 0.8177838835965171}]
function_evaluation time 1.037694 value -0.907457 suggestion {'alpha': 1.184999717530723e-05, 'batch_size': 118, 'beta_1': 0.9766747154141773, 'beta_2': 0.9999745474828428, 'epsilon': 1.4674045240309914e-07, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.00468955296534214, 'tol': 0.001821585137219602, 'validation_fraction': 0.8177838835965171}
observation time 0.000002, current best -0.930396 at iter 2
suggestion time taken 0.004525 iter 3 next_points [{'alpha': 0.2900967799968537, 'batch_size': 226, 'beta_1': 0.9357190797983594, 'beta_2': 0.9999988041792027, 'epsilon': 2.9784110306266847e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 2.9388078538493523e-05, 'tol': 0.049811874881880935, 'validation_fraction': 0.2623502990047986}]
function_evaluation time 0.806922 value -0.119657 suggestion {'alpha': 0.2900967799968537, 'batch_size': 226, 'beta_1': 0.9357190797983594, 'beta_2': 0.9999988041792027, 'epsilon': 2.9784110306266847e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 2.9388078538493523e-05, 'tol': 0.049811874881880935, 'validation_fraction': 0.2623502990047986}
observation time 0.000002, current best -0.930396 at iter 3
suggestion time taken 0.004548 iter 4 next_points [{'alpha': 0.007230267500718004, 'batch_size': 35, 'beta_1': 0.5247250919109132, 'beta_2': 0.999974429337695, 'epsilon': 6.244520070324182e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.012091852882162548, 'tol': 0.0001899804604475984, 'validation_fraction': 0.4720634483975253}]
function_evaluation time 2.693582 value -0.971472 suggestion {'alpha': 0.007230267500718004, 'batch_size': 35, 'beta_1': 0.5247250919109132, 'beta_2': 0.999974429337695, 'epsilon': 6.244520070324182e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.012091852882162548, 'tol': 0.0001899804604475984, 'validation_fraction': 0.4720634483975253}
observation time 0.000001, current best -0.971472 at iter 4
suggestion time taken 0.004482 iter 5 next_points [{'alpha': 1.1828071868440933, 'batch_size': 79, 'beta_1': 0.9812081375207283, 'beta_2': 0.9997171655739677, 'epsilon': 1.5657410698917992e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 7.908836527885936e-05, 'tol': 0.00010761185036862894, 'validation_fraction': 0.7021844636406098}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 6.756250 value -0.749286 suggestion {'alpha': 1.1828071868440933, 'batch_size': 79, 'beta_1': 0.9812081375207283, 'beta_2': 0.9997171655739677, 'epsilon': 1.5657410698917992e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 7.908836527885936e-05, 'tol': 0.00010761185036862894, 'validation_fraction': 0.7021844636406098}
observation time 0.000001, current best -0.971472 at iter 5
suggestion time taken 0.004501 iter 6 next_points [{'alpha': 0.0007934980911133714, 'batch_size': 105, 'beta_1': 0.5246940444975442, 'beta_2': 0.9994649086821097, 'epsilon': 4.681707416257772e-09, 'hidden_layer_sizes': 118, 'learning_rate_init': 1.9860742838878018e-05, 'tol': 0.019294369966361455, 'validation_fraction': 0.8774843325249914}]
function_evaluation time 0.320884 value -0.111370 suggestion {'alpha': 0.0007934980911133714, 'batch_size': 105, 'beta_1': 0.5246940444975442, 'beta_2': 0.9994649086821097, 'epsilon': 4.681707416257772e-09, 'hidden_layer_sizes': 118, 'learning_rate_init': 1.9860742838878018e-05, 'tol': 0.019294369966361455, 'validation_fraction': 0.8774843325249914}
observation time 0.000002, current best -0.971472 at iter 6
suggestion time taken 0.004521 iter 7 next_points [{'alpha': 0.22353183201748789, 'batch_size': 83, 'beta_1': 0.9717438806122088, 'beta_2': 0.9998856938328456, 'epsilon': 4.331035961419768e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.029185530010056134, 'tol': 0.010912491138506139, 'validation_fraction': 0.8645694493859093}]
function_evaluation time 0.676764 value -0.795557 suggestion {'alpha': 0.22353183201748789, 'batch_size': 83, 'beta_1': 0.9717438806122088, 'beta_2': 0.9998856938328456, 'epsilon': 4.331035961419768e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.029185530010056134, 'tol': 0.010912491138506139, 'validation_fraction': 0.8645694493859093}
observation time 0.000002, current best -0.971472 at iter 7
suggestion time taken 0.004514 iter 8 next_points [{'alpha': 0.008171187117812657, 'batch_size': 150, 'beta_1': 0.9889787458823579, 'beta_2': 0.9999983820337807, 'epsilon': 3.873618569975459e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 2.6362057313568323e-05, 'tol': 0.012641895258629238, 'validation_fraction': 0.8761082812630685}]
function_evaluation time 0.255514 value -0.092579 suggestion {'alpha': 0.008171187117812657, 'batch_size': 150, 'beta_1': 0.9889787458823579, 'beta_2': 0.9999983820337807, 'epsilon': 3.873618569975459e-08, 'hidden_layer_sizes': 90, 'learning_rate_init': 2.6362057313568323e-05, 'tol': 0.012641895258629238, 'validation_fraction': 0.8761082812630685}
observation time 0.000002, current best -0.971472 at iter 8
suggestion time taken 0.004490 iter 9 next_points [{'alpha': 0.03344342791664728, 'batch_size': 157, 'beta_1': 0.9846363768625187, 'beta_2': 0.9923151368987099, 'epsilon': 6.937951008753915e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 5.8664713630809976e-05, 'tol': 0.00012910900380156784, 'validation_fraction': 0.34475928074276546}]
function_evaluation time 8.021146 value -0.930439 suggestion {'alpha': 0.03344342791664728, 'batch_size': 157, 'beta_1': 0.9846363768625187, 'beta_2': 0.9923151368987099, 'epsilon': 6.937951008753915e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 5.8664713630809976e-05, 'tol': 0.00012910900380156784, 'validation_fraction': 0.34475928074276546}
observation time 0.000010, current best -0.971472 at iter 9
suggestion time taken 0.004843 iter 10 next_points [{'alpha': 0.002978637173278569, 'batch_size': 88, 'beta_1': 0.7645658857102002, 'beta_2': 0.999189977239319, 'epsilon': 1.2643175078033054e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 6.986880678821843e-05, 'tol': 2.3663399107348482e-05, 'validation_fraction': 0.45027022540427697}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 7.822529 value -0.695006 suggestion {'alpha': 0.002978637173278569, 'batch_size': 88, 'beta_1': 0.7645658857102002, 'beta_2': 0.999189977239319, 'epsilon': 1.2643175078033054e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 6.986880678821843e-05, 'tol': 2.3663399107348482e-05, 'validation_fraction': 0.45027022540427697}
observation time 0.000002, current best -0.971472 at iter 10
suggestion time taken 0.004481 iter 11 next_points [{'alpha': 0.38371240965078773, 'batch_size': 156, 'beta_1': 0.9597714116194364, 'beta_2': 0.9987386296622177, 'epsilon': 3.845392439495875e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.014069115913215881, 'tol': 0.007535124253765584, 'validation_fraction': 0.49881456636052135}]
function_evaluation time 1.168711 value -0.949202 suggestion {'alpha': 0.38371240965078773, 'batch_size': 156, 'beta_1': 0.9597714116194364, 'beta_2': 0.9987386296622177, 'epsilon': 3.845392439495875e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 0.014069115913215881, 'tol': 0.007535124253765584, 'validation_fraction': 0.49881456636052135}
observation time 0.000001, current best -0.971472 at iter 11
suggestion time taken 0.004505 iter 12 next_points [{'alpha': 0.041640371703699816, 'batch_size': 231, 'beta_1': 0.5810523966611418, 'beta_2': 0.9999414562172924, 'epsilon': 4.287065149508271e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0362472922696012, 'tol': 0.02562334319997787, 'validation_fraction': 0.3659413643498744}]
function_evaluation time 0.811124 value -0.935980 suggestion {'alpha': 0.041640371703699816, 'batch_size': 231, 'beta_1': 0.5810523966611418, 'beta_2': 0.9999414562172924, 'epsilon': 4.287065149508271e-08, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0362472922696012, 'tol': 0.02562334319997787, 'validation_fraction': 0.3659413643498744}
observation time 0.000002, current best -0.971472 at iter 12
suggestion time taken 0.004501 iter 13 next_points [{'alpha': 1.028790972612809, 'batch_size': 191, 'beta_1': 0.989734899038419, 'beta_2': 0.9998946436489222, 'epsilon': 1.0656789153330462e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00016905054816890403, 'tol': 0.0034261100923410866, 'validation_fraction': 0.7065927792187192}]
function_evaluation time 2.713762 value -0.565837 suggestion {'alpha': 1.028790972612809, 'batch_size': 191, 'beta_1': 0.989734899038419, 'beta_2': 0.9998946436489222, 'epsilon': 1.0656789153330462e-07, 'hidden_layer_sizes': 148, 'learning_rate_init': 0.00016905054816890403, 'tol': 0.0034261100923410866, 'validation_fraction': 0.7065927792187192}
observation time 0.000001, current best -0.971472 at iter 13
suggestion time taken 0.004464 iter 14 next_points [{'alpha': 8.884980596639454e-05, 'batch_size': 117, 'beta_1': 0.9896271850373429, 'beta_2': 0.9999630823329821, 'epsilon': 6.683557060725113e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.002280001786747432, 'tol': 0.014090228164029401, 'validation_fraction': 0.8059435591193168}]
function_evaluation time 0.792459 value -0.889361 suggestion {'alpha': 8.884980596639454e-05, 'batch_size': 117, 'beta_1': 0.9896271850373429, 'beta_2': 0.9999630823329821, 'epsilon': 6.683557060725113e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.002280001786747432, 'tol': 0.014090228164029401, 'validation_fraction': 0.8059435591193168}
observation time 0.000002, current best -0.971472 at iter 14
saving meta data: {'args': {'--uuid': 'a285847330a85bff9c5e47a960f91884', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
