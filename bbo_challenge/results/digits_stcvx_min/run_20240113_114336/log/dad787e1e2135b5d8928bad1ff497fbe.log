running: {'--uuid': 'dad787e1e2135b5d8928bad1ff497fbe', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d digits -o random -u dad787e1e2135b5d8928bad1ff497fbe -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_114336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.004976 iter 0 next_points [{'alpha': 5.31947710852489, 'batch_size': 24, 'beta_1': 0.9823870103934018, 'beta_2': 0.9998484600999635, 'epsilon': 4.204493781356697e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.0010695194503851887, 'tol': 0.003995607695311881, 'validation_fraction': 0.13231797169576576}]
function_evaluation time 5.103955 value -0.950590 suggestion {'alpha': 5.31947710852489, 'batch_size': 24, 'beta_1': 0.9823870103934018, 'beta_2': 0.9998484600999635, 'epsilon': 4.204493781356697e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.0010695194503851887, 'tol': 0.003995607695311881, 'validation_fraction': 0.13231797169576576}
observation time 0.000005, current best -0.950590 at iter 0
suggestion time taken 0.004612 iter 1 next_points [{'alpha': 3.0724374628516955, 'batch_size': 29, 'beta_1': 0.8670800725988749, 'beta_2': 0.9997022931495555, 'epsilon': 2.185405600112977e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.044815565630722504, 'tol': 1.0620167765770177e-05, 'validation_fraction': 0.5863767269732072}]
function_evaluation time 1.740598 value -0.907448 suggestion {'alpha': 3.0724374628516955, 'batch_size': 29, 'beta_1': 0.8670800725988749, 'beta_2': 0.9997022931495555, 'epsilon': 2.185405600112977e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.044815565630722504, 'tol': 1.0620167765770177e-05, 'validation_fraction': 0.5863767269732072}
observation time 0.000007, current best -0.950590 at iter 1
suggestion time taken 0.004788 iter 2 next_points [{'alpha': 1.1676201951457313e-05, 'batch_size': 27, 'beta_1': 0.8228650419630087, 'beta_2': 0.9663032342879729, 'epsilon': 8.802003306569123e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 1.1568801651351848e-05, 'tol': 0.0003551931639803293, 'validation_fraction': 0.2677536474130499}]
function_evaluation time 24.237331 value -0.763023 suggestion {'alpha': 1.1676201951457313e-05, 'batch_size': 27, 'beta_1': 0.8228650419630087, 'beta_2': 0.9663032342879729, 'epsilon': 8.802003306569123e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 1.1568801651351848e-05, 'tol': 0.0003551931639803293, 'validation_fraction': 0.2677536474130499}
observation time 0.000008, current best -0.950590 at iter 2
suggestion time taken 0.004836 iter 3 next_points [{'alpha': 0.4979519406855332, 'batch_size': 115, 'beta_1': 0.5665388594193549, 'beta_2': 0.9970357199950983, 'epsilon': 3.528441271583448e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 9.99749014032235e-05, 'tol': 0.00014925992775202869, 'validation_fraction': 0.6545035569429445}]
function_evaluation time 9.029509 value -0.911660 suggestion {'alpha': 0.4979519406855332, 'batch_size': 115, 'beta_1': 0.5665388594193549, 'beta_2': 0.9970357199950983, 'epsilon': 3.528441271583448e-09, 'hidden_layer_sizes': 163, 'learning_rate_init': 9.99749014032235e-05, 'tol': 0.00014925992775202869, 'validation_fraction': 0.6545035569429445}
observation time 0.000002, current best -0.950590 at iter 3
suggestion time taken 0.004600 iter 4 next_points [{'alpha': 0.8400639264598636, 'batch_size': 125, 'beta_1': 0.7825206986588383, 'beta_2': 0.9841009979871769, 'epsilon': 2.125557311148388e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.0941505948776506e-05, 'tol': 0.00016960276796270705, 'validation_fraction': 0.4291523704980032}]
function_evaluation time 1.680161 value -0.096683 suggestion {'alpha': 0.8400639264598636, 'batch_size': 125, 'beta_1': 0.7825206986588383, 'beta_2': 0.9841009979871769, 'epsilon': 2.125557311148388e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.0941505948776506e-05, 'tol': 0.00016960276796270705, 'validation_fraction': 0.4291523704980032}
observation time 0.000002, current best -0.950590 at iter 4
suggestion time taken 0.004511 iter 5 next_points [{'alpha': 0.002621348600031125, 'batch_size': 84, 'beta_1': 0.6645650707418355, 'beta_2': 0.9999920046678558, 'epsilon': 2.349635783781575e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 5.92791923725082e-05, 'tol': 3.2008041508853106e-05, 'validation_fraction': 0.482241757683111}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 10.575029 value -0.869904 suggestion {'alpha': 0.002621348600031125, 'batch_size': 84, 'beta_1': 0.6645650707418355, 'beta_2': 0.9999920046678558, 'epsilon': 2.349635783781575e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 5.92791923725082e-05, 'tol': 3.2008041508853106e-05, 'validation_fraction': 0.482241757683111}
observation time 0.000008, current best -0.950590 at iter 5
suggestion time taken 0.004948 iter 6 next_points [{'alpha': 2.5010969010831346e-05, 'batch_size': 121, 'beta_1': 0.9716343072574952, 'beta_2': 0.9889894149352837, 'epsilon': 1.944714456667021e-09, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.03164845451047016, 'tol': 0.0005086274104948532, 'validation_fraction': 0.5430026305209971}]
function_evaluation time 2.322860 value -0.927633 suggestion {'alpha': 2.5010969010831346e-05, 'batch_size': 121, 'beta_1': 0.9716343072574952, 'beta_2': 0.9889894149352837, 'epsilon': 1.944714456667021e-09, 'hidden_layer_sizes': 168, 'learning_rate_init': 0.03164845451047016, 'tol': 0.0005086274104948532, 'validation_fraction': 0.5430026305209971}
observation time 0.000002, current best -0.950590 at iter 6
suggestion time taken 0.004524 iter 7 next_points [{'alpha': 1.8645465725382645e-05, 'batch_size': 156, 'beta_1': 0.9897465701394182, 'beta_2': 0.9999525517431522, 'epsilon': 6.983019544390817e-07, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.0062802326701280695, 'tol': 0.01662881149488949, 'validation_fraction': 0.6364269373509189}]
function_evaluation time 0.759804 value -0.926224 suggestion {'alpha': 1.8645465725382645e-05, 'batch_size': 156, 'beta_1': 0.9897465701394182, 'beta_2': 0.9999525517431522, 'epsilon': 6.983019544390817e-07, 'hidden_layer_sizes': 119, 'learning_rate_init': 0.0062802326701280695, 'tol': 0.01662881149488949, 'validation_fraction': 0.6364269373509189}
observation time 0.000001, current best -0.950590 at iter 7
suggestion time taken 0.004551 iter 8 next_points [{'alpha': 0.004193557323051279, 'batch_size': 200, 'beta_1': 0.9256573203547527, 'beta_2': 0.9999936720229077, 'epsilon': 2.97743458872e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.0030650890405427293, 'tol': 0.0667085143508, 'validation_fraction': 0.8066878280830196}]
function_evaluation time 0.495583 value -0.875428 suggestion {'alpha': 0.004193557323051279, 'batch_size': 200, 'beta_1': 0.9256573203547527, 'beta_2': 0.9999936720229077, 'epsilon': 2.97743458872e-09, 'hidden_layer_sizes': 140, 'learning_rate_init': 0.0030650890405427293, 'tol': 0.0667085143508, 'validation_fraction': 0.8066878280830196}
observation time 0.000001, current best -0.950590 at iter 8
suggestion time taken 0.004572 iter 9 next_points [{'alpha': 0.8896628720889488, 'batch_size': 113, 'beta_1': 0.9706132817390158, 'beta_2': 0.9999309217157143, 'epsilon': 3.9266219940376775e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.016590802583376, 'tol': 0.015976943132141028, 'validation_fraction': 0.15406385400265535}]
function_evaluation time 1.121308 value -0.965210 suggestion {'alpha': 0.8896628720889488, 'batch_size': 113, 'beta_1': 0.9706132817390158, 'beta_2': 0.9999309217157143, 'epsilon': 3.9266219940376775e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.016590802583376, 'tol': 0.015976943132141028, 'validation_fraction': 0.15406385400265535}
observation time 0.000001, current best -0.965210 at iter 9
suggestion time taken 0.004523 iter 10 next_points [{'alpha': 0.0025909186111248905, 'batch_size': 93, 'beta_1': 0.5858829285319428, 'beta_2': 0.9999841796332161, 'epsilon': 1.9153394194416616e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.00025487082369280285, 'tol': 3.6126721342878244e-05, 'validation_fraction': 0.26445714304204304}]
function_evaluation time 6.081822 value -0.933193 suggestion {'alpha': 0.0025909186111248905, 'batch_size': 93, 'beta_1': 0.5858829285319428, 'beta_2': 0.9999841796332161, 'epsilon': 1.9153394194416616e-07, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.00025487082369280285, 'tol': 3.6126721342878244e-05, 'validation_fraction': 0.26445714304204304}
observation time 0.000001, current best -0.965210 at iter 10
suggestion time taken 0.004498 iter 11 next_points [{'alpha': 0.08260718781314001, 'batch_size': 161, 'beta_1': 0.9846832236487625, 'beta_2': 0.9993771918435407, 'epsilon': 1.4625705853283567e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.012856538163066901, 'tol': 0.0052931595635876925, 'validation_fraction': 0.13398861357367373}]
function_evaluation time 1.223438 value -0.943634 suggestion {'alpha': 0.08260718781314001, 'batch_size': 161, 'beta_1': 0.9846832236487625, 'beta_2': 0.9993771918435407, 'epsilon': 1.4625705853283567e-08, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.012856538163066901, 'tol': 0.0052931595635876925, 'validation_fraction': 0.13398861357367373}
observation time 0.000008, current best -0.965210 at iter 11
suggestion time taken 0.004843 iter 12 next_points [{'alpha': 0.7026222330511397, 'batch_size': 77, 'beta_1': 0.9481841271835985, 'beta_2': 0.9983745897087344, 'epsilon': 4.65177267629733e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.002546301369570062, 'tol': 1.140716573243647e-05, 'validation_fraction': 0.5022627589629381}]
function_evaluation time 2.037168 value -0.955466 suggestion {'alpha': 0.7026222330511397, 'batch_size': 77, 'beta_1': 0.9481841271835985, 'beta_2': 0.9983745897087344, 'epsilon': 4.65177267629733e-09, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.002546301369570062, 'tol': 1.140716573243647e-05, 'validation_fraction': 0.5022627589629381}
observation time 0.000002, current best -0.965210 at iter 12
suggestion time taken 0.004537 iter 13 next_points [{'alpha': 0.0007081507644568829, 'batch_size': 67, 'beta_1': 0.9691610620866973, 'beta_2': 0.9038436829225248, 'epsilon': 2.759330957641123e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.0033534763644687982, 'tol': 0.044561516724908344, 'validation_fraction': 0.39853555113982325}]
function_evaluation time 0.986062 value -0.958258 suggestion {'alpha': 0.0007081507644568829, 'batch_size': 67, 'beta_1': 0.9691610620866973, 'beta_2': 0.9038436829225248, 'epsilon': 2.759330957641123e-08, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.0033534763644687982, 'tol': 0.044561516724908344, 'validation_fraction': 0.39853555113982325}
observation time 0.000001, current best -0.965210 at iter 13
suggestion time taken 0.004524 iter 14 next_points [{'alpha': 1.719533386819068e-05, 'batch_size': 51, 'beta_1': 0.936044395401546, 'beta_2': 0.999936164275548, 'epsilon': 2.3246543573419186e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 5.693669116450086e-05, 'tol': 0.0033626824355594076, 'validation_fraction': 0.7933254517473812}]
function_evaluation time 4.433513 value -0.689465 suggestion {'alpha': 1.719533386819068e-05, 'batch_size': 51, 'beta_1': 0.936044395401546, 'beta_2': 0.999936164275548, 'epsilon': 2.3246543573419186e-08, 'hidden_layer_sizes': 185, 'learning_rate_init': 5.693669116450086e-05, 'tol': 0.0033626824355594076, 'validation_fraction': 0.7933254517473812}
observation time 0.000002, current best -0.965210 at iter 14
saving meta data: {'args': {'--uuid': 'dad787e1e2135b5d8928bad1ff497fbe', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
