running: {'--uuid': '7e5502dec0045ed29dca8f0af8db8db0', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d digits -o random -u 7e5502dec0045ed29dca8f0af8db8db0 -m nll -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_114336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.25190216699945595])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.004727 iter 0 next_points [{'alpha': 0.0005686421232059015, 'batch_size': 232, 'beta_1': 0.7582637656808101, 'beta_2': 0.9878849990665821, 'epsilon': 3.689713844005185e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.01707133338296465, 'tol': 0.0016766416156610046, 'validation_fraction': 0.7712463246559106}]
function_evaluation time 1.079218 value 0.243729 suggestion {'alpha': 0.0005686421232059015, 'batch_size': 232, 'beta_1': 0.7582637656808101, 'beta_2': 0.9878849990665821, 'epsilon': 3.689713844005185e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.01707133338296465, 'tol': 0.0016766416156610046, 'validation_fraction': 0.7712463246559106}
observation time 0.000006, current best 0.243729 at iter 0
suggestion time taken 0.004663 iter 1 next_points [{'alpha': 0.06267279902211918, 'batch_size': 213, 'beta_1': 0.9580514842793366, 'beta_2': 0.9998338094712089, 'epsilon': 6.210222043089314e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.005713360766540514, 'tol': 1.155905636258399e-05, 'validation_fraction': 0.8594373939208447}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 1.273928 value 0.566093 suggestion {'alpha': 0.06267279902211918, 'batch_size': 213, 'beta_1': 0.9580514842793366, 'beta_2': 0.9998338094712089, 'epsilon': 6.210222043089314e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.005713360766540514, 'tol': 1.155905636258399e-05, 'validation_fraction': 0.8594373939208447}
observation time 0.000002, current best 0.243729 at iter 1
suggestion time taken 0.004690 iter 2 next_points [{'alpha': 3.927021930824931e-05, 'batch_size': 173, 'beta_1': 0.8428402643150562, 'beta_2': 0.9998880708449814, 'epsilon': 3.2130854892971724e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.005040651441827141, 'tol': 0.001228663034191514, 'validation_fraction': 0.16441739821241683}]
function_evaluation time 1.731006 value 0.145449 suggestion {'alpha': 3.927021930824931e-05, 'batch_size': 173, 'beta_1': 0.8428402643150562, 'beta_2': 0.9998880708449814, 'epsilon': 3.2130854892971724e-08, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.005040651441827141, 'tol': 0.001228663034191514, 'validation_fraction': 0.16441739821241683}
observation time 0.000002, current best 0.145449 at iter 2
suggestion time taken 0.004598 iter 3 next_points [{'alpha': 1.1809550938726135e-05, 'batch_size': 17, 'beta_1': 0.8080197627568605, 'beta_2': 0.9999961397724582, 'epsilon': 2.802544592134739e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.060750484257746665, 'tol': 7.792242630108737e-05, 'validation_fraction': 0.8059583678242642}]
function_evaluation time 0.933973 value 1.424361 suggestion {'alpha': 1.1809550938726135e-05, 'batch_size': 17, 'beta_1': 0.8080197627568605, 'beta_2': 0.9999961397724582, 'epsilon': 2.802544592134739e-09, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.060750484257746665, 'tol': 7.792242630108737e-05, 'validation_fraction': 0.8059583678242642}
observation time 0.000001, current best 0.145449 at iter 3
suggestion time taken 0.004572 iter 4 next_points [{'alpha': 8.401562115103988e-05, 'batch_size': 223, 'beta_1': 0.9634844178321302, 'beta_2': 0.9999985921352613, 'epsilon': 1.5665668123261785e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.00021022767617097772, 'tol': 5.209133970991521e-05, 'validation_fraction': 0.7309981397596547}]
function_evaluation time 5.113102 value 0.352023 suggestion {'alpha': 8.401562115103988e-05, 'batch_size': 223, 'beta_1': 0.9634844178321302, 'beta_2': 0.9999985921352613, 'epsilon': 1.5665668123261785e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.00021022767617097772, 'tol': 5.209133970991521e-05, 'validation_fraction': 0.7309981397596547}
observation time 0.000020, current best 0.145449 at iter 4
suggestion time taken 0.005439 iter 5 next_points [{'alpha': 2.611569947696675e-05, 'batch_size': 69, 'beta_1': 0.6133457674717353, 'beta_2': 0.9999893467110764, 'epsilon': 2.711775178368069e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.001483052353826582, 'tol': 0.01067370088975833, 'validation_fraction': 0.5515450721596737}]
function_evaluation time 1.410423 value 0.176776 suggestion {'alpha': 2.611569947696675e-05, 'batch_size': 69, 'beta_1': 0.6133457674717353, 'beta_2': 0.9999893467110764, 'epsilon': 2.711775178368069e-08, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.001483052353826582, 'tol': 0.01067370088975833, 'validation_fraction': 0.5515450721596737}
observation time 0.000002, current best 0.145449 at iter 5
suggestion time taken 0.004548 iter 6 next_points [{'alpha': 0.006054293854404908, 'batch_size': 122, 'beta_1': 0.6905753145480699, 'beta_2': 0.99998671776858, 'epsilon': 2.056604693072569e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 2.1407391935424955e-05, 'tol': 0.00746768957487001, 'validation_fraction': 0.1297106133177911}]
function_evaluation time 1.247160 value 10.358853 suggestion {'alpha': 0.006054293854404908, 'batch_size': 122, 'beta_1': 0.6905753145480699, 'beta_2': 0.99998671776858, 'epsilon': 2.056604693072569e-07, 'hidden_layer_sizes': 98, 'learning_rate_init': 2.1407391935424955e-05, 'tol': 0.00746768957487001, 'validation_fraction': 0.1297106133177911}
observation time 0.000001, current best 0.145449 at iter 6
suggestion time taken 0.004588 iter 7 next_points [{'alpha': 0.0001660251618185459, 'batch_size': 223, 'beta_1': 0.9683286269574214, 'beta_2': 0.9999975723700144, 'epsilon': 5.291169917893627e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.004938460925771734, 'tol': 0.0005238237056420964, 'validation_fraction': 0.27204458364719725}]
function_evaluation time 2.212516 value 0.135891 suggestion {'alpha': 0.0001660251618185459, 'batch_size': 223, 'beta_1': 0.9683286269574214, 'beta_2': 0.9999975723700144, 'epsilon': 5.291169917893627e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.004938460925771734, 'tol': 0.0005238237056420964, 'validation_fraction': 0.27204458364719725}
observation time 0.000002, current best 0.135891 at iter 7
suggestion time taken 0.004603 iter 8 next_points [{'alpha': 0.03303416765997473, 'batch_size': 89, 'beta_1': 0.9391085933160076, 'beta_2': 0.9999898397363064, 'epsilon': 2.0408755572955807e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.003244019221678538, 'tol': 0.03846977766735644, 'validation_fraction': 0.15989142802656195}]
function_evaluation time 1.216299 value 0.123920 suggestion {'alpha': 0.03303416765997473, 'batch_size': 89, 'beta_1': 0.9391085933160076, 'beta_2': 0.9999898397363064, 'epsilon': 2.0408755572955807e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.003244019221678538, 'tol': 0.03846977766735644, 'validation_fraction': 0.15989142802656195}
observation time 0.000001, current best 0.123920 at iter 8
suggestion time taken 0.004568 iter 9 next_points [{'alpha': 0.4947344189324752, 'batch_size': 186, 'beta_1': 0.9827951995278946, 'beta_2': 0.9914777571474187, 'epsilon': 1.7067064280367886e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 8.299043495176544e-05, 'tol': 3.810607798881765e-05, 'validation_fraction': 0.622782231688536}]
function_evaluation time 4.063717 value 2.377714 suggestion {'alpha': 0.4947344189324752, 'batch_size': 186, 'beta_1': 0.9827951995278946, 'beta_2': 0.9914777571474187, 'epsilon': 1.7067064280367886e-08, 'hidden_layer_sizes': 76, 'learning_rate_init': 8.299043495176544e-05, 'tol': 3.810607798881765e-05, 'validation_fraction': 0.622782231688536}
observation time 0.000001, current best 0.123920 at iter 9
suggestion time taken 0.004569 iter 10 next_points [{'alpha': 0.36107518380079223, 'batch_size': 131, 'beta_1': 0.9885936266855566, 'beta_2': 0.9999965171654716, 'epsilon': 1.0851613866016616e-09, 'hidden_layer_sizes': 151, 'learning_rate_init': 1.1455015362289767e-05, 'tol': 0.00021675652807209514, 'validation_fraction': 0.40693946390603486}]
function_evaluation time 1.451840 value 9.259531 suggestion {'alpha': 0.36107518380079223, 'batch_size': 131, 'beta_1': 0.9885936266855566, 'beta_2': 0.9999965171654716, 'epsilon': 1.0851613866016616e-09, 'hidden_layer_sizes': 151, 'learning_rate_init': 1.1455015362289767e-05, 'tol': 0.00021675652807209514, 'validation_fraction': 0.40693946390603486}
observation time 0.000001, current best 0.123920 at iter 10
suggestion time taken 0.004575 iter 11 next_points [{'alpha': 0.0001859954087738198, 'batch_size': 158, 'beta_1': 0.9552027843150345, 'beta_2': 0.9999519960374352, 'epsilon': 4.572584779086998e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.002860599906012029, 'tol': 0.0011572195937447423, 'validation_fraction': 0.8000375025152197}]
function_evaluation time 1.255828 value 0.408090 suggestion {'alpha': 0.0001859954087738198, 'batch_size': 158, 'beta_1': 0.9552027843150345, 'beta_2': 0.9999519960374352, 'epsilon': 4.572584779086998e-09, 'hidden_layer_sizes': 64, 'learning_rate_init': 0.002860599906012029, 'tol': 0.0011572195937447423, 'validation_fraction': 0.8000375025152197}
observation time 0.000018, current best 0.123920 at iter 11
suggestion time taken 0.005183 iter 12 next_points [{'alpha': 0.9531012480177271, 'batch_size': 68, 'beta_1': 0.9461906717887306, 'beta_2': 0.9999983170285307, 'epsilon': 1.2420008204758116e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 5.215779391706732e-05, 'tol': 0.0006093129948332671, 'validation_fraction': 0.8383841297802045}]
function_evaluation time 3.798437 value 3.533724 suggestion {'alpha': 0.9531012480177271, 'batch_size': 68, 'beta_1': 0.9461906717887306, 'beta_2': 0.9999983170285307, 'epsilon': 1.2420008204758116e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 5.215779391706732e-05, 'tol': 0.0006093129948332671, 'validation_fraction': 0.8383841297802045}
observation time 0.000006, current best 0.123920 at iter 12
suggestion time taken 0.004821 iter 13 next_points [{'alpha': 0.00030293063304939847, 'batch_size': 230, 'beta_1': 0.9532341381623783, 'beta_2': 0.9989666092284386, 'epsilon': 2.396905511333123e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.028704322061618586, 'tol': 0.07935598667945534, 'validation_fraction': 0.8827154422421378}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.536264 value 0.922982 suggestion {'alpha': 0.00030293063304939847, 'batch_size': 230, 'beta_1': 0.9532341381623783, 'beta_2': 0.9989666092284386, 'epsilon': 2.396905511333123e-08, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.028704322061618586, 'tol': 0.07935598667945534, 'validation_fraction': 0.8827154422421378}
observation time 0.000002, current best 0.123920 at iter 13
suggestion time taken 0.004610 iter 14 next_points [{'alpha': 0.38048538886601363, 'batch_size': 243, 'beta_1': 0.523835430061024, 'beta_2': 0.9999945508005782, 'epsilon': 1.3056271873144107e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.015372503150382771, 'tol': 0.00017827158964469093, 'validation_fraction': 0.17149213346505918}]
function_evaluation time 1.614062 value 0.128401 suggestion {'alpha': 0.38048538886601363, 'batch_size': 243, 'beta_1': 0.523835430061024, 'beta_2': 0.9999945508005782, 'epsilon': 1.3056271873144107e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.015372503150382771, 'tol': 0.00017827158964469093, 'validation_fraction': 0.17149213346505918}
observation time 0.000002, current best 0.123920 at iter 14
saving meta data: {'args': {'--uuid': '7e5502dec0045ed29dca8f0af8db8db0', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.25190216699945595])}
saving results
saving timing
saving suggest log
done
