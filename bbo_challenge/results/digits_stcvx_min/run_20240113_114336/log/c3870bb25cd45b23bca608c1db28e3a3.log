running: {'--uuid': 'c3870bb25cd45b23bca608c1db28e3a3', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d digits -o random -u c3870bb25cd45b23bca608c1db28e3a3 -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_114336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.004842 iter 0 next_points [{'alpha': 0.022725258535696593, 'batch_size': 128, 'beta_1': 0.5049726690402025, 'beta_2': 0.9910118823947709, 'epsilon': 3.38977546537132e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 3.921920538786356e-05, 'tol': 0.00014537553606245682, 'validation_fraction': 0.594009040392506}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 7.487856 value -0.683822 suggestion {'alpha': 0.022725258535696593, 'batch_size': 128, 'beta_1': 0.5049726690402025, 'beta_2': 0.9910118823947709, 'epsilon': 3.38977546537132e-07, 'hidden_layer_sizes': 130, 'learning_rate_init': 3.921920538786356e-05, 'tol': 0.00014537553606245682, 'validation_fraction': 0.594009040392506}
observation time 0.000008, current best -0.683822 at iter 0
suggestion time taken 0.005213 iter 1 next_points [{'alpha': 0.7402428760057915, 'batch_size': 44, 'beta_1': 0.6603009800815389, 'beta_2': 0.9999179578431944, 'epsilon': 4.205321593489011e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.007434392705805552, 'tol': 0.00045431394184911365, 'validation_fraction': 0.7698463923344547}]
function_evaluation time 2.304462 value -0.937386 suggestion {'alpha': 0.7402428760057915, 'batch_size': 44, 'beta_1': 0.6603009800815389, 'beta_2': 0.9999179578431944, 'epsilon': 4.205321593489011e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.007434392705805552, 'tol': 0.00045431394184911365, 'validation_fraction': 0.7698463923344547}
observation time 0.000002, current best -0.937386 at iter 1
suggestion time taken 0.004616 iter 2 next_points [{'alpha': 5.955004675795535e-05, 'batch_size': 184, 'beta_1': 0.883948116319954, 'beta_2': 0.9993807176488233, 'epsilon': 3.738154395066038e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0457717738413517, 'tol': 0.00952489974570736, 'validation_fraction': 0.3530867504738568}]
function_evaluation time 1.940875 value -0.831480 suggestion {'alpha': 5.955004675795535e-05, 'batch_size': 184, 'beta_1': 0.883948116319954, 'beta_2': 0.9993807176488233, 'epsilon': 3.738154395066038e-09, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0457717738413517, 'tol': 0.00952489974570736, 'validation_fraction': 0.3530867504738568}
observation time 0.000001, current best -0.937386 at iter 2
suggestion time taken 0.004611 iter 3 next_points [{'alpha': 0.38818123751588673, 'batch_size': 172, 'beta_1': 0.9886409828654771, 'beta_2': 0.999680178248554, 'epsilon': 6.146660636173331e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.06502448699098824, 'tol': 0.09602792314513138, 'validation_fraction': 0.43317404134452714}]
function_evaluation time 0.481754 value -0.429447 suggestion {'alpha': 0.38818123751588673, 'batch_size': 172, 'beta_1': 0.9886409828654771, 'beta_2': 0.999680178248554, 'epsilon': 6.146660636173331e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.06502448699098824, 'tol': 0.09602792314513138, 'validation_fraction': 0.43317404134452714}
observation time 0.000008, current best -0.937386 at iter 3
suggestion time taken 0.004828 iter 4 next_points [{'alpha': 0.8708340427690422, 'batch_size': 136, 'beta_1': 0.9515236501850713, 'beta_2': 0.9991516541939848, 'epsilon': 6.628075084759805e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.00432007450936043, 'tol': 0.00017155071465307996, 'validation_fraction': 0.7697939312704887}]
function_evaluation time 1.505657 value -0.923449 suggestion {'alpha': 0.8708340427690422, 'batch_size': 136, 'beta_1': 0.9515236501850713, 'beta_2': 0.9991516541939848, 'epsilon': 6.628075084759805e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.00432007450936043, 'tol': 0.00017155071465307996, 'validation_fraction': 0.7697939312704887}
observation time 0.000002, current best -0.937386 at iter 4
suggestion time taken 0.004558 iter 5 next_points [{'alpha': 0.0004954860501910682, 'batch_size': 37, 'beta_1': 0.9028727569661977, 'beta_2': 0.9981792017334383, 'epsilon': 3.8170056750098756e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 4.195363564449525e-05, 'tol': 3.768890584463086e-05, 'validation_fraction': 0.5179770399807628}]
function_evaluation time 14.594244 value -0.911639 suggestion {'alpha': 0.0004954860501910682, 'batch_size': 37, 'beta_1': 0.9028727569661977, 'beta_2': 0.9981792017334383, 'epsilon': 3.8170056750098756e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 4.195363564449525e-05, 'tol': 3.768890584463086e-05, 'validation_fraction': 0.5179770399807628}
observation time 0.000008, current best -0.937386 at iter 5
suggestion time taken 0.004793 iter 6 next_points [{'alpha': 0.006766126141178715, 'batch_size': 172, 'beta_1': 0.8059182261129979, 'beta_2': 0.9992865789519423, 'epsilon': 3.465172605011494e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 2.570455094156962e-05, 'tol': 9.860949196318204e-05, 'validation_fraction': 0.8981700371918888}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.790933 value -0.111397 suggestion {'alpha': 0.006766126141178715, 'batch_size': 172, 'beta_1': 0.8059182261129979, 'beta_2': 0.9992865789519423, 'epsilon': 3.465172605011494e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 2.570455094156962e-05, 'tol': 9.860949196318204e-05, 'validation_fraction': 0.8981700371918888}
observation time 0.000001, current best -0.937386 at iter 6
suggestion time taken 0.004556 iter 7 next_points [{'alpha': 0.08720675092037741, 'batch_size': 249, 'beta_1': 0.9103005868866698, 'beta_2': 0.9998938878938578, 'epsilon': 1.2687800042544373e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.03627777738886474, 'tol': 0.0015097144920767436, 'validation_fraction': 0.1228997567261506}]
function_evaluation time 1.381966 value -0.945030 suggestion {'alpha': 0.08720675092037741, 'batch_size': 249, 'beta_1': 0.9103005868866698, 'beta_2': 0.9998938878938578, 'epsilon': 1.2687800042544373e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.03627777738886474, 'tol': 0.0015097144920767436, 'validation_fraction': 0.1228997567261506}
observation time 0.000001, current best -0.945030 at iter 7
suggestion time taken 0.004587 iter 8 next_points [{'alpha': 0.9637173584407603, 'batch_size': 113, 'beta_1': 0.8090944912217122, 'beta_2': 0.989631862213119, 'epsilon': 6.517722799031476e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.005766659064635182, 'tol': 0.0005045009718606728, 'validation_fraction': 0.16962012928490014}]
function_evaluation time 2.430944 value -0.964508 suggestion {'alpha': 0.9637173584407603, 'batch_size': 113, 'beta_1': 0.8090944912217122, 'beta_2': 0.989631862213119, 'epsilon': 6.517722799031476e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.005766659064635182, 'tol': 0.0005045009718606728, 'validation_fraction': 0.16962012928490014}
observation time 0.000001, current best -0.964508 at iter 8
suggestion time taken 0.004573 iter 9 next_points [{'alpha': 2.925734418194231e-05, 'batch_size': 201, 'beta_1': 0.7521663360054255, 'beta_2': 0.9999256302018343, 'epsilon': 4.948640087114697e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 8.47939452265353e-05, 'tol': 0.0019236689856975847, 'validation_fraction': 0.16156203953830653}]
function_evaluation time 7.977564 value -0.892126 suggestion {'alpha': 2.925734418194231e-05, 'batch_size': 201, 'beta_1': 0.7521663360054255, 'beta_2': 0.9999256302018343, 'epsilon': 4.948640087114697e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 8.47939452265353e-05, 'tol': 0.0019236689856975847, 'validation_fraction': 0.16156203953830653}
observation time 0.000002, current best -0.964508 at iter 9
suggestion time taken 0.004587 iter 10 next_points [{'alpha': 0.07696777578955818, 'batch_size': 61, 'beta_1': 0.9517462384740443, 'beta_2': 0.9920167749057616, 'epsilon': 1.1715729985764164e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.002564584228046768, 'tol': 1.7821303609081995e-05, 'validation_fraction': 0.8570021390081796}]
function_evaluation time 1.547923 value -0.888661 suggestion {'alpha': 0.07696777578955818, 'batch_size': 61, 'beta_1': 0.9517462384740443, 'beta_2': 0.9920167749057616, 'epsilon': 1.1715729985764164e-09, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.002564584228046768, 'tol': 1.7821303609081995e-05, 'validation_fraction': 0.8570021390081796}
observation time 0.000001, current best -0.964508 at iter 10
suggestion time taken 0.004543 iter 11 next_points [{'alpha': 4.360476912611474, 'batch_size': 182, 'beta_1': 0.9789945657305604, 'beta_2': 0.9702117439801836, 'epsilon': 2.346248269931049e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 1.2199725372835792e-05, 'tol': 4.7654163624829535e-05, 'validation_fraction': 0.7091138917319944}]
function_evaluation time 1.804411 value -0.135025 suggestion {'alpha': 4.360476912611474, 'batch_size': 182, 'beta_1': 0.9789945657305604, 'beta_2': 0.9702117439801836, 'epsilon': 2.346248269931049e-08, 'hidden_layer_sizes': 118, 'learning_rate_init': 1.2199725372835792e-05, 'tol': 4.7654163624829535e-05, 'validation_fraction': 0.7091138917319944}
observation time 0.000001, current best -0.964508 at iter 11
suggestion time taken 0.004543 iter 12 next_points [{'alpha': 0.055058272918099796, 'batch_size': 136, 'beta_1': 0.7263570218731288, 'beta_2': 0.9999982350348409, 'epsilon': 6.587702533254326e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 4.464691095860551e-05, 'tol': 0.00027805949938459215, 'validation_fraction': 0.7194573986651706}]
function_evaluation time 3.094923 value -0.409233 suggestion {'alpha': 0.055058272918099796, 'batch_size': 136, 'beta_1': 0.7263570218731288, 'beta_2': 0.9999982350348409, 'epsilon': 6.587702533254326e-09, 'hidden_layer_sizes': 87, 'learning_rate_init': 4.464691095860551e-05, 'tol': 0.00027805949938459215, 'validation_fraction': 0.7194573986651706}
observation time 0.000001, current best -0.964508 at iter 12
suggestion time taken 0.004584 iter 13 next_points [{'alpha': 9.702955245259984e-05, 'batch_size': 59, 'beta_1': 0.8558639535264777, 'beta_2': 0.9999197831222, 'epsilon': 6.136850078498502e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.037625707250143706, 'tol': 0.0005083861338886227, 'validation_fraction': 0.6313815723158839}]
function_evaluation time 1.630279 value -0.931110 suggestion {'alpha': 9.702955245259984e-05, 'batch_size': 59, 'beta_1': 0.8558639535264777, 'beta_2': 0.9999197831222, 'epsilon': 6.136850078498502e-08, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.037625707250143706, 'tol': 0.0005083861338886227, 'validation_fraction': 0.6313815723158839}
observation time 0.000002, current best -0.964508 at iter 13
suggestion time taken 0.004532 iter 14 next_points [{'alpha': 0.04215694443536051, 'batch_size': 76, 'beta_1': 0.8618263599545347, 'beta_2': 0.9999730122845258, 'epsilon': 7.823198121277638e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.014599780147900893, 'tol': 0.06919411130652475, 'validation_fraction': 0.5084596430641436}]
function_evaluation time 0.677506 value -0.949898 suggestion {'alpha': 0.04215694443536051, 'batch_size': 76, 'beta_1': 0.8618263599545347, 'beta_2': 0.9999730122845258, 'epsilon': 7.823198121277638e-09, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.014599780147900893, 'tol': 0.06919411130652475, 'validation_fraction': 0.5084596430641436}
observation time 0.000001, current best -0.964508 at iter 14
saving meta data: {'args': {'--uuid': 'c3870bb25cd45b23bca608c1db28e3a3', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
