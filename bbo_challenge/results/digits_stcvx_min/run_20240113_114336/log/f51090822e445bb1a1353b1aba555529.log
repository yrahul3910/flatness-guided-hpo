running: {'--uuid': 'f51090822e445bb1a1353b1aba555529', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d digits -o random -u f51090822e445bb1a1353b1aba555529 -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_114336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.004653 iter 0 next_points [{'alpha': 0.0001512185344979347, 'batch_size': 74, 'beta_1': 0.5498939912118849, 'beta_2': 0.9991656800539921, 'epsilon': 2.0747370100887468e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 1.5791114713569662e-05, 'tol': 3.7717930782523916e-05, 'validation_fraction': 0.8292531527861855}]
function_evaluation time 1.759690 value -0.158512 suggestion {'alpha': 0.0001512185344979347, 'batch_size': 74, 'beta_1': 0.5498939912118849, 'beta_2': 0.9991656800539921, 'epsilon': 2.0747370100887468e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 1.5791114713569662e-05, 'tol': 3.7717930782523916e-05, 'validation_fraction': 0.8292531527861855}
observation time 0.000002, current best -0.158512 at iter 0
suggestion time taken 0.004618 iter 1 next_points [{'alpha': 1.7008183201232385, 'batch_size': 30, 'beta_1': 0.6963419134429886, 'beta_2': 0.9440728388624338, 'epsilon': 5.399419771283809e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0033905121540236016, 'tol': 5.0313494172305864e-05, 'validation_fraction': 0.6441072322237582}]
function_evaluation time 2.275123 value -0.949898 suggestion {'alpha': 1.7008183201232385, 'batch_size': 30, 'beta_1': 0.6963419134429886, 'beta_2': 0.9440728388624338, 'epsilon': 5.399419771283809e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0033905121540236016, 'tol': 5.0313494172305864e-05, 'validation_fraction': 0.6441072322237582}
observation time 0.000001, current best -0.949898 at iter 1
suggestion time taken 0.004595 iter 2 next_points [{'alpha': 0.04424128065118365, 'batch_size': 202, 'beta_1': 0.851423455037975, 'beta_2': 0.9869038550098173, 'epsilon': 3.79875385306312e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.000703471827204207, 'tol': 8.192727880744115e-05, 'validation_fraction': 0.29702380903633324}]
function_evaluation time 3.045601 value -0.941521 suggestion {'alpha': 0.04424128065118365, 'batch_size': 202, 'beta_1': 0.851423455037975, 'beta_2': 0.9869038550098173, 'epsilon': 3.79875385306312e-08, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.000703471827204207, 'tol': 8.192727880744115e-05, 'validation_fraction': 0.29702380903633324}
observation time 0.000001, current best -0.949898 at iter 2
suggestion time taken 0.004596 iter 3 next_points [{'alpha': 0.1031932326736826, 'batch_size': 44, 'beta_1': 0.6224650876755862, 'beta_2': 0.999997138561646, 'epsilon': 2.6308522503263225e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.00023152159508743448, 'tol': 9.010699591753882e-05, 'validation_fraction': 0.20152989332367585}]
function_evaluation time 6.171504 value -0.945035 suggestion {'alpha': 0.1031932326736826, 'batch_size': 44, 'beta_1': 0.6224650876755862, 'beta_2': 0.999997138561646, 'epsilon': 2.6308522503263225e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.00023152159508743448, 'tol': 9.010699591753882e-05, 'validation_fraction': 0.20152989332367585}
observation time 0.000005, current best -0.949898 at iter 3
suggestion time taken 0.005659 iter 4 next_points [{'alpha': 0.04274369156648547, 'batch_size': 172, 'beta_1': 0.8410395938289499, 'beta_2': 0.9999967267898008, 'epsilon': 4.034047304730829e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 3.7106659543253955e-05, 'tol': 0.003979604693652934, 'validation_fraction': 0.17783416136979513}]
function_evaluation time 5.786808 value -0.545466 suggestion {'alpha': 0.04274369156648547, 'batch_size': 172, 'beta_1': 0.8410395938289499, 'beta_2': 0.9999967267898008, 'epsilon': 4.034047304730829e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 3.7106659543253955e-05, 'tol': 0.003979604693652934, 'validation_fraction': 0.17783416136979513}
observation time 0.000002, current best -0.949898 at iter 4
suggestion time taken 0.004558 iter 5 next_points [{'alpha': 0.06123387625954456, 'batch_size': 250, 'beta_1': 0.9606471223105808, 'beta_2': 0.9999989956659386, 'epsilon': 1.0975584563747183e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 6.984144586979796e-05, 'tol': 0.0101458021404408, 'validation_fraction': 0.18995726398844637}]
function_evaluation time 2.384975 value -0.331932 suggestion {'alpha': 0.06123387625954456, 'batch_size': 250, 'beta_1': 0.9606471223105808, 'beta_2': 0.9999989956659386, 'epsilon': 1.0975584563747183e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 6.984144586979796e-05, 'tol': 0.0101458021404408, 'validation_fraction': 0.18995726398844637}
observation time 0.000001, current best -0.949898 at iter 5
suggestion time taken 0.004552 iter 6 next_points [{'alpha': 1.2809209348297665e-05, 'batch_size': 129, 'beta_1': 0.6522888363879894, 'beta_2': 0.9999980510044669, 'epsilon': 1.0212530338112861e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.000680911944780008, 'tol': 0.0004421193002978042, 'validation_fraction': 0.13222710563406131}]
function_evaluation time 3.469342 value -0.954075 suggestion {'alpha': 1.2809209348297665e-05, 'batch_size': 129, 'beta_1': 0.6522888363879894, 'beta_2': 0.9999980510044669, 'epsilon': 1.0212530338112861e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.000680911944780008, 'tol': 0.0004421193002978042, 'validation_fraction': 0.13222710563406131}
observation time 0.000001, current best -0.954075 at iter 6
suggestion time taken 0.004544 iter 7 next_points [{'alpha': 0.000260287711801966, 'batch_size': 224, 'beta_1': 0.938946351754707, 'beta_2': 0.9999846118262538, 'epsilon': 1.1782744947427506e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.022416590790812797, 'tol': 0.009973681328626475, 'validation_fraction': 0.5046744168222914}]
function_evaluation time 1.205564 value -0.947101 suggestion {'alpha': 0.000260287711801966, 'batch_size': 224, 'beta_1': 0.938946351754707, 'beta_2': 0.9999846118262538, 'epsilon': 1.1782744947427506e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.022416590790812797, 'tol': 0.009973681328626475, 'validation_fraction': 0.5046744168222914}
observation time 0.000002, current best -0.954075 at iter 7
suggestion time taken 0.004582 iter 8 next_points [{'alpha': 1.8409219919393148e-05, 'batch_size': 157, 'beta_1': 0.9337438199929522, 'beta_2': 0.9999901844616942, 'epsilon': 1.0036256892801167e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.00794838627479546, 'tol': 2.3610792024538076e-05, 'validation_fraction': 0.88728752191141}]
function_evaluation time 0.954381 value -0.849671 suggestion {'alpha': 1.8409219919393148e-05, 'batch_size': 157, 'beta_1': 0.9337438199929522, 'beta_2': 0.9999901844616942, 'epsilon': 1.0036256892801167e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.00794838627479546, 'tol': 2.3610792024538076e-05, 'validation_fraction': 0.88728752191141}
observation time 0.000001, current best -0.954075 at iter 8
suggestion time taken 0.004566 iter 9 next_points [{'alpha': 0.1746961343171679, 'batch_size': 62, 'beta_1': 0.9871465446680989, 'beta_2': 0.94136554633032, 'epsilon': 6.332952321675161e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.025429555162488664, 'tol': 0.03323281475417131, 'validation_fraction': 0.24190337509023874}]
function_evaluation time 1.791086 value -0.935978 suggestion {'alpha': 0.1746961343171679, 'batch_size': 62, 'beta_1': 0.9871465446680989, 'beta_2': 0.94136554633032, 'epsilon': 6.332952321675161e-09, 'hidden_layer_sizes': 187, 'learning_rate_init': 0.025429555162488664, 'tol': 0.03323281475417131, 'validation_fraction': 0.24190337509023874}
observation time 0.000004, current best -0.954075 at iter 9
suggestion time taken 0.004824 iter 10 next_points [{'alpha': 0.01698016068936944, 'batch_size': 97, 'beta_1': 0.8500939693008007, 'beta_2': 0.9998374247052928, 'epsilon': 1.7924254699676826e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 4.1456950124209816e-05, 'tol': 0.0008159500133526547, 'validation_fraction': 0.8550790784443619}]
function_evaluation time 1.301387 value -0.224867 suggestion {'alpha': 0.01698016068936944, 'batch_size': 97, 'beta_1': 0.8500939693008007, 'beta_2': 0.9998374247052928, 'epsilon': 1.7924254699676826e-07, 'hidden_layer_sizes': 114, 'learning_rate_init': 4.1456950124209816e-05, 'tol': 0.0008159500133526547, 'validation_fraction': 0.8550790784443619}
observation time 0.000001, current best -0.954075 at iter 10
suggestion time taken 0.004575 iter 11 next_points [{'alpha': 0.00011480124761019775, 'batch_size': 67, 'beta_1': 0.9294707774850803, 'beta_2': 0.9847393885764694, 'epsilon': 4.1442112071561575e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0009506175862193954, 'tol': 0.009036693524349595, 'validation_fraction': 0.11111535778979417}]
function_evaluation time 2.069843 value -0.956163 suggestion {'alpha': 0.00011480124761019775, 'batch_size': 67, 'beta_1': 0.9294707774850803, 'beta_2': 0.9847393885764694, 'epsilon': 4.1442112071561575e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0009506175862193954, 'tol': 0.009036693524349595, 'validation_fraction': 0.11111535778979417}
observation time 0.000001, current best -0.956163 at iter 11
suggestion time taken 0.004527 iter 12 next_points [{'alpha': 2.301248807243741, 'batch_size': 177, 'beta_1': 0.6995154587450365, 'beta_2': 0.9999653958597287, 'epsilon': 6.549111021774028e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.0030064475122566353, 'tol': 2.218901646705657e-05, 'validation_fraction': 0.49865121160794457}]
function_evaluation time 2.162820 value -0.958249 suggestion {'alpha': 2.301248807243741, 'batch_size': 177, 'beta_1': 0.6995154587450365, 'beta_2': 0.9999653958597287, 'epsilon': 6.549111021774028e-09, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.0030064475122566353, 'tol': 2.218901646705657e-05, 'validation_fraction': 0.49865121160794457}
observation time 0.000001, current best -0.958249 at iter 12
suggestion time taken 0.004550 iter 13 next_points [{'alpha': 1.422423979397905e-05, 'batch_size': 12, 'beta_1': 0.9762535580300643, 'beta_2': 0.9122926348187479, 'epsilon': 1.702149603778993e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.001931593633615916, 'tol': 0.0025156730424575066, 'validation_fraction': 0.5005027513722735}]
function_evaluation time 4.695529 value -0.938741 suggestion {'alpha': 1.422423979397905e-05, 'batch_size': 12, 'beta_1': 0.9762535580300643, 'beta_2': 0.9122926348187479, 'epsilon': 1.702149603778993e-08, 'hidden_layer_sizes': 164, 'learning_rate_init': 0.001931593633615916, 'tol': 0.0025156730424575066, 'validation_fraction': 0.5005027513722735}
observation time 0.000001, current best -0.958249 at iter 13
suggestion time taken 0.004540 iter 14 next_points [{'alpha': 1.3632952350114942, 'batch_size': 48, 'beta_1': 0.982302342237583, 'beta_2': 0.9991129950521531, 'epsilon': 2.9199972976228946e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.00019519074892883153, 'tol': 0.002446857248090426, 'validation_fraction': 0.8686285288576072}]
function_evaluation time 3.431662 value -0.808638 suggestion {'alpha': 1.3632952350114942, 'batch_size': 48, 'beta_1': 0.982302342237583, 'beta_2': 0.9991129950521531, 'epsilon': 2.9199972976228946e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.00019519074892883153, 'tol': 0.002446857248090426, 'validation_fraction': 0.8686285288576072}
observation time 0.000001, current best -0.958249 at iter 14
saving meta data: {'args': {'--uuid': 'f51090822e445bb1a1353b1aba555529', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
