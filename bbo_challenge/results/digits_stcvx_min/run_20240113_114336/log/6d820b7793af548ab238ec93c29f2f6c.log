running: {'--uuid': '6d820b7793af548ab238ec93c29f2f6c', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d digits -o random -u 6d820b7793af548ab238ec93c29f2f6c -m nll -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_114336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.25190216699945595])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.005943 iter 0 next_points [{'alpha': 0.00048795660494307887, 'batch_size': 71, 'beta_1': 0.98284984522873, 'beta_2': 0.9999417816128868, 'epsilon': 4.474360438479525e-08, 'hidden_layer_sizes': 200, 'learning_rate_init': 2.0822482053368964e-05, 'tol': 0.00035091937542875096, 'validation_fraction': 0.19540056188374758}]
function_evaluation time 14.044273 value 4.502558 suggestion {'alpha': 0.00048795660494307887, 'batch_size': 71, 'beta_1': 0.98284984522873, 'beta_2': 0.9999417816128868, 'epsilon': 4.474360438479525e-08, 'hidden_layer_sizes': 200, 'learning_rate_init': 2.0822482053368964e-05, 'tol': 0.00035091937542875096, 'validation_fraction': 0.19540056188374758}
observation time 0.000006, current best 4.502558 at iter 0
suggestion time taken 0.005679 iter 1 next_points [{'alpha': 0.8162587727466484, 'batch_size': 12, 'beta_1': 0.7735658869507529, 'beta_2': 0.9998902283165895, 'epsilon': 5.299822335752317e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00012919350084988427, 'tol': 0.0004204404664952392, 'validation_fraction': 0.5192578725268364}]
function_evaluation time 24.725585 value 0.202408 suggestion {'alpha': 0.8162587727466484, 'batch_size': 12, 'beta_1': 0.7735658869507529, 'beta_2': 0.9998902283165895, 'epsilon': 5.299822335752317e-07, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00012919350084988427, 'tol': 0.0004204404664952392, 'validation_fraction': 0.5192578725268364}
observation time 0.000005, current best 0.202408 at iter 1
suggestion time taken 0.005659 iter 2 next_points [{'alpha': 0.0002782802231391551, 'batch_size': 247, 'beta_1': 0.9585822872149736, 'beta_2': 0.9999959417454254, 'epsilon': 7.600675574320232e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00030752423154505054, 'tol': 0.006716620954081058, 'validation_fraction': 0.7547383041526351}]
function_evaluation time 2.062442 value 0.660346 suggestion {'alpha': 0.0002782802231391551, 'batch_size': 247, 'beta_1': 0.9585822872149736, 'beta_2': 0.9999959417454254, 'epsilon': 7.600675574320232e-07, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00030752423154505054, 'tol': 0.006716620954081058, 'validation_fraction': 0.7547383041526351}
observation time 0.000002, current best 0.202408 at iter 2
suggestion time taken 0.005436 iter 3 next_points [{'alpha': 1.2934536559157927e-05, 'batch_size': 235, 'beta_1': 0.9411829319880777, 'beta_2': 0.9161184716170784, 'epsilon': 1.7603355702675388e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 9.127926046864605e-05, 'tol': 0.04099330983815748, 'validation_fraction': 0.8772334645381293}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.284309 value 8.270201 suggestion {'alpha': 1.2934536559157927e-05, 'batch_size': 235, 'beta_1': 0.9411829319880777, 'beta_2': 0.9161184716170784, 'epsilon': 1.7603355702675388e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 9.127926046864605e-05, 'tol': 0.04099330983815748, 'validation_fraction': 0.8772334645381293}
observation time 0.000001, current best 0.202408 at iter 3
suggestion time taken 0.005410 iter 4 next_points [{'alpha': 0.016242300320524417, 'batch_size': 113, 'beta_1': 0.9846695771844229, 'beta_2': 0.9711032310384983, 'epsilon': 1.8639741454435395e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.007672705166135675, 'tol': 0.0003062214636664067, 'validation_fraction': 0.6547955189135372}]
function_evaluation time 1.375080 value 0.475847 suggestion {'alpha': 0.016242300320524417, 'batch_size': 113, 'beta_1': 0.9846695771844229, 'beta_2': 0.9711032310384983, 'epsilon': 1.8639741454435395e-07, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.007672705166135675, 'tol': 0.0003062214636664067, 'validation_fraction': 0.6547955189135372}
observation time 0.000001, current best 0.202408 at iter 4
suggestion time taken 0.005385 iter 5 next_points [{'alpha': 0.16874980941807183, 'batch_size': 80, 'beta_1': 0.9671672538749944, 'beta_2': 0.9999751197691535, 'epsilon': 4.682572692230132e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.0008246094479100942, 'tol': 0.002304888236690863, 'validation_fraction': 0.853591251895839}]
function_evaluation time 1.869275 value 0.361926 suggestion {'alpha': 0.16874980941807183, 'batch_size': 80, 'beta_1': 0.9671672538749944, 'beta_2': 0.9999751197691535, 'epsilon': 4.682572692230132e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.0008246094479100942, 'tol': 0.002304888236690863, 'validation_fraction': 0.853591251895839}
observation time 0.000001, current best 0.202408 at iter 5
suggestion time taken 0.005404 iter 6 next_points [{'alpha': 0.019591955169205214, 'batch_size': 102, 'beta_1': 0.9327961508971141, 'beta_2': 0.9298020034517395, 'epsilon': 8.137836328014791e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0025250568883140707, 'tol': 0.00140269280392023, 'validation_fraction': 0.10696230876686677}]
function_evaluation time 1.919395 value 0.112835 suggestion {'alpha': 0.019591955169205214, 'batch_size': 102, 'beta_1': 0.9327961508971141, 'beta_2': 0.9298020034517395, 'epsilon': 8.137836328014791e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.0025250568883140707, 'tol': 0.00140269280392023, 'validation_fraction': 0.10696230876686677}
observation time 0.000001, current best 0.112835 at iter 6
suggestion time taken 0.005398 iter 7 next_points [{'alpha': 0.015347928791058823, 'batch_size': 159, 'beta_1': 0.6457532375178008, 'beta_2': 0.9999957472318396, 'epsilon': 3.584650899835077e-08, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.030604533169568716, 'tol': 0.0025339294952764256, 'validation_fraction': 0.15715393972293704}]
function_evaluation time 2.126283 value 0.134693 suggestion {'alpha': 0.015347928791058823, 'batch_size': 159, 'beta_1': 0.6457532375178008, 'beta_2': 0.9999957472318396, 'epsilon': 3.584650899835077e-08, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.030604533169568716, 'tol': 0.0025339294952764256, 'validation_fraction': 0.15715393972293704}
observation time 0.000002, current best 0.112835 at iter 7
suggestion time taken 0.004483 iter 8 next_points [{'alpha': 0.0022983563476106387, 'batch_size': 26, 'beta_1': 0.9449258496969424, 'beta_2': 0.9999957437655075, 'epsilon': 3.39505187127663e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.017857802970515927, 'tol': 0.054064197784940746, 'validation_fraction': 0.5040900711282943}]
function_evaluation time 1.755999 value 0.196030 suggestion {'alpha': 0.0022983563476106387, 'batch_size': 26, 'beta_1': 0.9449258496969424, 'beta_2': 0.9999957437655075, 'epsilon': 3.39505187127663e-08, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.017857802970515927, 'tol': 0.054064197784940746, 'validation_fraction': 0.5040900711282943}
observation time 0.000001, current best 0.112835 at iter 8
suggestion time taken 0.004462 iter 9 next_points [{'alpha': 6.898770388644508e-05, 'batch_size': 65, 'beta_1': 0.933284065547063, 'beta_2': 0.9280250663352642, 'epsilon': 1.856128599047679e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0002984095913829682, 'tol': 0.0004640776420098142, 'validation_fraction': 0.15446642572662048}]
function_evaluation time 3.782895 value 0.103231 suggestion {'alpha': 6.898770388644508e-05, 'batch_size': 65, 'beta_1': 0.933284065547063, 'beta_2': 0.9280250663352642, 'epsilon': 1.856128599047679e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0002984095913829682, 'tol': 0.0004640776420098142, 'validation_fraction': 0.15446642572662048}
observation time 0.000001, current best 0.103231 at iter 9
suggestion time taken 0.004444 iter 10 next_points [{'alpha': 0.30895720025915185, 'batch_size': 44, 'beta_1': 0.8744691689428693, 'beta_2': 0.9999055558108917, 'epsilon': 2.8273601254849116e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 3.180795973303317e-05, 'tol': 1.0975761020452789e-05, 'validation_fraction': 0.2856937056485594}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 11.343811 value 3.729330 suggestion {'alpha': 0.30895720025915185, 'batch_size': 44, 'beta_1': 0.8744691689428693, 'beta_2': 0.9999055558108917, 'epsilon': 2.8273601254849116e-09, 'hidden_layer_sizes': 53, 'learning_rate_init': 3.180795973303317e-05, 'tol': 1.0975761020452789e-05, 'validation_fraction': 0.2856937056485594}
observation time 0.000001, current best 0.103231 at iter 10
suggestion time taken 0.004438 iter 11 next_points [{'alpha': 2.1964751391786335, 'batch_size': 184, 'beta_1': 0.9569572943412609, 'beta_2': 0.9998563588695224, 'epsilon': 2.912482745665768e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 9.351985692117367e-05, 'tol': 0.008227506663987146, 'validation_fraction': 0.8492795324425766}]
function_evaluation time 0.292373 value 8.391121 suggestion {'alpha': 2.1964751391786335, 'batch_size': 184, 'beta_1': 0.9569572943412609, 'beta_2': 0.9998563588695224, 'epsilon': 2.912482745665768e-08, 'hidden_layer_sizes': 106, 'learning_rate_init': 9.351985692117367e-05, 'tol': 0.008227506663987146, 'validation_fraction': 0.8492795324425766}
observation time 0.000001, current best 0.103231 at iter 11
suggestion time taken 0.004431 iter 12 next_points [{'alpha': 0.11524367186943929, 'batch_size': 160, 'beta_1': 0.805997005262457, 'beta_2': 0.9999753286236902, 'epsilon': 3.6861771222652703e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 6.37158117722381e-05, 'tol': 0.0053652324221488915, 'validation_fraction': 0.6565064091205947}]
function_evaluation time 2.979794 value 6.373233 suggestion {'alpha': 0.11524367186943929, 'batch_size': 160, 'beta_1': 0.805997005262457, 'beta_2': 0.9999753286236902, 'epsilon': 3.6861771222652703e-09, 'hidden_layer_sizes': 200, 'learning_rate_init': 6.37158117722381e-05, 'tol': 0.0053652324221488915, 'validation_fraction': 0.6565064091205947}
observation time 0.000002, current best 0.103231 at iter 12
suggestion time taken 0.004447 iter 13 next_points [{'alpha': 0.14704407137910852, 'batch_size': 67, 'beta_1': 0.9015614570352314, 'beta_2': 0.9980712088751693, 'epsilon': 2.7801772979529683e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 1.1336877234204095e-05, 'tol': 0.01282972103752219, 'validation_fraction': 0.31176463474636035}]
function_evaluation time 1.182209 value 7.712995 suggestion {'alpha': 0.14704407137910852, 'batch_size': 67, 'beta_1': 0.9015614570352314, 'beta_2': 0.9980712088751693, 'epsilon': 2.7801772979529683e-07, 'hidden_layer_sizes': 150, 'learning_rate_init': 1.1336877234204095e-05, 'tol': 0.01282972103752219, 'validation_fraction': 0.31176463474636035}
observation time 0.000001, current best 0.103231 at iter 13
suggestion time taken 0.004454 iter 14 next_points [{'alpha': 0.0003359657646334842, 'batch_size': 132, 'beta_1': 0.9897494951483873, 'beta_2': 0.9999958966781156, 'epsilon': 1.0544253958063503e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 1.5069050657409571e-05, 'tol': 0.0007267298465121202, 'validation_fraction': 0.7428694393834628}]
function_evaluation time 4.368761 value 4.492617 suggestion {'alpha': 0.0003359657646334842, 'batch_size': 132, 'beta_1': 0.9897494951483873, 'beta_2': 0.9999958966781156, 'epsilon': 1.0544253958063503e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 1.5069050657409571e-05, 'tol': 0.0007267298465121202, 'validation_fraction': 0.7428694393834628}
observation time 0.000007, current best 0.103231 at iter 14
saving meta data: {'args': {'--uuid': '6d820b7793af548ab238ec93c29f2f6c', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.25190216699945595])}
saving results
saving timing
saving suggest log
done
