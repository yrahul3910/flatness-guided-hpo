running: {'--uuid': 'df22dae58dd05b62867c033b903eda0e', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d digits -o random -u df22dae58dd05b62867c033b903eda0e -m nll -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_114336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.25190216699945595])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.004663 iter 0 next_points [{'alpha': 0.00014256686294114799, 'batch_size': 131, 'beta_1': 0.9874297174642082, 'beta_2': 0.9999890699592933, 'epsilon': 1.070600834892704e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.007241077608093646, 'tol': 0.00012978245325987286, 'validation_fraction': 0.12647544961567253}]
function_evaluation time 2.201560 value 0.155290 suggestion {'alpha': 0.00014256686294114799, 'batch_size': 131, 'beta_1': 0.9874297174642082, 'beta_2': 0.9999890699592933, 'epsilon': 1.070600834892704e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.007241077608093646, 'tol': 0.00012978245325987286, 'validation_fraction': 0.12647544961567253}
observation time 0.000003, current best 0.155290 at iter 0
suggestion time taken 0.004565 iter 1 next_points [{'alpha': 0.00011548765001156514, 'batch_size': 203, 'beta_1': 0.903020760457339, 'beta_2': 0.9662801446260231, 'epsilon': 2.101307224876714e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.027456665269387497, 'tol': 0.01685824873314643, 'validation_fraction': 0.11848912715795519}]
function_evaluation time 1.435665 value 0.155137 suggestion {'alpha': 0.00011548765001156514, 'batch_size': 203, 'beta_1': 0.903020760457339, 'beta_2': 0.9662801446260231, 'epsilon': 2.101307224876714e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.027456665269387497, 'tol': 0.01685824873314643, 'validation_fraction': 0.11848912715795519}
observation time 0.000002, current best 0.155137 at iter 1
suggestion time taken 0.004626 iter 2 next_points [{'alpha': 1.2115747329411821, 'batch_size': 195, 'beta_1': 0.9871219526932431, 'beta_2': 0.9997579047595788, 'epsilon': 7.513573537058498e-08, 'hidden_layer_sizes': 122, 'learning_rate_init': 3.322529778692127e-05, 'tol': 0.08795328804293542, 'validation_fraction': 0.710795931321036}]
function_evaluation time 0.403503 value 8.365020 suggestion {'alpha': 1.2115747329411821, 'batch_size': 195, 'beta_1': 0.9871219526932431, 'beta_2': 0.9997579047595788, 'epsilon': 7.513573537058498e-08, 'hidden_layer_sizes': 122, 'learning_rate_init': 3.322529778692127e-05, 'tol': 0.08795328804293542, 'validation_fraction': 0.710795931321036}
observation time 0.000003, current best 0.155137 at iter 2
suggestion time taken 0.004588 iter 3 next_points [{'alpha': 7.76640667267434, 'batch_size': 126, 'beta_1': 0.9502454429895575, 'beta_2': 0.9999981598530374, 'epsilon': 5.545688334697739e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 5.020552132594349e-05, 'tol': 0.03403325818462999, 'validation_fraction': 0.1366861810290982}]
function_evaluation time 1.032966 value 4.564830 suggestion {'alpha': 7.76640667267434, 'batch_size': 126, 'beta_1': 0.9502454429895575, 'beta_2': 0.9999981598530374, 'epsilon': 5.545688334697739e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 5.020552132594349e-05, 'tol': 0.03403325818462999, 'validation_fraction': 0.1366861810290982}
observation time 0.000001, current best 0.155137 at iter 3
suggestion time taken 0.004556 iter 4 next_points [{'alpha': 0.00028000987203793433, 'batch_size': 46, 'beta_1': 0.9246129690657405, 'beta_2': 0.9600463971966259, 'epsilon': 6.571482970803243e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.01928571521372047, 'tol': 0.03682923009727475, 'validation_fraction': 0.11707218218924625}]
function_evaluation time 1.930699 value 0.202409 suggestion {'alpha': 0.00028000987203793433, 'batch_size': 46, 'beta_1': 0.9246129690657405, 'beta_2': 0.9600463971966259, 'epsilon': 6.571482970803243e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.01928571521372047, 'tol': 0.03682923009727475, 'validation_fraction': 0.11707218218924625}
observation time 0.000001, current best 0.155137 at iter 4
suggestion time taken 0.004520 iter 5 next_points [{'alpha': 0.13525054385716517, 'batch_size': 196, 'beta_1': 0.9789897970528454, 'beta_2': 0.9995894389080052, 'epsilon': 5.475854356912961e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0004344506431673498, 'tol': 0.0003256991101214971, 'validation_fraction': 0.22263095559870907}]
function_evaluation time 3.339514 value 0.251349 suggestion {'alpha': 0.13525054385716517, 'batch_size': 196, 'beta_1': 0.9789897970528454, 'beta_2': 0.9995894389080052, 'epsilon': 5.475854356912961e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.0004344506431673498, 'tol': 0.0003256991101214971, 'validation_fraction': 0.22263095559870907}
observation time 0.000020, current best 0.155137 at iter 5
suggestion time taken 0.005419 iter 6 next_points [{'alpha': 1.4055133811936234e-05, 'batch_size': 220, 'beta_1': 0.917855881734351, 'beta_2': 0.9999900537267952, 'epsilon': 1.577851472695076e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.026025018039885266, 'tol': 7.28948771345378e-05, 'validation_fraction': 0.7106102619852357}]
function_evaluation time 1.740366 value 0.349160 suggestion {'alpha': 1.4055133811936234e-05, 'batch_size': 220, 'beta_1': 0.917855881734351, 'beta_2': 0.9999900537267952, 'epsilon': 1.577851472695076e-07, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.026025018039885266, 'tol': 7.28948771345378e-05, 'validation_fraction': 0.7106102619852357}
observation time 0.000002, current best 0.155137 at iter 6
suggestion time taken 0.004544 iter 7 next_points [{'alpha': 5.803535021340306, 'batch_size': 150, 'beta_1': 0.9888749394755305, 'beta_2': 0.9991697618465399, 'epsilon': 2.0397507897081563e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0080052327960258, 'tol': 0.00021925740647831034, 'validation_fraction': 0.7227317851664479}]
function_evaluation time 1.710823 value 0.233597 suggestion {'alpha': 5.803535021340306, 'batch_size': 150, 'beta_1': 0.9888749394755305, 'beta_2': 0.9991697618465399, 'epsilon': 2.0397507897081563e-08, 'hidden_layer_sizes': 149, 'learning_rate_init': 0.0080052327960258, 'tol': 0.00021925740647831034, 'validation_fraction': 0.7227317851664479}
observation time 0.000002, current best 0.155137 at iter 7
suggestion time taken 0.004577 iter 8 next_points [{'alpha': 0.5253085413079362, 'batch_size': 211, 'beta_1': 0.8711487202113382, 'beta_2': 0.9999983614298851, 'epsilon': 3.4315014505452523e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.004572642122583604, 'tol': 0.004880411429928978, 'validation_fraction': 0.8997872877995199}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.641729 value 0.516558 suggestion {'alpha': 0.5253085413079362, 'batch_size': 211, 'beta_1': 0.8711487202113382, 'beta_2': 0.9999983614298851, 'epsilon': 3.4315014505452523e-09, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.004572642122583604, 'tol': 0.004880411429928978, 'validation_fraction': 0.8997872877995199}
observation time 0.000002, current best 0.155137 at iter 8
suggestion time taken 0.004556 iter 9 next_points [{'alpha': 0.0007787815602914369, 'batch_size': 110, 'beta_1': 0.8326042228470416, 'beta_2': 0.9999236319347592, 'epsilon': 7.111857294560516e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00021048970142914535, 'tol': 2.47926347492626e-05, 'validation_fraction': 0.1641006154108603}]
function_evaluation time 5.138913 value 0.211335 suggestion {'alpha': 0.0007787815602914369, 'batch_size': 110, 'beta_1': 0.8326042228470416, 'beta_2': 0.9999236319347592, 'epsilon': 7.111857294560516e-08, 'hidden_layer_sizes': 100, 'learning_rate_init': 0.00021048970142914535, 'tol': 2.47926347492626e-05, 'validation_fraction': 0.1641006154108603}
observation time 0.000002, current best 0.155137 at iter 9
suggestion time taken 0.004557 iter 10 next_points [{'alpha': 0.46638659614631367, 'batch_size': 140, 'beta_1': 0.6543048430707915, 'beta_2': 0.9936208798496846, 'epsilon': 2.6515544453534574e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.05549335325678986, 'tol': 0.00019528146483728756, 'validation_fraction': 0.16883058401676998}]
function_evaluation time 1.558555 value 0.254124 suggestion {'alpha': 0.46638659614631367, 'batch_size': 140, 'beta_1': 0.6543048430707915, 'beta_2': 0.9936208798496846, 'epsilon': 2.6515544453534574e-08, 'hidden_layer_sizes': 157, 'learning_rate_init': 0.05549335325678986, 'tol': 0.00019528146483728756, 'validation_fraction': 0.16883058401676998}
observation time 0.000002, current best 0.155137 at iter 10
suggestion time taken 0.004540 iter 11 next_points [{'alpha': 0.00030243931235188854, 'batch_size': 172, 'beta_1': 0.634831190503074, 'beta_2': 0.9999969247971827, 'epsilon': 2.516102625701763e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.021215486304449454, 'tol': 2.697094532210291e-05, 'validation_fraction': 0.10589819187417765}]
function_evaluation time 1.553416 value 0.109064 suggestion {'alpha': 0.00030243931235188854, 'batch_size': 172, 'beta_1': 0.634831190503074, 'beta_2': 0.9999969247971827, 'epsilon': 2.516102625701763e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.021215486304449454, 'tol': 2.697094532210291e-05, 'validation_fraction': 0.10589819187417765}
observation time 0.000002, current best 0.109064 at iter 11
suggestion time taken 0.004510 iter 12 next_points [{'alpha': 0.0004447401510432814, 'batch_size': 151, 'beta_1': 0.9359643644076957, 'beta_2': 0.99938896495224, 'epsilon': 7.913256539329383e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0007470047798890397, 'tol': 0.03697777584308189, 'validation_fraction': 0.8984072953204995}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.320728 value 3.143366 suggestion {'alpha': 0.0004447401510432814, 'batch_size': 151, 'beta_1': 0.9359643644076957, 'beta_2': 0.99938896495224, 'epsilon': 7.913256539329383e-09, 'hidden_layer_sizes': 127, 'learning_rate_init': 0.0007470047798890397, 'tol': 0.03697777584308189, 'validation_fraction': 0.8984072953204995}
observation time 0.000002, current best 0.109064 at iter 12
suggestion time taken 0.004506 iter 13 next_points [{'alpha': 0.2165240182625834, 'batch_size': 212, 'beta_1': 0.7822757772625537, 'beta_2': 0.9848055805215897, 'epsilon': 1.6839739956933166e-09, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0002893520883314211, 'tol': 0.01647607016879421, 'validation_fraction': 0.38278402100956016}]
function_evaluation time 1.810282 value 0.416120 suggestion {'alpha': 0.2165240182625834, 'batch_size': 212, 'beta_1': 0.7822757772625537, 'beta_2': 0.9848055805215897, 'epsilon': 1.6839739956933166e-09, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.0002893520883314211, 'tol': 0.01647607016879421, 'validation_fraction': 0.38278402100956016}
observation time 0.000002, current best 0.109064 at iter 13
suggestion time taken 0.004498 iter 14 next_points [{'alpha': 0.3581902684001845, 'batch_size': 89, 'beta_1': 0.5437966811110925, 'beta_2': 0.9528408790867514, 'epsilon': 7.2417012883002775e-09, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.0019294553022782548, 'tol': 0.0030679055302379158, 'validation_fraction': 0.6181593254912104}]
function_evaluation time 1.652617 value 0.156340 suggestion {'alpha': 0.3581902684001845, 'batch_size': 89, 'beta_1': 0.5437966811110925, 'beta_2': 0.9528408790867514, 'epsilon': 7.2417012883002775e-09, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.0019294553022782548, 'tol': 0.0030679055302379158, 'validation_fraction': 0.6181593254912104}
observation time 0.000001, current best 0.109064 at iter 14
saving meta data: {'args': {'--uuid': 'df22dae58dd05b62867c033b903eda0e', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.25190216699945595])}
saving results
saving timing
saving suggest log
done
