running: {'--uuid': 'ed4e0d3c3db053dab23877499b941c85', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d digits -o random -u ed4e0d3c3db053dab23877499b941c85 -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_114336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam digits acc 15 1
with data root: None
suggestion time taken 0.005020 iter 0 next_points [{'alpha': 0.0018188876979468274, 'batch_size': 96, 'beta_1': 0.9882539604830892, 'beta_2': 0.9999209481750385, 'epsilon': 3.4298464304186945e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 1.9533816183427163e-05, 'tol': 3.8647058943601185e-05, 'validation_fraction': 0.753611053128419}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 3.915090 value -0.231952 suggestion {'alpha': 0.0018188876979468274, 'batch_size': 96, 'beta_1': 0.9882539604830892, 'beta_2': 0.9999209481750385, 'epsilon': 3.4298464304186945e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 1.9533816183427163e-05, 'tol': 3.8647058943601185e-05, 'validation_fraction': 0.753611053128419}
observation time 0.000002, current best -0.231952 at iter 0
suggestion time taken 0.004600 iter 1 next_points [{'alpha': 0.017503370664859425, 'batch_size': 80, 'beta_1': 0.9164351845982088, 'beta_2': 0.9862391288818525, 'epsilon': 7.664921516777633e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 1.0161149219519926e-05, 'tol': 6.561012807939667e-05, 'validation_fraction': 0.10543978412371464}]
function_evaluation time 7.327348 value -0.204126 suggestion {'alpha': 0.017503370664859425, 'batch_size': 80, 'beta_1': 0.9164351845982088, 'beta_2': 0.9862391288818525, 'epsilon': 7.664921516777633e-07, 'hidden_layer_sizes': 163, 'learning_rate_init': 1.0161149219519926e-05, 'tol': 6.561012807939667e-05, 'validation_fraction': 0.10543978412371464}
observation time 0.000009, current best -0.231952 at iter 1
suggestion time taken 0.004827 iter 2 next_points [{'alpha': 0.043868794094446474, 'batch_size': 190, 'beta_1': 0.8497781094744411, 'beta_2': 0.9990018909771159, 'epsilon': 9.690823843738353e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.004908974799965197, 'tol': 4.877230309630158e-05, 'validation_fraction': 0.7768824054629166}]
function_evaluation time 1.325466 value -0.925559 suggestion {'alpha': 0.043868794094446474, 'batch_size': 190, 'beta_1': 0.8497781094744411, 'beta_2': 0.9990018909771159, 'epsilon': 9.690823843738353e-09, 'hidden_layer_sizes': 104, 'learning_rate_init': 0.004908974799965197, 'tol': 4.877230309630158e-05, 'validation_fraction': 0.7768824054629166}
observation time 0.000001, current best -0.925559 at iter 2
suggestion time taken 0.004549 iter 3 next_points [{'alpha': 1.632694277234131e-05, 'batch_size': 80, 'beta_1': 0.9071678519396891, 'beta_2': 0.9967315504396222, 'epsilon': 8.112208218500694e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.00296671203272692, 'tol': 0.00036910787859363163, 'validation_fraction': 0.3033486518870744}]
function_evaluation time 3.270432 value -0.960344 suggestion {'alpha': 1.632694277234131e-05, 'batch_size': 80, 'beta_1': 0.9071678519396891, 'beta_2': 0.9967315504396222, 'epsilon': 8.112208218500694e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.00296671203272692, 'tol': 0.00036910787859363163, 'validation_fraction': 0.3033486518870744}
observation time 0.000001, current best -0.960344 at iter 3
suggestion time taken 0.004527 iter 4 next_points [{'alpha': 0.011913443772144958, 'batch_size': 82, 'beta_1': 0.7746163626876348, 'beta_2': 0.9999111622657214, 'epsilon': 2.0308938971418155e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.008644782651338298, 'tol': 0.00048091450034080805, 'validation_fraction': 0.46845692091894087}]
function_evaluation time 1.928052 value -0.965902 suggestion {'alpha': 0.011913443772144958, 'batch_size': 82, 'beta_1': 0.7746163626876348, 'beta_2': 0.9999111622657214, 'epsilon': 2.0308938971418155e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.008644782651338298, 'tol': 0.00048091450034080805, 'validation_fraction': 0.46845692091894087}
observation time 0.000001, current best -0.965902 at iter 4
suggestion time taken 0.004490 iter 5 next_points [{'alpha': 1.825356177366698, 'batch_size': 124, 'beta_1': 0.9883746814401353, 'beta_2': 0.9999560678407533, 'epsilon': 6.05003704492714e-07, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.00024163368544517666, 'tol': 0.003873164008219046, 'validation_fraction': 0.413153143249834}]
function_evaluation time 3.422068 value -0.897726 suggestion {'alpha': 1.825356177366698, 'batch_size': 124, 'beta_1': 0.9883746814401353, 'beta_2': 0.9999560678407533, 'epsilon': 6.05003704492714e-07, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.00024163368544517666, 'tol': 0.003873164008219046, 'validation_fraction': 0.413153143249834}
observation time 0.000001, current best -0.965902 at iter 5
suggestion time taken 0.004518 iter 6 next_points [{'alpha': 2.2473661543936077, 'batch_size': 25, 'beta_1': 0.7000775345886235, 'beta_2': 0.9999951592881688, 'epsilon': 1.8522739839829957e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0011106136636016, 'tol': 0.0004476285652133219, 'validation_fraction': 0.8849706547492715}]
function_evaluation time 3.343418 value -0.885925 suggestion {'alpha': 2.2473661543936077, 'batch_size': 25, 'beta_1': 0.7000775345886235, 'beta_2': 0.9999951592881688, 'epsilon': 1.8522739839829957e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.0011106136636016, 'tol': 0.0004476285652133219, 'validation_fraction': 0.8849706547492715}
observation time 0.000002, current best -0.965902 at iter 6
suggestion time taken 0.004533 iter 7 next_points [{'alpha': 0.8166707453591664, 'batch_size': 155, 'beta_1': 0.9250410465996568, 'beta_2': 0.9999979691146681, 'epsilon': 2.8982907600220532e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.014657656301076077, 'tol': 3.2376376116847956e-05, 'validation_fraction': 0.5578758815885932}]
function_evaluation time 2.184539 value -0.956877 suggestion {'alpha': 0.8166707453591664, 'batch_size': 155, 'beta_1': 0.9250410465996568, 'beta_2': 0.9999979691146681, 'epsilon': 2.8982907600220532e-08, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.014657656301076077, 'tol': 3.2376376116847956e-05, 'validation_fraction': 0.5578758815885932}
observation time 0.000001, current best -0.965902 at iter 7
suggestion time taken 0.004575 iter 8 next_points [{'alpha': 3.247258013350728e-05, 'batch_size': 130, 'beta_1': 0.9563350118564853, 'beta_2': 0.9512073579415825, 'epsilon': 2.3962098163960288e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0006406804667210258, 'tol': 0.0502535607587967, 'validation_fraction': 0.17393017578751815}]
function_evaluation time 1.276317 value -0.938758 suggestion {'alpha': 3.247258013350728e-05, 'batch_size': 130, 'beta_1': 0.9563350118564853, 'beta_2': 0.9512073579415825, 'epsilon': 2.3962098163960288e-08, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0006406804667210258, 'tol': 0.0502535607587967, 'validation_fraction': 0.17393017578751815}
observation time 0.000010, current best -0.965902 at iter 8
suggestion time taken 0.004826 iter 9 next_points [{'alpha': 0.002808074656784082, 'batch_size': 147, 'beta_1': 0.9607752638185886, 'beta_2': 0.9996167184659721, 'epsilon': 2.848093279956814e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.00014170950453714577, 'tol': 0.0156738343912463, 'validation_fraction': 0.8764407970660313}]
function_evaluation time 0.351508 value -0.112048 suggestion {'alpha': 0.002808074656784082, 'batch_size': 147, 'beta_1': 0.9607752638185886, 'beta_2': 0.9996167184659721, 'epsilon': 2.848093279956814e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.00014170950453714577, 'tol': 0.0156738343912463, 'validation_fraction': 0.8764407970660313}
observation time 0.000001, current best -0.965902 at iter 9
suggestion time taken 0.004538 iter 10 next_points [{'alpha': 3.9381071324861735e-05, 'batch_size': 159, 'beta_1': 0.6189147104213085, 'beta_2': 0.9999920897783471, 'epsilon': 7.036439719222934e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0006337285177975667, 'tol': 0.0006086874002810026, 'validation_fraction': 0.7369121278383636}]
function_evaluation time 4.070409 value -0.922082 suggestion {'alpha': 3.9381071324861735e-05, 'batch_size': 159, 'beta_1': 0.6189147104213085, 'beta_2': 0.9999920897783471, 'epsilon': 7.036439719222934e-08, 'hidden_layer_sizes': 182, 'learning_rate_init': 0.0006337285177975667, 'tol': 0.0006086874002810026, 'validation_fraction': 0.7369121278383636}
observation time 0.000002, current best -0.965902 at iter 10
suggestion time taken 0.004532 iter 11 next_points [{'alpha': 0.1164760965534991, 'batch_size': 56, 'beta_1': 0.9618495217414144, 'beta_2': 0.999238900487423, 'epsilon': 2.5235884970641373e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.0076031273691189605, 'tol': 0.0021752675175221964, 'validation_fraction': 0.765576958151444}]
function_evaluation time 1.642157 value -0.929019 suggestion {'alpha': 0.1164760965534991, 'batch_size': 56, 'beta_1': 0.9618495217414144, 'beta_2': 0.999238900487423, 'epsilon': 2.5235884970641373e-08, 'hidden_layer_sizes': 163, 'learning_rate_init': 0.0076031273691189605, 'tol': 0.0021752675175221964, 'validation_fraction': 0.765576958151444}
observation time 0.000001, current best -0.965902 at iter 11
suggestion time taken 0.004500 iter 12 next_points [{'alpha': 0.00010715395351667909, 'batch_size': 106, 'beta_1': 0.7456999396726955, 'beta_2': 0.9999976701580576, 'epsilon': 2.445618915887495e-08, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0010317141832141194, 'tol': 0.0003455836333165767, 'validation_fraction': 0.665158777838391}]
function_evaluation time 2.992634 value -0.926958 suggestion {'alpha': 0.00010715395351667909, 'batch_size': 106, 'beta_1': 0.7456999396726955, 'beta_2': 0.9999976701580576, 'epsilon': 2.445618915887495e-08, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0010317141832141194, 'tol': 0.0003455836333165767, 'validation_fraction': 0.665158777838391}
observation time 0.000002, current best -0.965902 at iter 12
suggestion time taken 0.004524 iter 13 next_points [{'alpha': 0.11924493593571488, 'batch_size': 122, 'beta_1': 0.59209159703603, 'beta_2': 0.9999976058347979, 'epsilon': 5.228280152200217e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.09290878413106148, 'tol': 0.008427204644275234, 'validation_fraction': 0.18717761249295525}]
function_evaluation time 1.332811 value -0.565800 suggestion {'alpha': 0.11924493593571488, 'batch_size': 122, 'beta_1': 0.59209159703603, 'beta_2': 0.9999976058347979, 'epsilon': 5.228280152200217e-09, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.09290878413106148, 'tol': 0.008427204644275234, 'validation_fraction': 0.18717761249295525}
observation time 0.000001, current best -0.965902 at iter 13
suggestion time taken 0.004496 iter 14 next_points [{'alpha': 1.9511344576486763e-05, 'batch_size': 96, 'beta_1': 0.5341579265723504, 'beta_2': 0.901556816347197, 'epsilon': 4.1067843671335343e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.00021650152885885972, 'tol': 0.04142421551148863, 'validation_fraction': 0.7382808099353824}]
function_evaluation time 0.451858 value -0.251142 suggestion {'alpha': 1.9511344576486763e-05, 'batch_size': 96, 'beta_1': 0.5341579265723504, 'beta_2': 0.901556816347197, 'epsilon': 4.1067843671335343e-07, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.00021650152885885972, 'tol': 0.04142421551148863, 'validation_fraction': 0.7382808099353824}
observation time 0.000010, current best -0.965902 at iter 14
saving meta data: {'args': {'--uuid': 'ed4e0d3c3db053dab23877499b941c85', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.21081107239643826, -0.1295489740611692, -0.27999177313201706, -0.9422522260936896, -0.9332050909794812])}
saving results
saving timing
saving suggest log
done
