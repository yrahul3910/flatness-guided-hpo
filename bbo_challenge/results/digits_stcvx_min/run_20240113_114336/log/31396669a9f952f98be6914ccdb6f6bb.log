running: {'--uuid': '31396669a9f952f98be6914ccdb6f6bb', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d digits -o random -u 31396669a9f952f98be6914ccdb6f6bb -m nll -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_114336
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.25190216699945595])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam digits nll 15 1
with data root: None
suggestion time taken 0.005195 iter 0 next_points [{'alpha': 0.0003280223869213758, 'batch_size': 82, 'beta_1': 0.9788644883448823, 'beta_2': 0.9880557313411561, 'epsilon': 3.271242456366871e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.08692666454105268, 'tol': 0.007889108362113793, 'validation_fraction': 0.6603129588432328}]
function_evaluation time 0.840386 value 6.735332 suggestion {'alpha': 0.0003280223869213758, 'batch_size': 82, 'beta_1': 0.9788644883448823, 'beta_2': 0.9880557313411561, 'epsilon': 3.271242456366871e-07, 'hidden_layer_sizes': 142, 'learning_rate_init': 0.08692666454105268, 'tol': 0.007889108362113793, 'validation_fraction': 0.6603129588432328}
observation time 0.000010, current best 6.735332 at iter 0
suggestion time taken 0.004668 iter 1 next_points [{'alpha': 1.1523986749199198, 'batch_size': 210, 'beta_1': 0.9698585417429764, 'beta_2': 0.9573661721875686, 'epsilon': 1.156554855710574e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0014549080881081906, 'tol': 0.014192954900709766, 'validation_fraction': 0.8763016452927787}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.898765 value 0.618854 suggestion {'alpha': 1.1523986749199198, 'batch_size': 210, 'beta_1': 0.9698585417429764, 'beta_2': 0.9573661721875686, 'epsilon': 1.156554855710574e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.0014549080881081906, 'tol': 0.014192954900709766, 'validation_fraction': 0.8763016452927787}
observation time 0.000001, current best 0.618854 at iter 1
suggestion time taken 0.004659 iter 2 next_points [{'alpha': 0.39497178938297867, 'batch_size': 247, 'beta_1': 0.9482135668273285, 'beta_2': 0.999984273216611, 'epsilon': 9.869865611124939e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0004547238273273161, 'tol': 0.03202120042281442, 'validation_fraction': 0.859627885302183}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.294944 value 4.627654 suggestion {'alpha': 0.39497178938297867, 'batch_size': 247, 'beta_1': 0.9482135668273285, 'beta_2': 0.999984273216611, 'epsilon': 9.869865611124939e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0004547238273273161, 'tol': 0.03202120042281442, 'validation_fraction': 0.859627885302183}
observation time 0.000001, current best 0.618854 at iter 2
suggestion time taken 0.004647 iter 3 next_points [{'alpha': 6.349131296307592e-05, 'batch_size': 22, 'beta_1': 0.9839118068743098, 'beta_2': 0.9996585403498448, 'epsilon': 2.428149521425194e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.002705989602525886, 'tol': 0.006677439076702524, 'validation_fraction': 0.24946931256640947}]
function_evaluation time 3.053366 value 0.154363 suggestion {'alpha': 6.349131296307592e-05, 'batch_size': 22, 'beta_1': 0.9839118068743098, 'beta_2': 0.9996585403498448, 'epsilon': 2.428149521425194e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.002705989602525886, 'tol': 0.006677439076702524, 'validation_fraction': 0.24946931256640947}
observation time 0.000006, current best 0.154363 at iter 3
suggestion time taken 0.004861 iter 4 next_points [{'alpha': 0.11286450096352828, 'batch_size': 226, 'beta_1': 0.9383056588187605, 'beta_2': 0.9999063895405648, 'epsilon': 4.0769221660255855e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 7.315448784820014e-05, 'tol': 0.0002119857108315244, 'validation_fraction': 0.6276204629480087}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

function_evaluation time 7.736228 value 0.483032 suggestion {'alpha': 0.11286450096352828, 'batch_size': 226, 'beta_1': 0.9383056588187605, 'beta_2': 0.9999063895405648, 'epsilon': 4.0769221660255855e-07, 'hidden_layer_sizes': 170, 'learning_rate_init': 7.315448784820014e-05, 'tol': 0.0002119857108315244, 'validation_fraction': 0.6276204629480087}
observation time 0.000001, current best 0.154363 at iter 4
suggestion time taken 0.004622 iter 5 next_points [{'alpha': 0.0021671886241071536, 'batch_size': 115, 'beta_1': 0.8811478085696249, 'beta_2': 0.9242925654300133, 'epsilon': 2.5606847554622423e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.039846074818441636, 'tol': 0.008866479836658201, 'validation_fraction': 0.8976296190418587}]
function_evaluation time 0.902571 value 1.081653 suggestion {'alpha': 0.0021671886241071536, 'batch_size': 115, 'beta_1': 0.8811478085696249, 'beta_2': 0.9242925654300133, 'epsilon': 2.5606847554622423e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 0.039846074818441636, 'tol': 0.008866479836658201, 'validation_fraction': 0.8976296190418587}
observation time 0.000001, current best 0.154363 at iter 5
suggestion time taken 0.004606 iter 6 next_points [{'alpha': 0.20618405451925048, 'batch_size': 95, 'beta_1': 0.8868353557340087, 'beta_2': 0.9999351839503847, 'epsilon': 1.1801911192620468e-07, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.00028312810455971105, 'tol': 0.046392296006125364, 'validation_fraction': 0.13833373610680516}]
function_evaluation time 1.706971 value 0.352270 suggestion {'alpha': 0.20618405451925048, 'batch_size': 95, 'beta_1': 0.8868353557340087, 'beta_2': 0.9999351839503847, 'epsilon': 1.1801911192620468e-07, 'hidden_layer_sizes': 136, 'learning_rate_init': 0.00028312810455971105, 'tol': 0.046392296006125364, 'validation_fraction': 0.13833373610680516}
observation time 0.000001, current best 0.154363 at iter 6
suggestion time taken 0.004626 iter 7 next_points [{'alpha': 0.013536463309314314, 'batch_size': 213, 'beta_1': 0.9633563079962658, 'beta_2': 0.9998388530811448, 'epsilon': 2.7224761455198294e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 2.927020991656633e-05, 'tol': 0.04733034378295502, 'validation_fraction': 0.7149402547038042}]
function_evaluation time 0.490599 value 8.671768 suggestion {'alpha': 0.013536463309314314, 'batch_size': 213, 'beta_1': 0.9633563079962658, 'beta_2': 0.9998388530811448, 'epsilon': 2.7224761455198294e-07, 'hidden_layer_sizes': 186, 'learning_rate_init': 2.927020991656633e-05, 'tol': 0.04733034378295502, 'validation_fraction': 0.7149402547038042}
observation time 0.000002, current best 0.154363 at iter 7
suggestion time taken 0.004628 iter 8 next_points [{'alpha': 0.2013394615821751, 'batch_size': 167, 'beta_1': 0.9794777142597948, 'beta_2': 0.9999973419466057, 'epsilon': 1.0738775811152432e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0006195765792991455, 'tol': 0.0027020636809681996, 'validation_fraction': 0.8989899352272669}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 1.902029 value 3.311686 suggestion {'alpha': 0.2013394615821751, 'batch_size': 167, 'beta_1': 0.9794777142597948, 'beta_2': 0.9999973419466057, 'epsilon': 1.0738775811152432e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.0006195765792991455, 'tol': 0.0027020636809681996, 'validation_fraction': 0.8989899352272669}
observation time 0.000002, current best 0.154363 at iter 8
suggestion time taken 0.004609 iter 9 next_points [{'alpha': 0.03756479350767141, 'batch_size': 192, 'beta_1': 0.7361454335213052, 'beta_2': 0.9999958160376053, 'epsilon': 2.755164243123346e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.08479412868786569, 'tol': 1.3406568114973463e-05, 'validation_fraction': 0.2693637551376977}]
function_evaluation time 2.218236 value 1.131102 suggestion {'alpha': 0.03756479350767141, 'batch_size': 192, 'beta_1': 0.7361454335213052, 'beta_2': 0.9999958160376053, 'epsilon': 2.755164243123346e-08, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.08479412868786569, 'tol': 1.3406568114973463e-05, 'validation_fraction': 0.2693637551376977}
observation time 0.000001, current best 0.154363 at iter 9
suggestion time taken 0.004581 iter 10 next_points [{'alpha': 0.23920511331258498, 'batch_size': 232, 'beta_1': 0.9411460241584877, 'beta_2': 0.9984074715480769, 'epsilon': 2.7703848253922255e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.010260320210783852, 'tol': 0.00014467796622552657, 'validation_fraction': 0.13007827241194317}]
function_evaluation time 1.972493 value 0.136077 suggestion {'alpha': 0.23920511331258498, 'batch_size': 232, 'beta_1': 0.9411460241584877, 'beta_2': 0.9984074715480769, 'epsilon': 2.7703848253922255e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.010260320210783852, 'tol': 0.00014467796622552657, 'validation_fraction': 0.13007827241194317}
observation time 0.000005, current best 0.136077 at iter 10
suggestion time taken 0.004840 iter 11 next_points [{'alpha': 2.4458230366387616e-05, 'batch_size': 103, 'beta_1': 0.9744974236011804, 'beta_2': 0.9706813100790381, 'epsilon': 6.819877830241157e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.00010020214704847458, 'tol': 0.0005994079057536221, 'validation_fraction': 0.600595854065562}]
function_evaluation time 7.109097 value 0.200850 suggestion {'alpha': 2.4458230366387616e-05, 'batch_size': 103, 'beta_1': 0.9744974236011804, 'beta_2': 0.9706813100790381, 'epsilon': 6.819877830241157e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.00010020214704847458, 'tol': 0.0005994079057536221, 'validation_fraction': 0.600595854065562}
observation time 0.000005, current best 0.136077 at iter 11
suggestion time taken 0.004910 iter 12 next_points [{'alpha': 0.0013616468527745489, 'batch_size': 170, 'beta_1': 0.9878342525669923, 'beta_2': 0.9999927075744703, 'epsilon': 2.6087957817238234e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0010309354737012828, 'tol': 0.002409433203709831, 'validation_fraction': 0.7415121841661647}]
function_evaluation time 1.679729 value 0.360548 suggestion {'alpha': 0.0013616468527745489, 'batch_size': 170, 'beta_1': 0.9878342525669923, 'beta_2': 0.9999927075744703, 'epsilon': 2.6087957817238234e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0010309354737012828, 'tol': 0.002409433203709831, 'validation_fraction': 0.7415121841661647}
observation time 0.000002, current best 0.136077 at iter 12
suggestion time taken 0.004613 iter 13 next_points [{'alpha': 0.0729804877182202, 'batch_size': 240, 'beta_1': 0.862586466755771, 'beta_2': 0.9999724667715197, 'epsilon': 1.2736624681771366e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.004531807728477406, 'tol': 0.007993869909244281, 'validation_fraction': 0.8936504884136426}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.618699 value 0.511635 suggestion {'alpha': 0.0729804877182202, 'batch_size': 240, 'beta_1': 0.862586466755771, 'beta_2': 0.9999724667715197, 'epsilon': 1.2736624681771366e-08, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.004531807728477406, 'tol': 0.007993869909244281, 'validation_fraction': 0.8936504884136426}
observation time 0.000001, current best 0.136077 at iter 13
suggestion time taken 0.004591 iter 14 next_points [{'alpha': 0.00020222216759150448, 'batch_size': 194, 'beta_1': 0.9757195169144618, 'beta_2': 0.9999979516404045, 'epsilon': 1.4861500796365675e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.013249451834360743, 'tol': 8.940850936572184e-05, 'validation_fraction': 0.17562765166201783}]
function_evaluation time 1.681415 value 0.181997 suggestion {'alpha': 0.00020222216759150448, 'batch_size': 194, 'beta_1': 0.9757195169144618, 'beta_2': 0.9999979516404045, 'epsilon': 1.4861500796365675e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.013249451834360743, 'tol': 8.940850936572184e-05, 'validation_fraction': 0.17562765166201783}
observation time 0.000001, current best 0.136077 at iter 14
saving meta data: {'args': {'--uuid': '31396669a9f952f98be6914ccdb6f6bb', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_114336', '--opt': 'random', '--data': 'digits', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [4.8709522768835765, 9.712622772033223, 5.950791832993735, 0.19438427080405424, 0.25190216699945595])}
saving results
saving timing
saving suggest log
done
