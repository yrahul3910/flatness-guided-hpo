running: {'--uuid': '0f8a90b4724a571695b54f7388775cc6', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240114_032559', '--opt': 'stcvx', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python stcvx/optimizer.py -c MLP-adam -d wine -o stcvx -u 0f8a90b4724a571695b54f7388775cc6 -m nll -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240114_032559
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [16.063962273407764, 23.274250254613083, 19.80193088400322, 3.463918210725012, 15.210579700922182])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study stcvx MLP-adam wine nll 15 1
with data root: None
suggestion time taken 29.853793 iter 0 next_points [{'alpha': 1.9125558810710996e-05, 'batch_size': 24, 'beta_1': 0.5509115171067198, 'beta_2': 0.9999878610296911, 'epsilon': 1.385887415816679e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.00035644888152592364, 'tol': 0.004768969788775956, 'validation_fraction': 0.8662991170129322}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.148106 value 16.370749 suggestion {'alpha': 1.9125558810710996e-05, 'batch_size': 24, 'beta_1': 0.5509115171067198, 'beta_2': 0.9999878610296911, 'epsilon': 1.385887415816679e-09, 'hidden_layer_sizes': 195, 'learning_rate_init': 0.00035644888152592364, 'tol': 0.004768969788775956, 'validation_fraction': 0.8662991170129322}
observation time 0.000002, current best 16.370749 at iter 0
suggestion time taken 26.797387 iter 1 next_points [{'alpha': 0.8098702684717081, 'batch_size': 24, 'beta_1': 0.9792989633549803, 'beta_2': 0.9948120065188866, 'epsilon': 4.829271294260793e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 6.286389633116772e-05, 'tol': 0.02964989387531081, 'validation_fraction': 0.47020335402288166}]
function_evaluation time 0.152089 value 23.366230 suggestion {'alpha': 0.8098702684717081, 'batch_size': 24, 'beta_1': 0.9792989633549803, 'beta_2': 0.9948120065188866, 'epsilon': 4.829271294260793e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 6.286389633116772e-05, 'tol': 0.02964989387531081, 'validation_fraction': 0.47020335402288166}
observation time 0.000002, current best 16.370749 at iter 1
suggestion time taken 27.386525 iter 2 next_points [{'alpha': 0.0003852576240978095, 'batch_size': 11, 'beta_1': 0.5451436670847912, 'beta_2': 0.9999731509142212, 'epsilon': 1.0710538942403351e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0025410800932976884, 'tol': 1.8873307003856734e-05, 'validation_fraction': 0.22501447725409993}]
function_evaluation time 0.636546 value 0.442792 suggestion {'alpha': 0.0003852576240978095, 'batch_size': 11, 'beta_1': 0.5451436670847912, 'beta_2': 0.9999731509142212, 'epsilon': 1.0710538942403351e-09, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0025410800932976884, 'tol': 1.8873307003856734e-05, 'validation_fraction': 0.22501447725409993}
observation time 0.000004, current best 0.442792 at iter 2
suggestion time taken 27.135825 iter 3 next_points [{'alpha': 1.3755394825047249e-05, 'batch_size': 16, 'beta_1': 0.7658641364904224, 'beta_2': 0.9998432528114531, 'epsilon': 2.6194753572396157e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0002462781629312035, 'tol': 0.0005766340944988426, 'validation_fraction': 0.8799141479245888}]
function_evaluation time 0.098729 value 22.581388 suggestion {'alpha': 1.3755394825047249e-05, 'batch_size': 16, 'beta_1': 0.7658641364904224, 'beta_2': 0.9998432528114531, 'epsilon': 2.6194753572396157e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.0002462781629312035, 'tol': 0.0005766340944988426, 'validation_fraction': 0.8799141479245888}
observation time 0.000002, current best 0.442792 at iter 3
suggestion time taken 26.862059 iter 4 next_points [{'alpha': 0.8316648577815806, 'batch_size': 20, 'beta_1': 0.9771848896535715, 'beta_2': 0.9999969781359462, 'epsilon': 1.9848639824635295e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.00019214454006722588, 'tol': 0.0002901631284332019, 'validation_fraction': 0.16510032479694248}]
function_evaluation time 0.480306 value 11.283925 suggestion {'alpha': 0.8316648577815806, 'batch_size': 20, 'beta_1': 0.9771848896535715, 'beta_2': 0.9999969781359462, 'epsilon': 1.9848639824635295e-07, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.00019214454006722588, 'tol': 0.0002901631284332019, 'validation_fraction': 0.16510032479694248}
observation time 0.000004, current best 0.442792 at iter 4
suggestion time taken 26.329467 iter 5 next_points [{'alpha': 0.00023082813572586187, 'batch_size': 38, 'beta_1': 0.7572398037463232, 'beta_2': 0.9563117276739599, 'epsilon': 3.336813093110593e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 1.3074119846132134e-05, 'tol': 0.0005894025572444287, 'validation_fraction': 0.2397959884876636}]
function_evaluation time 0.153198 value 23.590002 suggestion {'alpha': 0.00023082813572586187, 'batch_size': 38, 'beta_1': 0.7572398037463232, 'beta_2': 0.9563117276739599, 'epsilon': 3.336813093110593e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 1.3074119846132134e-05, 'tol': 0.0005894025572444287, 'validation_fraction': 0.2397959884876636}
observation time 0.000002, current best 0.442792 at iter 5
suggestion time taken 24.415581 iter 6 next_points [{'alpha': 0.0342159432033658, 'batch_size': 13, 'beta_1': 0.9205311562692416, 'beta_2': 0.9994433189373727, 'epsilon': 4.3544952299187974e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0001437449933379718, 'tol': 0.0003788707962865508, 'validation_fraction': 0.5225522380440288}]
function_evaluation time 0.387945 value 12.094761 suggestion {'alpha': 0.0342159432033658, 'batch_size': 13, 'beta_1': 0.9205311562692416, 'beta_2': 0.9994433189373727, 'epsilon': 4.3544952299187974e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.0001437449933379718, 'tol': 0.0003788707962865508, 'validation_fraction': 0.5225522380440288}
observation time 0.000002, current best 0.442792 at iter 6
suggestion time taken 24.967313 iter 7 next_points [{'alpha': 0.003602495722561899, 'batch_size': 15, 'beta_1': 0.9427990018683963, 'beta_2': 0.9991324374570989, 'epsilon': 4.8914497465406515e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 3.486713971423088e-05, 'tol': 1.0839479834836682e-05, 'validation_fraction': 0.15025985571142855}]
function_evaluation time 0.260677 value 20.451100 suggestion {'alpha': 0.003602495722561899, 'batch_size': 15, 'beta_1': 0.9427990018683963, 'beta_2': 0.9991324374570989, 'epsilon': 4.8914497465406515e-08, 'hidden_layer_sizes': 70, 'learning_rate_init': 3.486713971423088e-05, 'tol': 1.0839479834836682e-05, 'validation_fraction': 0.15025985571142855}
observation time 0.000002, current best 0.442792 at iter 7
suggestion time taken 25.505089 iter 8 next_points [{'alpha': 0.003418084485691441, 'batch_size': 13, 'beta_1': 0.9278595146088386, 'beta_2': 0.9881322531675187, 'epsilon': 1.3262350044260954e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.007869097433593741, 'tol': 0.07324375830780878, 'validation_fraction': 0.42423516421534935}]
function_evaluation time 0.390834 value 0.918834 suggestion {'alpha': 0.003418084485691441, 'batch_size': 13, 'beta_1': 0.9278595146088386, 'beta_2': 0.9881322531675187, 'epsilon': 1.3262350044260954e-09, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.007869097433593741, 'tol': 0.07324375830780878, 'validation_fraction': 0.42423516421534935}
observation time 0.000002, current best 0.442792 at iter 8
suggestion time taken 24.695592 iter 9 next_points [{'alpha': 0.08301132666944668, 'batch_size': 41, 'beta_1': 0.9340957175147644, 'beta_2': 0.9810953422114027, 'epsilon': 1.6243699007496845e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.011434449541619006, 'tol': 0.0010667277151332683, 'validation_fraction': 0.8116432830707182}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.354198 value 5.220171 suggestion {'alpha': 0.08301132666944668, 'batch_size': 41, 'beta_1': 0.9340957175147644, 'beta_2': 0.9810953422114027, 'epsilon': 1.6243699007496845e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.011434449541619006, 'tol': 0.0010667277151332683, 'validation_fraction': 0.8116432830707182}
observation time 0.000002, current best 0.442792 at iter 9
suggestion time taken 23.766068 iter 10 next_points [{'alpha': 2.5406811545533293e-05, 'batch_size': 23, 'beta_1': 0.9807346483355778, 'beta_2': 0.9997774659660373, 'epsilon': 7.259235628368311e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.027851018267649935, 'tol': 1.86912456023088e-05, 'validation_fraction': 0.25151286302773196}]
function_evaluation time 0.467451 value 1.081660 suggestion {'alpha': 2.5406811545533293e-05, 'batch_size': 23, 'beta_1': 0.9807346483355778, 'beta_2': 0.9997774659660373, 'epsilon': 7.259235628368311e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.027851018267649935, 'tol': 1.86912456023088e-05, 'validation_fraction': 0.25151286302773196}
observation time 0.000002, current best 0.442792 at iter 10
suggestion time taken 25.058954 iter 11 next_points [{'alpha': 0.1620187916719281, 'batch_size': 16, 'beta_1': 0.8543285186692428, 'beta_2': 0.9999981726118914, 'epsilon': 2.5690174310116078e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 2.2107553927775627e-05, 'tol': 0.00014545319139698643, 'validation_fraction': 0.40884784880862207}]
function_evaluation time 0.302666 value 15.924831 suggestion {'alpha': 0.1620187916719281, 'batch_size': 16, 'beta_1': 0.8543285186692428, 'beta_2': 0.9999981726118914, 'epsilon': 2.5690174310116078e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 2.2107553927775627e-05, 'tol': 0.00014545319139698643, 'validation_fraction': 0.40884784880862207}
observation time 0.000002, current best 0.442792 at iter 11
suggestion time taken 24.961635 iter 12 next_points [{'alpha': 0.8904130356189387, 'batch_size': 24, 'beta_1': 0.9871980330295476, 'beta_2': 0.9938847852705628, 'epsilon': 5.6103777411373544e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 7.031178762983051e-05, 'tol': 0.002952317000929372, 'validation_fraction': 0.2653435836898334}]
function_evaluation time 0.212266 value 17.738627 suggestion {'alpha': 0.8904130356189387, 'batch_size': 24, 'beta_1': 0.9871980330295476, 'beta_2': 0.9938847852705628, 'epsilon': 5.6103777411373544e-08, 'hidden_layer_sizes': 173, 'learning_rate_init': 7.031178762983051e-05, 'tol': 0.002952317000929372, 'validation_fraction': 0.2653435836898334}
observation time 0.000002, current best 0.442792 at iter 12
suggestion time taken 24.117466 iter 13 next_points [{'alpha': 6.197859611923776e-05, 'batch_size': 13, 'beta_1': 0.9669694457897161, 'beta_2': 0.9999989927345313, 'epsilon': 1.5587575938834326e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 3.225675982490194e-05, 'tol': 0.001076310270512593, 'validation_fraction': 0.39336286342814486}]
function_evaluation time 0.322711 value 18.234368 suggestion {'alpha': 6.197859611923776e-05, 'batch_size': 13, 'beta_1': 0.9669694457897161, 'beta_2': 0.9999989927345313, 'epsilon': 1.5587575938834326e-09, 'hidden_layer_sizes': 189, 'learning_rate_init': 3.225675982490194e-05, 'tol': 0.001076310270512593, 'validation_fraction': 0.39336286342814486}
observation time 0.000002, current best 0.442792 at iter 13
suggestion time taken 24.508825 iter 14 next_points [{'alpha': 0.263504084527836, 'batch_size': 14, 'beta_1': 0.6699234104133545, 'beta_2': 0.9999978696249293, 'epsilon': 2.149717087439963e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.00025801365805719134, 'tol': 0.0016303089677076061, 'validation_fraction': 0.42019989416346804}]
function_evaluation time 0.575729 value 1.615383 suggestion {'alpha': 0.263504084527836, 'batch_size': 14, 'beta_1': 0.6699234104133545, 'beta_2': 0.9999978696249293, 'epsilon': 2.149717087439963e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.00025801365805719134, 'tol': 0.0016303089677076061, 'validation_fraction': 0.42019989416346804}
observation time 0.000002, current best 0.442792 at iter 14
saving meta data: {'args': {'--uuid': '0f8a90b4724a571695b54f7388775cc6', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240114_032559', '--opt': 'stcvx', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [16.063962273407764, 23.274250254613083, 19.80193088400322, 3.463918210725012, 15.210579700922182])}
saving results
saving timing
saving suggest log
done
