running: {'--uuid': '9ad874a61bfd5819b4b63fda480ebb20', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240114_032559', '--opt': 'random', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d wine -o random -u 9ad874a61bfd5819b4b63fda480ebb20 -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240114_032559
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam wine acc 15 1
with data root: None
suggestion time taken 0.003410 iter 0 next_points [{'alpha': 0.02391058513273279, 'batch_size': 146, 'beta_1': 0.7644723527435219, 'beta_2': 0.9999959279007826, 'epsilon': 2.3181374121584344e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.000470802072350651, 'tol': 0.013548598109097419, 'validation_fraction': 0.22338033700736235}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.143434 value -0.423153 suggestion {'alpha': 0.02391058513273279, 'batch_size': 146, 'beta_1': 0.7644723527435219, 'beta_2': 0.9999959279007826, 'epsilon': 2.3181374121584344e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 0.000470802072350651, 'tol': 0.013548598109097419, 'validation_fraction': 0.22338033700736235}
observation time 0.000002, current best -0.423153 at iter 0
suggestion time taken 0.003459 iter 1 next_points [{'alpha': 0.00013607717302083642, 'batch_size': 14, 'beta_1': 0.8542338373275784, 'beta_2': 0.995910077855352, 'epsilon': 2.0736601847336933e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.006176800474734856, 'tol': 0.00037272817479889434, 'validation_fraction': 0.6380047538826252}]
function_evaluation time 0.466689 value -0.844581 suggestion {'alpha': 0.00013607717302083642, 'batch_size': 14, 'beta_1': 0.8542338373275784, 'beta_2': 0.995910077855352, 'epsilon': 2.0736601847336933e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.006176800474734856, 'tol': 0.00037272817479889434, 'validation_fraction': 0.6380047538826252}
observation time 0.000001, current best -0.844581 at iter 1
suggestion time taken 0.003441 iter 2 next_points [{'alpha': 3.234664991603318e-05, 'batch_size': 71, 'beta_1': 0.9825746531547395, 'beta_2': 0.9990585647509249, 'epsilon': 1.0907008632381373e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0009437621858095001, 'tol': 0.00020790667721785726, 'validation_fraction': 0.8940110814816107}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.136339 value -0.464286 suggestion {'alpha': 3.234664991603318e-05, 'batch_size': 71, 'beta_1': 0.9825746531547395, 'beta_2': 0.9990585647509249, 'epsilon': 1.0907008632381373e-09, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.0009437621858095001, 'tol': 0.00020790667721785726, 'validation_fraction': 0.8940110814816107}
observation time 0.000001, current best -0.844581 at iter 2
suggestion time taken 0.003456 iter 3 next_points [{'alpha': 0.00011065067864968925, 'batch_size': 116, 'beta_1': 0.986660210055599, 'beta_2': 0.9998635945615176, 'epsilon': 1.8362478282217581e-09, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.015912698711552226, 'tol': 0.00698330661425723, 'validation_fraction': 0.25645410060783985}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.214927 value -0.605419 suggestion {'alpha': 0.00011065067864968925, 'batch_size': 116, 'beta_1': 0.986660210055599, 'beta_2': 0.9998635945615176, 'epsilon': 1.8362478282217581e-09, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.015912698711552226, 'tol': 0.00698330661425723, 'validation_fraction': 0.25645410060783985}
observation time 0.000001, current best -0.844581 at iter 3
suggestion time taken 0.003430 iter 4 next_points [{'alpha': 0.0002198075191382809, 'batch_size': 76, 'beta_1': 0.9633312757326238, 'beta_2': 0.999374781337029, 'epsilon': 1.391481823457177e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.00014462678808425835, 'tol': 0.00012049927336609299, 'validation_fraction': 0.32935766975590025}]
function_evaluation time 0.093652 value -0.331281 suggestion {'alpha': 0.0002198075191382809, 'batch_size': 76, 'beta_1': 0.9633312757326238, 'beta_2': 0.999374781337029, 'epsilon': 1.391481823457177e-09, 'hidden_layer_sizes': 60, 'learning_rate_init': 0.00014462678808425835, 'tol': 0.00012049927336609299, 'validation_fraction': 0.32935766975590025}
observation time 0.000001, current best -0.844581 at iter 4
suggestion time taken 0.003421 iter 5 next_points [{'alpha': 0.00041553773495848036, 'batch_size': 50, 'beta_1': 0.986480623108354, 'beta_2': 0.9979532771846125, 'epsilon': 3.847380958556335e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.045038661895981776, 'tol': 0.0001608941478849049, 'validation_fraction': 0.47524095950230183}]
function_evaluation time 0.204859 value -0.612069 suggestion {'alpha': 0.00041553773495848036, 'batch_size': 50, 'beta_1': 0.986480623108354, 'beta_2': 0.9979532771846125, 'epsilon': 3.847380958556335e-08, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.045038661895981776, 'tol': 0.0001608941478849049, 'validation_fraction': 0.47524095950230183}
observation time 0.000001, current best -0.844581 at iter 5
suggestion time taken 0.003420 iter 6 next_points [{'alpha': 0.004288586548343923, 'batch_size': 72, 'beta_1': 0.8941193513458724, 'beta_2': 0.9315846561638534, 'epsilon': 1.7689827096622024e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 1.2599030010522598e-05, 'tol': 3.98110030702484e-05, 'validation_fraction': 0.6369465407201691}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.108851 value -0.331281 suggestion {'alpha': 0.004288586548343923, 'batch_size': 72, 'beta_1': 0.8941193513458724, 'beta_2': 0.9315846561638534, 'epsilon': 1.7689827096622024e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 1.2599030010522598e-05, 'tol': 3.98110030702484e-05, 'validation_fraction': 0.6369465407201691}
observation time 0.000001, current best -0.844581 at iter 6
suggestion time taken 0.003411 iter 7 next_points [{'alpha': 3.4164303195568736e-05, 'batch_size': 30, 'beta_1': 0.9350892605323968, 'beta_2': 0.9999400846817958, 'epsilon': 3.993967749069466e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.002932166068628136, 'tol': 0.00012816815622655246, 'validation_fraction': 0.5253008926941182}]
function_evaluation time 0.530947 value -0.851970 suggestion {'alpha': 3.4164303195568736e-05, 'batch_size': 30, 'beta_1': 0.9350892605323968, 'beta_2': 0.9999400846817958, 'epsilon': 3.993967749069466e-09, 'hidden_layer_sizes': 191, 'learning_rate_init': 0.002932166068628136, 'tol': 0.00012816815622655246, 'validation_fraction': 0.5253008926941182}
observation time 0.000001, current best -0.851970 at iter 7
suggestion time taken 0.003449 iter 8 next_points [{'alpha': 0.002402307252946124, 'batch_size': 20, 'beta_1': 0.9819313347050285, 'beta_2': 0.9998359632934245, 'epsilon': 5.950896675017872e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0007938262594464054, 'tol': 1.1923291715630585e-05, 'validation_fraction': 0.11978210096570586}]
function_evaluation time 0.427063 value -0.585714 suggestion {'alpha': 0.002402307252946124, 'batch_size': 20, 'beta_1': 0.9819313347050285, 'beta_2': 0.9998359632934245, 'epsilon': 5.950896675017872e-07, 'hidden_layer_sizes': 198, 'learning_rate_init': 0.0007938262594464054, 'tol': 1.1923291715630585e-05, 'validation_fraction': 0.11978210096570586}
observation time 0.000011, current best -0.851970 at iter 8
suggestion time taken 0.003877 iter 9 next_points [{'alpha': 0.06048860099775908, 'batch_size': 151, 'beta_1': 0.6216265948431353, 'beta_2': 0.9997278256743733, 'epsilon': 2.0239523833691406e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0014902809504675804, 'tol': 0.001094591372902828, 'validation_fraction': 0.8436253619869281}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.315592 value -0.549015 suggestion {'alpha': 0.06048860099775908, 'batch_size': 151, 'beta_1': 0.6216265948431353, 'beta_2': 0.9997278256743733, 'epsilon': 2.0239523833691406e-09, 'hidden_layer_sizes': 133, 'learning_rate_init': 0.0014902809504675804, 'tol': 0.001094591372902828, 'validation_fraction': 0.8436253619869281}
observation time 0.000002, current best -0.851970 at iter 9
suggestion time taken 0.003449 iter 10 next_points [{'alpha': 0.025631419064604498, 'batch_size': 240, 'beta_1': 0.7629547551634146, 'beta_2': 0.9999975242522032, 'epsilon': 4.9076108143928385e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.004556314622923726, 'tol': 3.906556796265752e-05, 'validation_fraction': 0.4486329676076734}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.221141 value -0.748276 suggestion {'alpha': 0.025631419064604498, 'batch_size': 240, 'beta_1': 0.7629547551634146, 'beta_2': 0.9999975242522032, 'epsilon': 4.9076108143928385e-09, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.004556314622923726, 'tol': 3.906556796265752e-05, 'validation_fraction': 0.4486329676076734}
observation time 0.000001, current best -0.851970 at iter 10
suggestion time taken 0.003433 iter 11 next_points [{'alpha': 0.052221923153895206, 'batch_size': 10, 'beta_1': 0.9455118770696377, 'beta_2': 0.9978277167936136, 'epsilon': 8.904434624203328e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 1.0757818342277682e-05, 'tol': 0.0010250598788924615, 'validation_fraction': 0.418976857821963}]
function_evaluation time 0.317255 value -0.381281 suggestion {'alpha': 0.052221923153895206, 'batch_size': 10, 'beta_1': 0.9455118770696377, 'beta_2': 0.9978277167936136, 'epsilon': 8.904434624203328e-08, 'hidden_layer_sizes': 192, 'learning_rate_init': 1.0757818342277682e-05, 'tol': 0.0010250598788924615, 'validation_fraction': 0.418976857821963}
observation time 0.000001, current best -0.851970 at iter 11
suggestion time taken 0.003411 iter 12 next_points [{'alpha': 0.0028225926611855612, 'batch_size': 109, 'beta_1': 0.9270012625887557, 'beta_2': 0.9999240025548627, 'epsilon': 2.2320226168184453e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0002933380923297256, 'tol': 0.0015059493288716547, 'validation_fraction': 0.19500835467184838}]
function_evaluation time 0.152694 value -0.388424 suggestion {'alpha': 0.0028225926611855612, 'batch_size': 109, 'beta_1': 0.9270012625887557, 'beta_2': 0.9999240025548627, 'epsilon': 2.2320226168184453e-08, 'hidden_layer_sizes': 114, 'learning_rate_init': 0.0002933380923297256, 'tol': 0.0015059493288716547, 'validation_fraction': 0.19500835467184838}
observation time 0.000001, current best -0.851970 at iter 12
suggestion time taken 0.003385 iter 13 next_points [{'alpha': 0.0006321348257047976, 'batch_size': 27, 'beta_1': 0.7251854646913127, 'beta_2': 0.9998446231552439, 'epsilon': 5.859241696936286e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 2.7813996239985858e-05, 'tol': 0.0020285629295969474, 'validation_fraction': 0.40359289030419787}]
function_evaluation time 0.166674 value -0.407635 suggestion {'alpha': 0.0006321348257047976, 'batch_size': 27, 'beta_1': 0.7251854646913127, 'beta_2': 0.9998446231552439, 'epsilon': 5.859241696936286e-07, 'hidden_layer_sizes': 176, 'learning_rate_init': 2.7813996239985858e-05, 'tol': 0.0020285629295969474, 'validation_fraction': 0.40359289030419787}
observation time 0.000000, current best -0.851970 at iter 13
suggestion time taken 0.003387 iter 14 next_points [{'alpha': 0.0005515867114226195, 'batch_size': 11, 'beta_1': 0.9659419220960013, 'beta_2': 0.9999937711137749, 'epsilon': 2.230465019704948e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0008119994463170833, 'tol': 0.010826068924111613, 'validation_fraction': 0.4301255129259328}]
function_evaluation time 0.771589 value -0.831773 suggestion {'alpha': 0.0005515867114226195, 'batch_size': 11, 'beta_1': 0.9659419220960013, 'beta_2': 0.9999937711137749, 'epsilon': 2.230465019704948e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0008119994463170833, 'tol': 0.010826068924111613, 'validation_fraction': 0.4301255129259328}
observation time 0.000005, current best -0.851970 at iter 14
saving meta data: {'args': {'--uuid': '9ad874a61bfd5819b4b63fda480ebb20', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240114_032559', '--opt': 'random', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])}
saving results
saving timing
saving suggest log
done
