running: {'--uuid': '2643757b28305cd591dee4a3cbb683dc', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240114_032559', '--opt': 'stcvx', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python stcvx/optimizer.py -c MLP-adam -d wine -o stcvx -u 2643757b28305cd591dee4a3cbb683dc -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240114_032559
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study stcvx MLP-adam wine acc 15 1
with data root: None
suggestion time taken 27.887623 iter 0 next_points [{'alpha': 0.027228421191222502, 'batch_size': 28, 'beta_1': 0.8747940896673263, 'beta_2': 0.9193100051579981, 'epsilon': 1.4334319636366485e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 2.0746979330453112e-05, 'tol': 1.0889699613029995e-05, 'validation_fraction': 0.8751733185773}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.097097 value -0.309360 suggestion {'alpha': 0.027228421191222502, 'batch_size': 28, 'beta_1': 0.8747940896673263, 'beta_2': 0.9193100051579981, 'epsilon': 1.4334319636366485e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 2.0746979330453112e-05, 'tol': 1.0889699613029995e-05, 'validation_fraction': 0.8751733185773}
observation time 0.000002, current best -0.309360 at iter 0
suggestion time taken 25.564419 iter 1 next_points [{'alpha': 5.198828350318938, 'batch_size': 14, 'beta_1': 0.6051715695198016, 'beta_2': 0.9756324534007823, 'epsilon': 5.3123213466194705e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.00413638502424558, 'tol': 0.0011939776990666203, 'validation_fraction': 0.10236168287059175}]
function_evaluation time 0.516222 value -0.710345 suggestion {'alpha': 5.198828350318938, 'batch_size': 14, 'beta_1': 0.6051715695198016, 'beta_2': 0.9756324534007823, 'epsilon': 5.3123213466194705e-09, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.00413638502424558, 'tol': 0.0011939776990666203, 'validation_fraction': 0.10236168287059175}
observation time 0.000003, current best -0.710345 at iter 1
suggestion time taken 25.524321 iter 2 next_points [{'alpha': 0.0007993689241040822, 'batch_size': 12, 'beta_1': 0.7491123050098459, 'beta_2': 0.9998968028392649, 'epsilon': 2.2527106814200022e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.013050844631049987, 'tol': 3.871703092959392e-05, 'validation_fraction': 0.37544968027635545}]
function_evaluation time 0.536640 value -0.831281 suggestion {'alpha': 0.0007993689241040822, 'batch_size': 12, 'beta_1': 0.7491123050098459, 'beta_2': 0.9998968028392649, 'epsilon': 2.2527106814200022e-08, 'hidden_layer_sizes': 117, 'learning_rate_init': 0.013050844631049987, 'tol': 3.871703092959392e-05, 'validation_fraction': 0.37544968027635545}
observation time 0.000003, current best -0.831281 at iter 2
suggestion time taken 26.618169 iter 3 next_points [{'alpha': 0.0008901625665765149, 'batch_size': 93, 'beta_1': 0.9812915609689445, 'beta_2': 0.9996237448359965, 'epsilon': 1.524866531169389e-08, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.00045923071187008423, 'tol': 0.0031193016544437987, 'validation_fraction': 0.12441592003418003}]
function_evaluation time 0.205064 value -0.436207 suggestion {'alpha': 0.0008901625665765149, 'batch_size': 93, 'beta_1': 0.9812915609689445, 'beta_2': 0.9996237448359965, 'epsilon': 1.524866531169389e-08, 'hidden_layer_sizes': 87, 'learning_rate_init': 0.00045923071187008423, 'tol': 0.0031193016544437987, 'validation_fraction': 0.12441592003418003}
observation time 0.000003, current best -0.831281 at iter 3
suggestion time taken 24.502634 iter 4 next_points [{'alpha': 0.007571769064792554, 'batch_size': 12, 'beta_1': 0.8586728208344753, 'beta_2': 0.9999975522959147, 'epsilon': 1.6664768832088104e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.00011628925930813343, 'tol': 0.014420901667695446, 'validation_fraction': 0.6311765821647828}]
function_evaluation time 0.195260 value -0.309852 suggestion {'alpha': 0.007571769064792554, 'batch_size': 12, 'beta_1': 0.8586728208344753, 'beta_2': 0.9999975522959147, 'epsilon': 1.6664768832088104e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 0.00011628925930813343, 'tol': 0.014420901667695446, 'validation_fraction': 0.6311765821647828}
observation time 0.000002, current best -0.831281 at iter 4
suggestion time taken 25.625141 iter 5 next_points [{'alpha': 0.005897166946718444, 'batch_size': 11, 'beta_1': 0.9710255385040047, 'beta_2': 0.9999241271209645, 'epsilon': 4.321466781571113e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.00035839828700420795, 'tol': 0.005382323755418842, 'validation_fraction': 0.3077316646805531}]
function_evaluation time 0.650200 value -0.662315 suggestion {'alpha': 0.005897166946718444, 'batch_size': 11, 'beta_1': 0.9710255385040047, 'beta_2': 0.9999241271209645, 'epsilon': 4.321466781571113e-08, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.00035839828700420795, 'tol': 0.005382323755418842, 'validation_fraction': 0.3077316646805531}
observation time 0.000003, current best -0.831281 at iter 5
suggestion time taken 24.784904 iter 6 next_points [{'alpha': 0.8651675268023975, 'batch_size': 37, 'beta_1': 0.5631274891385059, 'beta_2': 0.9999805301558887, 'epsilon': 7.963442091623158e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 1.670379135036802e-05, 'tol': 1.07243489865993e-05, 'validation_fraction': 0.12841161104869522}]
function_evaluation time 0.170154 value -0.330788 suggestion {'alpha': 0.8651675268023975, 'batch_size': 37, 'beta_1': 0.5631274891385059, 'beta_2': 0.9999805301558887, 'epsilon': 7.963442091623158e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 1.670379135036802e-05, 'tol': 1.07243489865993e-05, 'validation_fraction': 0.12841161104869522}
observation time 0.000002, current best -0.831281 at iter 6
suggestion time taken 24.468651 iter 7 next_points [{'alpha': 1.3812288969458308, 'batch_size': 15, 'beta_1': 0.8466088898176335, 'beta_2': 0.9685384487595079, 'epsilon': 1.7496771718330428e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0001952301174227436, 'tol': 0.002251772580588752, 'validation_fraction': 0.23707583223364728}]
function_evaluation time 0.483487 value -0.444335 suggestion {'alpha': 1.3812288969458308, 'batch_size': 15, 'beta_1': 0.8466088898176335, 'beta_2': 0.9685384487595079, 'epsilon': 1.7496771718330428e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0001952301174227436, 'tol': 0.002251772580588752, 'validation_fraction': 0.23707583223364728}
observation time 0.000002, current best -0.831281 at iter 7
suggestion time taken 24.414865 iter 8 next_points [{'alpha': 0.014822340557171663, 'batch_size': 12, 'beta_1': 0.7781689565269372, 'beta_2': 0.9999983764897437, 'epsilon': 2.0488476970864304e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0006943148624208873, 'tol': 0.00040575457960300543, 'validation_fraction': 0.5117359453515347}]
function_evaluation time 0.567824 value -0.796059 suggestion {'alpha': 0.014822340557171663, 'batch_size': 12, 'beta_1': 0.7781689565269372, 'beta_2': 0.9999983764897437, 'epsilon': 2.0488476970864304e-07, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.0006943148624208873, 'tol': 0.00040575457960300543, 'validation_fraction': 0.5117359453515347}
observation time 0.000002, current best -0.831281 at iter 8
suggestion time taken 24.759020 iter 9 next_points [{'alpha': 0.1939147834366598, 'batch_size': 12, 'beta_1': 0.6389765037323567, 'beta_2': 0.9996109899217225, 'epsilon': 9.068356610186563e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.006270690827840648, 'tol': 2.4707122397661792e-05, 'validation_fraction': 0.4089633681074815}]
function_evaluation time 0.612714 value -0.880296 suggestion {'alpha': 0.1939147834366598, 'batch_size': 12, 'beta_1': 0.6389765037323567, 'beta_2': 0.9996109899217225, 'epsilon': 9.068356610186563e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.006270690827840648, 'tol': 2.4707122397661792e-05, 'validation_fraction': 0.4089633681074815}
observation time 0.000002, current best -0.880296 at iter 9
suggestion time taken 23.978120 iter 10 next_points [{'alpha': 0.001170226796438029, 'batch_size': 27, 'beta_1': 0.9865295402796667, 'beta_2': 0.9996623867961757, 'epsilon': 1.1523515148467138e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.03325457246850045, 'tol': 0.0008493636169839196, 'validation_fraction': 0.28286209759157455}]
function_evaluation time 0.335763 value -0.768473 suggestion {'alpha': 0.001170226796438029, 'batch_size': 27, 'beta_1': 0.9865295402796667, 'beta_2': 0.9996623867961757, 'epsilon': 1.1523515148467138e-09, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.03325457246850045, 'tol': 0.0008493636169839196, 'validation_fraction': 0.28286209759157455}
observation time 0.000002, current best -0.880296 at iter 10
suggestion time taken 25.495524 iter 11 next_points [{'alpha': 0.2908338469964868, 'batch_size': 13, 'beta_1': 0.9829858153974521, 'beta_2': 0.9997338155958151, 'epsilon': 7.062967047227249e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0009883168459650393, 'tol': 0.01589678580695173, 'validation_fraction': 0.6291109739103096}]
function_evaluation time 0.316525 value -0.628079 suggestion {'alpha': 0.2908338469964868, 'batch_size': 13, 'beta_1': 0.9829858153974521, 'beta_2': 0.9997338155958151, 'epsilon': 7.062967047227249e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.0009883168459650393, 'tol': 0.01589678580695173, 'validation_fraction': 0.6291109739103096}
observation time 0.000002, current best -0.880296 at iter 11
suggestion time taken 24.599960 iter 12 next_points [{'alpha': 0.001075308315745604, 'batch_size': 21, 'beta_1': 0.9814224409949576, 'beta_2': 0.9998254676528575, 'epsilon': 9.23446978994304e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.004469492371275209, 'tol': 3.5579174742067014e-05, 'validation_fraction': 0.4518538099543077}]
function_evaluation time 0.307697 value -0.627586 suggestion {'alpha': 0.001075308315745604, 'batch_size': 21, 'beta_1': 0.9814224409949576, 'beta_2': 0.9998254676528575, 'epsilon': 9.23446978994304e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.004469492371275209, 'tol': 3.5579174742067014e-05, 'validation_fraction': 0.4518538099543077}
observation time 0.000002, current best -0.880296 at iter 12
suggestion time taken 23.740986 iter 13 next_points [{'alpha': 0.0010315013477780399, 'batch_size': 21, 'beta_1': 0.9810078651825556, 'beta_2': 0.9999952494836406, 'epsilon': 1.1777369880253082e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.0012494179689860167, 'tol': 0.008105112987109942, 'validation_fraction': 0.878162990828282}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.165733 value -0.592118 suggestion {'alpha': 0.0010315013477780399, 'batch_size': 21, 'beta_1': 0.9810078651825556, 'beta_2': 0.9999952494836406, 'epsilon': 1.1777369880253082e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.0012494179689860167, 'tol': 0.008105112987109942, 'validation_fraction': 0.878162990828282}
observation time 0.000002, current best -0.880296 at iter 13
suggestion time taken 24.273513 iter 14 next_points [{'alpha': 2.273229565731973e-05, 'batch_size': 16, 'beta_1': 0.6918538876433119, 'beta_2': 0.9999607864243696, 'epsilon': 2.567901976610789e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0009991259332847477, 'tol': 0.00012928806152568027, 'validation_fraction': 0.11921157086333245}]
function_evaluation time 0.528645 value -0.755419 suggestion {'alpha': 2.273229565731973e-05, 'batch_size': 16, 'beta_1': 0.6918538876433119, 'beta_2': 0.9999607864243696, 'epsilon': 2.567901976610789e-08, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0009991259332847477, 'tol': 0.00012928806152568027, 'validation_fraction': 0.11921157086333245}
observation time 0.000003, current best -0.880296 at iter 14
saving meta data: {'args': {'--uuid': '2643757b28305cd591dee4a3cbb683dc', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240114_032559', '--opt': 'stcvx', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])}
saving results
saving timing
saving suggest log
done
