running: {'--uuid': '5ffdc9f8beec5efa804174e2e933fe79', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240114_032559', '--opt': 'stcvx', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python stcvx/optimizer.py -c MLP-adam -d wine -o stcvx -u 5ffdc9f8beec5efa804174e2e933fe79 -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240114_032559
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study stcvx MLP-adam wine acc 15 1
with data root: None
suggestion time taken 29.150043 iter 0 next_points [{'alpha': 0.0013773467817044416, 'batch_size': 14, 'beta_1': 0.9875277064833935, 'beta_2': 0.9846584436256572, 'epsilon': 4.4640110020487757e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0002452309107405289, 'tol': 5.768828701909972e-05, 'validation_fraction': 0.34692912540622317}]
function_evaluation time 0.616971 value -0.571921 suggestion {'alpha': 0.0013773467817044416, 'batch_size': 14, 'beta_1': 0.9875277064833935, 'beta_2': 0.9846584436256572, 'epsilon': 4.4640110020487757e-07, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0002452309107405289, 'tol': 5.768828701909972e-05, 'validation_fraction': 0.34692912540622317}
observation time 0.000002, current best -0.571921 at iter 0
suggestion time taken 26.810435 iter 1 next_points [{'alpha': 7.602960469316347, 'batch_size': 11, 'beta_1': 0.9527745277796315, 'beta_2': 0.999975991544402, 'epsilon': 3.620085808382591e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 4.0056519917009155e-05, 'tol': 0.00028570650581948866, 'validation_fraction': 0.26048740849574065}]
function_evaluation time 0.321544 value -0.366995 suggestion {'alpha': 7.602960469316347, 'batch_size': 11, 'beta_1': 0.9527745277796315, 'beta_2': 0.999975991544402, 'epsilon': 3.620085808382591e-08, 'hidden_layer_sizes': 54, 'learning_rate_init': 4.0056519917009155e-05, 'tol': 0.00028570650581948866, 'validation_fraction': 0.26048740849574065}
observation time 0.000002, current best -0.571921 at iter 1
suggestion time taken 26.279661 iter 2 next_points [{'alpha': 0.0856301963061765, 'batch_size': 13, 'beta_1': 0.9820397510720185, 'beta_2': 0.967762239919795, 'epsilon': 3.071610119801723e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0010000633883420098, 'tol': 0.0032533678484774993, 'validation_fraction': 0.6958420772807553}]
function_evaluation time 0.255432 value -0.598276 suggestion {'alpha': 0.0856301963061765, 'batch_size': 13, 'beta_1': 0.9820397510720185, 'beta_2': 0.967762239919795, 'epsilon': 3.071610119801723e-08, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0010000633883420098, 'tol': 0.0032533678484774993, 'validation_fraction': 0.6958420772807553}
observation time 0.000002, current best -0.598276 at iter 2
suggestion time taken 26.137825 iter 3 next_points [{'alpha': 8.47668494014313, 'batch_size': 12, 'beta_1': 0.7851128995640886, 'beta_2': 0.9914041114285514, 'epsilon': 1.696428535691241e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.0007328583433250221, 'tol': 4.690855741792639e-05, 'validation_fraction': 0.8667911006650921}]
function_evaluation time 0.190750 value -0.475862 suggestion {'alpha': 8.47668494014313, 'batch_size': 12, 'beta_1': 0.7851128995640886, 'beta_2': 0.9914041114285514, 'epsilon': 1.696428535691241e-09, 'hidden_layer_sizes': 98, 'learning_rate_init': 0.0007328583433250221, 'tol': 4.690855741792639e-05, 'validation_fraction': 0.8667911006650921}
observation time 0.000002, current best -0.598276 at iter 3
suggestion time taken 26.066595 iter 4 next_points [{'alpha': 0.09681206682908733, 'batch_size': 32, 'beta_1': 0.9832747644609433, 'beta_2': 0.9883128993505683, 'epsilon': 1.7128081796589584e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.041328918837845445, 'tol': 0.00010848344598826117, 'validation_fraction': 0.699622778736333}]
function_evaluation time 0.207989 value -0.648276 suggestion {'alpha': 0.09681206682908733, 'batch_size': 32, 'beta_1': 0.9832747644609433, 'beta_2': 0.9883128993505683, 'epsilon': 1.7128081796589584e-09, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.041328918837845445, 'tol': 0.00010848344598826117, 'validation_fraction': 0.699622778736333}
observation time 0.000002, current best -0.648276 at iter 4
suggestion time taken 24.823213 iter 5 next_points [{'alpha': 1.8677146622547543e-05, 'batch_size': 13, 'beta_1': 0.907772025089691, 'beta_2': 0.9998349636070278, 'epsilon': 6.07688393800085e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00034637185377386876, 'tol': 0.003965050576414014, 'validation_fraction': 0.8002181497736862}]
function_evaluation time 0.369366 value -0.571675 suggestion {'alpha': 1.8677146622547543e-05, 'batch_size': 13, 'beta_1': 0.907772025089691, 'beta_2': 0.9998349636070278, 'epsilon': 6.07688393800085e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00034637185377386876, 'tol': 0.003965050576414014, 'validation_fraction': 0.8002181497736862}
observation time 0.000002, current best -0.648276 at iter 5
suggestion time taken 25.426545 iter 6 next_points [{'alpha': 0.04034694930057111, 'batch_size': 18, 'beta_1': 0.9857195764886296, 'beta_2': 0.9998212790440376, 'epsilon': 1.2214182881893085e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.03287426828988032, 'tol': 0.00018399949435972092, 'validation_fraction': 0.7431367005408052}]
function_evaluation time 0.308136 value -0.732266 suggestion {'alpha': 0.04034694930057111, 'batch_size': 18, 'beta_1': 0.9857195764886296, 'beta_2': 0.9998212790440376, 'epsilon': 1.2214182881893085e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.03287426828988032, 'tol': 0.00018399949435972092, 'validation_fraction': 0.7431367005408052}
observation time 0.000002, current best -0.732266 at iter 6
suggestion time taken 25.002517 iter 7 next_points [{'alpha': 0.006891497362753469, 'batch_size': 26, 'beta_1': 0.6845788908910926, 'beta_2': 0.9990559772710739, 'epsilon': 1.0254339486612415e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.002728641774901307, 'tol': 0.0010684826047264672, 'validation_fraction': 0.8230625796786023}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.247170 value -0.589655 suggestion {'alpha': 0.006891497362753469, 'batch_size': 26, 'beta_1': 0.6845788908910926, 'beta_2': 0.9990559772710739, 'epsilon': 1.0254339486612415e-07, 'hidden_layer_sizes': 111, 'learning_rate_init': 0.002728641774901307, 'tol': 0.0010684826047264672, 'validation_fraction': 0.8230625796786023}
observation time 0.000003, current best -0.732266 at iter 7
suggestion time taken 25.164878 iter 8 next_points [{'alpha': 2.280963138570146e-05, 'batch_size': 20, 'beta_1': 0.9432302385286161, 'beta_2': 0.9999906836369741, 'epsilon': 1.248054644611899e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.044971071495214704, 'tol': 5.160949006377025e-05, 'validation_fraction': 0.7388417693567553}]
function_evaluation time 0.220344 value -0.556404 suggestion {'alpha': 2.280963138570146e-05, 'batch_size': 20, 'beta_1': 0.9432302385286161, 'beta_2': 0.9999906836369741, 'epsilon': 1.248054644611899e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.044971071495214704, 'tol': 5.160949006377025e-05, 'validation_fraction': 0.7388417693567553}
observation time 0.000002, current best -0.732266 at iter 8
suggestion time taken 23.260023 iter 9 next_points [{'alpha': 0.0014359614614537723, 'batch_size': 12, 'beta_1': 0.9798664352314135, 'beta_2': 0.999945487671507, 'epsilon': 5.03981688117814e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.016814014581417337, 'tol': 0.0008984911490999292, 'validation_fraction': 0.5546665822823085}]
function_evaluation time 0.566899 value -0.782020 suggestion {'alpha': 0.0014359614614537723, 'batch_size': 12, 'beta_1': 0.9798664352314135, 'beta_2': 0.999945487671507, 'epsilon': 5.03981688117814e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.016814014581417337, 'tol': 0.0008984911490999292, 'validation_fraction': 0.5546665822823085}
observation time 0.000002, current best -0.782020 at iter 9
suggestion time taken 23.646639 iter 10 next_points [{'alpha': 0.047731089395716526, 'batch_size': 12, 'beta_1': 0.9742283670782517, 'beta_2': 0.9999913587748779, 'epsilon': 3.921720603598664e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.013697640054119324, 'tol': 0.0002803608563422469, 'validation_fraction': 0.8644440520592445}]
function_evaluation time 0.307471 value -0.586453 suggestion {'alpha': 0.047731089395716526, 'batch_size': 12, 'beta_1': 0.9742283670782517, 'beta_2': 0.9999913587748779, 'epsilon': 3.921720603598664e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.013697640054119324, 'tol': 0.0002803608563422469, 'validation_fraction': 0.8644440520592445}
observation time 0.000003, current best -0.782020 at iter 10
suggestion time taken 24.507399 iter 11 next_points [{'alpha': 3.4636544060003254, 'batch_size': 18, 'beta_1': 0.5882356601887163, 'beta_2': 0.9999989289867517, 'epsilon': 1.6167744399703567e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.008707707196404988, 'tol': 0.0025116512289005462, 'validation_fraction': 0.3695491365405821}]
function_evaluation time 0.465821 value -0.755665 suggestion {'alpha': 3.4636544060003254, 'batch_size': 18, 'beta_1': 0.5882356601887163, 'beta_2': 0.9999989289867517, 'epsilon': 1.6167744399703567e-07, 'hidden_layer_sizes': 135, 'learning_rate_init': 0.008707707196404988, 'tol': 0.0025116512289005462, 'validation_fraction': 0.3695491365405821}
observation time 0.000002, current best -0.782020 at iter 11
suggestion time taken 24.995918 iter 12 next_points [{'alpha': 8.640367224335929, 'batch_size': 24, 'beta_1': 0.9522798036517541, 'beta_2': 0.9999889812229666, 'epsilon': 6.259914149985701e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 2.5993418296115407e-05, 'tol': 7.554460609615915e-05, 'validation_fraction': 0.8876972845426453}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.092054 value -0.338424 suggestion {'alpha': 8.640367224335929, 'batch_size': 24, 'beta_1': 0.9522798036517541, 'beta_2': 0.9999889812229666, 'epsilon': 6.259914149985701e-07, 'hidden_layer_sizes': 70, 'learning_rate_init': 2.5993418296115407e-05, 'tol': 7.554460609615915e-05, 'validation_fraction': 0.8876972845426453}
observation time 0.000003, current best -0.782020 at iter 12
suggestion time taken 23.448626 iter 13 next_points [{'alpha': 0.0005047389775066121, 'batch_size': 32, 'beta_1': 0.984074061681724, 'beta_2': 0.9999632341085989, 'epsilon': 1.589525566263847e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0006841104730221049, 'tol': 0.0012700678315235722, 'validation_fraction': 0.7346130720093306}]
function_evaluation time 0.120406 value -0.288424 suggestion {'alpha': 0.0005047389775066121, 'batch_size': 32, 'beta_1': 0.984074061681724, 'beta_2': 0.9999632341085989, 'epsilon': 1.589525566263847e-08, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0006841104730221049, 'tol': 0.0012700678315235722, 'validation_fraction': 0.7346130720093306}
observation time 0.000002, current best -0.782020 at iter 13
suggestion time taken 23.763464 iter 14 next_points [{'alpha': 2.9333389703075516, 'batch_size': 11, 'beta_1': 0.7337020383108148, 'beta_2': 0.9999825058837686, 'epsilon': 1.4457452927099986e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.00010981660966024122, 'tol': 0.02842576392943043, 'validation_fraction': 0.19818616356077062}]
function_evaluation time 0.811575 value -0.528571 suggestion {'alpha': 2.9333389703075516, 'batch_size': 11, 'beta_1': 0.7337020383108148, 'beta_2': 0.9999825058837686, 'epsilon': 1.4457452927099986e-09, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.00010981660966024122, 'tol': 0.02842576392943043, 'validation_fraction': 0.19818616356077062}
observation time 0.000002, current best -0.782020 at iter 14
saving meta data: {'args': {'--uuid': '5ffdc9f8beec5efa804174e2e933fe79', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240114_032559', '--opt': 'stcvx', '--data': 'wine', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.4359605911330049, -0.3169950738916256, -0.3312807881773399, -0.6620689655172413, -0.5017241379310344])}
saving results
saving timing
saving suggest log
done
