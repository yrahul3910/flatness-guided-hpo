running: {'--uuid': 'da575e6c81335f1b838914c23ad06438', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_220618', '--opt': 'stcvx', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python stcvx/optimizer.py -c MLP-adam -d iris -o stcvx -u da575e6c81335f1b838914c23ad06438 -m nll -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_220618
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [1.3105719841770722, 1.7760947732249062, 1.4322107566090756, 0.9097804858215804, 0.5745987066718419])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study stcvx MLP-adam iris nll 15 1
with data root: None
suggestion time taken 30.154372 iter 0 next_points [{'alpha': 0.5972644048503001, 'batch_size': 18, 'beta_1': 0.8979873175234794, 'beta_2': 0.9841260564915596, 'epsilon': 2.899905026960854e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 7.982640920547403e-05, 'tol': 0.09031077517153181, 'validation_fraction': 0.8596719986385334}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.102781 value 1.211581 suggestion {'alpha': 0.5972644048503001, 'batch_size': 18, 'beta_1': 0.8979873175234794, 'beta_2': 0.9841260564915596, 'epsilon': 2.899905026960854e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 7.982640920547403e-05, 'tol': 0.09031077517153181, 'validation_fraction': 0.8596719986385334}
observation time 0.000002, current best 1.211581 at iter 0
suggestion time taken 27.305072 iter 1 next_points [{'alpha': 1.090283544046798e-05, 'batch_size': 13, 'beta_1': 0.7966154596738598, 'beta_2': 0.9971671010426424, 'epsilon': 7.99629116909739e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 2.266149290491074e-05, 'tol': 0.0005377978653091865, 'validation_fraction': 0.719638120744463}]
function_evaluation time 0.125828 value 1.432095 suggestion {'alpha': 1.090283544046798e-05, 'batch_size': 13, 'beta_1': 0.7966154596738598, 'beta_2': 0.9971671010426424, 'epsilon': 7.99629116909739e-09, 'hidden_layer_sizes': 114, 'learning_rate_init': 2.266149290491074e-05, 'tol': 0.0005377978653091865, 'validation_fraction': 0.719638120744463}
observation time 0.000005, current best 1.211581 at iter 1
suggestion time taken 25.770391 iter 2 next_points [{'alpha': 6.144647755655537e-05, 'batch_size': 12, 'beta_1': 0.6523793426978196, 'beta_2': 0.9865669758190081, 'epsilon': 4.4543828866436413e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.00025523622346567396, 'tol': 0.005766160052633222, 'validation_fraction': 0.7880166870655461}]
function_evaluation time 0.138809 value 1.531773 suggestion {'alpha': 6.144647755655537e-05, 'batch_size': 12, 'beta_1': 0.6523793426978196, 'beta_2': 0.9865669758190081, 'epsilon': 4.4543828866436413e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.00025523622346567396, 'tol': 0.005766160052633222, 'validation_fraction': 0.7880166870655461}
observation time 0.000004, current best 1.211581 at iter 2
suggestion time taken 27.399542 iter 3 next_points [{'alpha': 1.4727655810404954e-05, 'batch_size': 12, 'beta_1': 0.9576006132364795, 'beta_2': 0.9954952596917308, 'epsilon': 1.1759779930497792e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0006060982104794869, 'tol': 0.008997221695305698, 'validation_fraction': 0.2481653683197026}]
function_evaluation time 0.351133 value 0.910032 suggestion {'alpha': 1.4727655810404954e-05, 'batch_size': 12, 'beta_1': 0.9576006132364795, 'beta_2': 0.9954952596917308, 'epsilon': 1.1759779930497792e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 0.0006060982104794869, 'tol': 0.008997221695305698, 'validation_fraction': 0.2481653683197026}
observation time 0.000006, current best 0.910032 at iter 3
suggestion time taken 25.511403 iter 4 next_points [{'alpha': 7.299304968063761e-05, 'batch_size': 36, 'beta_1': 0.7402252363946984, 'beta_2': 0.9973819741629087, 'epsilon': 2.2612837766370208e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.013329446695847302, 'tol': 9.21625888414169e-05, 'validation_fraction': 0.8120707253713847}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.175042 value 0.448464 suggestion {'alpha': 7.299304968063761e-05, 'batch_size': 36, 'beta_1': 0.7402252363946984, 'beta_2': 0.9973819741629087, 'epsilon': 2.2612837766370208e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.013329446695847302, 'tol': 9.21625888414169e-05, 'validation_fraction': 0.8120707253713847}
observation time 0.000002, current best 0.448464 at iter 4
suggestion time taken 24.745551 iter 5 next_points [{'alpha': 0.037055954276236425, 'batch_size': 23, 'beta_1': 0.7835331849626803, 'beta_2': 0.9999911371952201, 'epsilon': 4.517606276246335e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0005320555540338886, 'tol': 0.0001906581117582359, 'validation_fraction': 0.3445614704477654}]
function_evaluation time 0.355434 value 0.780381 suggestion {'alpha': 0.037055954276236425, 'batch_size': 23, 'beta_1': 0.7835331849626803, 'beta_2': 0.9999911371952201, 'epsilon': 4.517606276246335e-09, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.0005320555540338886, 'tol': 0.0001906581117582359, 'validation_fraction': 0.3445614704477654}
observation time 0.000002, current best 0.448464 at iter 5
suggestion time taken 25.935977 iter 6 next_points [{'alpha': 2.3197961021170603e-05, 'batch_size': 18, 'beta_1': 0.9618975556912261, 'beta_2': 0.9999465295772053, 'epsilon': 2.2023094302921426e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.022216153052884175, 'tol': 0.02376853196636548, 'validation_fraction': 0.561379114853986}]
function_evaluation time 0.243183 value 0.272879 suggestion {'alpha': 2.3197961021170603e-05, 'batch_size': 18, 'beta_1': 0.9618975556912261, 'beta_2': 0.9999465295772053, 'epsilon': 2.2023094302921426e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.022216153052884175, 'tol': 0.02376853196636548, 'validation_fraction': 0.561379114853986}
observation time 0.000006, current best 0.272879 at iter 6
suggestion time taken 24.979683 iter 7 next_points [{'alpha': 6.312097212345227e-05, 'batch_size': 17, 'beta_1': 0.8959435076641795, 'beta_2': 0.9777273496860465, 'epsilon': 2.8934220141125997e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 5.9789575262690923e-05, 'tol': 0.08615861671080682, 'validation_fraction': 0.7346552432484}]
function_evaluation time 0.131057 value 1.321736 suggestion {'alpha': 6.312097212345227e-05, 'batch_size': 17, 'beta_1': 0.8959435076641795, 'beta_2': 0.9777273496860465, 'epsilon': 2.8934220141125997e-07, 'hidden_layer_sizes': 193, 'learning_rate_init': 5.9789575262690923e-05, 'tol': 0.08615861671080682, 'validation_fraction': 0.7346552432484}
observation time 0.000002, current best 0.272879 at iter 7
suggestion time taken 24.154166 iter 8 next_points [{'alpha': 0.003261863602896571, 'batch_size': 12, 'beta_1': 0.5877361377721323, 'beta_2': 0.9999163169111807, 'epsilon': 4.3187933125094244e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0003638988108373647, 'tol': 1.6124450365063016e-05, 'validation_fraction': 0.30412641459783296}]
function_evaluation time 0.454383 value 0.783308 suggestion {'alpha': 0.003261863602896571, 'batch_size': 12, 'beta_1': 0.5877361377721323, 'beta_2': 0.9999163169111807, 'epsilon': 4.3187933125094244e-07, 'hidden_layer_sizes': 139, 'learning_rate_init': 0.0003638988108373647, 'tol': 1.6124450365063016e-05, 'validation_fraction': 0.30412641459783296}
observation time 0.000005, current best 0.272879 at iter 8
suggestion time taken 24.682567 iter 9 next_points [{'alpha': 0.01682185717045636, 'batch_size': 25, 'beta_1': 0.9867055873590168, 'beta_2': 0.9999969421782677, 'epsilon': 2.151239561316456e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 3.089372547210409e-05, 'tol': 0.00044840358224073056, 'validation_fraction': 0.81541956274005}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.091517 value 1.414911 suggestion {'alpha': 0.01682185717045636, 'batch_size': 25, 'beta_1': 0.9867055873590168, 'beta_2': 0.9999969421782677, 'epsilon': 2.151239561316456e-07, 'hidden_layer_sizes': 71, 'learning_rate_init': 3.089372547210409e-05, 'tol': 0.00044840358224073056, 'validation_fraction': 0.81541956274005}
observation time 0.000002, current best 0.272879 at iter 9
suggestion time taken 23.291942 iter 10 next_points [{'alpha': 0.5423691609264474, 'batch_size': 34, 'beta_1': 0.7172104837085067, 'beta_2': 0.9998917874147686, 'epsilon': 5.5997639805593684e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.00481190770031528, 'tol': 0.027841724706899332, 'validation_fraction': 0.630481233385388}]
function_evaluation time 0.222608 value 0.766998 suggestion {'alpha': 0.5423691609264474, 'batch_size': 34, 'beta_1': 0.7172104837085067, 'beta_2': 0.9998917874147686, 'epsilon': 5.5997639805593684e-08, 'hidden_layer_sizes': 68, 'learning_rate_init': 0.00481190770031528, 'tol': 0.027841724706899332, 'validation_fraction': 0.630481233385388}
observation time 0.000002, current best 0.272879 at iter 10
suggestion time taken 23.961366 iter 11 next_points [{'alpha': 0.19466083833653272, 'batch_size': 11, 'beta_1': 0.9633571290691002, 'beta_2': 0.999109102026535, 'epsilon': 6.313862370943043e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0032697940924228557, 'tol': 7.03040646018346e-05, 'validation_fraction': 0.8974548429024894}]
function_evaluation time 0.126470 value 1.215859 suggestion {'alpha': 0.19466083833653272, 'batch_size': 11, 'beta_1': 0.9633571290691002, 'beta_2': 0.999109102026535, 'epsilon': 6.313862370943043e-09, 'hidden_layer_sizes': 61, 'learning_rate_init': 0.0032697940924228557, 'tol': 7.03040646018346e-05, 'validation_fraction': 0.8974548429024894}
observation time 0.000002, current best 0.272879 at iter 11
suggestion time taken 24.530245 iter 12 next_points [{'alpha': 2.8455035026229768e-05, 'batch_size': 17, 'beta_1': 0.9262965161999441, 'beta_2': 0.9435079205357755, 'epsilon': 8.014192676413045e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0007838973989903766, 'tol': 0.0027902317035575037, 'validation_fraction': 0.2302325375899005}]
function_evaluation time 0.462183 value 0.643825 suggestion {'alpha': 2.8455035026229768e-05, 'batch_size': 17, 'beta_1': 0.9262965161999441, 'beta_2': 0.9435079205357755, 'epsilon': 8.014192676413045e-07, 'hidden_layer_sizes': 109, 'learning_rate_init': 0.0007838973989903766, 'tol': 0.0027902317035575037, 'validation_fraction': 0.2302325375899005}
observation time 0.000002, current best 0.272879 at iter 12
suggestion time taken 23.608202 iter 13 next_points [{'alpha': 0.002693730120734226, 'batch_size': 13, 'beta_1': 0.8897363381739757, 'beta_2': 0.9183062578193548, 'epsilon': 5.02613257719483e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00978236335708675, 'tol': 0.07375274542804018, 'validation_fraction': 0.714563358283803}]
function_evaluation time 0.234330 value 0.452880 suggestion {'alpha': 0.002693730120734226, 'batch_size': 13, 'beta_1': 0.8897363381739757, 'beta_2': 0.9183062578193548, 'epsilon': 5.02613257719483e-09, 'hidden_layer_sizes': 188, 'learning_rate_init': 0.00978236335708675, 'tol': 0.07375274542804018, 'validation_fraction': 0.714563358283803}
observation time 0.000001, current best 0.272879 at iter 13
suggestion time taken 24.549171 iter 14 next_points [{'alpha': 0.0015176606423149134, 'batch_size': 14, 'beta_1': 0.9889469397468115, 'beta_2': 0.9570537654735691, 'epsilon': 1.7289629727549657e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.09545705560547692, 'tol': 0.0027511220436692214, 'validation_fraction': 0.8519985023449694}]
function_evaluation time 0.194797 value 0.363095 suggestion {'alpha': 0.0015176606423149134, 'batch_size': 14, 'beta_1': 0.9889469397468115, 'beta_2': 0.9570537654735691, 'epsilon': 1.7289629727549657e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.09545705560547692, 'tol': 0.0027511220436692214, 'validation_fraction': 0.8519985023449694}
observation time 0.000002, current best 0.272879 at iter 14
saving meta data: {'args': {'--uuid': 'da575e6c81335f1b838914c23ad06438', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_220618', '--opt': 'stcvx', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [1.3105719841770722, 1.7760947732249062, 1.4322107566090756, 0.9097804858215804, 0.5745987066718419])}
saving results
saving timing
saving suggest log
done
