running: {'--uuid': '805d2ee83bf55ca5b8a0ecb0a5a5ec15', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_220618', '--opt': 'stcvx', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python stcvx/optimizer.py -c MLP-adam -d iris -o stcvx -u 805d2ee83bf55ca5b8a0ecb0a5a5ec15 -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_220618
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.41666666666666663, -0.275, -0.3416666666666667, -0.725, -0.875])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study stcvx MLP-adam iris acc 15 1
with data root: None
suggestion time taken 29.560388 iter 0 next_points [{'alpha': 0.060623066551449174, 'batch_size': 20, 'beta_1': 0.9879351416020972, 'beta_2': 0.9977009784704954, 'epsilon': 1.5646487810756342e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.07892055309184551, 'tol': 0.0005703092849407021, 'validation_fraction': 0.8485706528051806}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.174309 value -0.900000 suggestion {'alpha': 0.060623066551449174, 'batch_size': 20, 'beta_1': 0.9879351416020972, 'beta_2': 0.9977009784704954, 'epsilon': 1.5646487810756342e-07, 'hidden_layer_sizes': 76, 'learning_rate_init': 0.07892055309184551, 'tol': 0.0005703092849407021, 'validation_fraction': 0.8485706528051806}
observation time 0.000003, current best -0.900000 at iter 0
suggestion time taken 26.231765 iter 1 next_points [{'alpha': 0.0018890564025798725, 'batch_size': 34, 'beta_1': 0.9247585847568085, 'beta_2': 0.9862439530020073, 'epsilon': 6.153601282634731e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.00017344999731681054, 'tol': 9.882046709274329e-05, 'validation_fraction': 0.3569159458611051}]
function_evaluation time 0.205093 value -0.466667 suggestion {'alpha': 0.0018890564025798725, 'batch_size': 34, 'beta_1': 0.9247585847568085, 'beta_2': 0.9862439530020073, 'epsilon': 6.153601282634731e-09, 'hidden_layer_sizes': 193, 'learning_rate_init': 0.00017344999731681054, 'tol': 9.882046709274329e-05, 'validation_fraction': 0.3569159458611051}
observation time 0.000003, current best -0.900000 at iter 1
suggestion time taken 26.397152 iter 2 next_points [{'alpha': 0.7129233220260407, 'batch_size': 19, 'beta_1': 0.9866346428433931, 'beta_2': 0.9999226056519862, 'epsilon': 7.135463356591434e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.00014947821502240606, 'tol': 0.0007522036306307628, 'validation_fraction': 0.7280323791859519}]
function_evaluation time 0.149279 value -0.408333 suggestion {'alpha': 0.7129233220260407, 'batch_size': 19, 'beta_1': 0.9866346428433931, 'beta_2': 0.9999226056519862, 'epsilon': 7.135463356591434e-08, 'hidden_layer_sizes': 128, 'learning_rate_init': 0.00014947821502240606, 'tol': 0.0007522036306307628, 'validation_fraction': 0.7280323791859519}
observation time 0.000003, current best -0.900000 at iter 2
suggestion time taken 27.574483 iter 3 next_points [{'alpha': 1.811053025606685e-05, 'batch_size': 12, 'beta_1': 0.9688475898245603, 'beta_2': 0.9999887607611045, 'epsilon': 5.703929407090788e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.00016857455641335742, 'tol': 0.005767264235016397, 'validation_fraction': 0.30380221578396693}]
function_evaluation time 0.342481 value -0.616667 suggestion {'alpha': 1.811053025606685e-05, 'batch_size': 12, 'beta_1': 0.9688475898245603, 'beta_2': 0.9999887607611045, 'epsilon': 5.703929407090788e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.00016857455641335742, 'tol': 0.005767264235016397, 'validation_fraction': 0.30380221578396693}
observation time 0.000002, current best -0.900000 at iter 3
suggestion time taken 24.887793 iter 4 next_points [{'alpha': 0.0019508723780965634, 'batch_size': 12, 'beta_1': 0.972668602840743, 'beta_2': 0.9999741801878593, 'epsilon': 7.026759703335646e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0003122111918145707, 'tol': 0.013955437026896257, 'validation_fraction': 0.461602564836914}]
function_evaluation time 0.297062 value -0.650000 suggestion {'alpha': 0.0019508723780965634, 'batch_size': 12, 'beta_1': 0.972668602840743, 'beta_2': 0.9999741801878593, 'epsilon': 7.026759703335646e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.0003122111918145707, 'tol': 0.013955437026896257, 'validation_fraction': 0.461602564836914}
observation time 0.000002, current best -0.900000 at iter 4
suggestion time taken 25.362652 iter 5 next_points [{'alpha': 0.1356634767405506, 'batch_size': 42, 'beta_1': 0.6953637132677097, 'beta_2': 0.9674073542751411, 'epsilon': 4.5416865027932645e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.04150226885421633, 'tol': 0.0004756073366819166, 'validation_fraction': 0.8525789358529448}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.168825 value -0.950000 suggestion {'alpha': 0.1356634767405506, 'batch_size': 42, 'beta_1': 0.6953637132677097, 'beta_2': 0.9674073542751411, 'epsilon': 4.5416865027932645e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.04150226885421633, 'tol': 0.0004756073366819166, 'validation_fraction': 0.8525789358529448}
observation time 0.000003, current best -0.950000 at iter 5
suggestion time taken 24.231255 iter 6 next_points [{'alpha': 0.1841425724260349, 'batch_size': 11, 'beta_1': 0.5869505198444631, 'beta_2': 0.9994019065099158, 'epsilon': 3.934051578755689e-08, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.00017508650226285319, 'tol': 6.47160143015575e-05, 'validation_fraction': 0.7643051095754051}]
function_evaluation time 0.138093 value -0.533333 suggestion {'alpha': 0.1841425724260349, 'batch_size': 11, 'beta_1': 0.5869505198444631, 'beta_2': 0.9994019065099158, 'epsilon': 3.934051578755689e-08, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.00017508650226285319, 'tol': 6.47160143015575e-05, 'validation_fraction': 0.7643051095754051}
observation time 0.000002, current best -0.950000 at iter 6
suggestion time taken 23.426237 iter 7 next_points [{'alpha': 0.0002060007282308527, 'batch_size': 12, 'beta_1': 0.5421243360548367, 'beta_2': 0.9970447762651482, 'epsilon': 1.7474068749757054e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0002733554873471011, 'tol': 0.02939900662343163, 'validation_fraction': 0.651779119955093}]
function_evaluation time 0.277109 value -0.700000 suggestion {'alpha': 0.0002060007282308527, 'batch_size': 12, 'beta_1': 0.5421243360548367, 'beta_2': 0.9970447762651482, 'epsilon': 1.7474068749757054e-07, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0002733554873471011, 'tol': 0.02939900662343163, 'validation_fraction': 0.651779119955093}
observation time 0.000002, current best -0.950000 at iter 7
suggestion time taken 24.644292 iter 8 next_points [{'alpha': 0.023787372500010787, 'batch_size': 28, 'beta_1': 0.9764352881637668, 'beta_2': 0.9987721514725174, 'epsilon': 1.5069561223631443e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 1.9229066047510426e-05, 'tol': 0.031073655568765228, 'validation_fraction': 0.26695630587128233}]
function_evaluation time 0.148991 value -0.366667 suggestion {'alpha': 0.023787372500010787, 'batch_size': 28, 'beta_1': 0.9764352881637668, 'beta_2': 0.9987721514725174, 'epsilon': 1.5069561223631443e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 1.9229066047510426e-05, 'tol': 0.031073655568765228, 'validation_fraction': 0.26695630587128233}
observation time 0.000003, current best -0.950000 at iter 8
suggestion time taken 23.513430 iter 9 next_points [{'alpha': 4.340914939863807e-05, 'batch_size': 15, 'beta_1': 0.9377968841471287, 'beta_2': 0.9998721075654382, 'epsilon': 4.056086210287821e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.04682158028843724, 'tol': 4.5082899744661005e-05, 'validation_fraction': 0.6252935561473795}]
function_evaluation time 0.236215 value -0.933333 suggestion {'alpha': 4.340914939863807e-05, 'batch_size': 15, 'beta_1': 0.9377968841471287, 'beta_2': 0.9998721075654382, 'epsilon': 4.056086210287821e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.04682158028843724, 'tol': 4.5082899744661005e-05, 'validation_fraction': 0.6252935561473795}
observation time 0.000002, current best -0.950000 at iter 9
suggestion time taken 24.197922 iter 10 next_points [{'alpha': 0.033099757835335954, 'batch_size': 16, 'beta_1': 0.6069820146478594, 'beta_2': 0.9999953950860588, 'epsilon': 3.815856969665741e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0006251259214459259, 'tol': 6.061960298871605e-05, 'validation_fraction': 0.716908596152602}]
function_evaluation time 0.273110 value -0.641667 suggestion {'alpha': 0.033099757835335954, 'batch_size': 16, 'beta_1': 0.6069820146478594, 'beta_2': 0.9999953950860588, 'epsilon': 3.815856969665741e-08, 'hidden_layer_sizes': 85, 'learning_rate_init': 0.0006251259214459259, 'tol': 6.061960298871605e-05, 'validation_fraction': 0.716908596152602}
observation time 0.000002, current best -0.950000 at iter 10
suggestion time taken 23.986242 iter 11 next_points [{'alpha': 0.0072751543064117855, 'batch_size': 16, 'beta_1': 0.8741920886193628, 'beta_2': 0.9926820862150457, 'epsilon': 8.84227241752356e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 9.546917181913001e-05, 'tol': 0.0011858714086937492, 'validation_fraction': 0.8271981495900157}]
function_evaluation time 0.118934 value -0.308333 suggestion {'alpha': 0.0072751543064117855, 'batch_size': 16, 'beta_1': 0.8741920886193628, 'beta_2': 0.9926820862150457, 'epsilon': 8.84227241752356e-07, 'hidden_layer_sizes': 108, 'learning_rate_init': 9.546917181913001e-05, 'tol': 0.0011858714086937492, 'validation_fraction': 0.8271981495900157}
observation time 0.000002, current best -0.950000 at iter 11
suggestion time taken 23.826801 iter 12 next_points [{'alpha': 0.07984812005318492, 'batch_size': 44, 'beta_1': 0.9850492915271899, 'beta_2': 0.9540338883783739, 'epsilon': 3.896711060506331e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 7.52866194697588e-05, 'tol': 1.3130266672740725e-05, 'validation_fraction': 0.37009200202607356}]
function_evaluation time 0.154860 value -0.566667 suggestion {'alpha': 0.07984812005318492, 'batch_size': 44, 'beta_1': 0.9850492915271899, 'beta_2': 0.9540338883783739, 'epsilon': 3.896711060506331e-09, 'hidden_layer_sizes': 142, 'learning_rate_init': 7.52866194697588e-05, 'tol': 1.3130266672740725e-05, 'validation_fraction': 0.37009200202607356}
observation time 0.000003, current best -0.950000 at iter 12
suggestion time taken 23.449897 iter 13 next_points [{'alpha': 0.0008445456034342194, 'batch_size': 16, 'beta_1': 0.970042383073393, 'beta_2': 0.9998664832765626, 'epsilon': 2.3061579090863644e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.006726115524391766, 'tol': 0.0008357525162304578, 'validation_fraction': 0.8877328642065744}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.239117 value -0.900000 suggestion {'alpha': 0.0008445456034342194, 'batch_size': 16, 'beta_1': 0.970042383073393, 'beta_2': 0.9998664832765626, 'epsilon': 2.3061579090863644e-09, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.006726115524391766, 'tol': 0.0008357525162304578, 'validation_fraction': 0.8877328642065744}
observation time 0.000003, current best -0.950000 at iter 13
suggestion time taken 24.651412 iter 14 next_points [{'alpha': 0.04338498185125829, 'batch_size': 17, 'beta_1': 0.9708343451859531, 'beta_2': 0.9996613848943957, 'epsilon': 6.122675023964689e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 4.8775229697391634e-05, 'tol': 0.0953046312551182, 'validation_fraction': 0.7930599572613506}]
function_evaluation time 0.115294 value -0.325000 suggestion {'alpha': 0.04338498185125829, 'batch_size': 17, 'beta_1': 0.9708343451859531, 'beta_2': 0.9996613848943957, 'epsilon': 6.122675023964689e-09, 'hidden_layer_sizes': 74, 'learning_rate_init': 4.8775229697391634e-05, 'tol': 0.0953046312551182, 'validation_fraction': 0.7930599572613506}
observation time 0.000003, current best -0.950000 at iter 14
saving meta data: {'args': {'--uuid': '805d2ee83bf55ca5b8a0ecb0a5a5ec15', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_220618', '--opt': 'stcvx', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.41666666666666663, -0.275, -0.3416666666666667, -0.725, -0.875])}
saving results
saving timing
saving suggest log
done
