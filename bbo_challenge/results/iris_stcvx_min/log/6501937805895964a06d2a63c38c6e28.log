running: {'--uuid': '6501937805895964a06d2a63c38c6e28', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_220618', '--opt': 'stcvx', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}
cmd: python stcvx/optimizer.py -c MLP-adam -d iris -o stcvx -u 6501937805895964a06d2a63c38c6e28 -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_220618
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.41666666666666663, -0.275, -0.3416666666666667, -0.725, -0.875])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study stcvx MLP-adam iris acc 15 1
with data root: None
suggestion time taken 27.366585 iter 0 next_points [{'alpha': 0.00016861239449770388, 'batch_size': 16, 'beta_1': 0.6603229658776838, 'beta_2': 0.999634550422866, 'epsilon': 6.642187438376692e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.02992604399626027, 'tol': 0.00017694823730726988, 'validation_fraction': 0.5891384758315049}]
function_evaluation time 0.263602 value -0.966667 suggestion {'alpha': 0.00016861239449770388, 'batch_size': 16, 'beta_1': 0.6603229658776838, 'beta_2': 0.999634550422866, 'epsilon': 6.642187438376692e-09, 'hidden_layer_sizes': 97, 'learning_rate_init': 0.02992604399626027, 'tol': 0.00017694823730726988, 'validation_fraction': 0.5891384758315049}
observation time 0.000003, current best -0.966667 at iter 0
suggestion time taken 25.309333 iter 1 next_points [{'alpha': 0.001641862997520432, 'batch_size': 23, 'beta_1': 0.9820263145469951, 'beta_2': 0.9995051898613879, 'epsilon': 6.281598972830088e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.08693335294014551, 'tol': 0.004665965375335628, 'validation_fraction': 0.8844540111416513}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.173684 value -0.908333 suggestion {'alpha': 0.001641862997520432, 'batch_size': 23, 'beta_1': 0.9820263145469951, 'beta_2': 0.9995051898613879, 'epsilon': 6.281598972830088e-08, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.08693335294014551, 'tol': 0.004665965375335628, 'validation_fraction': 0.8844540111416513}
observation time 0.000002, current best -0.966667 at iter 1
suggestion time taken 25.291326 iter 2 next_points [{'alpha': 0.01629915286089707, 'batch_size': 22, 'beta_1': 0.8611399853787207, 'beta_2': 0.9851518477856671, 'epsilon': 1.7828494278547084e-07, 'hidden_layer_sizes': 97, 'learning_rate_init': 3.06902301588505e-05, 'tol': 0.008806182920665494, 'validation_fraction': 0.2630952977923842}]
function_evaluation time 0.204301 value -0.350000 suggestion {'alpha': 0.01629915286089707, 'batch_size': 22, 'beta_1': 0.8611399853787207, 'beta_2': 0.9851518477856671, 'epsilon': 1.7828494278547084e-07, 'hidden_layer_sizes': 97, 'learning_rate_init': 3.06902301588505e-05, 'tol': 0.008806182920665494, 'validation_fraction': 0.2630952977923842}
observation time 0.000003, current best -0.966667 at iter 2
suggestion time taken 25.180292 iter 3 next_points [{'alpha': 0.030316997639604413, 'batch_size': 41, 'beta_1': 0.9582718807550191, 'beta_2': 0.9947229046988025, 'epsilon': 1.4151603085163896e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.02405527404529245, 'tol': 0.04469111623857582, 'validation_fraction': 0.8690533210328472}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.158562 value -0.825000 suggestion {'alpha': 0.030316997639604413, 'batch_size': 41, 'beta_1': 0.9582718807550191, 'beta_2': 0.9947229046988025, 'epsilon': 1.4151603085163896e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.02405527404529245, 'tol': 0.04469111623857582, 'validation_fraction': 0.8690533210328472}
observation time 0.000003, current best -0.966667 at iter 3
suggestion time taken 25.518794 iter 4 next_points [{'alpha': 0.01588394143193075, 'batch_size': 15, 'beta_1': 0.8924860079641521, 'beta_2': 0.9993350784707586, 'epsilon': 4.377917961108605e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.024399105244760435, 'tol': 0.006187616488352892, 'validation_fraction': 0.4451197608414027}]
function_evaluation time 0.303576 value -0.916667 suggestion {'alpha': 0.01588394143193075, 'batch_size': 15, 'beta_1': 0.8924860079641521, 'beta_2': 0.9993350784707586, 'epsilon': 4.377917961108605e-08, 'hidden_layer_sizes': 132, 'learning_rate_init': 0.024399105244760435, 'tol': 0.006187616488352892, 'validation_fraction': 0.4451197608414027}
observation time 0.000003, current best -0.966667 at iter 4
suggestion time taken 23.973213 iter 5 next_points [{'alpha': 0.002849525926796638, 'batch_size': 16, 'beta_1': 0.8335552985216732, 'beta_2': 0.9999306107946512, 'epsilon': 4.288383650988855e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 6.154696626695788e-05, 'tol': 1.208975296513415e-05, 'validation_fraction': 0.5583706360571504}]
function_evaluation time 0.315659 value -0.258333 suggestion {'alpha': 0.002849525926796638, 'batch_size': 16, 'beta_1': 0.8335552985216732, 'beta_2': 0.9999306107946512, 'epsilon': 4.288383650988855e-08, 'hidden_layer_sizes': 66, 'learning_rate_init': 6.154696626695788e-05, 'tol': 1.208975296513415e-05, 'validation_fraction': 0.5583706360571504}
observation time 0.000003, current best -0.966667 at iter 5
suggestion time taken 24.821295 iter 6 next_points [{'alpha': 0.008742746758276146, 'batch_size': 15, 'beta_1': 0.8586741826682849, 'beta_2': 0.9994905641980798, 'epsilon': 1.8571714998784115e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0005412463948393435, 'tol': 0.005007906180664727, 'validation_fraction': 0.5073256981747049}]
function_evaluation time 0.263696 value -0.550000 suggestion {'alpha': 0.008742746758276146, 'batch_size': 15, 'beta_1': 0.8586741826682849, 'beta_2': 0.9994905641980798, 'epsilon': 1.8571714998784115e-09, 'hidden_layer_sizes': 56, 'learning_rate_init': 0.0005412463948393435, 'tol': 0.005007906180664727, 'validation_fraction': 0.5073256981747049}
observation time 0.000003, current best -0.966667 at iter 6
suggestion time taken 24.708270 iter 7 next_points [{'alpha': 1.8569516550219334, 'batch_size': 16, 'beta_1': 0.8130650626302488, 'beta_2': 0.9955380244119274, 'epsilon': 9.86497815456093e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.00013523394406794747, 'tol': 0.00531831333549655, 'validation_fraction': 0.8411233446719875}]
function_evaluation time 0.164227 value -0.308333 suggestion {'alpha': 1.8569516550219334, 'batch_size': 16, 'beta_1': 0.8130650626302488, 'beta_2': 0.9955380244119274, 'epsilon': 9.86497815456093e-07, 'hidden_layer_sizes': 91, 'learning_rate_init': 0.00013523394406794747, 'tol': 0.00531831333549655, 'validation_fraction': 0.8411233446719875}
observation time 0.000003, current best -0.966667 at iter 7
suggestion time taken 23.705115 iter 8 next_points [{'alpha': 0.0027007564552428407, 'batch_size': 21, 'beta_1': 0.9728465914808724, 'beta_2': 0.9997537824758088, 'epsilon': 7.769677306179694e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0011181255773325851, 'tol': 2.28626421600901e-05, 'validation_fraction': 0.6053900018466867}]
function_evaluation time 0.191499 value -0.591667 suggestion {'alpha': 0.0027007564552428407, 'batch_size': 21, 'beta_1': 0.9728465914808724, 'beta_2': 0.9997537824758088, 'epsilon': 7.769677306179694e-08, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.0011181255773325851, 'tol': 2.28626421600901e-05, 'validation_fraction': 0.6053900018466867}
observation time 0.000002, current best -0.966667 at iter 8
suggestion time taken 24.446916 iter 9 next_points [{'alpha': 1.106397167527483, 'batch_size': 11, 'beta_1': 0.9629148811572648, 'beta_2': 0.9991712465279082, 'epsilon': 1.7454400178767132e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0008201605370286223, 'tol': 1.9990940688416597e-05, 'validation_fraction': 0.35815034729755574}]
function_evaluation time 0.503742 value -0.866667 suggestion {'alpha': 1.106397167527483, 'batch_size': 11, 'beta_1': 0.9629148811572648, 'beta_2': 0.9991712465279082, 'epsilon': 1.7454400178767132e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0008201605370286223, 'tol': 1.9990940688416597e-05, 'validation_fraction': 0.35815034729755574}
observation time 0.000003, current best -0.966667 at iter 9
suggestion time taken 23.852345 iter 10 next_points [{'alpha': 1.1812749493116013, 'batch_size': 17, 'beta_1': 0.8771400286550466, 'beta_2': 0.9999982988974495, 'epsilon': 2.553811977654556e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 1.3018056160340118e-05, 'tol': 0.009530598327731425, 'validation_fraction': 0.6703977244259708}]
function_evaluation time 0.126692 value -0.358333 suggestion {'alpha': 1.1812749493116013, 'batch_size': 17, 'beta_1': 0.8771400286550466, 'beta_2': 0.9999982988974495, 'epsilon': 2.553811977654556e-09, 'hidden_layer_sizes': 169, 'learning_rate_init': 1.3018056160340118e-05, 'tol': 0.009530598327731425, 'validation_fraction': 0.6703977244259708}
observation time 0.000003, current best -0.966667 at iter 10
suggestion time taken 23.859654 iter 11 next_points [{'alpha': 0.0003447957403697183, 'batch_size': 12, 'beta_1': 0.6342380414078492, 'beta_2': 0.9341635335565784, 'epsilon': 1.9461969233088984e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0058617153048036354, 'tol': 0.00013349639987616764, 'validation_fraction': 0.2238123483047479}]
function_evaluation time 0.526162 value -0.950000 suggestion {'alpha': 0.0003447957403697183, 'batch_size': 12, 'beta_1': 0.6342380414078492, 'beta_2': 0.9341635335565784, 'epsilon': 1.9461969233088984e-08, 'hidden_layer_sizes': 95, 'learning_rate_init': 0.0058617153048036354, 'tol': 0.00013349639987616764, 'validation_fraction': 0.2238123483047479}
observation time 0.000002, current best -0.966667 at iter 11
suggestion time taken 24.145986 iter 12 next_points [{'alpha': 0.8732942521277691, 'batch_size': 12, 'beta_1': 0.7202595847418465, 'beta_2': 0.9995974201868983, 'epsilon': 3.188876376887405e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 7.96634196759677e-05, 'tol': 0.008758387810785664, 'validation_fraction': 0.8856727676201618}]
function_evaluation time 0.129079 value -0.416667 suggestion {'alpha': 0.8732942521277691, 'batch_size': 12, 'beta_1': 0.7202595847418465, 'beta_2': 0.9995974201868983, 'epsilon': 3.188876376887405e-07, 'hidden_layer_sizes': 87, 'learning_rate_init': 7.96634196759677e-05, 'tol': 0.008758387810785664, 'validation_fraction': 0.8856727676201618}
observation time 0.000002, current best -0.966667 at iter 12
suggestion time taken 23.177664 iter 13 next_points [{'alpha': 6.291801739030278, 'batch_size': 10, 'beta_1': 0.6749417143722098, 'beta_2': 0.9999753531262912, 'epsilon': 1.5983424642899399e-09, 'hidden_layer_sizes': 156, 'learning_rate_init': 3.82942433597487e-05, 'tol': 0.0029613341681294742, 'validation_fraction': 0.8583882629973675}]
function_evaluation time 0.195505 value -0.250000 suggestion {'alpha': 6.291801739030278, 'batch_size': 10, 'beta_1': 0.6749417143722098, 'beta_2': 0.9999753531262912, 'epsilon': 1.5983424642899399e-09, 'hidden_layer_sizes': 156, 'learning_rate_init': 3.82942433597487e-05, 'tol': 0.0029613341681294742, 'validation_fraction': 0.8583882629973675}
observation time 0.000003, current best -0.966667 at iter 13
suggestion time taken 23.969824 iter 14 next_points [{'alpha': 2.826089180472449e-05, 'batch_size': 19, 'beta_1': 0.9692957469199636, 'beta_2': 0.9999416542522195, 'epsilon': 5.316924878221308e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 6.598030641150937e-05, 'tol': 0.004197540544612748, 'validation_fraction': 0.8839490557298353}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.087542 value -0.333333 suggestion {'alpha': 2.826089180472449e-05, 'batch_size': 19, 'beta_1': 0.9692957469199636, 'beta_2': 0.9999416542522195, 'epsilon': 5.316924878221308e-08, 'hidden_layer_sizes': 64, 'learning_rate_init': 6.598030641150937e-05, 'tol': 0.004197540544612748, 'validation_fraction': 0.8839490557298353}
observation time 0.000003, current best -0.966667 at iter 14
saving meta data: {'args': {'--uuid': '6501937805895964a06d2a63c38c6e28', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_220618', '--opt': 'stcvx', '--data': 'iris', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': 'x.x.x'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.0019982467392329444, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.0018781738757161913, 'tol': 1.1889379831773004e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00617340520407431, 'tol': 1.741413418158619e-05, 'validation_fraction': 0.6754299026638921}], [-0.41666666666666663, -0.275, -0.3416666666666667, -0.725, -0.875])}
saving results
saving timing
saving suggest log
done
