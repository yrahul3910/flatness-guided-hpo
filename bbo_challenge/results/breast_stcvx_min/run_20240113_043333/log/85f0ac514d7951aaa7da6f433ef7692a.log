running: {'--uuid': '85f0ac514d7951aaa7da6f433ef7692a', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 85f0ac514d7951aaa7da6f433ef7692a -m nll -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_043333
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.269783589486869, 3.4904310816393633])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.004253 iter 0 next_points [{'alpha': 0.000593036053345349, 'batch_size': 113, 'beta_1': 0.5673711849093415, 'beta_2': 0.9110213763891494, 'epsilon': 3.820242407529906e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 3.902741008513662e-05, 'tol': 0.001691997625871874, 'validation_fraction': 0.14559997520680365}]
function_evaluation time 0.173640 value 14.323387 suggestion {'alpha': 0.000593036053345349, 'batch_size': 113, 'beta_1': 0.5673711849093415, 'beta_2': 0.9110213763891494, 'epsilon': 3.820242407529906e-07, 'hidden_layer_sizes': 95, 'learning_rate_init': 3.902741008513662e-05, 'tol': 0.001691997625871874, 'validation_fraction': 0.14559997520680365}
observation time 0.000001, current best 14.323387 at iter 0
suggestion time taken 0.004186 iter 1 next_points [{'alpha': 0.0002595602881062599, 'batch_size': 189, 'beta_1': 0.9874804257769039, 'beta_2': 0.9999977271735542, 'epsilon': 7.262171249008255e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0032068153714920277, 'tol': 0.002032035753384555, 'validation_fraction': 0.874091951604751}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.217469 value 3.343495 suggestion {'alpha': 0.0002595602881062599, 'batch_size': 189, 'beta_1': 0.9874804257769039, 'beta_2': 0.9999977271735542, 'epsilon': 7.262171249008255e-07, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.0032068153714920277, 'tol': 0.002032035753384555, 'validation_fraction': 0.874091951604751}
observation time 0.000001, current best 3.343495 at iter 1
suggestion time taken 0.004203 iter 2 next_points [{'alpha': 0.017907492351409173, 'batch_size': 210, 'beta_1': 0.9864676094611211, 'beta_2': 0.9999496474580724, 'epsilon': 2.4603937933237144e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 2.825455600915168e-05, 'tol': 0.0002739605024996477, 'validation_fraction': 0.4227647929571257}]
function_evaluation time 0.169982 value 14.174015 suggestion {'alpha': 0.017907492351409173, 'batch_size': 210, 'beta_1': 0.9864676094611211, 'beta_2': 0.9999496474580724, 'epsilon': 2.4603937933237144e-09, 'hidden_layer_sizes': 102, 'learning_rate_init': 2.825455600915168e-05, 'tol': 0.0002739605024996477, 'validation_fraction': 0.4227647929571257}
observation time 0.000001, current best 3.343495 at iter 2
suggestion time taken 0.004191 iter 3 next_points [{'alpha': 2.238549150270341, 'batch_size': 64, 'beta_1': 0.570423768659684, 'beta_2': 0.9595584003710051, 'epsilon': 2.5619387248694144e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.009161411527078963, 'tol': 0.07108830219449876, 'validation_fraction': 0.6422228317154163}]
function_evaluation time 0.160419 value 2.116672 suggestion {'alpha': 2.238549150270341, 'batch_size': 64, 'beta_1': 0.570423768659684, 'beta_2': 0.9595584003710051, 'epsilon': 2.5619387248694144e-08, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.009161411527078963, 'tol': 0.07108830219449876, 'validation_fraction': 0.6422228317154163}
observation time 0.000001, current best 2.116672 at iter 3
suggestion time taken 0.004158 iter 4 next_points [{'alpha': 0.01352868421635766, 'batch_size': 162, 'beta_1': 0.6173817026914421, 'beta_2': 0.9907598533997646, 'epsilon': 3.6176446584259743e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.006527486288350588, 'tol': 0.0382984560247135, 'validation_fraction': 0.6674267008942933}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.148030 value 0.547437 suggestion {'alpha': 0.01352868421635766, 'batch_size': 162, 'beta_1': 0.6173817026914421, 'beta_2': 0.9907598533997646, 'epsilon': 3.6176446584259743e-07, 'hidden_layer_sizes': 75, 'learning_rate_init': 0.006527486288350588, 'tol': 0.0382984560247135, 'validation_fraction': 0.6674267008942933}
observation time 0.000001, current best 0.547437 at iter 4
suggestion time taken 0.004169 iter 5 next_points [{'alpha': 0.00047854531516468133, 'batch_size': 103, 'beta_1': 0.8526517296507913, 'beta_2': 0.9651540128825924, 'epsilon': 1.15810180853772e-09, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.0071318351981633134, 'tol': 0.041519706965440537, 'validation_fraction': 0.3381716975120741}]
function_evaluation time 0.285275 value 1.084789 suggestion {'alpha': 0.00047854531516468133, 'batch_size': 103, 'beta_1': 0.8526517296507913, 'beta_2': 0.9651540128825924, 'epsilon': 1.15810180853772e-09, 'hidden_layer_sizes': 185, 'learning_rate_init': 0.0071318351981633134, 'tol': 0.041519706965440537, 'validation_fraction': 0.3381716975120741}
observation time 0.000000, current best 0.547437 at iter 5
suggestion time taken 0.004180 iter 6 next_points [{'alpha': 0.18401803734424965, 'batch_size': 53, 'beta_1': 0.9549865722489208, 'beta_2': 0.9999574160697605, 'epsilon': 4.090132830345716e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 1.373348260146021e-05, 'tol': 1.8527431867100353e-05, 'validation_fraction': 0.27939623113482676}]
function_evaluation time 0.294428 value 7.513293 suggestion {'alpha': 0.18401803734424965, 'batch_size': 53, 'beta_1': 0.9549865722489208, 'beta_2': 0.9999574160697605, 'epsilon': 4.090132830345716e-09, 'hidden_layer_sizes': 126, 'learning_rate_init': 1.373348260146021e-05, 'tol': 1.8527431867100353e-05, 'validation_fraction': 0.27939623113482676}
observation time 0.000004, current best 0.547437 at iter 6
suggestion time taken 0.004319 iter 7 next_points [{'alpha': 0.00043342256587135426, 'batch_size': 51, 'beta_1': 0.9304817514126548, 'beta_2': 0.9830375258585609, 'epsilon': 8.981229972621875e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.06620668595988674, 'tol': 0.0031432096929377893, 'validation_fraction': 0.1587749214014455}]
function_evaluation time 0.524397 value 0.638297 suggestion {'alpha': 0.00043342256587135426, 'batch_size': 51, 'beta_1': 0.9304817514126548, 'beta_2': 0.9830375258585609, 'epsilon': 8.981229972621875e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.06620668595988674, 'tol': 0.0031432096929377893, 'validation_fraction': 0.1587749214014455}
observation time 0.000000, current best 0.547437 at iter 7
suggestion time taken 0.004173 iter 8 next_points [{'alpha': 0.0702785194808901, 'batch_size': 115, 'beta_1': 0.9060126310917146, 'beta_2': 0.9962794946639864, 'epsilon': 1.0024940295481057e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0032322887857783055, 'tol': 3.7013480003143935e-05, 'validation_fraction': 0.3658828291860449}]
function_evaluation time 0.414842 value 0.636074 suggestion {'alpha': 0.0702785194808901, 'batch_size': 115, 'beta_1': 0.9060126310917146, 'beta_2': 0.9962794946639864, 'epsilon': 1.0024940295481057e-07, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0032322887857783055, 'tol': 3.7013480003143935e-05, 'validation_fraction': 0.3658828291860449}
observation time 0.000001, current best 0.547437 at iter 8
suggestion time taken 0.004176 iter 9 next_points [{'alpha': 0.00017158241422003188, 'batch_size': 52, 'beta_1': 0.8993240854698791, 'beta_2': 0.9999987217563585, 'epsilon': 2.241431864276771e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.04561307948049183, 'tol': 0.07255647680275021, 'validation_fraction': 0.5205002526619161}]
function_evaluation time 0.192166 value 0.369223 suggestion {'alpha': 0.00017158241422003188, 'batch_size': 52, 'beta_1': 0.8993240854698791, 'beta_2': 0.9999987217563585, 'epsilon': 2.241431864276771e-09, 'hidden_layer_sizes': 81, 'learning_rate_init': 0.04561307948049183, 'tol': 0.07255647680275021, 'validation_fraction': 0.5205002526619161}
observation time 0.000001, current best 0.369223 at iter 9
suggestion time taken 0.004174 iter 10 next_points [{'alpha': 0.022311147443880266, 'batch_size': 118, 'beta_1': 0.9709537708417182, 'beta_2': 0.9998740126052685, 'epsilon': 7.891891686532425e-09, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.01998213367239029, 'tol': 0.031429253382377, 'validation_fraction': 0.4826913955622341}]
function_evaluation time 0.240059 value 0.994117 suggestion {'alpha': 0.022311147443880266, 'batch_size': 118, 'beta_1': 0.9709537708417182, 'beta_2': 0.9998740126052685, 'epsilon': 7.891891686532425e-09, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.01998213367239029, 'tol': 0.031429253382377, 'validation_fraction': 0.4826913955622341}
observation time 0.000001, current best 0.369223 at iter 10
suggestion time taken 0.004181 iter 11 next_points [{'alpha': 8.335286759915594, 'batch_size': 55, 'beta_1': 0.9670551178122245, 'beta_2': 0.9716009517634638, 'epsilon': 2.0404201692278165e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 1.0078772179111311e-05, 'tol': 6.161234819439422e-05, 'validation_fraction': 0.1679720332138406}]
function_evaluation time 0.227793 value 14.941563 suggestion {'alpha': 8.335286759915594, 'batch_size': 55, 'beta_1': 0.9670551178122245, 'beta_2': 0.9716009517634638, 'epsilon': 2.0404201692278165e-08, 'hidden_layer_sizes': 136, 'learning_rate_init': 1.0078772179111311e-05, 'tol': 6.161234819439422e-05, 'validation_fraction': 0.1679720332138406}
observation time 0.000000, current best 0.369223 at iter 11
suggestion time taken 0.004173 iter 12 next_points [{'alpha': 0.08612581333894197, 'batch_size': 67, 'beta_1': 0.9871958100386087, 'beta_2': 0.9909224059972533, 'epsilon': 2.4697497225885796e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 7.8190948420222e-05, 'tol': 1.2961589235869e-05, 'validation_fraction': 0.6405774070021798}]
function_evaluation time 0.133212 value 12.703406 suggestion {'alpha': 0.08612581333894197, 'batch_size': 67, 'beta_1': 0.9871958100386087, 'beta_2': 0.9909224059972533, 'epsilon': 2.4697497225885796e-08, 'hidden_layer_sizes': 57, 'learning_rate_init': 7.8190948420222e-05, 'tol': 1.2961589235869e-05, 'validation_fraction': 0.6405774070021798}
observation time 0.000005, current best 0.369223 at iter 12
suggestion time taken 0.004360 iter 13 next_points [{'alpha': 6.238874284515693e-05, 'batch_size': 186, 'beta_1': 0.9168525386256031, 'beta_2': 0.9586631356651568, 'epsilon': 2.0761918170756947e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.014906538813973734, 'tol': 1.0205497512321965e-05, 'validation_fraction': 0.21030262741601663}]
function_evaluation time 0.249770 value 0.673826 suggestion {'alpha': 6.238874284515693e-05, 'batch_size': 186, 'beta_1': 0.9168525386256031, 'beta_2': 0.9586631356651568, 'epsilon': 2.0761918170756947e-07, 'hidden_layer_sizes': 55, 'learning_rate_init': 0.014906538813973734, 'tol': 1.0205497512321965e-05, 'validation_fraction': 0.21030262741601663}
observation time 0.000001, current best 0.369223 at iter 13
suggestion time taken 0.004160 iter 14 next_points [{'alpha': 0.002241721723225402, 'batch_size': 18, 'beta_1': 0.955082758989835, 'beta_2': 0.9955605763226978, 'epsilon': 1.1724558585244523e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0011100396265404434, 'tol': 0.0005586725722825892, 'validation_fraction': 0.7666669907890278}]
function_evaluation time 0.433010 value 0.513991 suggestion {'alpha': 0.002241721723225402, 'batch_size': 18, 'beta_1': 0.955082758989835, 'beta_2': 0.9955605763226978, 'epsilon': 1.1724558585244523e-09, 'hidden_layer_sizes': 101, 'learning_rate_init': 0.0011100396265404434, 'tol': 0.0005586725722825892, 'validation_fraction': 0.7666669907890278}
observation time 0.000001, current best 0.369223 at iter 14
saving meta data: {'args': {'--uuid': '85f0ac514d7951aaa7da6f433ef7692a', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.269783589486869, 3.4904310816393633])}
saving results
saving timing
saving suggest log
done
