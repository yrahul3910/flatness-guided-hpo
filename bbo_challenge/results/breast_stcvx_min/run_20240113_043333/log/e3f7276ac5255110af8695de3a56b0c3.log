running: {'--uuid': 'e3f7276ac5255110af8695de3a56b0c3', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u e3f7276ac5255110af8695de3a56b0c3 -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_043333
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.004217 iter 0 next_points [{'alpha': 0.8737753920768699, 'batch_size': 150, 'beta_1': 0.9731818004186387, 'beta_2': 0.9999864964812577, 'epsilon': 5.052506796353653e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.07868228578411599, 'tol': 0.003118122264145567, 'validation_fraction': 0.10354388159843993}]
function_evaluation time 0.247086 value -0.740659 suggestion {'alpha': 0.8737753920768699, 'batch_size': 150, 'beta_1': 0.9731818004186387, 'beta_2': 0.9999864964812577, 'epsilon': 5.052506796353653e-07, 'hidden_layer_sizes': 121, 'learning_rate_init': 0.07868228578411599, 'tol': 0.003118122264145567, 'validation_fraction': 0.10354388159843993}
observation time 0.000000, current best -0.740659 at iter 0
suggestion time taken 0.004121 iter 1 next_points [{'alpha': 0.001413946759612814, 'batch_size': 197, 'beta_1': 0.8696661464067196, 'beta_2': 0.9957855683827013, 'epsilon': 4.5611006104379e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 7.407207886538486e-05, 'tol': 1.2215563923832097e-05, 'validation_fraction': 0.40143217363649486}]
function_evaluation time 0.190142 value -0.501099 suggestion {'alpha': 0.001413946759612814, 'batch_size': 197, 'beta_1': 0.8696661464067196, 'beta_2': 0.9957855683827013, 'epsilon': 4.5611006104379e-09, 'hidden_layer_sizes': 57, 'learning_rate_init': 7.407207886538486e-05, 'tol': 1.2215563923832097e-05, 'validation_fraction': 0.40143217363649486}
observation time 0.000001, current best -0.740659 at iter 1
suggestion time taken 0.004124 iter 2 next_points [{'alpha': 0.04984836467029073, 'batch_size': 211, 'beta_1': 0.9827883809216702, 'beta_2': 0.9989070362360666, 'epsilon': 3.106760104494189e-08, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.04015193459922317, 'tol': 3.128829983874515e-05, 'validation_fraction': 0.38784344863065456}]
function_evaluation time 0.401260 value -0.883516 suggestion {'alpha': 0.04984836467029073, 'batch_size': 211, 'beta_1': 0.9827883809216702, 'beta_2': 0.9989070362360666, 'epsilon': 3.106760104494189e-08, 'hidden_layer_sizes': 186, 'learning_rate_init': 0.04015193459922317, 'tol': 3.128829983874515e-05, 'validation_fraction': 0.38784344863065456}
observation time 0.000001, current best -0.883516 at iter 2
suggestion time taken 0.004124 iter 3 next_points [{'alpha': 1.7493324334957278e-05, 'batch_size': 120, 'beta_1': 0.8285152501347918, 'beta_2': 0.9999780569760393, 'epsilon': 9.725510024405139e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.022128215921763776, 'tol': 1.1098381626374117e-05, 'validation_fraction': 0.25534084065687657}]
function_evaluation time 0.373877 value -0.901099 suggestion {'alpha': 1.7493324334957278e-05, 'batch_size': 120, 'beta_1': 0.8285152501347918, 'beta_2': 0.9999780569760393, 'epsilon': 9.725510024405139e-08, 'hidden_layer_sizes': 161, 'learning_rate_init': 0.022128215921763776, 'tol': 1.1098381626374117e-05, 'validation_fraction': 0.25534084065687657}
observation time 0.000004, current best -0.901099 at iter 3
suggestion time taken 0.004282 iter 4 next_points [{'alpha': 0.00026296641226205105, 'batch_size': 16, 'beta_1': 0.9865839178252139, 'beta_2': 0.9999827565250683, 'epsilon': 2.6509832129839986e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.028696507953273723, 'tol': 0.00034325044681361337, 'validation_fraction': 0.482400365701841}]
function_evaluation time 0.538883 value -0.909890 suggestion {'alpha': 0.00026296641226205105, 'batch_size': 16, 'beta_1': 0.9865839178252139, 'beta_2': 0.9999827565250683, 'epsilon': 2.6509832129839986e-08, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.028696507953273723, 'tol': 0.00034325044681361337, 'validation_fraction': 0.482400365701841}
observation time 0.000001, current best -0.909890 at iter 4
suggestion time taken 0.004100 iter 5 next_points [{'alpha': 1.3477610666331583, 'batch_size': 215, 'beta_1': 0.9455379142094429, 'beta_2': 0.9999542836570524, 'epsilon': 4.5317301011415827e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0006013265081991394, 'tol': 1.0777961938485191e-05, 'validation_fraction': 0.2216339474106395}]
function_evaluation time 0.245517 value -0.841758 suggestion {'alpha': 1.3477610666331583, 'batch_size': 215, 'beta_1': 0.9455379142094429, 'beta_2': 0.9999542836570524, 'epsilon': 4.5317301011415827e-07, 'hidden_layer_sizes': 88, 'learning_rate_init': 0.0006013265081991394, 'tol': 1.0777961938485191e-05, 'validation_fraction': 0.2216339474106395}
observation time 0.000001, current best -0.909890 at iter 5
suggestion time taken 0.004095 iter 6 next_points [{'alpha': 0.25535149958750025, 'batch_size': 207, 'beta_1': 0.8016987175726971, 'beta_2': 0.9987648232195451, 'epsilon': 6.153696071116111e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0009899997712528696, 'tol': 2.77067260691806e-05, 'validation_fraction': 0.11930404677113421}]
function_evaluation time 0.300388 value -0.885714 suggestion {'alpha': 0.25535149958750025, 'batch_size': 207, 'beta_1': 0.8016987175726971, 'beta_2': 0.9987648232195451, 'epsilon': 6.153696071116111e-09, 'hidden_layer_sizes': 131, 'learning_rate_init': 0.0009899997712528696, 'tol': 2.77067260691806e-05, 'validation_fraction': 0.11930404677113421}
observation time 0.000001, current best -0.909890 at iter 6
suggestion time taken 0.004093 iter 7 next_points [{'alpha': 4.5524407312492206e-05, 'batch_size': 237, 'beta_1': 0.8840048150954484, 'beta_2': 0.9941715806048026, 'epsilon': 8.373137655806362e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.00010781795591360726, 'tol': 0.0006296563199177751, 'validation_fraction': 0.4898031051693567}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.205378 value -0.617582 suggestion {'alpha': 4.5524407312492206e-05, 'batch_size': 237, 'beta_1': 0.8840048150954484, 'beta_2': 0.9941715806048026, 'epsilon': 8.373137655806362e-08, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.00010781795591360726, 'tol': 0.0006296563199177751, 'validation_fraction': 0.4898031051693567}
observation time 0.000001, current best -0.909890 at iter 7
suggestion time taken 0.004838 iter 8 next_points [{'alpha': 0.46463415185526885, 'batch_size': 230, 'beta_1': 0.6721269008532625, 'beta_2': 0.990803610943307, 'epsilon': 6.997982004375952e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.00030275849346113077, 'tol': 0.013591852457056769, 'validation_fraction': 0.6964822690632254}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.155535 value -0.575824 suggestion {'alpha': 0.46463415185526885, 'batch_size': 230, 'beta_1': 0.6721269008532625, 'beta_2': 0.990803610943307, 'epsilon': 6.997982004375952e-09, 'hidden_layer_sizes': 134, 'learning_rate_init': 0.00030275849346113077, 'tol': 0.013591852457056769, 'validation_fraction': 0.6964822690632254}
observation time 0.000001, current best -0.909890 at iter 8
suggestion time taken 0.004115 iter 9 next_points [{'alpha': 2.5852528208476106e-05, 'batch_size': 68, 'beta_1': 0.8656664719920432, 'beta_2': 0.999918262498114, 'epsilon': 5.092784184580834e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.00022256606907532472, 'tol': 0.009580380607482043, 'validation_fraction': 0.42166098184298084}]
function_evaluation time 0.370178 value -0.786813 suggestion {'alpha': 2.5852528208476106e-05, 'batch_size': 68, 'beta_1': 0.8656664719920432, 'beta_2': 0.999918262498114, 'epsilon': 5.092784184580834e-07, 'hidden_layer_sizes': 172, 'learning_rate_init': 0.00022256606907532472, 'tol': 0.009580380607482043, 'validation_fraction': 0.42166098184298084}
observation time 0.000000, current best -0.909890 at iter 9
suggestion time taken 0.004099 iter 10 next_points [{'alpha': 0.0011707067350414015, 'batch_size': 60, 'beta_1': 0.7536387537518371, 'beta_2': 0.9999972499739438, 'epsilon': 3.046742103599153e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 5.606706607890398e-05, 'tol': 4.6422034180232704e-05, 'validation_fraction': 0.7956700595908364}]
function_evaluation time 0.111599 value -0.432967 suggestion {'alpha': 0.0011707067350414015, 'batch_size': 60, 'beta_1': 0.7536387537518371, 'beta_2': 0.9999972499739438, 'epsilon': 3.046742103599153e-08, 'hidden_layer_sizes': 86, 'learning_rate_init': 5.606706607890398e-05, 'tol': 4.6422034180232704e-05, 'validation_fraction': 0.7956700595908364}
observation time 0.000001, current best -0.909890 at iter 10
suggestion time taken 0.004091 iter 11 next_points [{'alpha': 0.04102550867077521, 'batch_size': 98, 'beta_1': 0.9861220956248633, 'beta_2': 0.9999808570085269, 'epsilon': 2.511672766836047e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0025635505822313442, 'tol': 0.004211452641453515, 'validation_fraction': 0.8512490096918192}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.157943 value -0.810989 suggestion {'alpha': 0.04102550867077521, 'batch_size': 98, 'beta_1': 0.9861220956248633, 'beta_2': 0.9999808570085269, 'epsilon': 2.511672766836047e-07, 'hidden_layer_sizes': 166, 'learning_rate_init': 0.0025635505822313442, 'tol': 0.004211452641453515, 'validation_fraction': 0.8512490096918192}
observation time 0.000003, current best -0.909890 at iter 11
suggestion time taken 0.004226 iter 12 next_points [{'alpha': 0.0245492025524463, 'batch_size': 118, 'beta_1': 0.6715271328459589, 'beta_2': 0.9543519627170777, 'epsilon': 9.190798626201218e-08, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00011979038478756449, 'tol': 0.0001867227088798503, 'validation_fraction': 0.4736581735696195}]
function_evaluation time 0.176215 value -0.630769 suggestion {'alpha': 0.0245492025524463, 'batch_size': 118, 'beta_1': 0.6715271328459589, 'beta_2': 0.9543519627170777, 'epsilon': 9.190798626201218e-08, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00011979038478756449, 'tol': 0.0001867227088798503, 'validation_fraction': 0.4736581735696195}
observation time 0.000001, current best -0.909890 at iter 12
suggestion time taken 0.004085 iter 13 next_points [{'alpha': 0.00024111134721530562, 'batch_size': 192, 'beta_1': 0.6654989814030591, 'beta_2': 0.9999622767841374, 'epsilon': 1.8500359928012763e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0001320064098596239, 'tol': 0.0006310159103224907, 'validation_fraction': 0.46447499491727223}]
function_evaluation time 0.434642 value -0.672527 suggestion {'alpha': 0.00024111134721530562, 'batch_size': 192, 'beta_1': 0.6654989814030591, 'beta_2': 0.9999622767841374, 'epsilon': 1.8500359928012763e-08, 'hidden_layer_sizes': 177, 'learning_rate_init': 0.0001320064098596239, 'tol': 0.0006310159103224907, 'validation_fraction': 0.46447499491727223}
observation time 0.000000, current best -0.909890 at iter 13
suggestion time taken 0.004086 iter 14 next_points [{'alpha': 0.00020975653235400906, 'batch_size': 39, 'beta_1': 0.9669057629428095, 'beta_2': 0.9994603757829476, 'epsilon': 1.3880421161053039e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.026543301454448925, 'tol': 0.0004943783973069703, 'validation_fraction': 0.13307473018387958}]
function_evaluation time 0.453039 value -0.896703 suggestion {'alpha': 0.00020975653235400906, 'batch_size': 39, 'beta_1': 0.9669057629428095, 'beta_2': 0.9994603757829476, 'epsilon': 1.3880421161053039e-08, 'hidden_layer_sizes': 124, 'learning_rate_init': 0.026543301454448925, 'tol': 0.0004943783973069703, 'validation_fraction': 0.13307473018387958}
observation time 0.000001, current best -0.909890 at iter 14
saving meta data: {'args': {'--uuid': 'e3f7276ac5255110af8695de3a56b0c3', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
