running: {'--uuid': 'd5afac14f9b458ffb2d621b5c17ef503', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u d5afac14f9b458ffb2d621b5c17ef503 -m nll -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_043333
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.269783589486869, 3.4904310816393633])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.004428 iter 0 next_points [{'alpha': 5.165166512029657e-05, 'batch_size': 17, 'beta_1': 0.8914392088970869, 'beta_2': 0.9866753272327913, 'epsilon': 1.8541048756296633e-09, 'hidden_layer_sizes': 156, 'learning_rate_init': 1.6984644548608573e-05, 'tol': 6.539122010691659e-05, 'validation_fraction': 0.537991896414048}]
function_evaluation time 0.342478 value 14.734965 suggestion {'alpha': 5.165166512029657e-05, 'batch_size': 17, 'beta_1': 0.8914392088970869, 'beta_2': 0.9866753272327913, 'epsilon': 1.8541048756296633e-09, 'hidden_layer_sizes': 156, 'learning_rate_init': 1.6984644548608573e-05, 'tol': 6.539122010691659e-05, 'validation_fraction': 0.537991896414048}
observation time 0.000001, current best 14.734965 at iter 0
suggestion time taken 0.004230 iter 1 next_points [{'alpha': 0.0006265172877333475, 'batch_size': 150, 'beta_1': 0.9878958017033957, 'beta_2': 0.9999939346951314, 'epsilon': 4.116023711693472e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.00033181035511010434, 'tol': 0.010651044307643453, 'validation_fraction': 0.3258598351881237}]
function_evaluation time 0.388123 value 2.475038 suggestion {'alpha': 0.0006265172877333475, 'batch_size': 150, 'beta_1': 0.9878958017033957, 'beta_2': 0.9999939346951314, 'epsilon': 4.116023711693472e-08, 'hidden_layer_sizes': 174, 'learning_rate_init': 0.00033181035511010434, 'tol': 0.010651044307643453, 'validation_fraction': 0.3258598351881237}
observation time 0.000001, current best 2.475038 at iter 1
suggestion time taken 0.004220 iter 2 next_points [{'alpha': 7.172641842106838e-05, 'batch_size': 127, 'beta_1': 0.9448393418053437, 'beta_2': 0.9529253755032964, 'epsilon': 8.768703660386819e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.02294301384752385, 'tol': 0.0003931665411878853, 'validation_fraction': 0.5003571302251925}]
function_evaluation time 0.289284 value 1.074881 suggestion {'alpha': 7.172641842106838e-05, 'batch_size': 127, 'beta_1': 0.9448393418053437, 'beta_2': 0.9529253755032964, 'epsilon': 8.768703660386819e-07, 'hidden_layer_sizes': 106, 'learning_rate_init': 0.02294301384752385, 'tol': 0.0003931665411878853, 'validation_fraction': 0.5003571302251925}
observation time 0.000001, current best 1.074881 at iter 2
suggestion time taken 0.004208 iter 3 next_points [{'alpha': 0.004412227257378599, 'batch_size': 233, 'beta_1': 0.9892061576758296, 'beta_2': 0.9934702273055357, 'epsilon': 1.5785202358727452e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0004920528754369252, 'tol': 0.00024695795098913473, 'validation_fraction': 0.5145379566937008}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.158705 value 9.001987 suggestion {'alpha': 0.004412227257378599, 'batch_size': 233, 'beta_1': 0.9892061576758296, 'beta_2': 0.9934702273055357, 'epsilon': 1.5785202358727452e-07, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0004920528754369252, 'tol': 0.00024695795098913473, 'validation_fraction': 0.5145379566937008}
observation time 0.000003, current best 1.074881 at iter 3
suggestion time taken 0.004310 iter 4 next_points [{'alpha': 0.2906794758217835, 'batch_size': 81, 'beta_1': 0.7902374029843247, 'beta_2': 0.9793478458704119, 'epsilon': 4.0309540129671384e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.00027967635248087047, 'tol': 0.008583943923447804, 'validation_fraction': 0.44151453275303953}]
function_evaluation time 0.353394 value 7.418245 suggestion {'alpha': 0.2906794758217835, 'batch_size': 81, 'beta_1': 0.7902374029843247, 'beta_2': 0.9793478458704119, 'epsilon': 4.0309540129671384e-07, 'hidden_layer_sizes': 143, 'learning_rate_init': 0.00027967635248087047, 'tol': 0.008583943923447804, 'validation_fraction': 0.44151453275303953}
observation time 0.000001, current best 1.074881 at iter 4
suggestion time taken 0.004177 iter 5 next_points [{'alpha': 0.012439314563370068, 'batch_size': 43, 'beta_1': 0.9765115527472058, 'beta_2': 0.9999693151958351, 'epsilon': 5.81521381344321e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.0003127365353879758, 'tol': 0.0005499654787304623, 'validation_fraction': 0.3392342596588033}]
function_evaluation time 0.498557 value 0.503121 suggestion {'alpha': 0.012439314563370068, 'batch_size': 43, 'beta_1': 0.9765115527472058, 'beta_2': 0.9999693151958351, 'epsilon': 5.81521381344321e-09, 'hidden_layer_sizes': 70, 'learning_rate_init': 0.0003127365353879758, 'tol': 0.0005499654787304623, 'validation_fraction': 0.3392342596588033}
observation time 0.000000, current best 0.503121 at iter 5
suggestion time taken 0.004190 iter 6 next_points [{'alpha': 0.0041812615144107505, 'batch_size': 138, 'beta_1': 0.7655776252824671, 'beta_2': 0.9578686152431387, 'epsilon': 1.830698337684629e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 1.0634079502881416e-05, 'tol': 0.00021710412505224064, 'validation_fraction': 0.23541839263566613}]
function_evaluation time 0.166569 value 20.462097 suggestion {'alpha': 0.0041812615144107505, 'batch_size': 138, 'beta_1': 0.7655776252824671, 'beta_2': 0.9578686152431387, 'epsilon': 1.830698337684629e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 1.0634079502881416e-05, 'tol': 0.00021710412505224064, 'validation_fraction': 0.23541839263566613}
observation time 0.000000, current best 0.503121 at iter 6
suggestion time taken 0.004173 iter 7 next_points [{'alpha': 0.04128429851021495, 'batch_size': 198, 'beta_1': 0.817494979254127, 'beta_2': 0.9965425994068701, 'epsilon': 6.374559019262833e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0003254663918827519, 'tol': 0.005786296139068537, 'validation_fraction': 0.4526781266539337}]
function_evaluation time 0.438494 value 7.346776 suggestion {'alpha': 0.04128429851021495, 'batch_size': 198, 'beta_1': 0.817494979254127, 'beta_2': 0.9965425994068701, 'epsilon': 6.374559019262833e-09, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.0003254663918827519, 'tol': 0.005786296139068537, 'validation_fraction': 0.4526781266539337}
observation time 0.000001, current best 0.503121 at iter 7
suggestion time taken 0.004195 iter 8 next_points [{'alpha': 0.027847133635153447, 'batch_size': 199, 'beta_1': 0.5211953852701062, 'beta_2': 0.9999245750315706, 'epsilon': 4.8561150525001194e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.047267296905817706, 'tol': 0.00028372982978600714, 'validation_fraction': 0.4870528894895271}]
function_evaluation time 0.265223 value 0.681575 suggestion {'alpha': 0.027847133635153447, 'batch_size': 199, 'beta_1': 0.5211953852701062, 'beta_2': 0.9999245750315706, 'epsilon': 4.8561150525001194e-08, 'hidden_layer_sizes': 130, 'learning_rate_init': 0.047267296905817706, 'tol': 0.00028372982978600714, 'validation_fraction': 0.4870528894895271}
observation time 0.000001, current best 0.503121 at iter 8
suggestion time taken 0.004184 iter 9 next_points [{'alpha': 0.06568764260410821, 'batch_size': 137, 'beta_1': 0.9644550849112251, 'beta_2': 0.9997635142246669, 'epsilon': 7.80987433088059e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.00035907627098157616, 'tol': 5.572119720888988e-05, 'validation_fraction': 0.6908593307560194}]
function_evaluation time 0.197193 value 7.422662 suggestion {'alpha': 0.06568764260410821, 'batch_size': 137, 'beta_1': 0.9644550849112251, 'beta_2': 0.9997635142246669, 'epsilon': 7.80987433088059e-09, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.00035907627098157616, 'tol': 5.572119720888988e-05, 'validation_fraction': 0.6908593307560194}
observation time 0.000000, current best 0.503121 at iter 9
suggestion time taken 0.004188 iter 10 next_points [{'alpha': 0.004289639647152413, 'batch_size': 188, 'beta_1': 0.9543229060540706, 'beta_2': 0.9985164300284702, 'epsilon': 9.06476258348629e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.012905096066671612, 'tol': 0.0003014360314762899, 'validation_fraction': 0.8856758135984415}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.262766 value 1.182812 suggestion {'alpha': 0.004289639647152413, 'batch_size': 188, 'beta_1': 0.9543229060540706, 'beta_2': 0.9985164300284702, 'epsilon': 9.06476258348629e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 0.012905096066671612, 'tol': 0.0003014360314762899, 'validation_fraction': 0.8856758135984415}
observation time 0.000000, current best 0.503121 at iter 10
suggestion time taken 0.004196 iter 11 next_points [{'alpha': 0.00013115287889571035, 'batch_size': 182, 'beta_1': 0.5648718873048745, 'beta_2': 0.9958060104395287, 'epsilon': 8.974953315794525e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0480888948259283, 'tol': 0.015981873492014603, 'validation_fraction': 0.6975891803937428}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.150647 value 0.768772 suggestion {'alpha': 0.00013115287889571035, 'batch_size': 182, 'beta_1': 0.5648718873048745, 'beta_2': 0.9958060104395287, 'epsilon': 8.974953315794525e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.0480888948259283, 'tol': 0.015981873492014603, 'validation_fraction': 0.6975891803937428}
observation time 0.000000, current best 0.503121 at iter 11
suggestion time taken 0.004183 iter 12 next_points [{'alpha': 0.001391384542497651, 'batch_size': 110, 'beta_1': 0.6766255042424553, 'beta_2': 0.9700954977706929, 'epsilon': 1.2341799870239198e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 6.475775356054823e-05, 'tol': 3.002664311792977e-05, 'validation_fraction': 0.6183292109001399}]
function_evaluation time 0.219604 value 15.906901 suggestion {'alpha': 0.001391384542497651, 'batch_size': 110, 'beta_1': 0.6766255042424553, 'beta_2': 0.9700954977706929, 'epsilon': 1.2341799870239198e-07, 'hidden_layer_sizes': 173, 'learning_rate_init': 6.475775356054823e-05, 'tol': 3.002664311792977e-05, 'validation_fraction': 0.6183292109001399}
observation time 0.000000, current best 0.503121 at iter 12
suggestion time taken 0.004166 iter 13 next_points [{'alpha': 0.015910465809646463, 'batch_size': 141, 'beta_1': 0.7400351218200166, 'beta_2': 0.9808833523604616, 'epsilon': 2.922183790554321e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 3.567740483887126e-05, 'tol': 0.004936205123576931, 'validation_fraction': 0.8732079611578298}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.108375 value 12.674556 suggestion {'alpha': 0.015910465809646463, 'batch_size': 141, 'beta_1': 0.7400351218200166, 'beta_2': 0.9808833523604616, 'epsilon': 2.922183790554321e-09, 'hidden_layer_sizes': 162, 'learning_rate_init': 3.567740483887126e-05, 'tol': 0.004936205123576931, 'validation_fraction': 0.8732079611578298}
observation time 0.000000, current best 0.503121 at iter 13
suggestion time taken 0.004201 iter 14 next_points [{'alpha': 8.653616725033954, 'batch_size': 226, 'beta_1': 0.8653364395572462, 'beta_2': 0.9997476329632592, 'epsilon': 3.2117967906061604e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.016425164924815834, 'tol': 0.042939270744214754, 'validation_fraction': 0.5607731342818604}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.223149 value 0.822802 suggestion {'alpha': 8.653616725033954, 'batch_size': 226, 'beta_1': 0.8653364395572462, 'beta_2': 0.9997476329632592, 'epsilon': 3.2117967906061604e-09, 'hidden_layer_sizes': 145, 'learning_rate_init': 0.016425164924815834, 'tol': 0.042939270744214754, 'validation_fraction': 0.5607731342818604}
observation time 0.000001, current best 0.503121 at iter 14
saving meta data: {'args': {'--uuid': 'd5afac14f9b458ffb2d621b5c17ef503', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.269783589486869, 3.4904310816393633])}
saving results
saving timing
saving suggest log
done
