running: {'--uuid': '2b733f626199592ba8079dc1678b1b98', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 2b733f626199592ba8079dc1678b1b98 -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_043333
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.004689 iter 0 next_points [{'alpha': 0.1367630733777638, 'batch_size': 39, 'beta_1': 0.9621503523697366, 'beta_2': 0.9999822841659533, 'epsilon': 2.187891230083596e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.001298027251368544, 'tol': 1.0281226711879391e-05, 'validation_fraction': 0.5222886917843429}]
function_evaluation time 0.449087 value -0.894505 suggestion {'alpha': 0.1367630733777638, 'batch_size': 39, 'beta_1': 0.9621503523697366, 'beta_2': 0.9999822841659533, 'epsilon': 2.187891230083596e-09, 'hidden_layer_sizes': 173, 'learning_rate_init': 0.001298027251368544, 'tol': 1.0281226711879391e-05, 'validation_fraction': 0.5222886917843429}
observation time 0.000001, current best -0.894505 at iter 0
suggestion time taken 0.004244 iter 1 next_points [{'alpha': 0.0014995509299244331, 'batch_size': 241, 'beta_1': 0.9335766030882029, 'beta_2': 0.9999954258891368, 'epsilon': 3.690148750133466e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 1.786024158345724e-05, 'tol': 8.993544121932999e-05, 'validation_fraction': 0.6353505230939963}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.161654 value -0.630769 suggestion {'alpha': 0.0014995509299244331, 'batch_size': 241, 'beta_1': 0.9335766030882029, 'beta_2': 0.9999954258891368, 'epsilon': 3.690148750133466e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 1.786024158345724e-05, 'tol': 8.993544121932999e-05, 'validation_fraction': 0.6353505230939963}
observation time 0.000001, current best -0.894505 at iter 1
suggestion time taken 0.004284 iter 2 next_points [{'alpha': 1.393960399444033, 'batch_size': 90, 'beta_1': 0.802930310794652, 'beta_2': 0.9982421748686383, 'epsilon': 1.0739318791907424e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0004007622562486549, 'tol': 3.865081822141589e-05, 'validation_fraction': 0.5036118555397281}]
function_evaluation time 0.317086 value -0.832967 suggestion {'alpha': 1.393960399444033, 'batch_size': 90, 'beta_1': 0.802930310794652, 'beta_2': 0.9982421748686383, 'epsilon': 1.0739318791907424e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.0004007622562486549, 'tol': 3.865081822141589e-05, 'validation_fraction': 0.5036118555397281}
observation time 0.000001, current best -0.894505 at iter 2
suggestion time taken 0.004246 iter 3 next_points [{'alpha': 0.0010901283680480687, 'batch_size': 178, 'beta_1': 0.548651724136258, 'beta_2': 0.999892787648575, 'epsilon': 4.779928155199377e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.00015361695024704392, 'tol': 0.027364289650747543, 'validation_fraction': 0.6189835138636486}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.102949 value -0.454945 suggestion {'alpha': 0.0010901283680480687, 'batch_size': 178, 'beta_1': 0.548651724136258, 'beta_2': 0.999892787648575, 'epsilon': 4.779928155199377e-09, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.00015361695024704392, 'tol': 0.027364289650747543, 'validation_fraction': 0.6189835138636486}
observation time 0.000001, current best -0.894505 at iter 3
suggestion time taken 0.004237 iter 4 next_points [{'alpha': 0.0025236437781378743, 'batch_size': 162, 'beta_1': 0.9455256886493084, 'beta_2': 0.9229772656707133, 'epsilon': 5.141764827476901e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0002687160174859603, 'tol': 6.324484487884511e-05, 'validation_fraction': 0.13802475033668976}]
function_evaluation time 0.173901 value -0.468132 suggestion {'alpha': 0.0025236437781378743, 'batch_size': 162, 'beta_1': 0.9455256886493084, 'beta_2': 0.9229772656707133, 'epsilon': 5.141764827476901e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.0002687160174859603, 'tol': 6.324484487884511e-05, 'validation_fraction': 0.13802475033668976}
observation time 0.000004, current best -0.894505 at iter 4
suggestion time taken 0.004341 iter 5 next_points [{'alpha': 0.6775367200807632, 'batch_size': 132, 'beta_1': 0.9554115600593183, 'beta_2': 0.9782100368189747, 'epsilon': 1.5333766313187244e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 1.67213877209757e-05, 'tol': 0.00778404971650169, 'validation_fraction': 0.38569079078673685}]
function_evaluation time 0.188310 value -0.527473 suggestion {'alpha': 0.6775367200807632, 'batch_size': 132, 'beta_1': 0.9554115600593183, 'beta_2': 0.9782100368189747, 'epsilon': 1.5333766313187244e-09, 'hidden_layer_sizes': 196, 'learning_rate_init': 1.67213877209757e-05, 'tol': 0.00778404971650169, 'validation_fraction': 0.38569079078673685}
observation time 0.000001, current best -0.894505 at iter 5
suggestion time taken 0.004202 iter 6 next_points [{'alpha': 0.00013360935343063957, 'batch_size': 145, 'beta_1': 0.8915512673388587, 'beta_2': 0.9905408800057208, 'epsilon': 1.244108468476569e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.01853796008020787, 'tol': 0.0037246322261349617, 'validation_fraction': 0.18318715235875405}]
function_evaluation time 0.307712 value -0.901099 suggestion {'alpha': 0.00013360935343063957, 'batch_size': 145, 'beta_1': 0.8915512673388587, 'beta_2': 0.9905408800057208, 'epsilon': 1.244108468476569e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 0.01853796008020787, 'tol': 0.0037246322261349617, 'validation_fraction': 0.18318715235875405}
observation time 0.000001, current best -0.901099 at iter 6
suggestion time taken 0.004212 iter 7 next_points [{'alpha': 1.283562468425427, 'batch_size': 114, 'beta_1': 0.9475979001214849, 'beta_2': 0.9816325469380984, 'epsilon': 5.594556370937915e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.00041178391563625197, 'tol': 0.002859894838135137, 'validation_fraction': 0.6298179978163528}]
function_evaluation time 0.142330 value -0.567033 suggestion {'alpha': 1.283562468425427, 'batch_size': 114, 'beta_1': 0.9475979001214849, 'beta_2': 0.9816325469380984, 'epsilon': 5.594556370937915e-09, 'hidden_layer_sizes': 62, 'learning_rate_init': 0.00041178391563625197, 'tol': 0.002859894838135137, 'validation_fraction': 0.6298179978163528}
observation time 0.000001, current best -0.901099 at iter 7
suggestion time taken 0.004248 iter 8 next_points [{'alpha': 0.07856499659639982, 'batch_size': 57, 'beta_1': 0.8416622679108159, 'beta_2': 0.999853996425659, 'epsilon': 6.887052470566555e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00862886255801076, 'tol': 0.06668473006197219, 'validation_fraction': 0.19823229752108068}]
function_evaluation time 0.203631 value -0.905495 suggestion {'alpha': 0.07856499659639982, 'batch_size': 57, 'beta_1': 0.8416622679108159, 'beta_2': 0.999853996425659, 'epsilon': 6.887052470566555e-07, 'hidden_layer_sizes': 84, 'learning_rate_init': 0.00862886255801076, 'tol': 0.06668473006197219, 'validation_fraction': 0.19823229752108068}
observation time 0.000001, current best -0.905495 at iter 8
suggestion time taken 0.004239 iter 9 next_points [{'alpha': 0.0007934114955842387, 'batch_size': 115, 'beta_1': 0.8950680244671649, 'beta_2': 0.947368239408588, 'epsilon': 2.147498540534419e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0035195842903669064, 'tol': 1.9299692669044155e-05, 'validation_fraction': 0.8058925753587657}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.228900 value -0.901099 suggestion {'alpha': 0.0007934114955842387, 'batch_size': 115, 'beta_1': 0.8950680244671649, 'beta_2': 0.947368239408588, 'epsilon': 2.147498540534419e-08, 'hidden_layer_sizes': 72, 'learning_rate_init': 0.0035195842903669064, 'tol': 1.9299692669044155e-05, 'validation_fraction': 0.8058925753587657}
observation time 0.000001, current best -0.905495 at iter 9
suggestion time taken 0.004221 iter 10 next_points [{'alpha': 1.9793203675130253, 'batch_size': 88, 'beta_1': 0.7263348910134734, 'beta_2': 0.9996267525497726, 'epsilon': 1.7426088444718305e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.02701894648560404, 'tol': 0.0001362313363414408, 'validation_fraction': 0.7604150598566605}]
function_evaluation time 0.485584 value -0.898901 suggestion {'alpha': 1.9793203675130253, 'batch_size': 88, 'beta_1': 0.7263348910134734, 'beta_2': 0.9996267525497726, 'epsilon': 1.7426088444718305e-08, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.02701894648560404, 'tol': 0.0001362313363414408, 'validation_fraction': 0.7604150598566605}
observation time 0.000001, current best -0.905495 at iter 10
suggestion time taken 0.004281 iter 11 next_points [{'alpha': 0.34918130883046916, 'batch_size': 131, 'beta_1': 0.7851984252341374, 'beta_2': 0.9998405094307354, 'epsilon': 1.9899365050123282e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 3.717059907305977e-05, 'tol': 0.005341366564087686, 'validation_fraction': 0.7988454936706452}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.100997 value -0.569231 suggestion {'alpha': 0.34918130883046916, 'batch_size': 131, 'beta_1': 0.7851984252341374, 'beta_2': 0.9998405094307354, 'epsilon': 1.9899365050123282e-07, 'hidden_layer_sizes': 104, 'learning_rate_init': 3.717059907305977e-05, 'tol': 0.005341366564087686, 'validation_fraction': 0.7988454936706452}
observation time 0.000001, current best -0.905495 at iter 11
suggestion time taken 0.004196 iter 12 next_points [{'alpha': 0.10140530871018705, 'batch_size': 100, 'beta_1': 0.9104822419367896, 'beta_2': 0.9999989000413756, 'epsilon': 2.8883987668164333e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0004189831188498399, 'tol': 0.009040272049031652, 'validation_fraction': 0.2883179463180944}]
function_evaluation time 0.324718 value -0.885714 suggestion {'alpha': 0.10140530871018705, 'batch_size': 100, 'beta_1': 0.9104822419367896, 'beta_2': 0.9999989000413756, 'epsilon': 2.8883987668164333e-08, 'hidden_layer_sizes': 102, 'learning_rate_init': 0.0004189831188498399, 'tol': 0.009040272049031652, 'validation_fraction': 0.2883179463180944}
observation time 0.000001, current best -0.905495 at iter 12
suggestion time taken 0.003358 iter 13 next_points [{'alpha': 0.050096582635218184, 'batch_size': 199, 'beta_1': 0.8472957161963829, 'beta_2': 0.9999961481856647, 'epsilon': 9.503446542778208e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00010189854492363152, 'tol': 0.00015750682004942986, 'validation_fraction': 0.879833369938629}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.096077 value -0.417582 suggestion {'alpha': 0.050096582635218184, 'batch_size': 199, 'beta_1': 0.8472957161963829, 'beta_2': 0.9999961481856647, 'epsilon': 9.503446542778208e-07, 'hidden_layer_sizes': 93, 'learning_rate_init': 0.00010189854492363152, 'tol': 0.00015750682004942986, 'validation_fraction': 0.879833369938629}
observation time 0.000001, current best -0.905495 at iter 13
suggestion time taken 0.004276 iter 14 next_points [{'alpha': 1.854542010759469, 'batch_size': 175, 'beta_1': 0.9762189033321768, 'beta_2': 0.9997526563646664, 'epsilon': 2.1116458545746477e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 3.3520844932716753e-05, 'tol': 0.0011718899978135362, 'validation_fraction': 0.15269191843662078}]
function_evaluation time 0.213939 value -0.527473 suggestion {'alpha': 1.854542010759469, 'batch_size': 175, 'beta_1': 0.9762189033321768, 'beta_2': 0.9997526563646664, 'epsilon': 2.1116458545746477e-08, 'hidden_layer_sizes': 199, 'learning_rate_init': 3.3520844932716753e-05, 'tol': 0.0011718899978135362, 'validation_fraction': 0.15269191843662078}
observation time 0.000001, current best -0.905495 at iter 14
saving meta data: {'args': {'--uuid': '2b733f626199592ba8079dc1678b1b98', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
