running: {'--uuid': '171a7368104a5188a392ba65f61f4d65', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 171a7368104a5188a392ba65f61f4d65 -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_043333
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.004221 iter 0 next_points [{'alpha': 0.014495559244611564, 'batch_size': 164, 'beta_1': 0.790002741153272, 'beta_2': 0.9999862831912568, 'epsilon': 7.004424410829516e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.07641322318397085, 'tol': 0.00023883060036981914, 'validation_fraction': 0.8302309288962698}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.200050 value -0.835165 suggestion {'alpha': 0.014495559244611564, 'batch_size': 164, 'beta_1': 0.790002741153272, 'beta_2': 0.9999862831912568, 'epsilon': 7.004424410829516e-09, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.07641322318397085, 'tol': 0.00023883060036981914, 'validation_fraction': 0.8302309288962698}
observation time 0.000001, current best -0.835165 at iter 0
suggestion time taken 0.004121 iter 1 next_points [{'alpha': 0.0008450282060018831, 'batch_size': 31, 'beta_1': 0.7951532366807822, 'beta_2': 0.996193782563772, 'epsilon': 4.6044593462282795e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.021682425186155506, 'tol': 0.014803475768910713, 'validation_fraction': 0.6257263243721135}]
function_evaluation time 0.225159 value -0.912088 suggestion {'alpha': 0.0008450282060018831, 'batch_size': 31, 'beta_1': 0.7951532366807822, 'beta_2': 0.996193782563772, 'epsilon': 4.6044593462282795e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.021682425186155506, 'tol': 0.014803475768910713, 'validation_fraction': 0.6257263243721135}
observation time 0.000001, current best -0.912088 at iter 1
suggestion time taken 0.004119 iter 2 next_points [{'alpha': 0.000746533405351857, 'batch_size': 158, 'beta_1': 0.6058065947679746, 'beta_2': 0.9999769068344938, 'epsilon': 3.095282644686286e-09, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.00037624432912655904, 'tol': 0.006921933602674508, 'validation_fraction': 0.6482965425463257}]
function_evaluation time 0.158603 value -0.575824 suggestion {'alpha': 0.000746533405351857, 'batch_size': 158, 'beta_1': 0.6058065947679746, 'beta_2': 0.9999769068344938, 'epsilon': 3.095282644686286e-09, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.00037624432912655904, 'tol': 0.006921933602674508, 'validation_fraction': 0.6482965425463257}
observation time 0.000001, current best -0.912088 at iter 2
suggestion time taken 0.004114 iter 3 next_points [{'alpha': 0.0018450292686588233, 'batch_size': 212, 'beta_1': 0.9377508721999013, 'beta_2': 0.9999298101684234, 'epsilon': 2.6892907867659884e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.00031148195397421983, 'tol': 0.0007140377406403802, 'validation_fraction': 0.376571340659357}]
function_evaluation time 0.162872 value -0.624176 suggestion {'alpha': 0.0018450292686588233, 'batch_size': 212, 'beta_1': 0.9377508721999013, 'beta_2': 0.9999298101684234, 'epsilon': 2.6892907867659884e-09, 'hidden_layer_sizes': 78, 'learning_rate_init': 0.00031148195397421983, 'tol': 0.0007140377406403802, 'validation_fraction': 0.376571340659357}
observation time 0.000001, current best -0.912088 at iter 3
suggestion time taken 0.004136 iter 4 next_points [{'alpha': 0.056988902901393385, 'batch_size': 209, 'beta_1': 0.9204973779146017, 'beta_2': 0.9740907097888134, 'epsilon': 1.3164686187822466e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.004705407770033711, 'tol': 0.00027222576810905793, 'validation_fraction': 0.4872187053811404}]
function_evaluation time 0.290079 value -0.892308 suggestion {'alpha': 0.056988902901393385, 'batch_size': 209, 'beta_1': 0.9204973779146017, 'beta_2': 0.9740907097888134, 'epsilon': 1.3164686187822466e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.004705407770033711, 'tol': 0.00027222576810905793, 'validation_fraction': 0.4872187053811404}
observation time 0.000001, current best -0.912088 at iter 4
suggestion time taken 0.004079 iter 5 next_points [{'alpha': 7.859294529798581, 'batch_size': 30, 'beta_1': 0.9444970163142444, 'beta_2': 0.9438459820375666, 'epsilon': 2.378446877913829e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 3.518685644346415e-05, 'tol': 5.599582336606822e-05, 'validation_fraction': 0.1537840786041623}]
function_evaluation time 0.462522 value -0.725275 suggestion {'alpha': 7.859294529798581, 'batch_size': 30, 'beta_1': 0.9444970163142444, 'beta_2': 0.9438459820375666, 'epsilon': 2.378446877913829e-08, 'hidden_layer_sizes': 112, 'learning_rate_init': 3.518685644346415e-05, 'tol': 5.599582336606822e-05, 'validation_fraction': 0.1537840786041623}
observation time 0.000003, current best -0.912088 at iter 5
suggestion time taken 0.004220 iter 6 next_points [{'alpha': 1.6870257422227563e-05, 'batch_size': 247, 'beta_1': 0.9522386740782245, 'beta_2': 0.9999986065635661, 'epsilon': 3.464186784430897e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 1.5373662439201553e-05, 'tol': 0.046355458791275825, 'validation_fraction': 0.8973867269984288}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.084768 value -0.410989 suggestion {'alpha': 1.6870257422227563e-05, 'batch_size': 247, 'beta_1': 0.9522386740782245, 'beta_2': 0.9999986065635661, 'epsilon': 3.464186784430897e-08, 'hidden_layer_sizes': 50, 'learning_rate_init': 1.5373662439201553e-05, 'tol': 0.046355458791275825, 'validation_fraction': 0.8973867269984288}
observation time 0.000001, current best -0.912088 at iter 6
suggestion time taken 0.004086 iter 7 next_points [{'alpha': 0.7956617699652531, 'batch_size': 177, 'beta_1': 0.7189699770983958, 'beta_2': 0.9999854436063699, 'epsilon': 7.877707624726768e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.003940779792046624, 'tol': 0.009473377281574678, 'validation_fraction': 0.11541805764748433}]
function_evaluation time 0.275813 value -0.907692 suggestion {'alpha': 0.7956617699652531, 'batch_size': 177, 'beta_1': 0.7189699770983958, 'beta_2': 0.9999854436063699, 'epsilon': 7.877707624726768e-07, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.003940779792046624, 'tol': 0.009473377281574678, 'validation_fraction': 0.11541805764748433}
observation time 0.000001, current best -0.912088 at iter 7
suggestion time taken 0.004106 iter 8 next_points [{'alpha': 0.004615047810114903, 'batch_size': 108, 'beta_1': 0.6398365444321108, 'beta_2': 0.9999579797079664, 'epsilon': 7.338986559177086e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.00010334573034406796, 'tol': 3.790159303033705e-05, 'validation_fraction': 0.6278718768999347}]
function_evaluation time 0.245665 value -0.362637 suggestion {'alpha': 0.004615047810114903, 'batch_size': 108, 'beta_1': 0.6398365444321108, 'beta_2': 0.9999579797079664, 'epsilon': 7.338986559177086e-07, 'hidden_layer_sizes': 63, 'learning_rate_init': 0.00010334573034406796, 'tol': 3.790159303033705e-05, 'validation_fraction': 0.6278718768999347}
observation time 0.000001, current best -0.912088 at iter 8
suggestion time taken 0.004110 iter 9 next_points [{'alpha': 0.001728100250445708, 'batch_size': 185, 'beta_1': 0.9423659338807682, 'beta_2': 0.9911652200115609, 'epsilon': 2.7766670140480836e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 4.847850443434127e-05, 'tol': 0.04089414703049982, 'validation_fraction': 0.2877583118298542}]
function_evaluation time 0.138713 value -0.736264 suggestion {'alpha': 0.001728100250445708, 'batch_size': 185, 'beta_1': 0.9423659338807682, 'beta_2': 0.9911652200115609, 'epsilon': 2.7766670140480836e-09, 'hidden_layer_sizes': 92, 'learning_rate_init': 4.847850443434127e-05, 'tol': 0.04089414703049982, 'validation_fraction': 0.2877583118298542}
observation time 0.000001, current best -0.912088 at iter 9
suggestion time taken 0.004094 iter 10 next_points [{'alpha': 6.771075068415745, 'batch_size': 32, 'beta_1': 0.6655385036390494, 'beta_2': 0.9781489613738156, 'epsilon': 1.4115427112120765e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.008099988573061937, 'tol': 0.0006404689906690951, 'validation_fraction': 0.19940049058982218}]
function_evaluation time 0.484440 value -0.903297 suggestion {'alpha': 6.771075068415745, 'batch_size': 32, 'beta_1': 0.6655385036390494, 'beta_2': 0.9781489613738156, 'epsilon': 1.4115427112120765e-08, 'hidden_layer_sizes': 179, 'learning_rate_init': 0.008099988573061937, 'tol': 0.0006404689906690951, 'validation_fraction': 0.19940049058982218}
observation time 0.000001, current best -0.912088 at iter 10
suggestion time taken 0.004094 iter 11 next_points [{'alpha': 0.047253258798193386, 'batch_size': 32, 'beta_1': 0.9422688216550867, 'beta_2': 0.9704444708800393, 'epsilon': 2.048623511256101e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.009065280292460252, 'tol': 0.0001662510439576017, 'validation_fraction': 0.29228932961792886}]
function_evaluation time 0.508936 value -0.914286 suggestion {'alpha': 0.047253258798193386, 'batch_size': 32, 'beta_1': 0.9422688216550867, 'beta_2': 0.9704444708800393, 'epsilon': 2.048623511256101e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.009065280292460252, 'tol': 0.0001662510439576017, 'validation_fraction': 0.29228932961792886}
observation time 0.000000, current best -0.914286 at iter 11
suggestion time taken 0.004084 iter 12 next_points [{'alpha': 0.0060816487875820155, 'batch_size': 117, 'beta_1': 0.7443242833369749, 'beta_2': 0.9991342783026693, 'epsilon': 8.753629200326987e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001117889398446455, 'tol': 0.0015226937735452644, 'validation_fraction': 0.678204007913293}]
function_evaluation time 0.159975 value -0.679121 suggestion {'alpha': 0.0060816487875820155, 'batch_size': 117, 'beta_1': 0.7443242833369749, 'beta_2': 0.9991342783026693, 'epsilon': 8.753629200326987e-07, 'hidden_layer_sizes': 50, 'learning_rate_init': 0.001117889398446455, 'tol': 0.0015226937735452644, 'validation_fraction': 0.678204007913293}
observation time 0.000001, current best -0.914286 at iter 12
suggestion time taken 0.004086 iter 13 next_points [{'alpha': 0.5909073459981816, 'batch_size': 163, 'beta_1': 0.8349486216427272, 'beta_2': 0.9750502004254802, 'epsilon': 1.9580506867853804e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.00033462835803454397, 'tol': 0.00020983129962406008, 'validation_fraction': 0.7979904346731113}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.245821 value -0.797802 suggestion {'alpha': 0.5909073459981816, 'batch_size': 163, 'beta_1': 0.8349486216427272, 'beta_2': 0.9750502004254802, 'epsilon': 1.9580506867853804e-07, 'hidden_layer_sizes': 194, 'learning_rate_init': 0.00033462835803454397, 'tol': 0.00020983129962406008, 'validation_fraction': 0.7979904346731113}
observation time 0.000001, current best -0.914286 at iter 13
suggestion time taken 0.004078 iter 14 next_points [{'alpha': 0.07026984251126661, 'batch_size': 22, 'beta_1': 0.5469622479802009, 'beta_2': 0.9999964696946424, 'epsilon': 1.7468646743773505e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 1.0439926794444808e-05, 'tol': 3.845576209763035e-05, 'validation_fraction': 0.6607067297443096}]
function_evaluation time 0.230790 value -0.525275 suggestion {'alpha': 0.07026984251126661, 'batch_size': 22, 'beta_1': 0.5469622479802009, 'beta_2': 0.9999964696946424, 'epsilon': 1.7468646743773505e-08, 'hidden_layer_sizes': 137, 'learning_rate_init': 1.0439926794444808e-05, 'tol': 3.845576209763035e-05, 'validation_fraction': 0.6607067297443096}
observation time 0.000001, current best -0.914286 at iter 14
saving meta data: {'args': {'--uuid': '171a7368104a5188a392ba65f61f4d65', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
