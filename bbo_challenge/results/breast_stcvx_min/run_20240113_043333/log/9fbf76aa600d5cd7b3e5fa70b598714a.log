running: {'--uuid': '9fbf76aa600d5cd7b3e5fa70b598714a', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 9fbf76aa600d5cd7b3e5fa70b598714a -m nll -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_043333
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.269783589486869, 3.4904310816393633])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.004443 iter 0 next_points [{'alpha': 0.006153240761742504, 'batch_size': 161, 'beta_1': 0.9190222002519374, 'beta_2': 0.9597558471453872, 'epsilon': 5.9266067035653795e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.0031281094302720936, 'tol': 7.141230208797103e-05, 'validation_fraction': 0.7297357781716707}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.311504 value 0.665626 suggestion {'alpha': 0.006153240761742504, 'batch_size': 161, 'beta_1': 0.9190222002519374, 'beta_2': 0.9597558471453872, 'epsilon': 5.9266067035653795e-09, 'hidden_layer_sizes': 125, 'learning_rate_init': 0.0031281094302720936, 'tol': 7.141230208797103e-05, 'validation_fraction': 0.7297357781716707}
observation time 0.000003, current best 0.665626 at iter 0
suggestion time taken 0.004166 iter 1 next_points [{'alpha': 0.013500362017332304, 'batch_size': 211, 'beta_1': 0.8536005596735893, 'beta_2': 0.9997227107566153, 'epsilon': 4.173904300656594e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 7.303319767993434e-05, 'tol': 0.05045524725244308, 'validation_fraction': 0.8260979082037943}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.116007 value 16.423321 suggestion {'alpha': 0.013500362017332304, 'batch_size': 211, 'beta_1': 0.8536005596735893, 'beta_2': 0.9997227107566153, 'epsilon': 4.173904300656594e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 7.303319767993434e-05, 'tol': 0.05045524725244308, 'validation_fraction': 0.8260979082037943}
observation time 0.000000, current best 0.665626 at iter 1
suggestion time taken 0.004151 iter 2 next_points [{'alpha': 0.1655222972733206, 'batch_size': 157, 'beta_1': 0.989321641675742, 'beta_2': 0.9999974269854889, 'epsilon': 3.786525327970909e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0005015811703324267, 'tol': 0.0007282059380271368, 'validation_fraction': 0.5311469740801147}]
function_evaluation time 0.285433 value 3.508110 suggestion {'alpha': 0.1655222972733206, 'batch_size': 157, 'beta_1': 0.989321641675742, 'beta_2': 0.9999974269854889, 'epsilon': 3.786525327970909e-09, 'hidden_layer_sizes': 155, 'learning_rate_init': 0.0005015811703324267, 'tol': 0.0007282059380271368, 'validation_fraction': 0.5311469740801147}
observation time 0.000001, current best 0.665626 at iter 2
suggestion time taken 0.004137 iter 3 next_points [{'alpha': 0.00032982013201489374, 'batch_size': 103, 'beta_1': 0.7035302903465505, 'beta_2': 0.9889885162159218, 'epsilon': 1.5283113297037105e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 1.795824374305025e-05, 'tol': 0.04655606600692209, 'validation_fraction': 0.29003514825621307}]
function_evaluation time 0.245069 value 10.148222 suggestion {'alpha': 0.00032982013201489374, 'batch_size': 103, 'beta_1': 0.7035302903465505, 'beta_2': 0.9889885162159218, 'epsilon': 1.5283113297037105e-08, 'hidden_layer_sizes': 170, 'learning_rate_init': 1.795824374305025e-05, 'tol': 0.04655606600692209, 'validation_fraction': 0.29003514825621307}
observation time 0.000001, current best 0.665626 at iter 3
suggestion time taken 0.004132 iter 4 next_points [{'alpha': 7.451775004353743e-05, 'batch_size': 102, 'beta_1': 0.9886111908286882, 'beta_2': 0.9999733765526602, 'epsilon': 6.142082540785426e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 6.430968165719827e-05, 'tol': 0.00013197277151725793, 'validation_fraction': 0.5069335554722307}]
function_evaluation time 0.152641 value 18.042936 suggestion {'alpha': 7.451775004353743e-05, 'batch_size': 102, 'beta_1': 0.9886111908286882, 'beta_2': 0.9999733765526602, 'epsilon': 6.142082540785426e-07, 'hidden_layer_sizes': 133, 'learning_rate_init': 6.430968165719827e-05, 'tol': 0.00013197277151725793, 'validation_fraction': 0.5069335554722307}
observation time 0.000000, current best 0.665626 at iter 4
suggestion time taken 0.004108 iter 5 next_points [{'alpha': 0.05894030013667061, 'batch_size': 54, 'beta_1': 0.9833594808361015, 'beta_2': 0.9999948899338333, 'epsilon': 1.1744159939246226e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0007984010309272143, 'tol': 0.0290082203951714, 'validation_fraction': 0.1586567732780765}]
function_evaluation time 0.361234 value 0.493785 suggestion {'alpha': 0.05894030013667061, 'batch_size': 54, 'beta_1': 0.9833594808361015, 'beta_2': 0.9999948899338333, 'epsilon': 1.1744159939246226e-09, 'hidden_layer_sizes': 105, 'learning_rate_init': 0.0007984010309272143, 'tol': 0.0290082203951714, 'validation_fraction': 0.1586567732780765}
observation time 0.000003, current best 0.493785 at iter 5
suggestion time taken 0.004246 iter 6 next_points [{'alpha': 0.00033593870891699106, 'batch_size': 177, 'beta_1': 0.7182462119349194, 'beta_2': 0.9873465661744452, 'epsilon': 3.9845060437408886e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0029404149242147374, 'tol': 0.0013967024747865825, 'validation_fraction': 0.4414355422965343}]
function_evaluation time 0.351444 value 0.491510 suggestion {'alpha': 0.00033593870891699106, 'batch_size': 177, 'beta_1': 0.7182462119349194, 'beta_2': 0.9873465661744452, 'epsilon': 3.9845060437408886e-07, 'hidden_layer_sizes': 178, 'learning_rate_init': 0.0029404149242147374, 'tol': 0.0013967024747865825, 'validation_fraction': 0.4414355422965343}
observation time 0.000001, current best 0.491510 at iter 6
suggestion time taken 0.004148 iter 7 next_points [{'alpha': 2.101946915473264e-05, 'batch_size': 127, 'beta_1': 0.7893361623096133, 'beta_2': 0.9995984575696591, 'epsilon': 3.1942071009853046e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0010405802306910476, 'tol': 4.346101981410851e-05, 'validation_fraction': 0.5698937470385226}]
function_evaluation time 0.459332 value 0.455056 suggestion {'alpha': 2.101946915473264e-05, 'batch_size': 127, 'beta_1': 0.7893361623096133, 'beta_2': 0.9995984575696591, 'epsilon': 3.1942071009853046e-08, 'hidden_layer_sizes': 181, 'learning_rate_init': 0.0010405802306910476, 'tol': 4.346101981410851e-05, 'validation_fraction': 0.5698937470385226}
observation time 0.000001, current best 0.455056 at iter 7
suggestion time taken 0.004133 iter 8 next_points [{'alpha': 0.17733740252080585, 'batch_size': 59, 'beta_1': 0.8504202448765721, 'beta_2': 0.9974195874387819, 'epsilon': 1.5685317678759576e-07, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.025137844528690622, 'tol': 0.00012937446279137946, 'validation_fraction': 0.8154049350617705}]
function_evaluation time 0.288883 value 0.964655 suggestion {'alpha': 0.17733740252080585, 'batch_size': 59, 'beta_1': 0.8504202448765721, 'beta_2': 0.9974195874387819, 'epsilon': 1.5685317678759576e-07, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.025137844528690622, 'tol': 0.00012937446279137946, 'validation_fraction': 0.8154049350617705}
observation time 0.000000, current best 0.455056 at iter 8
suggestion time taken 0.004150 iter 9 next_points [{'alpha': 0.0007489987662374882, 'batch_size': 177, 'beta_1': 0.7720084082876488, 'beta_2': 0.9929857069304119, 'epsilon': 2.20726456828281e-07, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.00039062404729121056, 'tol': 0.00016601528481541882, 'validation_fraction': 0.8327549708675442}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.269633 value 16.315707 suggestion {'alpha': 0.0007489987662374882, 'batch_size': 177, 'beta_1': 0.7720084082876488, 'beta_2': 0.9929857069304119, 'epsilon': 2.20726456828281e-07, 'hidden_layer_sizes': 144, 'learning_rate_init': 0.00039062404729121056, 'tol': 0.00016601528481541882, 'validation_fraction': 0.8327549708675442}
observation time 0.000001, current best 0.455056 at iter 9
suggestion time taken 0.004119 iter 10 next_points [{'alpha': 0.006699053602134062, 'batch_size': 76, 'beta_1': 0.7746297036477959, 'beta_2': 0.9986379081431265, 'epsilon': 1.888887147694042e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.003759926576836748, 'tol': 2.2636936163791627e-05, 'validation_fraction': 0.8411452414517643}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.243201 value 0.750689 suggestion {'alpha': 0.006699053602134062, 'batch_size': 76, 'beta_1': 0.7746297036477959, 'beta_2': 0.9986379081431265, 'epsilon': 1.888887147694042e-09, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.003759926576836748, 'tol': 2.2636936163791627e-05, 'validation_fraction': 0.8411452414517643}
observation time 0.000001, current best 0.455056 at iter 10
suggestion time taken 0.004124 iter 11 next_points [{'alpha': 0.4422980271338863, 'batch_size': 207, 'beta_1': 0.6978296401756028, 'beta_2': 0.9916022711711123, 'epsilon': 3.305033866219454e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.021519653106613443, 'tol': 0.001416338128610643, 'validation_fraction': 0.789254918962895}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.263438 value 0.928795 suggestion {'alpha': 0.4422980271338863, 'batch_size': 207, 'beta_1': 0.6978296401756028, 'beta_2': 0.9916022711711123, 'epsilon': 3.305033866219454e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.021519653106613443, 'tol': 0.001416338128610643, 'validation_fraction': 0.789254918962895}
observation time 0.000000, current best 0.455056 at iter 11
suggestion time taken 0.004127 iter 12 next_points [{'alpha': 1.4148868880955302e-05, 'batch_size': 160, 'beta_1': 0.9536430727772599, 'beta_2': 0.9882386111532897, 'epsilon': 1.2852163831387626e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.01677896804411803, 'tol': 0.0010264592253241896, 'validation_fraction': 0.8849497229284222}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.194485 value 2.047943 suggestion {'alpha': 1.4148868880955302e-05, 'batch_size': 160, 'beta_1': 0.9536430727772599, 'beta_2': 0.9882386111532897, 'epsilon': 1.2852163831387626e-08, 'hidden_layer_sizes': 120, 'learning_rate_init': 0.01677896804411803, 'tol': 0.0010264592253241896, 'validation_fraction': 0.8849497229284222}
observation time 0.000000, current best 0.455056 at iter 12
suggestion time taken 0.004133 iter 13 next_points [{'alpha': 0.02781629592604477, 'batch_size': 242, 'beta_1': 0.9668185320837195, 'beta_2': 0.9999986571532331, 'epsilon': 4.2493647522638503e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.00013277322609504686, 'tol': 0.001460540220220582, 'validation_fraction': 0.27733753468450867}]
function_evaluation time 0.219933 value 7.004700 suggestion {'alpha': 0.02781629592604477, 'batch_size': 242, 'beta_1': 0.9668185320837195, 'beta_2': 0.9999986571532331, 'epsilon': 4.2493647522638503e-07, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.00013277322609504686, 'tol': 0.001460540220220582, 'validation_fraction': 0.27733753468450867}
observation time 0.000000, current best 0.455056 at iter 13
suggestion time taken 0.004109 iter 14 next_points [{'alpha': 0.021505078985856557, 'batch_size': 20, 'beta_1': 0.9655811448783462, 'beta_2': 0.9889168704981046, 'epsilon': 1.769538519627968e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.006671499306951907, 'tol': 0.007967053452400293, 'validation_fraction': 0.4905105502964895}]
function_evaluation time 0.500006 value 0.889412 suggestion {'alpha': 0.021505078985856557, 'batch_size': 20, 'beta_1': 0.9655811448783462, 'beta_2': 0.9889168704981046, 'epsilon': 1.769538519627968e-08, 'hidden_layer_sizes': 171, 'learning_rate_init': 0.006671499306951907, 'tol': 0.007967053452400293, 'validation_fraction': 0.4905105502964895}
observation time 0.000001, current best 0.455056 at iter 14
saving meta data: {'args': {'--uuid': '9fbf76aa600d5cd7b3e5fa70b598714a', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.269783589486869, 3.4904310816393633])}
saving results
saving timing
saving suggest log
done
