running: {'--uuid': '4b49e5d6d7d5593ea1169af720d0b45d', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 4b49e5d6d7d5593ea1169af720d0b45d -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_043333
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.004214 iter 0 next_points [{'alpha': 0.0043423400079612776, 'batch_size': 104, 'beta_1': 0.7674310243370255, 'beta_2': 0.9999972808011128, 'epsilon': 7.801006615813296e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0019562158206195652, 'tol': 0.0004594820585154996, 'validation_fraction': 0.3154140593034767}]
function_evaluation time 0.298157 value -0.898901 suggestion {'alpha': 0.0043423400079612776, 'batch_size': 104, 'beta_1': 0.7674310243370255, 'beta_2': 0.9999972808011128, 'epsilon': 7.801006615813296e-08, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.0019562158206195652, 'tol': 0.0004594820585154996, 'validation_fraction': 0.3154140593034767}
observation time 0.000001, current best -0.898901 at iter 0
suggestion time taken 0.003248 iter 1 next_points [{'alpha': 0.5346053515029723, 'batch_size': 159, 'beta_1': 0.8907832085513668, 'beta_2': 0.9273199306115267, 'epsilon': 8.234673520671434e-08, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.001362752060117528, 'tol': 7.547400263105438e-05, 'validation_fraction': 0.6566779108550078}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.260524 value -0.912088 suggestion {'alpha': 0.5346053515029723, 'batch_size': 159, 'beta_1': 0.8907832085513668, 'beta_2': 0.9273199306115267, 'epsilon': 8.234673520671434e-08, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.001362752060117528, 'tol': 7.547400263105438e-05, 'validation_fraction': 0.6566779108550078}
observation time 0.000000, current best -0.912088 at iter 1
suggestion time taken 0.004152 iter 2 next_points [{'alpha': 6.312656319074398, 'batch_size': 245, 'beta_1': 0.5467726968684817, 'beta_2': 0.9999968218662505, 'epsilon': 4.751084650743038e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0034281412255155433, 'tol': 0.027575396451635075, 'validation_fraction': 0.1264449504678113}]
function_evaluation time 0.277713 value -0.892308 suggestion {'alpha': 6.312656319074398, 'batch_size': 245, 'beta_1': 0.5467726968684817, 'beta_2': 0.9999968218662505, 'epsilon': 4.751084650743038e-09, 'hidden_layer_sizes': 165, 'learning_rate_init': 0.0034281412255155433, 'tol': 0.027575396451635075, 'validation_fraction': 0.1264449504678113}
observation time 0.000000, current best -0.912088 at iter 2
suggestion time taken 0.004151 iter 3 next_points [{'alpha': 9.708830869025391, 'batch_size': 67, 'beta_1': 0.8353138351708337, 'beta_2': 0.9997099663579911, 'epsilon': 4.2592572591223644e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.01070781593751937, 'tol': 7.81028794724665e-05, 'validation_fraction': 0.2820781491731151}]
function_evaluation time 0.396465 value -0.907692 suggestion {'alpha': 9.708830869025391, 'batch_size': 67, 'beta_1': 0.8353138351708337, 'beta_2': 0.9997099663579911, 'epsilon': 4.2592572591223644e-07, 'hidden_layer_sizes': 154, 'learning_rate_init': 0.01070781593751937, 'tol': 7.81028794724665e-05, 'validation_fraction': 0.2820781491731151}
observation time 0.000004, current best -0.912088 at iter 3
suggestion time taken 0.004308 iter 4 next_points [{'alpha': 0.00012679939126265246, 'batch_size': 175, 'beta_1': 0.9740986168376305, 'beta_2': 0.9841752766512089, 'epsilon': 1.3796246066713976e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.05513019976792258, 'tol': 0.009381160347347496, 'validation_fraction': 0.8984462745974366}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.192615 value -0.850549 suggestion {'alpha': 0.00012679939126265246, 'batch_size': 175, 'beta_1': 0.9740986168376305, 'beta_2': 0.9841752766512089, 'epsilon': 1.3796246066713976e-08, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.05513019976792258, 'tol': 0.009381160347347496, 'validation_fraction': 0.8984462745974366}
observation time 0.000000, current best -0.912088 at iter 4
suggestion time taken 0.004147 iter 5 next_points [{'alpha': 0.000716429241315847, 'batch_size': 164, 'beta_1': 0.9866203503431629, 'beta_2': 0.9997821145658891, 'epsilon': 2.2565632613431916e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.014555336165224997, 'tol': 0.03294341729182313, 'validation_fraction': 0.6810759926267793}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.215130 value -0.890110 suggestion {'alpha': 0.000716429241315847, 'batch_size': 164, 'beta_1': 0.9866203503431629, 'beta_2': 0.9997821145658891, 'epsilon': 2.2565632613431916e-07, 'hidden_layer_sizes': 190, 'learning_rate_init': 0.014555336165224997, 'tol': 0.03294341729182313, 'validation_fraction': 0.6810759926267793}
observation time 0.000000, current best -0.912088 at iter 5
suggestion time taken 0.004128 iter 6 next_points [{'alpha': 3.9569890308871796, 'batch_size': 147, 'beta_1': 0.8653166023692351, 'beta_2': 0.9999715487473894, 'epsilon': 1.1098062031690938e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 7.453205686866158e-05, 'tol': 2.275538095999401e-05, 'validation_fraction': 0.3127663784908398}]
function_evaluation time 0.351937 value -0.657143 suggestion {'alpha': 3.9569890308871796, 'batch_size': 147, 'beta_1': 0.8653166023692351, 'beta_2': 0.9999715487473894, 'epsilon': 1.1098062031690938e-08, 'hidden_layer_sizes': 94, 'learning_rate_init': 7.453205686866158e-05, 'tol': 2.275538095999401e-05, 'validation_fraction': 0.3127663784908398}
observation time 0.000001, current best -0.912088 at iter 6
suggestion time taken 0.004158 iter 7 next_points [{'alpha': 2.230659756354951, 'batch_size': 52, 'beta_1': 0.5918966915806492, 'beta_2': 0.9528445834400244, 'epsilon': 5.039238153073298e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0002499750973186162, 'tol': 0.00035030589650732256, 'validation_fraction': 0.7722970162984204}]
function_evaluation time 0.219969 value -0.637363 suggestion {'alpha': 2.230659756354951, 'batch_size': 52, 'beta_1': 0.5918966915806492, 'beta_2': 0.9528445834400244, 'epsilon': 5.039238153073298e-07, 'hidden_layer_sizes': 103, 'learning_rate_init': 0.0002499750973186162, 'tol': 0.00035030589650732256, 'validation_fraction': 0.7722970162984204}
observation time 0.000000, current best -0.912088 at iter 7
suggestion time taken 0.004143 iter 8 next_points [{'alpha': 0.04449900745554158, 'batch_size': 155, 'beta_1': 0.9373920248799205, 'beta_2': 0.9998838961745884, 'epsilon': 2.883395591147643e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.05500284727454877, 'tol': 1.6117700240184866e-05, 'validation_fraction': 0.779849868441973}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.249441 value -0.832967 suggestion {'alpha': 0.04449900745554158, 'batch_size': 155, 'beta_1': 0.9373920248799205, 'beta_2': 0.9998838961745884, 'epsilon': 2.883395591147643e-07, 'hidden_layer_sizes': 159, 'learning_rate_init': 0.05500284727454877, 'tol': 1.6117700240184866e-05, 'validation_fraction': 0.779849868441973}
observation time 0.000001, current best -0.912088 at iter 8
suggestion time taken 0.004149 iter 9 next_points [{'alpha': 2.735005870192652, 'batch_size': 200, 'beta_1': 0.9837032130284542, 'beta_2': 0.9958496880703204, 'epsilon': 1.3407083849753601e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0003665580942136953, 'tol': 0.02883179946156378, 'validation_fraction': 0.3591206545550192}]
function_evaluation time 0.263006 value -0.872527 suggestion {'alpha': 2.735005870192652, 'batch_size': 200, 'beta_1': 0.9837032130284542, 'beta_2': 0.9958496880703204, 'epsilon': 1.3407083849753601e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0003665580942136953, 'tol': 0.02883179946156378, 'validation_fraction': 0.3591206545550192}
observation time 0.000001, current best -0.912088 at iter 9
suggestion time taken 0.004154 iter 10 next_points [{'alpha': 5.108714473081949, 'batch_size': 47, 'beta_1': 0.9566641420392614, 'beta_2': 0.9999893569511581, 'epsilon': 7.247984006459096e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.002241521212630841, 'tol': 7.521988471484881e-05, 'validation_fraction': 0.2211832913846616}]
function_evaluation time 0.413516 value -0.894505 suggestion {'alpha': 5.108714473081949, 'batch_size': 47, 'beta_1': 0.9566641420392614, 'beta_2': 0.9999893569511581, 'epsilon': 7.247984006459096e-08, 'hidden_layer_sizes': 67, 'learning_rate_init': 0.002241521212630841, 'tol': 7.521988471484881e-05, 'validation_fraction': 0.2211832913846616}
observation time 0.000001, current best -0.912088 at iter 10
suggestion time taken 0.003274 iter 11 next_points [{'alpha': 0.0016669871678013023, 'batch_size': 28, 'beta_1': 0.9821717195914944, 'beta_2': 0.9723442178265218, 'epsilon': 6.802164032333115e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.002364749635660929, 'tol': 0.05565424093462128, 'validation_fraction': 0.8690120505970009}]
function_evaluation time 0.179122 value -0.894505 suggestion {'alpha': 0.0016669871678013023, 'batch_size': 28, 'beta_1': 0.9821717195914944, 'beta_2': 0.9723442178265218, 'epsilon': 6.802164032333115e-08, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.002364749635660929, 'tol': 0.05565424093462128, 'validation_fraction': 0.8690120505970009}
observation time 0.000000, current best -0.912088 at iter 11
suggestion time taken 0.004137 iter 12 next_points [{'alpha': 0.0427121865500862, 'batch_size': 57, 'beta_1': 0.9872218486587454, 'beta_2': 0.9811379773118134, 'epsilon': 2.1561292103291053e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0010191718393294219, 'tol': 0.0006454992426574084, 'validation_fraction': 0.11161258863807037}]
function_evaluation time 0.402190 value -0.898901 suggestion {'alpha': 0.0427121865500862, 'batch_size': 57, 'beta_1': 0.9872218486587454, 'beta_2': 0.9811379773118134, 'epsilon': 2.1561292103291053e-08, 'hidden_layer_sizes': 83, 'learning_rate_init': 0.0010191718393294219, 'tol': 0.0006454992426574084, 'validation_fraction': 0.11161258863807037}
observation time 0.000001, current best -0.912088 at iter 12
suggestion time taken 0.004200 iter 13 next_points [{'alpha': 4.928817269815341e-05, 'batch_size': 242, 'beta_1': 0.8439255729748968, 'beta_2': 0.9994562896867175, 'epsilon': 3.801462378975538e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.004952082664124618, 'tol': 0.0005359943391783503, 'validation_fraction': 0.3982696603687051}]
function_evaluation time 0.379937 value -0.912088 suggestion {'alpha': 4.928817269815341e-05, 'batch_size': 242, 'beta_1': 0.8439255729748968, 'beta_2': 0.9994562896867175, 'epsilon': 3.801462378975538e-09, 'hidden_layer_sizes': 199, 'learning_rate_init': 0.004952082664124618, 'tol': 0.0005359943391783503, 'validation_fraction': 0.3982696603687051}
observation time 0.000001, current best -0.912088 at iter 13
suggestion time taken 0.004143 iter 14 next_points [{'alpha': 0.10295755336493587, 'batch_size': 202, 'beta_1': 0.930476687820419, 'beta_2': 0.9999900358387224, 'epsilon': 1.350154367419207e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.003891371045458161, 'tol': 1.909430811572882e-05, 'validation_fraction': 0.7584484699454533}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.245846 value -0.890110 suggestion {'alpha': 0.10295755336493587, 'batch_size': 202, 'beta_1': 0.930476687820419, 'beta_2': 0.9999900358387224, 'epsilon': 1.350154367419207e-07, 'hidden_layer_sizes': 175, 'learning_rate_init': 0.003891371045458161, 'tol': 1.909430811572882e-05, 'validation_fraction': 0.7584484699454533}
observation time 0.000000, current best -0.912088 at iter 14
saving meta data: {'args': {'--uuid': '4b49e5d6d7d5593ea1169af720d0b45d', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
