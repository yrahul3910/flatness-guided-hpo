running: {'--uuid': '40ad9eaad9ca5ef2a8fdfffbfb31c6a2', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 40ad9eaad9ca5ef2a8fdfffbfb31c6a2 -m acc -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_043333
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast acc 15 1
with data root: None
suggestion time taken 0.004802 iter 0 next_points [{'alpha': 0.6188466997965272, 'batch_size': 220, 'beta_1': 0.9888290981379823, 'beta_2': 0.9999830421779137, 'epsilon': 9.202169122663451e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.0006864726897419819, 'tol': 0.057583760038140766, 'validation_fraction': 0.2552598800464457}]
function_evaluation time 0.200312 value -0.848352 suggestion {'alpha': 0.6188466997965272, 'batch_size': 220, 'beta_1': 0.9888290981379823, 'beta_2': 0.9999830421779137, 'epsilon': 9.202169122663451e-09, 'hidden_layer_sizes': 107, 'learning_rate_init': 0.0006864726897419819, 'tol': 0.057583760038140766, 'validation_fraction': 0.2552598800464457}
observation time 0.000014, current best -0.848352 at iter 0
suggestion time taken 0.004154 iter 1 next_points [{'alpha': 7.717213248169926, 'batch_size': 151, 'beta_1': 0.9652282293466706, 'beta_2': 0.9998967498865822, 'epsilon': 1.8571903199651468e-09, 'hidden_layer_sizes': 149, 'learning_rate_init': 2.2712670789190238e-05, 'tol': 4.676590107369211e-05, 'validation_fraction': 0.16884246841785405}]
function_evaluation time 0.229565 value -0.483516 suggestion {'alpha': 7.717213248169926, 'batch_size': 151, 'beta_1': 0.9652282293466706, 'beta_2': 0.9998967498865822, 'epsilon': 1.8571903199651468e-09, 'hidden_layer_sizes': 149, 'learning_rate_init': 2.2712670789190238e-05, 'tol': 4.676590107369211e-05, 'validation_fraction': 0.16884246841785405}
observation time 0.000000, current best -0.848352 at iter 1
suggestion time taken 0.004152 iter 2 next_points [{'alpha': 0.008187575740850212, 'batch_size': 193, 'beta_1': 0.964629979409139, 'beta_2': 0.9982594390880716, 'epsilon': 4.816189800071864e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.0003375622029637199, 'tol': 0.08296938535188174, 'validation_fraction': 0.7833511411285617}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.133843 value -0.586813 suggestion {'alpha': 0.008187575740850212, 'batch_size': 193, 'beta_1': 0.964629979409139, 'beta_2': 0.9982594390880716, 'epsilon': 4.816189800071864e-07, 'hidden_layer_sizes': 167, 'learning_rate_init': 0.0003375622029637199, 'tol': 0.08296938535188174, 'validation_fraction': 0.7833511411285617}
observation time 0.000000, current best -0.848352 at iter 2
suggestion time taken 0.004145 iter 3 next_points [{'alpha': 0.043398476470722216, 'batch_size': 209, 'beta_1': 0.7660080341111137, 'beta_2': 0.9999931813281295, 'epsilon': 2.5000889938036133e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.00011486732494842709, 'tol': 0.0003556631386598016, 'validation_fraction': 0.24394139638420778}]
function_evaluation time 0.178563 value -0.527473 suggestion {'alpha': 0.043398476470722216, 'batch_size': 209, 'beta_1': 0.7660080341111137, 'beta_2': 0.9999931813281295, 'epsilon': 2.5000889938036133e-08, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.00011486732494842709, 'tol': 0.0003556631386598016, 'validation_fraction': 0.24394139638420778}
observation time 0.000000, current best -0.848352 at iter 3
suggestion time taken 0.004147 iter 4 next_points [{'alpha': 2.781198427382554e-05, 'batch_size': 145, 'beta_1': 0.7879749045012009, 'beta_2': 0.984019250299518, 'epsilon': 1.562225262206515e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 2.3897594856653337e-05, 'tol': 0.037502429490440824, 'validation_fraction': 0.4855952457899987}]
function_evaluation time 0.170636 value -0.685714 suggestion {'alpha': 2.781198427382554e-05, 'batch_size': 145, 'beta_1': 0.7879749045012009, 'beta_2': 0.984019250299518, 'epsilon': 1.562225262206515e-07, 'hidden_layer_sizes': 199, 'learning_rate_init': 2.3897594856653337e-05, 'tol': 0.037502429490440824, 'validation_fraction': 0.4855952457899987}
observation time 0.000001, current best -0.848352 at iter 4
suggestion time taken 0.004123 iter 5 next_points [{'alpha': 0.00013312370225124966, 'batch_size': 115, 'beta_1': 0.9848901401073307, 'beta_2': 0.9111140586189539, 'epsilon': 2.0220728063089853e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 1.0574045949592944e-05, 'tol': 0.04344962896607469, 'validation_fraction': 0.22013342912785167}]
function_evaluation time 0.163919 value -0.472527 suggestion {'alpha': 0.00013312370225124966, 'batch_size': 115, 'beta_1': 0.9848901401073307, 'beta_2': 0.9111140586189539, 'epsilon': 2.0220728063089853e-07, 'hidden_layer_sizes': 89, 'learning_rate_init': 1.0574045949592944e-05, 'tol': 0.04344962896607469, 'validation_fraction': 0.22013342912785167}
observation time 0.000000, current best -0.848352 at iter 5
suggestion time taken 0.004101 iter 6 next_points [{'alpha': 0.0005654284039048893, 'batch_size': 96, 'beta_1': 0.7487395888397879, 'beta_2': 0.9087861878293715, 'epsilon': 2.9519916961008766e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.01805632114634449, 'tol': 0.00010260354697349779, 'validation_fraction': 0.5015334335108453}]
function_evaluation time 0.251215 value -0.907692 suggestion {'alpha': 0.0005654284039048893, 'batch_size': 96, 'beta_1': 0.7487395888397879, 'beta_2': 0.9087861878293715, 'epsilon': 2.9519916961008766e-08, 'hidden_layer_sizes': 123, 'learning_rate_init': 0.01805632114634449, 'tol': 0.00010260354697349779, 'validation_fraction': 0.5015334335108453}
observation time 0.000003, current best -0.907692 at iter 6
suggestion time taken 0.004244 iter 7 next_points [{'alpha': 0.03653245630250392, 'batch_size': 106, 'beta_1': 0.787563790919408, 'beta_2': 0.9775076554545774, 'epsilon': 5.849137601289197e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0014191174957550706, 'tol': 0.011665833643739305, 'validation_fraction': 0.8393646676189793}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.141560 value -0.824176 suggestion {'alpha': 0.03653245630250392, 'batch_size': 106, 'beta_1': 0.787563790919408, 'beta_2': 0.9775076554545774, 'epsilon': 5.849137601289197e-09, 'hidden_layer_sizes': 59, 'learning_rate_init': 0.0014191174957550706, 'tol': 0.011665833643739305, 'validation_fraction': 0.8393646676189793}
observation time 0.000001, current best -0.907692 at iter 7
suggestion time taken 0.004321 iter 8 next_points [{'alpha': 2.1204465599620144e-05, 'batch_size': 167, 'beta_1': 0.9869411865372073, 'beta_2': 0.9999955830269822, 'epsilon': 1.5356063514404172e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00019680997856016375, 'tol': 2.472459519593936e-05, 'validation_fraction': 0.7259823175355136}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.138195 value -0.573626 suggestion {'alpha': 2.1204465599620144e-05, 'batch_size': 167, 'beta_1': 0.9869411865372073, 'beta_2': 0.9999955830269822, 'epsilon': 1.5356063514404172e-07, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.00019680997856016375, 'tol': 2.472459519593936e-05, 'validation_fraction': 0.7259823175355136}
observation time 0.000000, current best -0.907692 at iter 8
suggestion time taken 0.004110 iter 9 next_points [{'alpha': 0.000826231702533822, 'batch_size': 80, 'beta_1': 0.915966302743029, 'beta_2': 0.9265500882758272, 'epsilon': 3.484112754380095e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.006079104993376329, 'tol': 3.246577152737131e-05, 'validation_fraction': 0.8289745189879555}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.295526 value -0.912088 suggestion {'alpha': 0.000826231702533822, 'batch_size': 80, 'beta_1': 0.915966302743029, 'beta_2': 0.9265500882758272, 'epsilon': 3.484112754380095e-08, 'hidden_layer_sizes': 162, 'learning_rate_init': 0.006079104993376329, 'tol': 3.246577152737131e-05, 'validation_fraction': 0.8289745189879555}
observation time 0.000000, current best -0.912088 at iter 9
suggestion time taken 0.004126 iter 10 next_points [{'alpha': 8.527069832713133, 'batch_size': 146, 'beta_1': 0.8378381889034268, 'beta_2': 0.9996173635114776, 'epsilon': 1.5674766740681072e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.721953594299466e-05, 'tol': 0.0002501985977336926, 'validation_fraction': 0.6522837879610155}]
function_evaluation time 0.098446 value -0.417582 suggestion {'alpha': 8.527069832713133, 'batch_size': 146, 'beta_1': 0.8378381889034268, 'beta_2': 0.9996173635114776, 'epsilon': 1.5674766740681072e-09, 'hidden_layer_sizes': 71, 'learning_rate_init': 1.721953594299466e-05, 'tol': 0.0002501985977336926, 'validation_fraction': 0.6522837879610155}
observation time 0.000001, current best -0.912088 at iter 10
suggestion time taken 0.004113 iter 11 next_points [{'alpha': 0.10001611551843471, 'batch_size': 101, 'beta_1': 0.8144421324261286, 'beta_2': 0.9999923381073521, 'epsilon': 1.6504931813254308e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.0016221090681008022, 'tol': 0.0003174890709207918, 'validation_fraction': 0.5599820866953111}]
function_evaluation time 0.310442 value -0.916484 suggestion {'alpha': 0.10001611551843471, 'batch_size': 101, 'beta_1': 0.8144421324261286, 'beta_2': 0.9999923381073521, 'epsilon': 1.6504931813254308e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.0016221090681008022, 'tol': 0.0003174890709207918, 'validation_fraction': 0.5599820866953111}
observation time 0.000000, current best -0.916484 at iter 11
suggestion time taken 0.004095 iter 12 next_points [{'alpha': 0.25964688473651376, 'batch_size': 25, 'beta_1': 0.9788156042724684, 'beta_2': 0.9927755097209063, 'epsilon': 4.812864152435861e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.07672234286287137, 'tol': 0.00016104524477478748, 'validation_fraction': 0.8900004934601028}]
function_evaluation time 0.158894 value -0.870330 suggestion {'alpha': 0.25964688473651376, 'batch_size': 25, 'beta_1': 0.9788156042724684, 'beta_2': 0.9927755097209063, 'epsilon': 4.812864152435861e-09, 'hidden_layer_sizes': 52, 'learning_rate_init': 0.07672234286287137, 'tol': 0.00016104524477478748, 'validation_fraction': 0.8900004934601028}
observation time 0.000000, current best -0.916484 at iter 12
suggestion time taken 0.004119 iter 13 next_points [{'alpha': 0.33672006964135087, 'batch_size': 167, 'beta_1': 0.5655449335196236, 'beta_2': 0.943722571552691, 'epsilon': 6.303040054302655e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.055429595823095056, 'tol': 1.3045505453145577e-05, 'validation_fraction': 0.12772703252512108}]
function_evaluation time 0.169509 value -0.903297 suggestion {'alpha': 0.33672006964135087, 'batch_size': 167, 'beta_1': 0.5655449335196236, 'beta_2': 0.943722571552691, 'epsilon': 6.303040054302655e-09, 'hidden_layer_sizes': 51, 'learning_rate_init': 0.055429595823095056, 'tol': 1.3045505453145577e-05, 'validation_fraction': 0.12772703252512108}
observation time 0.000001, current best -0.916484 at iter 13
suggestion time taken 0.003313 iter 14 next_points [{'alpha': 0.027935970290599754, 'batch_size': 72, 'beta_1': 0.5070544738569663, 'beta_2': 0.9628323696813885, 'epsilon': 1.4490732440585536e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0025618480829916954, 'tol': 2.3628400136137486e-05, 'validation_fraction': 0.7666109364427075}]
function_evaluation time 0.297725 value -0.925275 suggestion {'alpha': 0.027935970290599754, 'batch_size': 72, 'beta_1': 0.5070544738569663, 'beta_2': 0.9628323696813885, 'epsilon': 1.4490732440585536e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.0025618480829916954, 'tol': 2.3628400136137486e-05, 'validation_fraction': 0.7666109364427075}
observation time 0.000000, current best -0.925275 at iter 14
saving meta data: {'args': {'--uuid': '40ad9eaad9ca5ef2a8fdfffbfb31c6a2', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'acc', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [-0.676923076923077, -0.567032967032967, -0.545054945054945, -0.7824175824175824, -0.843956043956044])}
saving results
saving timing
saving suggest log
done
