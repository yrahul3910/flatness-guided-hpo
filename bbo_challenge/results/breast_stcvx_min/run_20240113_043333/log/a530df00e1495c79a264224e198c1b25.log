running: {'--uuid': 'a530df00e1495c79a264224e198c1b25', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u a530df00e1495c79a264224e198c1b25 -m nll -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_043333
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.269783589486869, 3.4904310816393633])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.004886 iter 0 next_points [{'alpha': 0.0049642242114105945, 'batch_size': 187, 'beta_1': 0.7003801121812314, 'beta_2': 0.9999805686921748, 'epsilon': 1.042385072750324e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 1.4209197296203442e-05, 'tol': 0.008726804242194767, 'validation_fraction': 0.28221396158641915}]
function_evaluation time 0.216728 value 14.351230 suggestion {'alpha': 0.0049642242114105945, 'batch_size': 187, 'beta_1': 0.7003801121812314, 'beta_2': 0.9999805686921748, 'epsilon': 1.042385072750324e-08, 'hidden_layer_sizes': 196, 'learning_rate_init': 1.4209197296203442e-05, 'tol': 0.008726804242194767, 'validation_fraction': 0.28221396158641915}
observation time 0.000019, current best 14.351230 at iter 0
suggestion time taken 0.004247 iter 1 next_points [{'alpha': 8.385053289400703e-05, 'batch_size': 245, 'beta_1': 0.8520588883753885, 'beta_2': 0.9909955793033423, 'epsilon': 1.5715782305319537e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.442189340661455e-05, 'tol': 5.5336599327923444e-05, 'validation_fraction': 0.5947689275910012}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.104076 value 11.693889 suggestion {'alpha': 8.385053289400703e-05, 'batch_size': 245, 'beta_1': 0.8520588883753885, 'beta_2': 0.9909955793033423, 'epsilon': 1.5715782305319537e-09, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.442189340661455e-05, 'tol': 5.5336599327923444e-05, 'validation_fraction': 0.5947689275910012}
observation time 0.000001, current best 11.693889 at iter 1
suggestion time taken 0.004240 iter 2 next_points [{'alpha': 3.086331516281989e-05, 'batch_size': 70, 'beta_1': 0.9450267440353378, 'beta_2': 0.9990486189663923, 'epsilon': 2.6699436226056715e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00024099134986021962, 'tol': 2.1120341418054535e-05, 'validation_fraction': 0.10567638721618725}]
function_evaluation time 0.259686 value 5.468285 suggestion {'alpha': 3.086331516281989e-05, 'batch_size': 70, 'beta_1': 0.9450267440353378, 'beta_2': 0.9990486189663923, 'epsilon': 2.6699436226056715e-08, 'hidden_layer_sizes': 69, 'learning_rate_init': 0.00024099134986021962, 'tol': 2.1120341418054535e-05, 'validation_fraction': 0.10567638721618725}
observation time 0.000000, current best 5.468285 at iter 2
suggestion time taken 0.003408 iter 3 next_points [{'alpha': 1.842676904687185, 'batch_size': 179, 'beta_1': 0.9493013402793952, 'beta_2': 0.9584722550538975, 'epsilon': 2.7058432503615243e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.016403235782565515, 'tol': 8.342777275178761e-05, 'validation_fraction': 0.6678556841015559}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.225146 value 3.321260 suggestion {'alpha': 1.842676904687185, 'batch_size': 179, 'beta_1': 0.9493013402793952, 'beta_2': 0.9584722550538975, 'epsilon': 2.7058432503615243e-09, 'hidden_layer_sizes': 122, 'learning_rate_init': 0.016403235782565515, 'tol': 8.342777275178761e-05, 'validation_fraction': 0.6678556841015559}
observation time 0.000001, current best 3.321260 at iter 3
suggestion time taken 0.004243 iter 4 next_points [{'alpha': 0.08496557319876762, 'batch_size': 178, 'beta_1': 0.7821879141691394, 'beta_2': 0.9772237814781716, 'epsilon': 6.060624005353822e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0001301131432957818, 'tol': 0.0003555430526475102, 'validation_fraction': 0.21977829525463696}]
function_evaluation time 0.139388 value 18.915990 suggestion {'alpha': 0.08496557319876762, 'batch_size': 178, 'beta_1': 0.7821879141691394, 'beta_2': 0.9772237814781716, 'epsilon': 6.060624005353822e-08, 'hidden_layer_sizes': 80, 'learning_rate_init': 0.0001301131432957818, 'tol': 0.0003555430526475102, 'validation_fraction': 0.21977829525463696}
observation time 0.000000, current best 3.321260 at iter 4
suggestion time taken 0.004220 iter 5 next_points [{'alpha': 0.0004333770883269856, 'batch_size': 105, 'beta_1': 0.9660013648758061, 'beta_2': 0.9999121000184611, 'epsilon': 7.669432746996197e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.00017200242405774992, 'tol': 0.00020791071503673968, 'validation_fraction': 0.6733664559952185}]
function_evaluation time 0.162949 value 12.868089 suggestion {'alpha': 0.0004333770883269856, 'batch_size': 105, 'beta_1': 0.9660013648758061, 'beta_2': 0.9999121000184611, 'epsilon': 7.669432746996197e-09, 'hidden_layer_sizes': 66, 'learning_rate_init': 0.00017200242405774992, 'tol': 0.00020791071503673968, 'validation_fraction': 0.6733664559952185}
observation time 0.000003, current best 3.321260 at iter 5
suggestion time taken 0.004385 iter 6 next_points [{'alpha': 0.0025246726415893996, 'batch_size': 116, 'beta_1': 0.7899003099310941, 'beta_2': 0.9986935484468541, 'epsilon': 3.371001700490986e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.003033520980034677, 'tol': 1.4481006290445006e-05, 'validation_fraction': 0.8479781403987234}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.200353 value 0.582091 suggestion {'alpha': 0.0025246726415893996, 'batch_size': 116, 'beta_1': 0.7899003099310941, 'beta_2': 0.9986935484468541, 'epsilon': 3.371001700490986e-07, 'hidden_layer_sizes': 156, 'learning_rate_init': 0.003033520980034677, 'tol': 1.4481006290445006e-05, 'validation_fraction': 0.8479781403987234}
observation time 0.000001, current best 0.582091 at iter 6
suggestion time taken 0.004226 iter 7 next_points [{'alpha': 0.0005453053877684062, 'batch_size': 51, 'beta_1': 0.8011966988176442, 'beta_2': 0.9991412620573085, 'epsilon': 1.9597077671569485e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.025869632873101404, 'tol': 0.00010055685674878908, 'validation_fraction': 0.5418384971457755}]
function_evaluation time 0.333387 value 0.709579 suggestion {'alpha': 0.0005453053877684062, 'batch_size': 51, 'beta_1': 0.8011966988176442, 'beta_2': 0.9991412620573085, 'epsilon': 1.9597077671569485e-08, 'hidden_layer_sizes': 113, 'learning_rate_init': 0.025869632873101404, 'tol': 0.00010055685674878908, 'validation_fraction': 0.5418384971457755}
observation time 0.000001, current best 0.582091 at iter 7
suggestion time taken 0.004217 iter 8 next_points [{'alpha': 0.0001279251748607742, 'batch_size': 70, 'beta_1': 0.9194941846346724, 'beta_2': 0.9992375934584714, 'epsilon': 2.211963656079477e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.05816177610602549, 'tol': 0.005954570522111934, 'validation_fraction': 0.4418113013504436}]
function_evaluation time 0.430932 value 0.313467 suggestion {'alpha': 0.0001279251748607742, 'batch_size': 70, 'beta_1': 0.9194941846346724, 'beta_2': 0.9992375934584714, 'epsilon': 2.211963656079477e-08, 'hidden_layer_sizes': 183, 'learning_rate_init': 0.05816177610602549, 'tol': 0.005954570522111934, 'validation_fraction': 0.4418113013504436}
observation time 0.000001, current best 0.313467 at iter 8
suggestion time taken 0.004231 iter 9 next_points [{'alpha': 0.0017003086580886792, 'batch_size': 216, 'beta_1': 0.5452592215750321, 'beta_2': 0.9999948074619475, 'epsilon': 2.674567795574288e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 7.550441664652986e-05, 'tol': 0.0011286822469979772, 'validation_fraction': 0.699538643397633}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.096308 value 14.486227 suggestion {'alpha': 0.0017003086580886792, 'batch_size': 216, 'beta_1': 0.5452592215750321, 'beta_2': 0.9999948074619475, 'epsilon': 2.674567795574288e-09, 'hidden_layer_sizes': 72, 'learning_rate_init': 7.550441664652986e-05, 'tol': 0.0011286822469979772, 'validation_fraction': 0.699538643397633}
observation time 0.000000, current best 0.313467 at iter 9
suggestion time taken 0.004217 iter 10 next_points [{'alpha': 6.775860137892932e-05, 'batch_size': 147, 'beta_1': 0.567044065110273, 'beta_2': 0.9997669047419222, 'epsilon': 2.0418841115801952e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.03881264447571209, 'tol': 2.0643450704665303e-05, 'validation_fraction': 0.8655332860424425}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.215707 value 0.568639 suggestion {'alpha': 6.775860137892932e-05, 'batch_size': 147, 'beta_1': 0.567044065110273, 'beta_2': 0.9997669047419222, 'epsilon': 2.0418841115801952e-08, 'hidden_layer_sizes': 77, 'learning_rate_init': 0.03881264447571209, 'tol': 2.0643450704665303e-05, 'validation_fraction': 0.8655332860424425}
observation time 0.000001, current best 0.313467 at iter 10
suggestion time taken 0.004207 iter 11 next_points [{'alpha': 0.014201984832258192, 'batch_size': 198, 'beta_1': 0.986433178168744, 'beta_2': 0.9992928571504328, 'epsilon': 1.2480463993203805e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.00023944005672484146, 'tol': 0.006229471046692454, 'validation_fraction': 0.8769999868145255}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.125360 value 11.389653 suggestion {'alpha': 0.014201984832258192, 'batch_size': 198, 'beta_1': 0.986433178168744, 'beta_2': 0.9992928571504328, 'epsilon': 1.2480463993203805e-09, 'hidden_layer_sizes': 138, 'learning_rate_init': 0.00023944005672484146, 'tol': 0.006229471046692454, 'validation_fraction': 0.8769999868145255}
observation time 0.000000, current best 0.313467 at iter 11
suggestion time taken 0.004225 iter 12 next_points [{'alpha': 0.09162105606680494, 'batch_size': 104, 'beta_1': 0.9896215476266297, 'beta_2': 0.9997509103639264, 'epsilon': 1.252848359964119e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.01874102288423306, 'tol': 6.141803718877714e-05, 'validation_fraction': 0.3493805108092681}]
function_evaluation time 0.321834 value 1.248920 suggestion {'alpha': 0.09162105606680494, 'batch_size': 104, 'beta_1': 0.9896215476266297, 'beta_2': 0.9997509103639264, 'epsilon': 1.252848359964119e-08, 'hidden_layer_sizes': 158, 'learning_rate_init': 0.01874102288423306, 'tol': 6.141803718877714e-05, 'validation_fraction': 0.3493805108092681}
observation time 0.000001, current best 0.313467 at iter 12
suggestion time taken 0.004220 iter 13 next_points [{'alpha': 0.03628708871144008, 'batch_size': 177, 'beta_1': 0.8302867139518897, 'beta_2': 0.9999684838245503, 'epsilon': 8.227866634713536e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.005207475348912739, 'tol': 7.74803001388441e-05, 'validation_fraction': 0.24542781895210633}]
function_evaluation time 0.285976 value 0.693595 suggestion {'alpha': 0.03628708871144008, 'batch_size': 177, 'beta_1': 0.8302867139518897, 'beta_2': 0.9999684838245503, 'epsilon': 8.227866634713536e-07, 'hidden_layer_sizes': 99, 'learning_rate_init': 0.005207475348912739, 'tol': 7.74803001388441e-05, 'validation_fraction': 0.24542781895210633}
observation time 0.000001, current best 0.313467 at iter 13
suggestion time taken 0.004225 iter 14 next_points [{'alpha': 0.01374459722013511, 'batch_size': 59, 'beta_1': 0.5919601080043798, 'beta_2': 0.9999834519135299, 'epsilon': 6.529886967210799e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.01828713723793756, 'tol': 0.006553398865898003, 'validation_fraction': 0.24650408416495603}]
function_evaluation time 0.440480 value 0.978960 suggestion {'alpha': 0.01374459722013511, 'batch_size': 59, 'beta_1': 0.5919601080043798, 'beta_2': 0.9999834519135299, 'epsilon': 6.529886967210799e-09, 'hidden_layer_sizes': 153, 'learning_rate_init': 0.01828713723793756, 'tol': 0.006553398865898003, 'validation_fraction': 0.24650408416495603}
observation time 0.000000, current best 0.313467 at iter 14
saving meta data: {'args': {'--uuid': 'a530df00e1495c79a264224e198c1b25', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.269783589486869, 3.4904310816393633])}
saving results
saving timing
saving suggest log
done
