running: {'--uuid': '27aa4bb4d05f50e98fdc20b2cec265a9', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}
cmd: python /home/ryedida/.local/bin/bayesmark-exp -c MLP-adam -d breast -o random -u 27aa4bb4d05f50e98fdc20b2cec265a9 -m nll -n 15 -p 1 -dir /home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output -b run_20240113_043333
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

computed signature: ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.269783589486869, 3.4904310816393633])
/home/ryedida/.local/lib/python3.8/site-packages/bayesmark/experiment.py:469: UserWarning: Baselines not found. Will not log intermediate scores.
  warnings.warn("Baselines not found. Will not log intermediate scores.")

starting sklearn study random MLP-adam breast nll 15 1
with data root: None
suggestion time taken 0.004223 iter 0 next_points [{'alpha': 0.05095944567050023, 'batch_size': 34, 'beta_1': 0.7319073026934796, 'beta_2': 0.9992885115650849, 'epsilon': 3.417747792623705e-08, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.0003092612503226393, 'tol': 0.006644322916796788, 'validation_fraction': 0.2604767850386578}]
function_evaluation time 0.565790 value 2.933112 suggestion {'alpha': 0.05095944567050023, 'batch_size': 34, 'beta_1': 0.7319073026934796, 'beta_2': 0.9992885115650849, 'epsilon': 3.417747792623705e-08, 'hidden_layer_sizes': 110, 'learning_rate_init': 0.0003092612503226393, 'tol': 0.006644322916796788, 'validation_fraction': 0.2604767850386578}
observation time 0.000001, current best 2.933112 at iter 0
suggestion time taken 0.004199 iter 1 next_points [{'alpha': 0.7515043808948141, 'batch_size': 154, 'beta_1': 0.7860228208224709, 'beta_2': 0.9941157767487666, 'epsilon': 5.443383671499232e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 3.377201966576417e-05, 'tol': 0.0002945884078526138, 'validation_fraction': 0.16538581560253784}]
function_evaluation time 0.153456 value 20.934121 suggestion {'alpha': 0.7515043808948141, 'batch_size': 154, 'beta_1': 0.7860228208224709, 'beta_2': 0.9941157767487666, 'epsilon': 5.443383671499232e-08, 'hidden_layer_sizes': 92, 'learning_rate_init': 3.377201966576417e-05, 'tol': 0.0002945884078526138, 'validation_fraction': 0.16538581560253784}
observation time 0.000000, current best 2.933112 at iter 1
suggestion time taken 0.004165 iter 2 next_points [{'alpha': 0.14970960401579728, 'batch_size': 84, 'beta_1': 0.9252720755667357, 'beta_2': 0.9983568767575762, 'epsilon': 8.995437582463001e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.019517327554656915, 'tol': 0.003672877897616072, 'validation_fraction': 0.24122778749859744}]
function_evaluation time 0.210299 value 0.965043 suggestion {'alpha': 0.14970960401579728, 'batch_size': 84, 'beta_1': 0.9252720755667357, 'beta_2': 0.9983568767575762, 'epsilon': 8.995437582463001e-07, 'hidden_layer_sizes': 54, 'learning_rate_init': 0.019517327554656915, 'tol': 0.003672877897616072, 'validation_fraction': 0.24122778749859744}
observation time 0.000000, current best 0.965043 at iter 2
suggestion time taken 0.003316 iter 3 next_points [{'alpha': 0.000495931687186542, 'batch_size': 193, 'beta_1': 0.7831836217553475, 'beta_2': 0.9890938191579232, 'epsilon': 8.704826349303584e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00017890108225180408, 'tol': 0.03119240803666571, 'validation_fraction': 0.22234220166189533}]
function_evaluation time 0.148975 value 6.495889 suggestion {'alpha': 0.000495931687186542, 'batch_size': 193, 'beta_1': 0.7831836217553475, 'beta_2': 0.9890938191579232, 'epsilon': 8.704826349303584e-09, 'hidden_layer_sizes': 58, 'learning_rate_init': 0.00017890108225180408, 'tol': 0.03119240803666571, 'validation_fraction': 0.22234220166189533}
observation time 0.000004, current best 0.965043 at iter 3
suggestion time taken 0.004299 iter 4 next_points [{'alpha': 0.005093794637936063, 'batch_size': 142, 'beta_1': 0.8361339252446853, 'beta_2': 0.9996259584889083, 'epsilon': 3.1023808085434377e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.010917661857178487, 'tol': 0.01740349380983347, 'validation_fraction': 0.3828950616639452}]
function_evaluation time 0.280349 value 0.744232 suggestion {'alpha': 0.005093794637936063, 'batch_size': 142, 'beta_1': 0.8361339252446853, 'beta_2': 0.9996259584889083, 'epsilon': 3.1023808085434377e-07, 'hidden_layer_sizes': 184, 'learning_rate_init': 0.010917661857178487, 'tol': 0.01740349380983347, 'validation_fraction': 0.3828950616639452}
observation time 0.000001, current best 0.744232 at iter 4
suggestion time taken 0.004132 iter 5 next_points [{'alpha': 0.40042762408935384, 'batch_size': 185, 'beta_1': 0.9593378317870545, 'beta_2': 0.9962345982555701, 'epsilon': 6.193990949361696e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.022141813779502882, 'tol': 0.015342314994644156, 'validation_fraction': 0.8591390702238465}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.183440 value 0.802578 suggestion {'alpha': 0.40042762408935384, 'batch_size': 185, 'beta_1': 0.9593378317870545, 'beta_2': 0.9962345982555701, 'epsilon': 6.193990949361696e-07, 'hidden_layer_sizes': 90, 'learning_rate_init': 0.022141813779502882, 'tol': 0.015342314994644156, 'validation_fraction': 0.8591390702238465}
observation time 0.000001, current best 0.744232 at iter 5
suggestion time taken 0.004151 iter 6 next_points [{'alpha': 0.016881795810802184, 'batch_size': 133, 'beta_1': 0.9879087982865496, 'beta_2': 0.9999987850976787, 'epsilon': 4.578806110369283e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0004957477331901508, 'tol': 2.9955606537778594e-05, 'validation_fraction': 0.1061083474414678}]
function_evaluation time 0.304011 value 8.334281 suggestion {'alpha': 0.016881795810802184, 'batch_size': 133, 'beta_1': 0.9879087982865496, 'beta_2': 0.9999987850976787, 'epsilon': 4.578806110369283e-08, 'hidden_layer_sizes': 126, 'learning_rate_init': 0.0004957477331901508, 'tol': 2.9955606537778594e-05, 'validation_fraction': 0.1061083474414678}
observation time 0.000001, current best 0.744232 at iter 6
suggestion time taken 0.004138 iter 7 next_points [{'alpha': 0.19616987403523178, 'batch_size': 61, 'beta_1': 0.5074357833315386, 'beta_2': 0.9977157186409938, 'epsilon': 2.3154891523849424e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.007914757169408, 'tol': 0.0004780610907182597, 'validation_fraction': 0.3441584875178088}]
function_evaluation time 0.313280 value 0.724468 suggestion {'alpha': 0.19616987403523178, 'batch_size': 61, 'beta_1': 0.5074357833315386, 'beta_2': 0.9977157186409938, 'epsilon': 2.3154891523849424e-07, 'hidden_layer_sizes': 73, 'learning_rate_init': 0.007914757169408, 'tol': 0.0004780610907182597, 'validation_fraction': 0.3441584875178088}
observation time 0.000000, current best 0.724468 at iter 7
suggestion time taken 0.004144 iter 8 next_points [{'alpha': 9.667623153018983e-05, 'batch_size': 197, 'beta_1': 0.7620351890869433, 'beta_2': 0.9861183742887504, 'epsilon': 6.252618369987397e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.0900128285316488e-05, 'tol': 0.010236875674068738, 'validation_fraction': 0.46421839332679027}]
function_evaluation time 0.110984 value 14.478285 suggestion {'alpha': 9.667623153018983e-05, 'batch_size': 197, 'beta_1': 0.7620351890869433, 'beta_2': 0.9861183742887504, 'epsilon': 6.252618369987397e-07, 'hidden_layer_sizes': 69, 'learning_rate_init': 1.0900128285316488e-05, 'tol': 0.010236875674068738, 'validation_fraction': 0.46421839332679027}
observation time 0.000000, current best 0.724468 at iter 8
suggestion time taken 0.004131 iter 9 next_points [{'alpha': 1.9293278271564656, 'batch_size': 89, 'beta_1': 0.8455754717272722, 'beta_2': 0.9999314776816699, 'epsilon': 2.197818768152701e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.014705686049138888, 'tol': 1.2040583831210565e-05, 'validation_fraction': 0.19205201946381997}]
function_evaluation time 0.276650 value 0.565390 suggestion {'alpha': 1.9293278271564656, 'batch_size': 89, 'beta_1': 0.8455754717272722, 'beta_2': 0.9999314776816699, 'epsilon': 2.197818768152701e-09, 'hidden_layer_sizes': 86, 'learning_rate_init': 0.014705686049138888, 'tol': 1.2040583831210565e-05, 'validation_fraction': 0.19205201946381997}
observation time 0.000000, current best 0.565390 at iter 9
suggestion time taken 0.004143 iter 10 next_points [{'alpha': 5.471462589677482e-05, 'batch_size': 25, 'beta_1': 0.9559882574900056, 'beta_2': 0.9999941904657993, 'epsilon': 4.5263939506853596e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0004555160492283762, 'tol': 0.0002984028520672104, 'validation_fraction': 0.45216278871786186}]
function_evaluation time 0.839700 value 0.372278 suggestion {'alpha': 5.471462589677482e-05, 'batch_size': 25, 'beta_1': 0.9559882574900056, 'beta_2': 0.9999941904657993, 'epsilon': 4.5263939506853596e-07, 'hidden_layer_sizes': 96, 'learning_rate_init': 0.0004555160492283762, 'tol': 0.0002984028520672104, 'validation_fraction': 0.45216278871786186}
observation time 0.000001, current best 0.372278 at iter 10
suggestion time taken 0.004131 iter 11 next_points [{'alpha': 8.245794560587596, 'batch_size': 141, 'beta_1': 0.979044831115238, 'beta_2': 0.9922450327512125, 'epsilon': 6.627687887998544e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.07860078252227574, 'tol': 8.226985629698014e-05, 'validation_fraction': 0.7615459163102701}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.176347 value 8.206138 suggestion {'alpha': 8.245794560587596, 'batch_size': 141, 'beta_1': 0.979044831115238, 'beta_2': 0.9922450327512125, 'epsilon': 6.627687887998544e-07, 'hidden_layer_sizes': 129, 'learning_rate_init': 0.07860078252227574, 'tol': 8.226985629698014e-05, 'validation_fraction': 0.7615459163102701}
observation time 0.000001, current best 0.372278 at iter 11
suggestion time taken 0.004126 iter 12 next_points [{'alpha': 0.7479279075722761, 'batch_size': 238, 'beta_1': 0.7882750077424218, 'beta_2': 0.9999762354185725, 'epsilon': 1.3371729586147758e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.047256296272850794, 'tol': 2.6575162007080774e-05, 'validation_fraction': 0.6687141637671757}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.302010 value 3.405478 suggestion {'alpha': 0.7479279075722761, 'batch_size': 238, 'beta_1': 0.7882750077424218, 'beta_2': 0.9999762354185725, 'epsilon': 1.3371729586147758e-07, 'hidden_layer_sizes': 141, 'learning_rate_init': 0.047256296272850794, 'tol': 2.6575162007080774e-05, 'validation_fraction': 0.6687141637671757}
observation time 0.000000, current best 0.372278 at iter 12
suggestion time taken 0.004140 iter 13 next_points [{'alpha': 0.0006021270811826981, 'batch_size': 210, 'beta_1': 0.9589009114908513, 'beta_2': 0.9999984984712786, 'epsilon': 3.2596449806639415e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.03591946124649932, 'tol': 0.00037670309824554797, 'validation_fraction': 0.5912358455824364}]
/home/ryedida/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:603: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped
  warnings.warn(

function_evaluation time 0.219673 value 2.975207 suggestion {'alpha': 0.0006021270811826981, 'batch_size': 210, 'beta_1': 0.9589009114908513, 'beta_2': 0.9999984984712786, 'epsilon': 3.2596449806639415e-09, 'hidden_layer_sizes': 89, 'learning_rate_init': 0.03591946124649932, 'tol': 0.00037670309824554797, 'validation_fraction': 0.5912358455824364}
observation time 0.000001, current best 0.372278 at iter 13
suggestion time taken 0.004131 iter 14 next_points [{'alpha': 3.177820099249005e-05, 'batch_size': 134, 'beta_1': 0.720620591943371, 'beta_2': 0.9999377998605564, 'epsilon': 6.7531231236741975e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 2.756614498728262e-05, 'tol': 0.00014706298923083272, 'validation_fraction': 0.25935276575364596}]
function_evaluation time 0.207509 value 17.747390 suggestion {'alpha': 3.177820099249005e-05, 'batch_size': 134, 'beta_1': 0.720620591943371, 'beta_2': 0.9999377998605564, 'epsilon': 6.7531231236741975e-09, 'hidden_layer_sizes': 159, 'learning_rate_init': 2.756614498728262e-05, 'tol': 0.00014706298923083272, 'validation_fraction': 0.25935276575364596}
observation time 0.000000, current best 0.372278 at iter 14
saving meta data: {'args': {'--uuid': '27aa4bb4d05f50e98fdc20b2cec265a9', '-db-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/output', '--opt-root': '/home/ryedida/smoothness-hpo/bbo_challenge_starter_kit/example_submissions', '--data-root': None, '--db': 'run_20240113_043333', '--opt': 'random', '--data': 'breast', '--classifier': 'MLP-adam', '--metric': 'nll', '--calls': 15, '--suggestions': 1, '--jobs-file': None, '--verbose': False, 'dry_run': False, 'rev': 'a376313', 'opt_rev': '0.0.8'}, 'signature': ([{'alpha': 0.019628224813442792, 'batch_size': 182, 'beta_1': 0.9410202200271762, 'beta_2': 0.9998021557676793, 'epsilon': 1.8662266976518e-08, 'hidden_layer_sizes': 147, 'learning_rate_init': 0.0005627932047415167, 'tol': 0.03690557729213761, 'validation_fraction': 0.8846827852548593}, {'alpha': 0.001998246739232944, 'batch_size': 200, 'beta_1': 0.919111482530466, 'beta_2': 0.9998488260436156, 'epsilon': 5.981221901152555e-07, 'hidden_layer_sizes': 61, 'learning_rate_init': 2.2310905607443014e-05, 'tol': 1.2046852412030316e-05, 'validation_fraction': 0.8117896445826539}, {'alpha': 0.46659545670218433, 'batch_size': 219, 'beta_1': 0.9889789783750891, 'beta_2': 0.9999896868093284, 'epsilon': 2.4234724484675948e-08, 'hidden_layer_sizes': 167, 'learning_rate_init': 2.972334644335654e-05, 'tol': 0.0036281404040243792, 'validation_fraction': 0.17260651658522078}, {'alpha': 4.656005689076002, 'batch_size': 135, 'beta_1': 0.870503881627747, 'beta_2': 0.9948873266941017, 'epsilon': 2.1023308743480125e-07, 'hidden_layer_sizes': 118, 'learning_rate_init': 0.001878173875716191, 'tol': 1.1889379831773006e-05, 'validation_fraction': 0.6264327093752792}, {'alpha': 0.04705159350400542, 'batch_size': 158, 'beta_1': 0.9870884262730957, 'beta_2': 0.9999596874382349, 'epsilon': 1.1981845126013875e-08, 'hidden_layer_sizes': 116, 'learning_rate_init': 0.006173405204074311, 'tol': 1.7414134181586194e-05, 'validation_fraction': 0.6754299026638921}], [8.104566516477803, 14.643876498263253, 12.332285721418042, 5.269783589486869, 3.4904310816393633])}
saving results
saving timing
saving suggest log
done
